{
  "best_global_step": null,
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 9.0,
  "eval_steps": 100,
  "global_step": 4500,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.02,
      "grad_norm": 23.909286499023438,
      "learning_rate": 2.9999999999999997e-05,
      "loss": 4.5924,
      "step": 10
    },
    {
      "epoch": 0.04,
      "grad_norm": 8.383941650390625,
      "learning_rate": 8.999999999999999e-05,
      "loss": 3.6441,
      "step": 20
    },
    {
      "epoch": 0.06,
      "grad_norm": 5.173739433288574,
      "learning_rate": 0.00015,
      "loss": 2.4724,
      "step": 30
    },
    {
      "epoch": 0.08,
      "grad_norm": 3.8590455055236816,
      "learning_rate": 0.00020999999999999998,
      "loss": 1.6465,
      "step": 40
    },
    {
      "epoch": 0.1,
      "grad_norm": 2.9802443981170654,
      "learning_rate": 0.00027,
      "loss": 1.4478,
      "step": 50
    },
    {
      "epoch": 0.12,
      "grad_norm": 2.5917234420776367,
      "learning_rate": 0.00029969696969696965,
      "loss": 1.4944,
      "step": 60
    },
    {
      "epoch": 0.14,
      "grad_norm": 2.3005967140197754,
      "learning_rate": 0.00029909090909090906,
      "loss": 1.4018,
      "step": 70
    },
    {
      "epoch": 0.16,
      "grad_norm": 2.673065185546875,
      "learning_rate": 0.00029848484848484847,
      "loss": 1.3241,
      "step": 80
    },
    {
      "epoch": 0.18,
      "grad_norm": 2.054089069366455,
      "learning_rate": 0.00029787878787878783,
      "loss": 1.2648,
      "step": 90
    },
    {
      "epoch": 0.2,
      "grad_norm": 2.5220489501953125,
      "learning_rate": 0.00029727272727272724,
      "loss": 1.0684,
      "step": 100
    },
    {
      "epoch": 0.2,
      "eval_loss": 1.3558062314987183,
      "eval_runtime": 8.3363,
      "eval_samples_per_second": 23.991,
      "eval_steps_per_second": 23.991,
      "step": 100
    },
    {
      "epoch": 0.22,
      "grad_norm": 2.9462807178497314,
      "learning_rate": 0.00029666666666666665,
      "loss": 1.1027,
      "step": 110
    },
    {
      "epoch": 0.24,
      "grad_norm": 2.761101484298706,
      "learning_rate": 0.00029606060606060606,
      "loss": 1.4014,
      "step": 120
    },
    {
      "epoch": 0.26,
      "grad_norm": 2.3471367359161377,
      "learning_rate": 0.0002954545454545454,
      "loss": 1.1187,
      "step": 130
    },
    {
      "epoch": 0.28,
      "grad_norm": 1.7835782766342163,
      "learning_rate": 0.0002948484848484848,
      "loss": 1.0533,
      "step": 140
    },
    {
      "epoch": 0.3,
      "grad_norm": 2.900111198425293,
      "learning_rate": 0.00029424242424242424,
      "loss": 1.4069,
      "step": 150
    },
    {
      "epoch": 0.32,
      "grad_norm": 3.4514963626861572,
      "learning_rate": 0.0002936363636363636,
      "loss": 1.4525,
      "step": 160
    },
    {
      "epoch": 0.34,
      "grad_norm": 2.302333354949951,
      "learning_rate": 0.000293030303030303,
      "loss": 1.3991,
      "step": 170
    },
    {
      "epoch": 0.36,
      "grad_norm": 2.7613918781280518,
      "learning_rate": 0.00029242424242424236,
      "loss": 1.1578,
      "step": 180
    },
    {
      "epoch": 0.38,
      "grad_norm": 2.580972671508789,
      "learning_rate": 0.0002918181818181818,
      "loss": 1.355,
      "step": 190
    },
    {
      "epoch": 0.4,
      "grad_norm": 2.5419228076934814,
      "learning_rate": 0.0002912121212121212,
      "loss": 1.1255,
      "step": 200
    },
    {
      "epoch": 0.4,
      "eval_loss": 1.2983200550079346,
      "eval_runtime": 8.3526,
      "eval_samples_per_second": 23.945,
      "eval_steps_per_second": 23.945,
      "step": 200
    },
    {
      "epoch": 0.42,
      "grad_norm": 1.6791682243347168,
      "learning_rate": 0.0002906060606060606,
      "loss": 1.3818,
      "step": 210
    },
    {
      "epoch": 0.44,
      "grad_norm": 1.5026180744171143,
      "learning_rate": 0.00029,
      "loss": 1.2104,
      "step": 220
    },
    {
      "epoch": 0.46,
      "grad_norm": 2.3680763244628906,
      "learning_rate": 0.00028939393939393936,
      "loss": 1.2968,
      "step": 230
    },
    {
      "epoch": 0.48,
      "grad_norm": 1.8690800666809082,
      "learning_rate": 0.00028878787878787877,
      "loss": 1.2627,
      "step": 240
    },
    {
      "epoch": 0.5,
      "grad_norm": 2.5991592407226562,
      "learning_rate": 0.0002881818181818181,
      "loss": 1.2375,
      "step": 250
    },
    {
      "epoch": 0.52,
      "grad_norm": 2.671203136444092,
      "learning_rate": 0.00028757575757575753,
      "loss": 1.1145,
      "step": 260
    },
    {
      "epoch": 0.54,
      "grad_norm": 2.091531276702881,
      "learning_rate": 0.00028696969696969695,
      "loss": 1.3943,
      "step": 270
    },
    {
      "epoch": 0.56,
      "grad_norm": 2.7737300395965576,
      "learning_rate": 0.00028636363636363636,
      "loss": 1.22,
      "step": 280
    },
    {
      "epoch": 0.58,
      "grad_norm": 2.1825759410858154,
      "learning_rate": 0.00028575757575757577,
      "loss": 1.2319,
      "step": 290
    },
    {
      "epoch": 0.6,
      "grad_norm": 1.7472985982894897,
      "learning_rate": 0.0002851515151515151,
      "loss": 1.3791,
      "step": 300
    },
    {
      "epoch": 0.6,
      "eval_loss": 1.2815710306167603,
      "eval_runtime": 8.2755,
      "eval_samples_per_second": 24.168,
      "eval_steps_per_second": 24.168,
      "step": 300
    },
    {
      "epoch": 0.62,
      "grad_norm": 2.2792105674743652,
      "learning_rate": 0.00028454545454545453,
      "loss": 1.2043,
      "step": 310
    },
    {
      "epoch": 0.64,
      "grad_norm": 2.4191267490386963,
      "learning_rate": 0.0002839393939393939,
      "loss": 1.0593,
      "step": 320
    },
    {
      "epoch": 0.66,
      "grad_norm": 1.8560482263565063,
      "learning_rate": 0.0002833333333333333,
      "loss": 1.2653,
      "step": 330
    },
    {
      "epoch": 0.68,
      "grad_norm": 2.579815149307251,
      "learning_rate": 0.0002827272727272727,
      "loss": 1.2957,
      "step": 340
    },
    {
      "epoch": 0.7,
      "grad_norm": 1.5495421886444092,
      "learning_rate": 0.00028212121212121207,
      "loss": 1.1372,
      "step": 350
    },
    {
      "epoch": 0.72,
      "grad_norm": 1.9534529447555542,
      "learning_rate": 0.00028151515151515153,
      "loss": 1.108,
      "step": 360
    },
    {
      "epoch": 0.74,
      "grad_norm": 2.991136074066162,
      "learning_rate": 0.0002809090909090909,
      "loss": 1.3708,
      "step": 370
    },
    {
      "epoch": 0.76,
      "grad_norm": 3.0597891807556152,
      "learning_rate": 0.0002803030303030303,
      "loss": 1.3657,
      "step": 380
    },
    {
      "epoch": 0.78,
      "grad_norm": 2.408247947692871,
      "learning_rate": 0.00027969696969696965,
      "loss": 1.4235,
      "step": 390
    },
    {
      "epoch": 0.8,
      "grad_norm": 2.0384650230407715,
      "learning_rate": 0.00027909090909090906,
      "loss": 1.1914,
      "step": 400
    },
    {
      "epoch": 0.8,
      "eval_loss": 1.273164987564087,
      "eval_runtime": 8.4309,
      "eval_samples_per_second": 23.722,
      "eval_steps_per_second": 23.722,
      "step": 400
    },
    {
      "epoch": 0.82,
      "grad_norm": 2.519879102706909,
      "learning_rate": 0.0002784848484848485,
      "loss": 1.1103,
      "step": 410
    },
    {
      "epoch": 0.84,
      "grad_norm": 1.7892732620239258,
      "learning_rate": 0.00027787878787878783,
      "loss": 1.0131,
      "step": 420
    },
    {
      "epoch": 0.86,
      "grad_norm": 2.4048571586608887,
      "learning_rate": 0.00027727272727272724,
      "loss": 1.4203,
      "step": 430
    },
    {
      "epoch": 0.88,
      "grad_norm": 2.3288848400115967,
      "learning_rate": 0.00027666666666666665,
      "loss": 1.2166,
      "step": 440
    },
    {
      "epoch": 0.9,
      "grad_norm": 2.350905179977417,
      "learning_rate": 0.00027606060606060606,
      "loss": 1.2864,
      "step": 450
    },
    {
      "epoch": 0.92,
      "grad_norm": 3.1172759532928467,
      "learning_rate": 0.0002754545454545454,
      "loss": 1.153,
      "step": 460
    },
    {
      "epoch": 0.94,
      "grad_norm": 2.131765127182007,
      "learning_rate": 0.00027484848484848483,
      "loss": 1.2483,
      "step": 470
    },
    {
      "epoch": 0.96,
      "grad_norm": 1.9055124521255493,
      "learning_rate": 0.00027424242424242424,
      "loss": 1.3206,
      "step": 480
    },
    {
      "epoch": 0.98,
      "grad_norm": 1.6144134998321533,
      "learning_rate": 0.0002736363636363636,
      "loss": 1.2451,
      "step": 490
    },
    {
      "epoch": 1.0,
      "grad_norm": 2.650592088699341,
      "learning_rate": 0.000273030303030303,
      "loss": 1.4269,
      "step": 500
    },
    {
      "epoch": 1.0,
      "eval_loss": 1.263787865638733,
      "eval_runtime": 8.402,
      "eval_samples_per_second": 23.804,
      "eval_steps_per_second": 23.804,
      "step": 500
    },
    {
      "epoch": 1.02,
      "grad_norm": 1.330959439277649,
      "learning_rate": 0.0002724242424242424,
      "loss": 1.2026,
      "step": 510
    },
    {
      "epoch": 1.04,
      "grad_norm": 0.9907354116439819,
      "learning_rate": 0.00027181818181818177,
      "loss": 1.0951,
      "step": 520
    },
    {
      "epoch": 1.06,
      "grad_norm": 2.334825277328491,
      "learning_rate": 0.0002712121212121212,
      "loss": 0.8851,
      "step": 530
    },
    {
      "epoch": 1.08,
      "grad_norm": 3.960980176925659,
      "learning_rate": 0.0002706060606060606,
      "loss": 0.9498,
      "step": 540
    },
    {
      "epoch": 1.1,
      "grad_norm": 2.168321132659912,
      "learning_rate": 0.00027,
      "loss": 0.9252,
      "step": 550
    },
    {
      "epoch": 1.12,
      "grad_norm": 2.1398115158081055,
      "learning_rate": 0.00026939393939393936,
      "loss": 1.0457,
      "step": 560
    },
    {
      "epoch": 1.1400000000000001,
      "grad_norm": 2.9573633670806885,
      "learning_rate": 0.00026878787878787877,
      "loss": 0.9917,
      "step": 570
    },
    {
      "epoch": 1.16,
      "grad_norm": 2.3473212718963623,
      "learning_rate": 0.0002681818181818181,
      "loss": 0.964,
      "step": 580
    },
    {
      "epoch": 1.18,
      "grad_norm": 2.6402196884155273,
      "learning_rate": 0.00026757575757575754,
      "loss": 1.1104,
      "step": 590
    },
    {
      "epoch": 1.2,
      "grad_norm": 2.309628486633301,
      "learning_rate": 0.00026696969696969695,
      "loss": 1.0201,
      "step": 600
    },
    {
      "epoch": 1.2,
      "eval_loss": 1.2914401292800903,
      "eval_runtime": 8.4056,
      "eval_samples_per_second": 23.794,
      "eval_steps_per_second": 23.794,
      "step": 600
    },
    {
      "epoch": 1.22,
      "grad_norm": 2.2739174365997314,
      "learning_rate": 0.00026636363636363636,
      "loss": 1.1777,
      "step": 610
    },
    {
      "epoch": 1.24,
      "grad_norm": 2.591114044189453,
      "learning_rate": 0.00026575757575757577,
      "loss": 0.8675,
      "step": 620
    },
    {
      "epoch": 1.26,
      "grad_norm": 2.9945828914642334,
      "learning_rate": 0.0002651515151515151,
      "loss": 1.1785,
      "step": 630
    },
    {
      "epoch": 1.28,
      "grad_norm": 2.794996976852417,
      "learning_rate": 0.00026454545454545453,
      "loss": 0.9196,
      "step": 640
    },
    {
      "epoch": 1.3,
      "grad_norm": 2.4318437576293945,
      "learning_rate": 0.0002639393939393939,
      "loss": 0.8905,
      "step": 650
    },
    {
      "epoch": 1.32,
      "grad_norm": 2.9949660301208496,
      "learning_rate": 0.0002633333333333333,
      "loss": 1.0017,
      "step": 660
    },
    {
      "epoch": 1.34,
      "grad_norm": 2.768009901046753,
      "learning_rate": 0.0002627272727272727,
      "loss": 0.9847,
      "step": 670
    },
    {
      "epoch": 1.3599999999999999,
      "grad_norm": 2.2118325233459473,
      "learning_rate": 0.00026212121212121207,
      "loss": 1.1102,
      "step": 680
    },
    {
      "epoch": 1.38,
      "grad_norm": 2.732910633087158,
      "learning_rate": 0.0002615151515151515,
      "loss": 1.0339,
      "step": 690
    },
    {
      "epoch": 1.4,
      "grad_norm": 2.667846202850342,
      "learning_rate": 0.0002609090909090909,
      "loss": 1.1961,
      "step": 700
    },
    {
      "epoch": 1.4,
      "eval_loss": 1.289394497871399,
      "eval_runtime": 8.359,
      "eval_samples_per_second": 23.926,
      "eval_steps_per_second": 23.926,
      "step": 700
    },
    {
      "epoch": 1.42,
      "grad_norm": 2.1757473945617676,
      "learning_rate": 0.0002603030303030303,
      "loss": 1.0654,
      "step": 710
    },
    {
      "epoch": 1.44,
      "grad_norm": 2.667475938796997,
      "learning_rate": 0.00025969696969696966,
      "loss": 1.041,
      "step": 720
    },
    {
      "epoch": 1.46,
      "grad_norm": 2.3365883827209473,
      "learning_rate": 0.00025909090909090907,
      "loss": 1.0981,
      "step": 730
    },
    {
      "epoch": 1.48,
      "grad_norm": 1.5941457748413086,
      "learning_rate": 0.0002584848484848485,
      "loss": 0.9134,
      "step": 740
    },
    {
      "epoch": 1.5,
      "grad_norm": 2.0003693103790283,
      "learning_rate": 0.00025787878787878783,
      "loss": 0.9804,
      "step": 750
    },
    {
      "epoch": 1.52,
      "grad_norm": 2.941385269165039,
      "learning_rate": 0.00025727272727272724,
      "loss": 0.9144,
      "step": 760
    },
    {
      "epoch": 1.54,
      "grad_norm": 2.5037357807159424,
      "learning_rate": 0.00025666666666666665,
      "loss": 1.0673,
      "step": 770
    },
    {
      "epoch": 1.56,
      "grad_norm": 2.2723336219787598,
      "learning_rate": 0.000256060606060606,
      "loss": 0.8845,
      "step": 780
    },
    {
      "epoch": 1.58,
      "grad_norm": 2.9404473304748535,
      "learning_rate": 0.0002554545454545454,
      "loss": 1.0695,
      "step": 790
    },
    {
      "epoch": 1.6,
      "grad_norm": 2.649592399597168,
      "learning_rate": 0.00025484848484848483,
      "loss": 1.0768,
      "step": 800
    },
    {
      "epoch": 1.6,
      "eval_loss": 1.2906843423843384,
      "eval_runtime": 8.3679,
      "eval_samples_per_second": 23.901,
      "eval_steps_per_second": 23.901,
      "step": 800
    },
    {
      "epoch": 1.62,
      "grad_norm": 2.2471792697906494,
      "learning_rate": 0.00025424242424242424,
      "loss": 1.0567,
      "step": 810
    },
    {
      "epoch": 1.6400000000000001,
      "grad_norm": 2.9974257946014404,
      "learning_rate": 0.0002536363636363636,
      "loss": 1.0816,
      "step": 820
    },
    {
      "epoch": 1.6600000000000001,
      "grad_norm": 3.132855176925659,
      "learning_rate": 0.000253030303030303,
      "loss": 1.1672,
      "step": 830
    },
    {
      "epoch": 1.6800000000000002,
      "grad_norm": 3.8298532962799072,
      "learning_rate": 0.0002524242424242424,
      "loss": 1.2467,
      "step": 840
    },
    {
      "epoch": 1.7,
      "grad_norm": 2.591599225997925,
      "learning_rate": 0.0002518181818181818,
      "loss": 0.9157,
      "step": 850
    },
    {
      "epoch": 1.72,
      "grad_norm": 2.3197836875915527,
      "learning_rate": 0.0002512121212121212,
      "loss": 1.0525,
      "step": 860
    },
    {
      "epoch": 1.74,
      "grad_norm": 3.492522954940796,
      "learning_rate": 0.0002506060606060606,
      "loss": 0.9694,
      "step": 870
    },
    {
      "epoch": 1.76,
      "grad_norm": 2.849717378616333,
      "learning_rate": 0.00025,
      "loss": 1.1471,
      "step": 880
    },
    {
      "epoch": 1.78,
      "grad_norm": 2.414450168609619,
      "learning_rate": 0.00024939393939393936,
      "loss": 1.0032,
      "step": 890
    },
    {
      "epoch": 1.8,
      "grad_norm": 2.675736427307129,
      "learning_rate": 0.00024878787878787877,
      "loss": 0.9391,
      "step": 900
    },
    {
      "epoch": 1.8,
      "eval_loss": 1.2960063219070435,
      "eval_runtime": 8.2928,
      "eval_samples_per_second": 24.117,
      "eval_steps_per_second": 24.117,
      "step": 900
    },
    {
      "epoch": 1.8199999999999998,
      "grad_norm": 2.599820852279663,
      "learning_rate": 0.0002481818181818182,
      "loss": 0.9826,
      "step": 910
    },
    {
      "epoch": 1.8399999999999999,
      "grad_norm": 4.29273796081543,
      "learning_rate": 0.00024757575757575754,
      "loss": 1.1975,
      "step": 920
    },
    {
      "epoch": 1.8599999999999999,
      "grad_norm": 2.788105010986328,
      "learning_rate": 0.00024696969696969695,
      "loss": 0.942,
      "step": 930
    },
    {
      "epoch": 1.88,
      "grad_norm": 2.5083699226379395,
      "learning_rate": 0.0002463636363636363,
      "loss": 1.0398,
      "step": 940
    },
    {
      "epoch": 1.9,
      "grad_norm": 3.000854969024658,
      "learning_rate": 0.0002457575757575757,
      "loss": 0.923,
      "step": 950
    },
    {
      "epoch": 1.92,
      "grad_norm": 2.491736888885498,
      "learning_rate": 0.0002451515151515151,
      "loss": 0.9288,
      "step": 960
    },
    {
      "epoch": 1.94,
      "grad_norm": 3.385535478591919,
      "learning_rate": 0.00024454545454545454,
      "loss": 0.8734,
      "step": 970
    },
    {
      "epoch": 1.96,
      "grad_norm": 2.861555814743042,
      "learning_rate": 0.00024393939393939392,
      "loss": 1.2232,
      "step": 980
    },
    {
      "epoch": 1.98,
      "grad_norm": 3.273343324661255,
      "learning_rate": 0.0002433333333333333,
      "loss": 1.171,
      "step": 990
    },
    {
      "epoch": 2.0,
      "grad_norm": 2.7705917358398438,
      "learning_rate": 0.0002427272727272727,
      "loss": 0.7962,
      "step": 1000
    },
    {
      "epoch": 2.0,
      "eval_loss": 1.289706826210022,
      "eval_runtime": 8.4058,
      "eval_samples_per_second": 23.793,
      "eval_steps_per_second": 23.793,
      "step": 1000
    },
    {
      "epoch": 2.02,
      "grad_norm": 2.7827630043029785,
      "learning_rate": 0.0002421212121212121,
      "loss": 0.6274,
      "step": 1010
    },
    {
      "epoch": 2.04,
      "grad_norm": 3.5088887214660645,
      "learning_rate": 0.00024151515151515148,
      "loss": 0.6664,
      "step": 1020
    },
    {
      "epoch": 2.06,
      "grad_norm": 3.1288676261901855,
      "learning_rate": 0.00024090909090909086,
      "loss": 0.8593,
      "step": 1030
    },
    {
      "epoch": 2.08,
      "grad_norm": 3.9390153884887695,
      "learning_rate": 0.0002403030303030303,
      "loss": 0.6818,
      "step": 1040
    },
    {
      "epoch": 2.1,
      "grad_norm": 3.907855987548828,
      "learning_rate": 0.00023969696969696968,
      "loss": 0.6309,
      "step": 1050
    },
    {
      "epoch": 2.12,
      "grad_norm": 0.5151548981666565,
      "learning_rate": 0.00023909090909090907,
      "loss": 0.9519,
      "step": 1060
    },
    {
      "epoch": 2.14,
      "grad_norm": 2.903230667114258,
      "learning_rate": 0.00023848484848484848,
      "loss": 0.7702,
      "step": 1070
    },
    {
      "epoch": 2.16,
      "grad_norm": 3.140345335006714,
      "learning_rate": 0.00023787878787878786,
      "loss": 0.8317,
      "step": 1080
    },
    {
      "epoch": 2.18,
      "grad_norm": 2.834841251373291,
      "learning_rate": 0.00023727272727272724,
      "loss": 0.7242,
      "step": 1090
    },
    {
      "epoch": 2.2,
      "grad_norm": 2.790362596511841,
      "learning_rate": 0.00023666666666666663,
      "loss": 0.6723,
      "step": 1100
    },
    {
      "epoch": 2.2,
      "eval_loss": 1.3984631299972534,
      "eval_runtime": 8.3848,
      "eval_samples_per_second": 23.853,
      "eval_steps_per_second": 23.853,
      "step": 1100
    },
    {
      "epoch": 2.22,
      "grad_norm": 3.239795207977295,
      "learning_rate": 0.00023606060606060604,
      "loss": 0.7577,
      "step": 1110
    },
    {
      "epoch": 2.24,
      "grad_norm": 4.460026264190674,
      "learning_rate": 0.00023545454545454542,
      "loss": 0.755,
      "step": 1120
    },
    {
      "epoch": 2.26,
      "grad_norm": 2.3151350021362305,
      "learning_rate": 0.00023484848484848483,
      "loss": 0.6542,
      "step": 1130
    },
    {
      "epoch": 2.2800000000000002,
      "grad_norm": 3.0661120414733887,
      "learning_rate": 0.00023424242424242424,
      "loss": 0.8152,
      "step": 1140
    },
    {
      "epoch": 2.3,
      "grad_norm": 3.729109525680542,
      "learning_rate": 0.00023363636363636363,
      "loss": 0.7058,
      "step": 1150
    },
    {
      "epoch": 2.32,
      "grad_norm": 3.0270445346832275,
      "learning_rate": 0.000233030303030303,
      "loss": 0.6729,
      "step": 1160
    },
    {
      "epoch": 2.34,
      "grad_norm": 1.3939067125320435,
      "learning_rate": 0.0002324242424242424,
      "loss": 0.7093,
      "step": 1170
    },
    {
      "epoch": 2.36,
      "grad_norm": 3.4735822677612305,
      "learning_rate": 0.0002318181818181818,
      "loss": 0.7979,
      "step": 1180
    },
    {
      "epoch": 2.38,
      "grad_norm": 3.7465903759002686,
      "learning_rate": 0.00023121212121212119,
      "loss": 0.8241,
      "step": 1190
    },
    {
      "epoch": 2.4,
      "grad_norm": 4.077390193939209,
      "learning_rate": 0.00023060606060606057,
      "loss": 0.7068,
      "step": 1200
    },
    {
      "epoch": 2.4,
      "eval_loss": 1.4270775318145752,
      "eval_runtime": 8.3862,
      "eval_samples_per_second": 23.849,
      "eval_steps_per_second": 23.849,
      "step": 1200
    },
    {
      "epoch": 2.42,
      "grad_norm": 3.2843520641326904,
      "learning_rate": 0.00023,
      "loss": 0.7656,
      "step": 1210
    },
    {
      "epoch": 2.44,
      "grad_norm": 3.114668607711792,
      "learning_rate": 0.0002293939393939394,
      "loss": 0.7618,
      "step": 1220
    },
    {
      "epoch": 2.46,
      "grad_norm": 3.0523760318756104,
      "learning_rate": 0.00022878787878787877,
      "loss": 0.6723,
      "step": 1230
    },
    {
      "epoch": 2.48,
      "grad_norm": 2.305710792541504,
      "learning_rate": 0.00022818181818181816,
      "loss": 0.7608,
      "step": 1240
    },
    {
      "epoch": 2.5,
      "grad_norm": 4.831836223602295,
      "learning_rate": 0.00022757575757575757,
      "loss": 0.7298,
      "step": 1250
    },
    {
      "epoch": 2.52,
      "grad_norm": 3.185865879058838,
      "learning_rate": 0.00022696969696969695,
      "loss": 0.7436,
      "step": 1260
    },
    {
      "epoch": 2.54,
      "grad_norm": 2.7440900802612305,
      "learning_rate": 0.00022636363636363633,
      "loss": 0.829,
      "step": 1270
    },
    {
      "epoch": 2.56,
      "grad_norm": 2.3245022296905518,
      "learning_rate": 0.00022575757575757572,
      "loss": 0.7461,
      "step": 1280
    },
    {
      "epoch": 2.58,
      "grad_norm": 7.108658313751221,
      "learning_rate": 0.00022515151515151513,
      "loss": 0.8792,
      "step": 1290
    },
    {
      "epoch": 2.6,
      "grad_norm": 5.0040483474731445,
      "learning_rate": 0.00022454545454545454,
      "loss": 0.8364,
      "step": 1300
    },
    {
      "epoch": 2.6,
      "eval_loss": 1.3970293998718262,
      "eval_runtime": 8.3768,
      "eval_samples_per_second": 23.875,
      "eval_steps_per_second": 23.875,
      "step": 1300
    },
    {
      "epoch": 2.62,
      "grad_norm": 6.745498180389404,
      "learning_rate": 0.00022393939393939392,
      "loss": 0.7252,
      "step": 1310
    },
    {
      "epoch": 2.64,
      "grad_norm": 3.384861946105957,
      "learning_rate": 0.00022333333333333333,
      "loss": 0.8305,
      "step": 1320
    },
    {
      "epoch": 2.66,
      "grad_norm": 2.7862226963043213,
      "learning_rate": 0.00022272727272727272,
      "loss": 0.8549,
      "step": 1330
    },
    {
      "epoch": 2.68,
      "grad_norm": 3.7203369140625,
      "learning_rate": 0.0002221212121212121,
      "loss": 0.7735,
      "step": 1340
    },
    {
      "epoch": 2.7,
      "grad_norm": 3.2680323123931885,
      "learning_rate": 0.00022151515151515148,
      "loss": 0.645,
      "step": 1350
    },
    {
      "epoch": 2.7199999999999998,
      "grad_norm": 3.375364065170288,
      "learning_rate": 0.0002209090909090909,
      "loss": 0.7349,
      "step": 1360
    },
    {
      "epoch": 2.74,
      "grad_norm": 2.8992996215820312,
      "learning_rate": 0.00022030303030303028,
      "loss": 0.7426,
      "step": 1370
    },
    {
      "epoch": 2.76,
      "grad_norm": 4.770599842071533,
      "learning_rate": 0.00021969696969696969,
      "loss": 0.7442,
      "step": 1380
    },
    {
      "epoch": 2.7800000000000002,
      "grad_norm": 4.193373680114746,
      "learning_rate": 0.0002190909090909091,
      "loss": 0.6938,
      "step": 1390
    },
    {
      "epoch": 2.8,
      "grad_norm": 4.437289237976074,
      "learning_rate": 0.00021848484848484848,
      "loss": 0.7138,
      "step": 1400
    },
    {
      "epoch": 2.8,
      "eval_loss": 1.4032223224639893,
      "eval_runtime": 8.3224,
      "eval_samples_per_second": 24.032,
      "eval_steps_per_second": 24.032,
      "step": 1400
    },
    {
      "epoch": 2.82,
      "grad_norm": 3.9197840690612793,
      "learning_rate": 0.00021787878787878786,
      "loss": 0.7931,
      "step": 1410
    },
    {
      "epoch": 2.84,
      "grad_norm": 2.2155821323394775,
      "learning_rate": 0.00021727272727272725,
      "loss": 0.7896,
      "step": 1420
    },
    {
      "epoch": 2.86,
      "grad_norm": 3.3222532272338867,
      "learning_rate": 0.00021666666666666666,
      "loss": 0.752,
      "step": 1430
    },
    {
      "epoch": 2.88,
      "grad_norm": 3.1991543769836426,
      "learning_rate": 0.00021606060606060604,
      "loss": 0.6356,
      "step": 1440
    },
    {
      "epoch": 2.9,
      "grad_norm": 2.6639597415924072,
      "learning_rate": 0.00021545454545454542,
      "loss": 0.7736,
      "step": 1450
    },
    {
      "epoch": 2.92,
      "grad_norm": 2.4192757606506348,
      "learning_rate": 0.0002148484848484848,
      "loss": 0.7194,
      "step": 1460
    },
    {
      "epoch": 2.94,
      "grad_norm": 2.62149715423584,
      "learning_rate": 0.00021424242424242424,
      "loss": 0.7483,
      "step": 1470
    },
    {
      "epoch": 2.96,
      "grad_norm": 2.5852439403533936,
      "learning_rate": 0.00021363636363636363,
      "loss": 0.7603,
      "step": 1480
    },
    {
      "epoch": 2.98,
      "grad_norm": 4.117901802062988,
      "learning_rate": 0.000213030303030303,
      "loss": 0.8774,
      "step": 1490
    },
    {
      "epoch": 3.0,
      "grad_norm": 2.1225178241729736,
      "learning_rate": 0.00021242424242424242,
      "loss": 0.7211,
      "step": 1500
    },
    {
      "epoch": 3.0,
      "eval_loss": 1.367620825767517,
      "eval_runtime": 8.3228,
      "eval_samples_per_second": 24.03,
      "eval_steps_per_second": 24.03,
      "step": 1500
    },
    {
      "epoch": 3.02,
      "grad_norm": 2.7058401107788086,
      "learning_rate": 0.0002118181818181818,
      "loss": 0.5397,
      "step": 1510
    },
    {
      "epoch": 3.04,
      "grad_norm": 6.328164100646973,
      "learning_rate": 0.0002112121212121212,
      "loss": 0.6047,
      "step": 1520
    },
    {
      "epoch": 3.06,
      "grad_norm": 0.7525256872177124,
      "learning_rate": 0.00021060606060606057,
      "loss": 0.4353,
      "step": 1530
    },
    {
      "epoch": 3.08,
      "grad_norm": 2.671274185180664,
      "learning_rate": 0.00020999999999999998,
      "loss": 0.5671,
      "step": 1540
    },
    {
      "epoch": 3.1,
      "grad_norm": 4.022649765014648,
      "learning_rate": 0.0002093939393939394,
      "loss": 0.3988,
      "step": 1550
    },
    {
      "epoch": 3.12,
      "grad_norm": 1.4923932552337646,
      "learning_rate": 0.00020878787878787878,
      "loss": 0.4116,
      "step": 1560
    },
    {
      "epoch": 3.14,
      "grad_norm": 4.004339694976807,
      "learning_rate": 0.00020818181818181816,
      "loss": 0.3917,
      "step": 1570
    },
    {
      "epoch": 3.16,
      "grad_norm": 2.768418312072754,
      "learning_rate": 0.00020757575757575757,
      "loss": 0.4649,
      "step": 1580
    },
    {
      "epoch": 3.18,
      "grad_norm": 3.7489609718322754,
      "learning_rate": 0.00020696969696969695,
      "loss": 0.5254,
      "step": 1590
    },
    {
      "epoch": 3.2,
      "grad_norm": 3.3115828037261963,
      "learning_rate": 0.00020636363636363634,
      "loss": 0.6539,
      "step": 1600
    },
    {
      "epoch": 3.2,
      "eval_loss": 1.5733208656311035,
      "eval_runtime": 8.3046,
      "eval_samples_per_second": 24.083,
      "eval_steps_per_second": 24.083,
      "step": 1600
    },
    {
      "epoch": 3.22,
      "grad_norm": 6.064995765686035,
      "learning_rate": 0.00020575757575757572,
      "loss": 0.4524,
      "step": 1610
    },
    {
      "epoch": 3.24,
      "grad_norm": 3.2926976680755615,
      "learning_rate": 0.00020515151515151513,
      "loss": 0.519,
      "step": 1620
    },
    {
      "epoch": 3.26,
      "grad_norm": 4.845382213592529,
      "learning_rate": 0.0002045454545454545,
      "loss": 0.4523,
      "step": 1630
    },
    {
      "epoch": 3.2800000000000002,
      "grad_norm": 4.108020782470703,
      "learning_rate": 0.00020393939393939392,
      "loss": 0.5804,
      "step": 1640
    },
    {
      "epoch": 3.3,
      "grad_norm": 4.65017032623291,
      "learning_rate": 0.00020333333333333333,
      "loss": 0.6401,
      "step": 1650
    },
    {
      "epoch": 3.32,
      "grad_norm": 6.378913879394531,
      "learning_rate": 0.00020272727272727272,
      "loss": 0.5752,
      "step": 1660
    },
    {
      "epoch": 3.34,
      "grad_norm": 3.9602386951446533,
      "learning_rate": 0.0002021212121212121,
      "loss": 0.4882,
      "step": 1670
    },
    {
      "epoch": 3.36,
      "grad_norm": 4.7650885581970215,
      "learning_rate": 0.00020151515151515148,
      "loss": 0.5091,
      "step": 1680
    },
    {
      "epoch": 3.38,
      "grad_norm": 6.049823760986328,
      "learning_rate": 0.0002009090909090909,
      "loss": 0.5201,
      "step": 1690
    },
    {
      "epoch": 3.4,
      "grad_norm": 1.8656972646713257,
      "learning_rate": 0.00020030303030303028,
      "loss": 0.4444,
      "step": 1700
    },
    {
      "epoch": 3.4,
      "eval_loss": 1.5854392051696777,
      "eval_runtime": 8.3703,
      "eval_samples_per_second": 23.894,
      "eval_steps_per_second": 23.894,
      "step": 1700
    },
    {
      "epoch": 3.42,
      "grad_norm": 0.39766040444374084,
      "learning_rate": 0.00019969696969696966,
      "loss": 0.4837,
      "step": 1710
    },
    {
      "epoch": 3.44,
      "grad_norm": 4.282209873199463,
      "learning_rate": 0.0001990909090909091,
      "loss": 0.6104,
      "step": 1720
    },
    {
      "epoch": 3.46,
      "grad_norm": 2.63321852684021,
      "learning_rate": 0.00019848484848484848,
      "loss": 0.4672,
      "step": 1730
    },
    {
      "epoch": 3.48,
      "grad_norm": 3.429921865463257,
      "learning_rate": 0.00019787878787878786,
      "loss": 0.4621,
      "step": 1740
    },
    {
      "epoch": 3.5,
      "grad_norm": 4.5519514083862305,
      "learning_rate": 0.00019727272727272725,
      "loss": 0.5589,
      "step": 1750
    },
    {
      "epoch": 3.52,
      "grad_norm": 3.309013605117798,
      "learning_rate": 0.00019666666666666666,
      "loss": 0.583,
      "step": 1760
    },
    {
      "epoch": 3.54,
      "grad_norm": 3.7831742763519287,
      "learning_rate": 0.00019606060606060604,
      "loss": 0.4685,
      "step": 1770
    },
    {
      "epoch": 3.56,
      "grad_norm": 3.7378039360046387,
      "learning_rate": 0.00019545454545454543,
      "loss": 0.4343,
      "step": 1780
    },
    {
      "epoch": 3.58,
      "grad_norm": 4.9018096923828125,
      "learning_rate": 0.0001948484848484848,
      "loss": 0.5539,
      "step": 1790
    },
    {
      "epoch": 3.6,
      "grad_norm": 3.926302671432495,
      "learning_rate": 0.00019424242424242422,
      "loss": 0.4069,
      "step": 1800
    },
    {
      "epoch": 3.6,
      "eval_loss": 1.594805121421814,
      "eval_runtime": 8.3609,
      "eval_samples_per_second": 23.921,
      "eval_steps_per_second": 23.921,
      "step": 1800
    },
    {
      "epoch": 3.62,
      "grad_norm": 6.622114658355713,
      "learning_rate": 0.00019363636363636363,
      "loss": 0.5394,
      "step": 1810
    },
    {
      "epoch": 3.64,
      "grad_norm": 2.2355141639709473,
      "learning_rate": 0.000193030303030303,
      "loss": 0.4986,
      "step": 1820
    },
    {
      "epoch": 3.66,
      "grad_norm": 3.092597246170044,
      "learning_rate": 0.00019242424242424242,
      "loss": 0.3924,
      "step": 1830
    },
    {
      "epoch": 3.68,
      "grad_norm": 0.3274734318256378,
      "learning_rate": 0.0001918181818181818,
      "loss": 0.5083,
      "step": 1840
    },
    {
      "epoch": 3.7,
      "grad_norm": 2.4023547172546387,
      "learning_rate": 0.0001912121212121212,
      "loss": 0.4693,
      "step": 1850
    },
    {
      "epoch": 3.7199999999999998,
      "grad_norm": 5.217644214630127,
      "learning_rate": 0.00019060606060606057,
      "loss": 0.653,
      "step": 1860
    },
    {
      "epoch": 3.74,
      "grad_norm": 5.6403117179870605,
      "learning_rate": 0.00018999999999999998,
      "loss": 0.6469,
      "step": 1870
    },
    {
      "epoch": 3.76,
      "grad_norm": 3.7321016788482666,
      "learning_rate": 0.00018939393939393937,
      "loss": 0.4803,
      "step": 1880
    },
    {
      "epoch": 3.7800000000000002,
      "grad_norm": 3.4689347743988037,
      "learning_rate": 0.00018878787878787878,
      "loss": 0.643,
      "step": 1890
    },
    {
      "epoch": 3.8,
      "grad_norm": 5.958554744720459,
      "learning_rate": 0.0001881818181818182,
      "loss": 0.5346,
      "step": 1900
    },
    {
      "epoch": 3.8,
      "eval_loss": 1.5369235277175903,
      "eval_runtime": 8.369,
      "eval_samples_per_second": 23.898,
      "eval_steps_per_second": 23.898,
      "step": 1900
    },
    {
      "epoch": 3.82,
      "grad_norm": 4.527348041534424,
      "learning_rate": 0.00018757575757575757,
      "loss": 0.3781,
      "step": 1910
    },
    {
      "epoch": 3.84,
      "grad_norm": 7.633658409118652,
      "learning_rate": 0.00018696969696969695,
      "loss": 0.5459,
      "step": 1920
    },
    {
      "epoch": 3.86,
      "grad_norm": 2.2889175415039062,
      "learning_rate": 0.00018636363636363634,
      "loss": 0.5451,
      "step": 1930
    },
    {
      "epoch": 3.88,
      "grad_norm": 4.209867477416992,
      "learning_rate": 0.00018575757575757575,
      "loss": 0.4804,
      "step": 1940
    },
    {
      "epoch": 3.9,
      "grad_norm": 3.609666109085083,
      "learning_rate": 0.00018515151515151513,
      "loss": 0.6264,
      "step": 1950
    },
    {
      "epoch": 3.92,
      "grad_norm": 4.907188892364502,
      "learning_rate": 0.00018454545454545451,
      "loss": 0.6333,
      "step": 1960
    },
    {
      "epoch": 3.94,
      "grad_norm": 3.2695493698120117,
      "learning_rate": 0.0001839393939393939,
      "loss": 0.5391,
      "step": 1970
    },
    {
      "epoch": 3.96,
      "grad_norm": 4.7140655517578125,
      "learning_rate": 0.00018333333333333334,
      "loss": 0.6703,
      "step": 1980
    },
    {
      "epoch": 3.98,
      "grad_norm": 3.3951399326324463,
      "learning_rate": 0.00018272727272727272,
      "loss": 0.4151,
      "step": 1990
    },
    {
      "epoch": 4.0,
      "grad_norm": 3.133073568344116,
      "learning_rate": 0.0001821212121212121,
      "loss": 0.4724,
      "step": 2000
    },
    {
      "epoch": 4.0,
      "eval_loss": 1.5727020502090454,
      "eval_runtime": 8.3711,
      "eval_samples_per_second": 23.892,
      "eval_steps_per_second": 23.892,
      "step": 2000
    },
    {
      "epoch": 4.02,
      "grad_norm": 6.486469745635986,
      "learning_rate": 0.0001815151515151515,
      "loss": 0.3727,
      "step": 2010
    },
    {
      "epoch": 4.04,
      "grad_norm": 4.442637920379639,
      "learning_rate": 0.0001809090909090909,
      "loss": 0.2859,
      "step": 2020
    },
    {
      "epoch": 4.06,
      "grad_norm": 5.246009349822998,
      "learning_rate": 0.00018030303030303028,
      "loss": 0.3611,
      "step": 2030
    },
    {
      "epoch": 4.08,
      "grad_norm": 4.8252854347229,
      "learning_rate": 0.00017969696969696966,
      "loss": 0.3787,
      "step": 2040
    },
    {
      "epoch": 4.1,
      "grad_norm": 5.427910804748535,
      "learning_rate": 0.00017909090909090907,
      "loss": 0.3059,
      "step": 2050
    },
    {
      "epoch": 4.12,
      "grad_norm": 1.696539282798767,
      "learning_rate": 0.00017848484848484846,
      "loss": 0.2634,
      "step": 2060
    },
    {
      "epoch": 4.14,
      "grad_norm": 4.055063247680664,
      "learning_rate": 0.00017787878787878787,
      "loss": 0.249,
      "step": 2070
    },
    {
      "epoch": 4.16,
      "grad_norm": 2.8494210243225098,
      "learning_rate": 0.00017727272727272728,
      "loss": 0.2546,
      "step": 2080
    },
    {
      "epoch": 4.18,
      "grad_norm": 4.913599491119385,
      "learning_rate": 0.00017666666666666666,
      "loss": 0.3812,
      "step": 2090
    },
    {
      "epoch": 4.2,
      "grad_norm": 2.1751654148101807,
      "learning_rate": 0.00017606060606060604,
      "loss": 0.2575,
      "step": 2100
    },
    {
      "epoch": 4.2,
      "eval_loss": 1.717313289642334,
      "eval_runtime": 8.3344,
      "eval_samples_per_second": 23.997,
      "eval_steps_per_second": 23.997,
      "step": 2100
    },
    {
      "epoch": 4.22,
      "grad_norm": 2.0720863342285156,
      "learning_rate": 0.00017545454545454543,
      "loss": 0.246,
      "step": 2110
    },
    {
      "epoch": 4.24,
      "grad_norm": 2.040238857269287,
      "learning_rate": 0.00017484848484848484,
      "loss": 0.2791,
      "step": 2120
    },
    {
      "epoch": 4.26,
      "grad_norm": 3.7585432529449463,
      "learning_rate": 0.00017424242424242422,
      "loss": 0.2292,
      "step": 2130
    },
    {
      "epoch": 4.28,
      "grad_norm": 3.9438865184783936,
      "learning_rate": 0.0001736363636363636,
      "loss": 0.3274,
      "step": 2140
    },
    {
      "epoch": 4.3,
      "grad_norm": 4.557584285736084,
      "learning_rate": 0.00017303030303030304,
      "loss": 0.3518,
      "step": 2150
    },
    {
      "epoch": 4.32,
      "grad_norm": 0.7574896812438965,
      "learning_rate": 0.00017242424242424242,
      "loss": 0.4,
      "step": 2160
    },
    {
      "epoch": 4.34,
      "grad_norm": 4.632214069366455,
      "learning_rate": 0.0001718181818181818,
      "loss": 0.3066,
      "step": 2170
    },
    {
      "epoch": 4.36,
      "grad_norm": 2.287168025970459,
      "learning_rate": 0.0001712121212121212,
      "loss": 0.3878,
      "step": 2180
    },
    {
      "epoch": 4.38,
      "grad_norm": 2.6103944778442383,
      "learning_rate": 0.0001706060606060606,
      "loss": 0.3322,
      "step": 2190
    },
    {
      "epoch": 4.4,
      "grad_norm": 4.311276912689209,
      "learning_rate": 0.00016999999999999999,
      "loss": 0.3783,
      "step": 2200
    },
    {
      "epoch": 4.4,
      "eval_loss": 1.690219759941101,
      "eval_runtime": 8.3227,
      "eval_samples_per_second": 24.031,
      "eval_steps_per_second": 24.031,
      "step": 2200
    },
    {
      "epoch": 4.42,
      "grad_norm": 7.500244140625,
      "learning_rate": 0.00016939393939393937,
      "loss": 0.3986,
      "step": 2210
    },
    {
      "epoch": 4.44,
      "grad_norm": 3.8118815422058105,
      "learning_rate": 0.00016878787878787875,
      "loss": 0.3802,
      "step": 2220
    },
    {
      "epoch": 4.46,
      "grad_norm": 3.389646291732788,
      "learning_rate": 0.00016818181818181816,
      "loss": 0.2723,
      "step": 2230
    },
    {
      "epoch": 4.48,
      "grad_norm": 3.815098762512207,
      "learning_rate": 0.00016757575757575757,
      "loss": 0.3384,
      "step": 2240
    },
    {
      "epoch": 4.5,
      "grad_norm": 2.6205556392669678,
      "learning_rate": 0.00016696969696969696,
      "loss": 0.3661,
      "step": 2250
    },
    {
      "epoch": 4.52,
      "grad_norm": 4.815027713775635,
      "learning_rate": 0.00016636363636363637,
      "loss": 0.2784,
      "step": 2260
    },
    {
      "epoch": 4.54,
      "grad_norm": 2.972849130630493,
      "learning_rate": 0.00016575757575757575,
      "loss": 0.3597,
      "step": 2270
    },
    {
      "epoch": 4.5600000000000005,
      "grad_norm": 4.271518707275391,
      "learning_rate": 0.00016515151515151513,
      "loss": 0.6522,
      "step": 2280
    },
    {
      "epoch": 4.58,
      "grad_norm": 1.1525681018829346,
      "learning_rate": 0.00016454545454545452,
      "loss": 0.3276,
      "step": 2290
    },
    {
      "epoch": 4.6,
      "grad_norm": 4.200610160827637,
      "learning_rate": 0.00016393939393939393,
      "loss": 0.3445,
      "step": 2300
    },
    {
      "epoch": 4.6,
      "eval_loss": 1.7199013233184814,
      "eval_runtime": 8.3045,
      "eval_samples_per_second": 24.083,
      "eval_steps_per_second": 24.083,
      "step": 2300
    },
    {
      "epoch": 4.62,
      "grad_norm": 4.056607246398926,
      "learning_rate": 0.0001633333333333333,
      "loss": 0.289,
      "step": 2310
    },
    {
      "epoch": 4.64,
      "grad_norm": 3.6462414264678955,
      "learning_rate": 0.00016272727272727272,
      "loss": 0.4649,
      "step": 2320
    },
    {
      "epoch": 4.66,
      "grad_norm": 6.196969032287598,
      "learning_rate": 0.00016212121212121213,
      "loss": 0.3854,
      "step": 2330
    },
    {
      "epoch": 4.68,
      "grad_norm": 4.781714916229248,
      "learning_rate": 0.00016151515151515151,
      "loss": 0.3243,
      "step": 2340
    },
    {
      "epoch": 4.7,
      "grad_norm": 4.081362247467041,
      "learning_rate": 0.0001609090909090909,
      "loss": 0.407,
      "step": 2350
    },
    {
      "epoch": 4.72,
      "grad_norm": 4.352219104766846,
      "learning_rate": 0.00016030303030303028,
      "loss": 0.3886,
      "step": 2360
    },
    {
      "epoch": 4.74,
      "grad_norm": 2.7382421493530273,
      "learning_rate": 0.0001596969696969697,
      "loss": 0.521,
      "step": 2370
    },
    {
      "epoch": 4.76,
      "grad_norm": 1.5209137201309204,
      "learning_rate": 0.00015909090909090907,
      "loss": 0.373,
      "step": 2380
    },
    {
      "epoch": 4.78,
      "grad_norm": 4.131263732910156,
      "learning_rate": 0.00015848484848484846,
      "loss": 0.3867,
      "step": 2390
    },
    {
      "epoch": 4.8,
      "grad_norm": 4.747944355010986,
      "learning_rate": 0.00015787878787878784,
      "loss": 0.4897,
      "step": 2400
    },
    {
      "epoch": 4.8,
      "eval_loss": 1.6928515434265137,
      "eval_runtime": 8.3126,
      "eval_samples_per_second": 24.06,
      "eval_steps_per_second": 24.06,
      "step": 2400
    },
    {
      "epoch": 4.82,
      "grad_norm": 3.258763074874878,
      "learning_rate": 0.00015727272727272728,
      "loss": 0.3771,
      "step": 2410
    },
    {
      "epoch": 4.84,
      "grad_norm": 5.821494102478027,
      "learning_rate": 0.00015666666666666666,
      "loss": 0.4447,
      "step": 2420
    },
    {
      "epoch": 4.86,
      "grad_norm": 4.528757095336914,
      "learning_rate": 0.00015606060606060605,
      "loss": 0.38,
      "step": 2430
    },
    {
      "epoch": 4.88,
      "grad_norm": 2.8911149501800537,
      "learning_rate": 0.00015545454545454546,
      "loss": 0.3425,
      "step": 2440
    },
    {
      "epoch": 4.9,
      "grad_norm": 3.254544496536255,
      "learning_rate": 0.00015484848484848484,
      "loss": 0.3285,
      "step": 2450
    },
    {
      "epoch": 4.92,
      "grad_norm": 4.204137325286865,
      "learning_rate": 0.00015424242424242422,
      "loss": 0.3775,
      "step": 2460
    },
    {
      "epoch": 4.9399999999999995,
      "grad_norm": 0.7518861293792725,
      "learning_rate": 0.0001536363636363636,
      "loss": 0.3514,
      "step": 2470
    },
    {
      "epoch": 4.96,
      "grad_norm": 3.5973527431488037,
      "learning_rate": 0.00015303030303030302,
      "loss": 0.3252,
      "step": 2480
    },
    {
      "epoch": 4.98,
      "grad_norm": 2.8385348320007324,
      "learning_rate": 0.00015242424242424243,
      "loss": 0.3837,
      "step": 2490
    },
    {
      "epoch": 5.0,
      "grad_norm": 8.143863677978516,
      "learning_rate": 0.0001518181818181818,
      "loss": 0.3843,
      "step": 2500
    },
    {
      "epoch": 5.0,
      "eval_loss": 1.7006853818893433,
      "eval_runtime": 8.316,
      "eval_samples_per_second": 24.05,
      "eval_steps_per_second": 24.05,
      "step": 2500
    },
    {
      "epoch": 5.02,
      "grad_norm": 6.130868911743164,
      "learning_rate": 0.00015121212121212122,
      "loss": 0.2596,
      "step": 2510
    },
    {
      "epoch": 5.04,
      "grad_norm": 2.65401291847229,
      "learning_rate": 0.0001506060606060606,
      "loss": 0.218,
      "step": 2520
    },
    {
      "epoch": 5.06,
      "grad_norm": 1.3866691589355469,
      "learning_rate": 0.00015,
      "loss": 0.2262,
      "step": 2530
    },
    {
      "epoch": 5.08,
      "grad_norm": 1.3278380632400513,
      "learning_rate": 0.00014939393939393937,
      "loss": 0.2165,
      "step": 2540
    },
    {
      "epoch": 5.1,
      "grad_norm": 6.101880073547363,
      "learning_rate": 0.00014878787878787875,
      "loss": 0.2964,
      "step": 2550
    },
    {
      "epoch": 5.12,
      "grad_norm": 1.0815578699111938,
      "learning_rate": 0.00014818181818181816,
      "loss": 0.2251,
      "step": 2560
    },
    {
      "epoch": 5.14,
      "grad_norm": 1.7232277393341064,
      "learning_rate": 0.00014757575757575757,
      "loss": 0.2573,
      "step": 2570
    },
    {
      "epoch": 5.16,
      "grad_norm": 1.7962565422058105,
      "learning_rate": 0.00014696969696969696,
      "loss": 0.3203,
      "step": 2580
    },
    {
      "epoch": 5.18,
      "grad_norm": 1.8994218111038208,
      "learning_rate": 0.00014636363636363634,
      "loss": 0.3451,
      "step": 2590
    },
    {
      "epoch": 5.2,
      "grad_norm": 3.9611029624938965,
      "learning_rate": 0.00014575757575757575,
      "loss": 0.2081,
      "step": 2600
    },
    {
      "epoch": 5.2,
      "eval_loss": 1.873401165008545,
      "eval_runtime": 8.3169,
      "eval_samples_per_second": 24.047,
      "eval_steps_per_second": 24.047,
      "step": 2600
    },
    {
      "epoch": 5.22,
      "grad_norm": 2.829465389251709,
      "learning_rate": 0.00014515151515151513,
      "loss": 0.2101,
      "step": 2610
    },
    {
      "epoch": 5.24,
      "grad_norm": 0.5540342330932617,
      "learning_rate": 0.00014454545454545452,
      "loss": 0.2215,
      "step": 2620
    },
    {
      "epoch": 5.26,
      "grad_norm": 3.7947142124176025,
      "learning_rate": 0.00014393939393939393,
      "loss": 0.2459,
      "step": 2630
    },
    {
      "epoch": 5.28,
      "grad_norm": 3.0109708309173584,
      "learning_rate": 0.00014333333333333334,
      "loss": 0.2119,
      "step": 2640
    },
    {
      "epoch": 5.3,
      "grad_norm": 6.814730167388916,
      "learning_rate": 0.00014272727272727272,
      "loss": 0.2176,
      "step": 2650
    },
    {
      "epoch": 5.32,
      "grad_norm": 4.342071056365967,
      "learning_rate": 0.0001421212121212121,
      "loss": 0.2516,
      "step": 2660
    },
    {
      "epoch": 5.34,
      "grad_norm": 13.253990173339844,
      "learning_rate": 0.0001415151515151515,
      "loss": 0.2964,
      "step": 2670
    },
    {
      "epoch": 5.36,
      "grad_norm": 3.6149182319641113,
      "learning_rate": 0.0001409090909090909,
      "loss": 0.2543,
      "step": 2680
    },
    {
      "epoch": 5.38,
      "grad_norm": 4.214117050170898,
      "learning_rate": 0.00014030303030303028,
      "loss": 0.2671,
      "step": 2690
    },
    {
      "epoch": 5.4,
      "grad_norm": 11.714090347290039,
      "learning_rate": 0.0001396969696969697,
      "loss": 0.1686,
      "step": 2700
    },
    {
      "epoch": 5.4,
      "eval_loss": 1.9066811800003052,
      "eval_runtime": 8.3875,
      "eval_samples_per_second": 23.845,
      "eval_steps_per_second": 23.845,
      "step": 2700
    },
    {
      "epoch": 5.42,
      "grad_norm": 2.248265027999878,
      "learning_rate": 0.00013909090909090908,
      "loss": 0.2088,
      "step": 2710
    },
    {
      "epoch": 5.44,
      "grad_norm": 2.0356125831604004,
      "learning_rate": 0.00013848484848484846,
      "loss": 0.2527,
      "step": 2720
    },
    {
      "epoch": 5.46,
      "grad_norm": 0.9487919807434082,
      "learning_rate": 0.00013787878787878787,
      "loss": 0.2557,
      "step": 2730
    },
    {
      "epoch": 5.48,
      "grad_norm": 4.4829559326171875,
      "learning_rate": 0.00013727272727272725,
      "loss": 0.2365,
      "step": 2740
    },
    {
      "epoch": 5.5,
      "grad_norm": 2.719364881515503,
      "learning_rate": 0.00013666666666666666,
      "loss": 0.2562,
      "step": 2750
    },
    {
      "epoch": 5.52,
      "grad_norm": 5.800804138183594,
      "learning_rate": 0.00013606060606060605,
      "loss": 0.2232,
      "step": 2760
    },
    {
      "epoch": 5.54,
      "grad_norm": 3.3319180011749268,
      "learning_rate": 0.00013545454545454546,
      "loss": 0.218,
      "step": 2770
    },
    {
      "epoch": 5.5600000000000005,
      "grad_norm": 2.7757294178009033,
      "learning_rate": 0.00013484848484848484,
      "loss": 0.2028,
      "step": 2780
    },
    {
      "epoch": 5.58,
      "grad_norm": 7.759043216705322,
      "learning_rate": 0.00013424242424242422,
      "loss": 0.2523,
      "step": 2790
    },
    {
      "epoch": 5.6,
      "grad_norm": 5.443719387054443,
      "learning_rate": 0.0001336363636363636,
      "loss": 0.3458,
      "step": 2800
    },
    {
      "epoch": 5.6,
      "eval_loss": 1.8361700773239136,
      "eval_runtime": 8.36,
      "eval_samples_per_second": 23.923,
      "eval_steps_per_second": 23.923,
      "step": 2800
    },
    {
      "epoch": 5.62,
      "grad_norm": 5.345704078674316,
      "learning_rate": 0.00013303030303030302,
      "loss": 0.2754,
      "step": 2810
    },
    {
      "epoch": 5.64,
      "grad_norm": 4.2322998046875,
      "learning_rate": 0.00013242424242424243,
      "loss": 0.2763,
      "step": 2820
    },
    {
      "epoch": 5.66,
      "grad_norm": 3.777042865753174,
      "learning_rate": 0.0001318181818181818,
      "loss": 0.2556,
      "step": 2830
    },
    {
      "epoch": 5.68,
      "grad_norm": 4.376269340515137,
      "learning_rate": 0.0001312121212121212,
      "loss": 0.2371,
      "step": 2840
    },
    {
      "epoch": 5.7,
      "grad_norm": 5.2267632484436035,
      "learning_rate": 0.00013060606060606058,
      "loss": 0.2595,
      "step": 2850
    },
    {
      "epoch": 5.72,
      "grad_norm": 2.427097797393799,
      "learning_rate": 0.00013,
      "loss": 0.2015,
      "step": 2860
    },
    {
      "epoch": 5.74,
      "grad_norm": 3.1499476432800293,
      "learning_rate": 0.00012939393939393937,
      "loss": 0.2181,
      "step": 2870
    },
    {
      "epoch": 5.76,
      "grad_norm": 0.8447995781898499,
      "learning_rate": 0.00012878787878787878,
      "loss": 0.2777,
      "step": 2880
    },
    {
      "epoch": 5.78,
      "grad_norm": 2.240246295928955,
      "learning_rate": 0.00012818181818181817,
      "loss": 0.1895,
      "step": 2890
    },
    {
      "epoch": 5.8,
      "grad_norm": 1.9640319347381592,
      "learning_rate": 0.00012757575757575758,
      "loss": 0.2319,
      "step": 2900
    },
    {
      "epoch": 5.8,
      "eval_loss": 1.8936047554016113,
      "eval_runtime": 8.3626,
      "eval_samples_per_second": 23.916,
      "eval_steps_per_second": 23.916,
      "step": 2900
    },
    {
      "epoch": 5.82,
      "grad_norm": 4.423397541046143,
      "learning_rate": 0.00012696969696969696,
      "loss": 0.2723,
      "step": 2910
    },
    {
      "epoch": 5.84,
      "grad_norm": 2.1660265922546387,
      "learning_rate": 0.00012636363636363634,
      "loss": 0.2807,
      "step": 2920
    },
    {
      "epoch": 5.86,
      "grad_norm": 5.407939434051514,
      "learning_rate": 0.00012575757575757575,
      "loss": 0.236,
      "step": 2930
    },
    {
      "epoch": 5.88,
      "grad_norm": 0.7849505543708801,
      "learning_rate": 0.00012515151515151514,
      "loss": 0.2121,
      "step": 2940
    },
    {
      "epoch": 5.9,
      "grad_norm": 7.314343452453613,
      "learning_rate": 0.00012454545454545455,
      "loss": 0.3022,
      "step": 2950
    },
    {
      "epoch": 5.92,
      "grad_norm": 4.58394718170166,
      "learning_rate": 0.00012393939393939393,
      "loss": 0.3833,
      "step": 2960
    },
    {
      "epoch": 5.9399999999999995,
      "grad_norm": 2.0143375396728516,
      "learning_rate": 0.0001233333333333333,
      "loss": 0.2209,
      "step": 2970
    },
    {
      "epoch": 5.96,
      "grad_norm": 7.103904724121094,
      "learning_rate": 0.00012272727272727272,
      "loss": 0.2463,
      "step": 2980
    },
    {
      "epoch": 5.98,
      "grad_norm": 4.382911682128906,
      "learning_rate": 0.0001221212121212121,
      "loss": 0.3216,
      "step": 2990
    },
    {
      "epoch": 6.0,
      "grad_norm": 5.558993816375732,
      "learning_rate": 0.0001215151515151515,
      "loss": 0.2646,
      "step": 3000
    },
    {
      "epoch": 6.0,
      "eval_loss": 1.8904051780700684,
      "eval_runtime": 8.3458,
      "eval_samples_per_second": 23.964,
      "eval_steps_per_second": 23.964,
      "step": 3000
    },
    {
      "epoch": 6.02,
      "grad_norm": 0.6057232618331909,
      "learning_rate": 0.0001209090909090909,
      "loss": 0.152,
      "step": 3010
    },
    {
      "epoch": 6.04,
      "grad_norm": 1.925193190574646,
      "learning_rate": 0.00012030303030303028,
      "loss": 0.1625,
      "step": 3020
    },
    {
      "epoch": 6.06,
      "grad_norm": 8.948258399963379,
      "learning_rate": 0.0001196969696969697,
      "loss": 0.2067,
      "step": 3030
    },
    {
      "epoch": 6.08,
      "grad_norm": 5.406137943267822,
      "learning_rate": 0.00011909090909090908,
      "loss": 0.2001,
      "step": 3040
    },
    {
      "epoch": 6.1,
      "grad_norm": 3.66767954826355,
      "learning_rate": 0.00011848484848484847,
      "loss": 0.1399,
      "step": 3050
    },
    {
      "epoch": 6.12,
      "grad_norm": 2.844085454940796,
      "learning_rate": 0.00011787878787878786,
      "loss": 0.1648,
      "step": 3060
    },
    {
      "epoch": 6.14,
      "grad_norm": 2.5839595794677734,
      "learning_rate": 0.00011727272727272727,
      "loss": 0.2317,
      "step": 3070
    },
    {
      "epoch": 6.16,
      "grad_norm": 2.295163631439209,
      "learning_rate": 0.00011666666666666665,
      "loss": 0.1982,
      "step": 3080
    },
    {
      "epoch": 6.18,
      "grad_norm": 5.26090669631958,
      "learning_rate": 0.00011606060606060605,
      "loss": 0.1852,
      "step": 3090
    },
    {
      "epoch": 6.2,
      "grad_norm": 0.8075666427612305,
      "learning_rate": 0.00011545454545454543,
      "loss": 0.1654,
      "step": 3100
    },
    {
      "epoch": 6.2,
      "eval_loss": 2.0218536853790283,
      "eval_runtime": 8.3225,
      "eval_samples_per_second": 24.031,
      "eval_steps_per_second": 24.031,
      "step": 3100
    },
    {
      "epoch": 6.22,
      "grad_norm": 3.9868271350860596,
      "learning_rate": 0.00011484848484848484,
      "loss": 0.2105,
      "step": 3110
    },
    {
      "epoch": 6.24,
      "grad_norm": 3.554943084716797,
      "learning_rate": 0.00011424242424242424,
      "loss": 0.187,
      "step": 3120
    },
    {
      "epoch": 6.26,
      "grad_norm": 1.8307080268859863,
      "learning_rate": 0.00011363636363636362,
      "loss": 0.1905,
      "step": 3130
    },
    {
      "epoch": 6.28,
      "grad_norm": 2.7842857837677,
      "learning_rate": 0.00011303030303030302,
      "loss": 0.1763,
      "step": 3140
    },
    {
      "epoch": 6.3,
      "grad_norm": 2.8158349990844727,
      "learning_rate": 0.00011242424242424242,
      "loss": 0.1769,
      "step": 3150
    },
    {
      "epoch": 6.32,
      "grad_norm": 2.2872743606567383,
      "learning_rate": 0.00011181818181818181,
      "loss": 0.2088,
      "step": 3160
    },
    {
      "epoch": 6.34,
      "grad_norm": 2.372375726699829,
      "learning_rate": 0.0001112121212121212,
      "loss": 0.2123,
      "step": 3170
    },
    {
      "epoch": 6.36,
      "grad_norm": 1.9411319494247437,
      "learning_rate": 0.0001106060606060606,
      "loss": 0.1701,
      "step": 3180
    },
    {
      "epoch": 6.38,
      "grad_norm": 1.878674864768982,
      "learning_rate": 0.00010999999999999998,
      "loss": 0.2013,
      "step": 3190
    },
    {
      "epoch": 6.4,
      "grad_norm": 2.6266987323760986,
      "learning_rate": 0.00010939393939393939,
      "loss": 0.1902,
      "step": 3200
    },
    {
      "epoch": 6.4,
      "eval_loss": 2.033447742462158,
      "eval_runtime": 8.3975,
      "eval_samples_per_second": 23.817,
      "eval_steps_per_second": 23.817,
      "step": 3200
    },
    {
      "epoch": 6.42,
      "grad_norm": 1.9866423606872559,
      "learning_rate": 0.00010878787878787878,
      "loss": 0.1591,
      "step": 3210
    },
    {
      "epoch": 6.44,
      "grad_norm": 7.173058986663818,
      "learning_rate": 0.00010818181818181817,
      "loss": 0.2325,
      "step": 3220
    },
    {
      "epoch": 6.46,
      "grad_norm": 3.5880701541900635,
      "learning_rate": 0.00010757575757575756,
      "loss": 0.1604,
      "step": 3230
    },
    {
      "epoch": 6.48,
      "grad_norm": 1.678176999092102,
      "learning_rate": 0.00010696969696969696,
      "loss": 0.1749,
      "step": 3240
    },
    {
      "epoch": 6.5,
      "grad_norm": 5.61200475692749,
      "learning_rate": 0.00010636363636363636,
      "loss": 0.2163,
      "step": 3250
    },
    {
      "epoch": 6.52,
      "grad_norm": 1.4244368076324463,
      "learning_rate": 0.00010575757575757574,
      "loss": 0.1968,
      "step": 3260
    },
    {
      "epoch": 6.54,
      "grad_norm": 3.2715237140655518,
      "learning_rate": 0.00010515151515151514,
      "loss": 0.1597,
      "step": 3270
    },
    {
      "epoch": 6.5600000000000005,
      "grad_norm": 1.3181583881378174,
      "learning_rate": 0.00010454545454545455,
      "loss": 0.1735,
      "step": 3280
    },
    {
      "epoch": 6.58,
      "grad_norm": 8.860838890075684,
      "learning_rate": 0.00010393939393939393,
      "loss": 0.2578,
      "step": 3290
    },
    {
      "epoch": 6.6,
      "grad_norm": 7.166907787322998,
      "learning_rate": 0.00010333333333333333,
      "loss": 0.1726,
      "step": 3300
    },
    {
      "epoch": 6.6,
      "eval_loss": 1.9932764768600464,
      "eval_runtime": 8.3935,
      "eval_samples_per_second": 23.828,
      "eval_steps_per_second": 23.828,
      "step": 3300
    },
    {
      "epoch": 6.62,
      "grad_norm": 3.233527660369873,
      "learning_rate": 0.00010272727272727271,
      "loss": 0.2347,
      "step": 3310
    },
    {
      "epoch": 6.64,
      "grad_norm": 1.3478331565856934,
      "learning_rate": 0.00010212121212121212,
      "loss": 0.1453,
      "step": 3320
    },
    {
      "epoch": 6.66,
      "grad_norm": 7.377655029296875,
      "learning_rate": 0.0001015151515151515,
      "loss": 0.1857,
      "step": 3330
    },
    {
      "epoch": 6.68,
      "grad_norm": 2.0218169689178467,
      "learning_rate": 0.0001009090909090909,
      "loss": 0.1871,
      "step": 3340
    },
    {
      "epoch": 6.7,
      "grad_norm": 2.389052629470825,
      "learning_rate": 0.00010030303030303029,
      "loss": 0.1534,
      "step": 3350
    },
    {
      "epoch": 6.72,
      "grad_norm": 1.0875636339187622,
      "learning_rate": 9.969696969696968e-05,
      "loss": 0.1586,
      "step": 3360
    },
    {
      "epoch": 6.74,
      "grad_norm": 5.052650451660156,
      "learning_rate": 9.90909090909091e-05,
      "loss": 0.1828,
      "step": 3370
    },
    {
      "epoch": 6.76,
      "grad_norm": 2.748514413833618,
      "learning_rate": 9.848484848484848e-05,
      "loss": 0.2156,
      "step": 3380
    },
    {
      "epoch": 6.78,
      "grad_norm": 1.1065398454666138,
      "learning_rate": 9.787878787878787e-05,
      "loss": 0.1908,
      "step": 3390
    },
    {
      "epoch": 6.8,
      "grad_norm": 9.453620910644531,
      "learning_rate": 9.727272727272726e-05,
      "loss": 0.1853,
      "step": 3400
    },
    {
      "epoch": 6.8,
      "eval_loss": 2.0327444076538086,
      "eval_runtime": 8.3167,
      "eval_samples_per_second": 24.048,
      "eval_steps_per_second": 24.048,
      "step": 3400
    },
    {
      "epoch": 6.82,
      "grad_norm": 3.0204994678497314,
      "learning_rate": 9.666666666666667e-05,
      "loss": 0.3482,
      "step": 3410
    },
    {
      "epoch": 6.84,
      "grad_norm": 4.118852138519287,
      "learning_rate": 9.606060606060605e-05,
      "loss": 0.209,
      "step": 3420
    },
    {
      "epoch": 6.86,
      "grad_norm": 2.006037950515747,
      "learning_rate": 9.545454545454545e-05,
      "loss": 0.1748,
      "step": 3430
    },
    {
      "epoch": 6.88,
      "grad_norm": 2.2219595909118652,
      "learning_rate": 9.484848484848483e-05,
      "loss": 0.1714,
      "step": 3440
    },
    {
      "epoch": 6.9,
      "grad_norm": 4.183417320251465,
      "learning_rate": 9.424242424242424e-05,
      "loss": 0.1981,
      "step": 3450
    },
    {
      "epoch": 6.92,
      "grad_norm": 4.429049015045166,
      "learning_rate": 9.363636363636364e-05,
      "loss": 0.1975,
      "step": 3460
    },
    {
      "epoch": 6.9399999999999995,
      "grad_norm": 0.905218780040741,
      "learning_rate": 9.303030303030302e-05,
      "loss": 0.2317,
      "step": 3470
    },
    {
      "epoch": 6.96,
      "grad_norm": 3.9642043113708496,
      "learning_rate": 9.242424242424242e-05,
      "loss": 0.2105,
      "step": 3480
    },
    {
      "epoch": 6.98,
      "grad_norm": 2.092358350753784,
      "learning_rate": 9.18181818181818e-05,
      "loss": 0.1739,
      "step": 3490
    },
    {
      "epoch": 7.0,
      "grad_norm": 2.503291368484497,
      "learning_rate": 9.121212121212121e-05,
      "loss": 0.1765,
      "step": 3500
    },
    {
      "epoch": 7.0,
      "eval_loss": 1.9738174676895142,
      "eval_runtime": 8.2992,
      "eval_samples_per_second": 24.099,
      "eval_steps_per_second": 24.099,
      "step": 3500
    },
    {
      "epoch": 7.02,
      "grad_norm": 2.2506446838378906,
      "learning_rate": 9.06060606060606e-05,
      "loss": 0.1608,
      "step": 3510
    },
    {
      "epoch": 7.04,
      "grad_norm": 4.481196403503418,
      "learning_rate": 8.999999999999999e-05,
      "loss": 0.1468,
      "step": 3520
    },
    {
      "epoch": 7.06,
      "grad_norm": 3.1055805683135986,
      "learning_rate": 8.939393939393938e-05,
      "loss": 0.183,
      "step": 3530
    },
    {
      "epoch": 7.08,
      "grad_norm": 1.436422348022461,
      "learning_rate": 8.878787878787879e-05,
      "loss": 0.1498,
      "step": 3540
    },
    {
      "epoch": 7.1,
      "grad_norm": 0.6633299589157104,
      "learning_rate": 8.818181818181817e-05,
      "loss": 0.1629,
      "step": 3550
    },
    {
      "epoch": 7.12,
      "grad_norm": 2.3895223140716553,
      "learning_rate": 8.757575757575757e-05,
      "loss": 0.1382,
      "step": 3560
    },
    {
      "epoch": 7.14,
      "grad_norm": 1.383744478225708,
      "learning_rate": 8.696969696969695e-05,
      "loss": 0.1421,
      "step": 3570
    },
    {
      "epoch": 7.16,
      "grad_norm": 1.608335018157959,
      "learning_rate": 8.636363636363636e-05,
      "loss": 0.1203,
      "step": 3580
    },
    {
      "epoch": 7.18,
      "grad_norm": 0.8068861365318298,
      "learning_rate": 8.575757575757576e-05,
      "loss": 0.1456,
      "step": 3590
    },
    {
      "epoch": 7.2,
      "grad_norm": 1.3155056238174438,
      "learning_rate": 8.515151515151514e-05,
      "loss": 0.1437,
      "step": 3600
    },
    {
      "epoch": 7.2,
      "eval_loss": 2.1227142810821533,
      "eval_runtime": 8.3294,
      "eval_samples_per_second": 24.011,
      "eval_steps_per_second": 24.011,
      "step": 3600
    },
    {
      "epoch": 7.22,
      "grad_norm": 0.7098769545555115,
      "learning_rate": 8.454545454545454e-05,
      "loss": 0.165,
      "step": 3610
    },
    {
      "epoch": 7.24,
      "grad_norm": 4.47345495223999,
      "learning_rate": 8.393939393939393e-05,
      "loss": 0.1651,
      "step": 3620
    },
    {
      "epoch": 7.26,
      "grad_norm": 1.4481292963027954,
      "learning_rate": 8.333333333333333e-05,
      "loss": 0.1315,
      "step": 3630
    },
    {
      "epoch": 7.28,
      "grad_norm": 0.9912613034248352,
      "learning_rate": 8.272727272727271e-05,
      "loss": 0.1354,
      "step": 3640
    },
    {
      "epoch": 7.3,
      "grad_norm": 2.5101704597473145,
      "learning_rate": 8.212121212121211e-05,
      "loss": 0.1405,
      "step": 3650
    },
    {
      "epoch": 7.32,
      "grad_norm": 3.6693193912506104,
      "learning_rate": 8.15151515151515e-05,
      "loss": 0.1876,
      "step": 3660
    },
    {
      "epoch": 7.34,
      "grad_norm": 4.0057806968688965,
      "learning_rate": 8.09090909090909e-05,
      "loss": 0.1546,
      "step": 3670
    },
    {
      "epoch": 7.36,
      "grad_norm": 1.3235442638397217,
      "learning_rate": 8.03030303030303e-05,
      "loss": 0.1326,
      "step": 3680
    },
    {
      "epoch": 7.38,
      "grad_norm": 1.8420815467834473,
      "learning_rate": 7.969696969696968e-05,
      "loss": 0.1623,
      "step": 3690
    },
    {
      "epoch": 7.4,
      "grad_norm": 2.4941911697387695,
      "learning_rate": 7.915151515151514e-05,
      "loss": 0.1514,
      "step": 3700
    },
    {
      "epoch": 7.4,
      "eval_loss": 2.099569797515869,
      "eval_runtime": 8.36,
      "eval_samples_per_second": 23.923,
      "eval_steps_per_second": 23.923,
      "step": 3700
    },
    {
      "epoch": 7.42,
      "grad_norm": 0.7203918695449829,
      "learning_rate": 7.854545454545454e-05,
      "loss": 0.1534,
      "step": 3710
    },
    {
      "epoch": 7.44,
      "grad_norm": 1.483193278312683,
      "learning_rate": 7.793939393939394e-05,
      "loss": 0.1658,
      "step": 3720
    },
    {
      "epoch": 7.46,
      "grad_norm": 2.1807961463928223,
      "learning_rate": 7.733333333333332e-05,
      "loss": 0.1304,
      "step": 3730
    },
    {
      "epoch": 7.48,
      "grad_norm": 2.8913471698760986,
      "learning_rate": 7.672727272727272e-05,
      "loss": 0.1648,
      "step": 3740
    },
    {
      "epoch": 7.5,
      "grad_norm": 0.9088821411132812,
      "learning_rate": 7.612121212121213e-05,
      "loss": 0.1682,
      "step": 3750
    },
    {
      "epoch": 7.52,
      "grad_norm": 2.0451982021331787,
      "learning_rate": 7.551515151515151e-05,
      "loss": 0.162,
      "step": 3760
    },
    {
      "epoch": 7.54,
      "grad_norm": 2.156583070755005,
      "learning_rate": 7.490909090909091e-05,
      "loss": 0.1649,
      "step": 3770
    },
    {
      "epoch": 7.5600000000000005,
      "grad_norm": 0.6945547461509705,
      "learning_rate": 7.43030303030303e-05,
      "loss": 0.1354,
      "step": 3780
    },
    {
      "epoch": 7.58,
      "grad_norm": 1.2209092378616333,
      "learning_rate": 7.369696969696969e-05,
      "loss": 0.1947,
      "step": 3790
    },
    {
      "epoch": 7.6,
      "grad_norm": 1.3863604068756104,
      "learning_rate": 7.309090909090908e-05,
      "loss": 0.1312,
      "step": 3800
    },
    {
      "epoch": 7.6,
      "eval_loss": 2.233210325241089,
      "eval_runtime": 8.3074,
      "eval_samples_per_second": 24.075,
      "eval_steps_per_second": 24.075,
      "step": 3800
    },
    {
      "epoch": 7.62,
      "grad_norm": 0.7875300645828247,
      "learning_rate": 7.248484848484848e-05,
      "loss": 0.1402,
      "step": 3810
    },
    {
      "epoch": 7.64,
      "grad_norm": 1.2166575193405151,
      "learning_rate": 7.187878787878786e-05,
      "loss": 0.1447,
      "step": 3820
    },
    {
      "epoch": 7.66,
      "grad_norm": 2.1061694622039795,
      "learning_rate": 7.127272727272726e-05,
      "loss": 0.1331,
      "step": 3830
    },
    {
      "epoch": 7.68,
      "grad_norm": 0.8931973576545715,
      "learning_rate": 7.066666666666666e-05,
      "loss": 0.1696,
      "step": 3840
    },
    {
      "epoch": 7.7,
      "grad_norm": 1.511211633682251,
      "learning_rate": 7.006060606060606e-05,
      "loss": 0.1711,
      "step": 3850
    },
    {
      "epoch": 7.72,
      "grad_norm": 2.5259525775909424,
      "learning_rate": 6.945454545454545e-05,
      "loss": 0.1416,
      "step": 3860
    },
    {
      "epoch": 7.74,
      "grad_norm": 8.216418266296387,
      "learning_rate": 6.884848484848485e-05,
      "loss": 0.1404,
      "step": 3870
    },
    {
      "epoch": 7.76,
      "grad_norm": 1.4024395942687988,
      "learning_rate": 6.824242424242423e-05,
      "loss": 0.1488,
      "step": 3880
    },
    {
      "epoch": 7.78,
      "grad_norm": 1.8662221431732178,
      "learning_rate": 6.763636363636363e-05,
      "loss": 0.1414,
      "step": 3890
    },
    {
      "epoch": 7.8,
      "grad_norm": 1.6802157163619995,
      "learning_rate": 6.703030303030303e-05,
      "loss": 0.1502,
      "step": 3900
    },
    {
      "epoch": 7.8,
      "eval_loss": 2.0907304286956787,
      "eval_runtime": 8.3222,
      "eval_samples_per_second": 24.032,
      "eval_steps_per_second": 24.032,
      "step": 3900
    },
    {
      "epoch": 7.82,
      "grad_norm": 6.489402770996094,
      "learning_rate": 6.642424242424242e-05,
      "loss": 0.1628,
      "step": 3910
    },
    {
      "epoch": 7.84,
      "grad_norm": 1.1942096948623657,
      "learning_rate": 6.58181818181818e-05,
      "loss": 0.1668,
      "step": 3920
    },
    {
      "epoch": 7.86,
      "grad_norm": 2.842167377471924,
      "learning_rate": 6.52121212121212e-05,
      "loss": 0.1691,
      "step": 3930
    },
    {
      "epoch": 7.88,
      "grad_norm": 2.724782705307007,
      "learning_rate": 6.46060606060606e-05,
      "loss": 0.1521,
      "step": 3940
    },
    {
      "epoch": 7.9,
      "grad_norm": 1.2568180561065674,
      "learning_rate": 6.4e-05,
      "loss": 0.1424,
      "step": 3950
    },
    {
      "epoch": 7.92,
      "grad_norm": 0.6225541234016418,
      "learning_rate": 6.33939393939394e-05,
      "loss": 0.1751,
      "step": 3960
    },
    {
      "epoch": 7.9399999999999995,
      "grad_norm": 1.216050624847412,
      "learning_rate": 6.278787878787878e-05,
      "loss": 0.1576,
      "step": 3970
    },
    {
      "epoch": 7.96,
      "grad_norm": 4.172018051147461,
      "learning_rate": 6.218181818181817e-05,
      "loss": 0.1446,
      "step": 3980
    },
    {
      "epoch": 7.98,
      "grad_norm": 1.980365514755249,
      "learning_rate": 6.157575757575757e-05,
      "loss": 0.1423,
      "step": 3990
    },
    {
      "epoch": 8.0,
      "grad_norm": 7.966225624084473,
      "learning_rate": 6.096969696969697e-05,
      "loss": 0.1803,
      "step": 4000
    },
    {
      "epoch": 8.0,
      "eval_loss": 2.1228411197662354,
      "eval_runtime": 8.3169,
      "eval_samples_per_second": 24.047,
      "eval_steps_per_second": 24.047,
      "step": 4000
    },
    {
      "epoch": 8.02,
      "grad_norm": 1.2764967679977417,
      "learning_rate": 6.036363636363636e-05,
      "loss": 0.1308,
      "step": 4010
    },
    {
      "epoch": 8.04,
      "grad_norm": 1.506238579750061,
      "learning_rate": 5.9757575757575755e-05,
      "loss": 0.1241,
      "step": 4020
    },
    {
      "epoch": 8.06,
      "grad_norm": 1.8593246936798096,
      "learning_rate": 5.9151515151515145e-05,
      "loss": 0.1108,
      "step": 4030
    },
    {
      "epoch": 8.08,
      "grad_norm": 2.9660708904266357,
      "learning_rate": 5.854545454545454e-05,
      "loss": 0.1244,
      "step": 4040
    },
    {
      "epoch": 8.1,
      "grad_norm": 2.5873615741729736,
      "learning_rate": 5.793939393939393e-05,
      "loss": 0.1469,
      "step": 4050
    },
    {
      "epoch": 8.12,
      "grad_norm": 1.1576122045516968,
      "learning_rate": 5.733333333333333e-05,
      "loss": 0.1138,
      "step": 4060
    },
    {
      "epoch": 8.14,
      "grad_norm": 1.0962010622024536,
      "learning_rate": 5.672727272727272e-05,
      "loss": 0.1522,
      "step": 4070
    },
    {
      "epoch": 8.16,
      "grad_norm": 1.8127813339233398,
      "learning_rate": 5.612121212121212e-05,
      "loss": 0.1171,
      "step": 4080
    },
    {
      "epoch": 8.18,
      "grad_norm": 1.630272626876831,
      "learning_rate": 5.551515151515151e-05,
      "loss": 0.1096,
      "step": 4090
    },
    {
      "epoch": 8.2,
      "grad_norm": 1.0578031539916992,
      "learning_rate": 5.490909090909091e-05,
      "loss": 0.1187,
      "step": 4100
    },
    {
      "epoch": 8.2,
      "eval_loss": 2.2935738563537598,
      "eval_runtime": 8.4137,
      "eval_samples_per_second": 23.771,
      "eval_steps_per_second": 23.771,
      "step": 4100
    },
    {
      "epoch": 8.22,
      "grad_norm": 1.439724087715149,
      "learning_rate": 5.43030303030303e-05,
      "loss": 0.1216,
      "step": 4110
    },
    {
      "epoch": 8.24,
      "grad_norm": 1.2967737913131714,
      "learning_rate": 5.369696969696969e-05,
      "loss": 0.1295,
      "step": 4120
    },
    {
      "epoch": 8.26,
      "grad_norm": 1.2206597328186035,
      "learning_rate": 5.3090909090909087e-05,
      "loss": 0.1134,
      "step": 4130
    },
    {
      "epoch": 8.28,
      "grad_norm": 2.02415132522583,
      "learning_rate": 5.2484848484848477e-05,
      "loss": 0.1199,
      "step": 4140
    },
    {
      "epoch": 8.3,
      "grad_norm": 2.0325934886932373,
      "learning_rate": 5.1878787878787873e-05,
      "loss": 0.1405,
      "step": 4150
    },
    {
      "epoch": 8.32,
      "grad_norm": 12.891498565673828,
      "learning_rate": 5.1272727272727264e-05,
      "loss": 0.1183,
      "step": 4160
    },
    {
      "epoch": 8.34,
      "grad_norm": 3.3237438201904297,
      "learning_rate": 5.066666666666666e-05,
      "loss": 0.1333,
      "step": 4170
    },
    {
      "epoch": 8.36,
      "grad_norm": 1.0077391862869263,
      "learning_rate": 5.006060606060605e-05,
      "loss": 0.1309,
      "step": 4180
    },
    {
      "epoch": 8.38,
      "grad_norm": 3.3809444904327393,
      "learning_rate": 4.9454545454545454e-05,
      "loss": 0.129,
      "step": 4190
    },
    {
      "epoch": 8.4,
      "grad_norm": 0.9207984209060669,
      "learning_rate": 4.8848484848484844e-05,
      "loss": 0.125,
      "step": 4200
    },
    {
      "epoch": 8.4,
      "eval_loss": 2.2915894985198975,
      "eval_runtime": 8.3257,
      "eval_samples_per_second": 24.022,
      "eval_steps_per_second": 24.022,
      "step": 4200
    },
    {
      "epoch": 8.42,
      "grad_norm": 0.6335203647613525,
      "learning_rate": 4.824242424242424e-05,
      "loss": 0.1636,
      "step": 4210
    },
    {
      "epoch": 8.44,
      "grad_norm": 0.512949526309967,
      "learning_rate": 4.763636363636363e-05,
      "loss": 0.1375,
      "step": 4220
    },
    {
      "epoch": 8.46,
      "grad_norm": 1.0492655038833618,
      "learning_rate": 4.703030303030303e-05,
      "loss": 0.1366,
      "step": 4230
    },
    {
      "epoch": 8.48,
      "grad_norm": 1.1447194814682007,
      "learning_rate": 4.642424242424242e-05,
      "loss": 0.1213,
      "step": 4240
    },
    {
      "epoch": 8.5,
      "grad_norm": 4.956345558166504,
      "learning_rate": 4.5818181818181815e-05,
      "loss": 0.1564,
      "step": 4250
    },
    {
      "epoch": 8.52,
      "grad_norm": 0.8715401887893677,
      "learning_rate": 4.5212121212121205e-05,
      "loss": 0.1247,
      "step": 4260
    },
    {
      "epoch": 8.54,
      "grad_norm": 1.1434836387634277,
      "learning_rate": 4.460606060606061e-05,
      "loss": 0.1457,
      "step": 4270
    },
    {
      "epoch": 8.56,
      "grad_norm": 2.1176929473876953,
      "learning_rate": 4.4e-05,
      "loss": 0.1219,
      "step": 4280
    },
    {
      "epoch": 8.58,
      "grad_norm": 0.9188893437385559,
      "learning_rate": 4.339393939393939e-05,
      "loss": 0.133,
      "step": 4290
    },
    {
      "epoch": 8.6,
      "grad_norm": 1.3675676584243774,
      "learning_rate": 4.2787878787878786e-05,
      "loss": 0.1164,
      "step": 4300
    },
    {
      "epoch": 8.6,
      "eval_loss": 2.2519984245300293,
      "eval_runtime": 8.3243,
      "eval_samples_per_second": 24.026,
      "eval_steps_per_second": 24.026,
      "step": 4300
    },
    {
      "epoch": 8.62,
      "grad_norm": 2.739760160446167,
      "learning_rate": 4.2181818181818176e-05,
      "loss": 0.1353,
      "step": 4310
    },
    {
      "epoch": 8.64,
      "grad_norm": 0.882678747177124,
      "learning_rate": 4.157575757575757e-05,
      "loss": 0.1286,
      "step": 4320
    },
    {
      "epoch": 8.66,
      "grad_norm": 1.3989923000335693,
      "learning_rate": 4.096969696969696e-05,
      "loss": 0.1218,
      "step": 4330
    },
    {
      "epoch": 8.68,
      "grad_norm": 1.1085797548294067,
      "learning_rate": 4.036363636363636e-05,
      "loss": 0.1379,
      "step": 4340
    },
    {
      "epoch": 8.7,
      "grad_norm": 0.573120653629303,
      "learning_rate": 3.975757575757575e-05,
      "loss": 0.1294,
      "step": 4350
    },
    {
      "epoch": 8.72,
      "grad_norm": 2.073396921157837,
      "learning_rate": 3.9151515151515153e-05,
      "loss": 0.1312,
      "step": 4360
    },
    {
      "epoch": 8.74,
      "grad_norm": 1.9744669198989868,
      "learning_rate": 3.8545454545454544e-05,
      "loss": 0.1274,
      "step": 4370
    },
    {
      "epoch": 8.76,
      "grad_norm": 2.4423577785491943,
      "learning_rate": 3.793939393939394e-05,
      "loss": 0.1268,
      "step": 4380
    },
    {
      "epoch": 8.78,
      "grad_norm": 0.6575141549110413,
      "learning_rate": 3.733333333333333e-05,
      "loss": 0.1448,
      "step": 4390
    },
    {
      "epoch": 8.8,
      "grad_norm": 1.1675184965133667,
      "learning_rate": 3.672727272727272e-05,
      "loss": 0.1134,
      "step": 4400
    },
    {
      "epoch": 8.8,
      "eval_loss": 2.2632176876068115,
      "eval_runtime": 8.3367,
      "eval_samples_per_second": 23.99,
      "eval_steps_per_second": 23.99,
      "step": 4400
    },
    {
      "epoch": 8.82,
      "grad_norm": 0.70200514793396,
      "learning_rate": 3.612121212121212e-05,
      "loss": 0.1326,
      "step": 4410
    },
    {
      "epoch": 8.84,
      "grad_norm": 1.3547320365905762,
      "learning_rate": 3.5515151515151514e-05,
      "loss": 0.1517,
      "step": 4420
    },
    {
      "epoch": 8.86,
      "grad_norm": 2.0725677013397217,
      "learning_rate": 3.4909090909090904e-05,
      "loss": 0.131,
      "step": 4430
    },
    {
      "epoch": 8.88,
      "grad_norm": 1.085806131362915,
      "learning_rate": 3.43030303030303e-05,
      "loss": 0.1262,
      "step": 4440
    },
    {
      "epoch": 8.9,
      "grad_norm": 1.1010099649429321,
      "learning_rate": 3.369696969696969e-05,
      "loss": 0.1216,
      "step": 4450
    },
    {
      "epoch": 8.92,
      "grad_norm": 1.3475760221481323,
      "learning_rate": 3.309090909090909e-05,
      "loss": 0.121,
      "step": 4460
    },
    {
      "epoch": 8.94,
      "grad_norm": 1.7916983366012573,
      "learning_rate": 3.2484848484848485e-05,
      "loss": 0.126,
      "step": 4470
    },
    {
      "epoch": 8.96,
      "grad_norm": 0.6732047200202942,
      "learning_rate": 3.1878787878787875e-05,
      "loss": 0.1213,
      "step": 4480
    },
    {
      "epoch": 8.98,
      "grad_norm": 2.144867420196533,
      "learning_rate": 3.127272727272727e-05,
      "loss": 0.1306,
      "step": 4490
    },
    {
      "epoch": 9.0,
      "grad_norm": 0.9604624509811401,
      "learning_rate": 3.066666666666667e-05,
      "loss": 0.1228,
      "step": 4500
    },
    {
      "epoch": 9.0,
      "eval_loss": 2.2486624717712402,
      "eval_runtime": 8.3514,
      "eval_samples_per_second": 23.948,
      "eval_steps_per_second": 23.948,
      "step": 4500
    }
  ],
  "logging_steps": 10,
  "max_steps": 5000,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 10,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 1.3472250200064e+16,
  "train_batch_size": 1,
  "trial_name": null,
  "trial_params": null
}

{
  "best_global_step": null,
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 9.0,
  "eval_steps": 100,
  "global_step": 4500,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.02,
      "grad_norm": 2.2539284229278564,
      "learning_rate": 4.2e-05,
      "loss": 2.6041,
      "step": 10
    },
    {
      "epoch": 0.04,
      "grad_norm": 4.980758190155029,
      "learning_rate": 0.000102,
      "loss": 2.4004,
      "step": 20
    },
    {
      "epoch": 0.06,
      "grad_norm": 3.490464448928833,
      "learning_rate": 0.000162,
      "loss": 1.8436,
      "step": 30
    },
    {
      "epoch": 0.08,
      "grad_norm": 3.8751893043518066,
      "learning_rate": 0.00022199999999999998,
      "loss": 1.4488,
      "step": 40
    },
    {
      "epoch": 0.1,
      "grad_norm": 4.206297397613525,
      "learning_rate": 0.00028199999999999997,
      "loss": 1.4192,
      "step": 50
    },
    {
      "epoch": 0.12,
      "grad_norm": 7.705833435058594,
      "learning_rate": 0.00029957575757575756,
      "loss": 1.2253,
      "step": 60
    },
    {
      "epoch": 0.14,
      "grad_norm": 3.2719924449920654,
      "learning_rate": 0.0002989696969696969,
      "loss": 1.2635,
      "step": 70
    },
    {
      "epoch": 0.16,
      "grad_norm": 10.392121315002441,
      "learning_rate": 0.0002983636363636363,
      "loss": 1.0617,
      "step": 80
    },
    {
      "epoch": 0.18,
      "grad_norm": 2.9605765342712402,
      "learning_rate": 0.00029775757575757573,
      "loss": 1.1502,
      "step": 90
    },
    {
      "epoch": 0.2,
      "grad_norm": 3.0141077041625977,
      "learning_rate": 0.00029715151515151514,
      "loss": 1.2571,
      "step": 100
    },
    {
      "epoch": 0.2,
      "eval_loss": 1.1176190376281738,
      "eval_runtime": 8.1943,
      "eval_samples_per_second": 24.407,
      "eval_steps_per_second": 24.407,
      "step": 100
    },
    {
      "epoch": 0.22,
      "grad_norm": 2.5651955604553223,
      "learning_rate": 0.00029654545454545455,
      "loss": 1.1019,
      "step": 110
    },
    {
      "epoch": 0.24,
      "grad_norm": 4.738255977630615,
      "learning_rate": 0.0002959393939393939,
      "loss": 0.8951,
      "step": 120
    },
    {
      "epoch": 0.26,
      "grad_norm": 3.1306614875793457,
      "learning_rate": 0.0002953333333333333,
      "loss": 1.337,
      "step": 130
    },
    {
      "epoch": 0.28,
      "grad_norm": 2.667384624481201,
      "learning_rate": 0.0002947272727272727,
      "loss": 1.2216,
      "step": 140
    },
    {
      "epoch": 0.3,
      "grad_norm": 2.2364466190338135,
      "learning_rate": 0.0002941212121212121,
      "loss": 0.73,
      "step": 150
    },
    {
      "epoch": 0.32,
      "grad_norm": 2.7202935218811035,
      "learning_rate": 0.0002935151515151515,
      "loss": 0.859,
      "step": 160
    },
    {
      "epoch": 0.34,
      "grad_norm": 6.894711017608643,
      "learning_rate": 0.00029296969696969693,
      "loss": 1.0504,
      "step": 170
    },
    {
      "epoch": 0.36,
      "grad_norm": 5.980502605438232,
      "learning_rate": 0.00029236363636363634,
      "loss": 1.2224,
      "step": 180
    },
    {
      "epoch": 0.38,
      "grad_norm": 1.8428807258605957,
      "learning_rate": 0.00029175757575757575,
      "loss": 1.0991,
      "step": 190
    },
    {
      "epoch": 0.4,
      "grad_norm": 4.067563533782959,
      "learning_rate": 0.00029115151515151516,
      "loss": 0.8709,
      "step": 200
    },
    {
      "epoch": 0.4,
      "eval_loss": 0.911726713180542,
      "eval_runtime": 8.2518,
      "eval_samples_per_second": 24.237,
      "eval_steps_per_second": 24.237,
      "step": 200
    },
    {
      "epoch": 0.42,
      "grad_norm": 4.546880722045898,
      "learning_rate": 0.0002905454545454545,
      "loss": 0.7414,
      "step": 210
    },
    {
      "epoch": 0.44,
      "grad_norm": 2.940703868865967,
      "learning_rate": 0.0002899393939393939,
      "loss": 0.9576,
      "step": 220
    },
    {
      "epoch": 0.46,
      "grad_norm": 4.332695960998535,
      "learning_rate": 0.0002893333333333333,
      "loss": 0.7792,
      "step": 230
    },
    {
      "epoch": 0.48,
      "grad_norm": 1.918545126914978,
      "learning_rate": 0.0002887272727272727,
      "loss": 0.7561,
      "step": 240
    },
    {
      "epoch": 0.5,
      "grad_norm": 7.30818510055542,
      "learning_rate": 0.0002881212121212121,
      "loss": 0.9209,
      "step": 250
    },
    {
      "epoch": 0.52,
      "grad_norm": 8.386688232421875,
      "learning_rate": 0.00028751515151515146,
      "loss": 0.9257,
      "step": 260
    },
    {
      "epoch": 0.54,
      "grad_norm": 3.759819984436035,
      "learning_rate": 0.0002869090909090909,
      "loss": 0.9813,
      "step": 270
    },
    {
      "epoch": 0.56,
      "grad_norm": 3.445704221725464,
      "learning_rate": 0.0002863030303030303,
      "loss": 1.0725,
      "step": 280
    },
    {
      "epoch": 0.58,
      "grad_norm": 4.92030668258667,
      "learning_rate": 0.0002856969696969697,
      "loss": 0.8985,
      "step": 290
    },
    {
      "epoch": 0.6,
      "grad_norm": 2.8157429695129395,
      "learning_rate": 0.00028509090909090905,
      "loss": 0.7548,
      "step": 300
    },
    {
      "epoch": 0.6,
      "eval_loss": 0.9003965854644775,
      "eval_runtime": 8.3159,
      "eval_samples_per_second": 24.05,
      "eval_steps_per_second": 24.05,
      "step": 300
    },
    {
      "epoch": 0.62,
      "grad_norm": 3.7750186920166016,
      "learning_rate": 0.00028448484848484846,
      "loss": 1.0425,
      "step": 310
    },
    {
      "epoch": 0.64,
      "grad_norm": 7.445575714111328,
      "learning_rate": 0.00028387878787878787,
      "loss": 0.5913,
      "step": 320
    },
    {
      "epoch": 0.66,
      "grad_norm": 3.475219964981079,
      "learning_rate": 0.0002832727272727272,
      "loss": 0.7168,
      "step": 330
    },
    {
      "epoch": 0.68,
      "grad_norm": 2.0083680152893066,
      "learning_rate": 0.00028266666666666663,
      "loss": 1.0042,
      "step": 340
    },
    {
      "epoch": 0.7,
      "grad_norm": 1.7115401029586792,
      "learning_rate": 0.00028206060606060605,
      "loss": 0.9004,
      "step": 350
    },
    {
      "epoch": 0.72,
      "grad_norm": 5.108808994293213,
      "learning_rate": 0.00028145454545454546,
      "loss": 0.8839,
      "step": 360
    },
    {
      "epoch": 0.74,
      "grad_norm": 2.4106369018554688,
      "learning_rate": 0.0002808484848484848,
      "loss": 0.8515,
      "step": 370
    },
    {
      "epoch": 0.76,
      "grad_norm": 3.525388717651367,
      "learning_rate": 0.0002802424242424242,
      "loss": 0.8517,
      "step": 380
    },
    {
      "epoch": 0.78,
      "grad_norm": 2.922837734222412,
      "learning_rate": 0.00027963636363636363,
      "loss": 0.6507,
      "step": 390
    },
    {
      "epoch": 0.8,
      "grad_norm": 9.409041404724121,
      "learning_rate": 0.000279030303030303,
      "loss": 0.7765,
      "step": 400
    },
    {
      "epoch": 0.8,
      "eval_loss": 0.8944511413574219,
      "eval_runtime": 8.2643,
      "eval_samples_per_second": 24.2,
      "eval_steps_per_second": 24.2,
      "step": 400
    },
    {
      "epoch": 0.82,
      "grad_norm": 2.9317915439605713,
      "learning_rate": 0.0002784242424242424,
      "loss": 1.1228,
      "step": 410
    },
    {
      "epoch": 0.84,
      "grad_norm": 3.171513080596924,
      "learning_rate": 0.0002778181818181818,
      "loss": 0.8135,
      "step": 420
    },
    {
      "epoch": 0.86,
      "grad_norm": 2.2589614391326904,
      "learning_rate": 0.00027721212121212117,
      "loss": 0.6906,
      "step": 430
    },
    {
      "epoch": 0.88,
      "grad_norm": 3.32767391204834,
      "learning_rate": 0.0002766060606060606,
      "loss": 0.6969,
      "step": 440
    },
    {
      "epoch": 0.9,
      "grad_norm": 2.579240560531616,
      "learning_rate": 0.000276,
      "loss": 0.6981,
      "step": 450
    },
    {
      "epoch": 0.92,
      "grad_norm": 3.306926965713501,
      "learning_rate": 0.0002753939393939394,
      "loss": 1.011,
      "step": 460
    },
    {
      "epoch": 0.94,
      "grad_norm": 3.368557929992676,
      "learning_rate": 0.00027478787878787875,
      "loss": 0.761,
      "step": 470
    },
    {
      "epoch": 0.96,
      "grad_norm": 2.030444860458374,
      "learning_rate": 0.00027418181818181816,
      "loss": 0.9105,
      "step": 480
    },
    {
      "epoch": 0.98,
      "grad_norm": 3.473198890686035,
      "learning_rate": 0.0002735757575757576,
      "loss": 0.9893,
      "step": 490
    },
    {
      "epoch": 1.0,
      "grad_norm": 7.339883804321289,
      "learning_rate": 0.00027296969696969693,
      "loss": 0.8075,
      "step": 500
    },
    {
      "epoch": 1.0,
      "eval_loss": 0.8610305786132812,
      "eval_runtime": 8.2648,
      "eval_samples_per_second": 24.199,
      "eval_steps_per_second": 24.199,
      "step": 500
    },
    {
      "epoch": 1.02,
      "grad_norm": 4.861204624176025,
      "learning_rate": 0.00027236363636363634,
      "loss": 0.7918,
      "step": 510
    },
    {
      "epoch": 1.04,
      "grad_norm": 5.825981616973877,
      "learning_rate": 0.0002717575757575757,
      "loss": 0.7379,
      "step": 520
    },
    {
      "epoch": 1.06,
      "grad_norm": 1.8802238702774048,
      "learning_rate": 0.00027115151515151516,
      "loss": 0.5962,
      "step": 530
    },
    {
      "epoch": 1.08,
      "grad_norm": 2.74953031539917,
      "learning_rate": 0.0002705454545454545,
      "loss": 0.7209,
      "step": 540
    },
    {
      "epoch": 1.1,
      "grad_norm": 2.567323923110962,
      "learning_rate": 0.00026993939393939393,
      "loss": 0.5713,
      "step": 550
    },
    {
      "epoch": 1.12,
      "grad_norm": 1.9702917337417603,
      "learning_rate": 0.00026933333333333334,
      "loss": 0.6892,
      "step": 560
    },
    {
      "epoch": 1.1400000000000001,
      "grad_norm": 2.9831879138946533,
      "learning_rate": 0.0002687272727272727,
      "loss": 0.5804,
      "step": 570
    },
    {
      "epoch": 1.16,
      "grad_norm": 4.1638689041137695,
      "learning_rate": 0.0002681212121212121,
      "loss": 0.8601,
      "step": 580
    },
    {
      "epoch": 1.18,
      "grad_norm": 2.1582164764404297,
      "learning_rate": 0.00026751515151515146,
      "loss": 0.6424,
      "step": 590
    },
    {
      "epoch": 1.2,
      "grad_norm": 1.9755598306655884,
      "learning_rate": 0.00026690909090909087,
      "loss": 0.5851,
      "step": 600
    },
    {
      "epoch": 1.2,
      "eval_loss": 0.8786433935165405,
      "eval_runtime": 8.2849,
      "eval_samples_per_second": 24.14,
      "eval_steps_per_second": 24.14,
      "step": 600
    },
    {
      "epoch": 1.22,
      "grad_norm": 4.596745014190674,
      "learning_rate": 0.0002663030303030303,
      "loss": 0.6617,
      "step": 610
    },
    {
      "epoch": 1.24,
      "grad_norm": 3.8859376907348633,
      "learning_rate": 0.0002656969696969697,
      "loss": 0.764,
      "step": 620
    },
    {
      "epoch": 1.26,
      "grad_norm": 2.849489212036133,
      "learning_rate": 0.00026509090909090905,
      "loss": 0.7056,
      "step": 630
    },
    {
      "epoch": 1.28,
      "grad_norm": 2.921898603439331,
      "learning_rate": 0.00026448484848484846,
      "loss": 0.7121,
      "step": 640
    },
    {
      "epoch": 1.3,
      "grad_norm": 2.521214723587036,
      "learning_rate": 0.00026387878787878787,
      "loss": 0.7342,
      "step": 650
    },
    {
      "epoch": 1.32,
      "grad_norm": 2.9133553504943848,
      "learning_rate": 0.0002632727272727272,
      "loss": 0.5789,
      "step": 660
    },
    {
      "epoch": 1.34,
      "grad_norm": 1.6724708080291748,
      "learning_rate": 0.00026266666666666664,
      "loss": 0.7567,
      "step": 670
    },
    {
      "epoch": 1.3599999999999999,
      "grad_norm": 4.905216217041016,
      "learning_rate": 0.00026206060606060605,
      "loss": 0.8774,
      "step": 680
    },
    {
      "epoch": 1.38,
      "grad_norm": 3.2569854259490967,
      "learning_rate": 0.0002614545454545454,
      "loss": 0.5805,
      "step": 690
    },
    {
      "epoch": 1.4,
      "grad_norm": 4.177483558654785,
      "learning_rate": 0.0002608484848484848,
      "loss": 0.6394,
      "step": 700
    },
    {
      "epoch": 1.4,
      "eval_loss": 0.8763906955718994,
      "eval_runtime": 8.2699,
      "eval_samples_per_second": 24.184,
      "eval_steps_per_second": 24.184,
      "step": 700
    },
    {
      "epoch": 1.42,
      "grad_norm": 1.8596291542053223,
      "learning_rate": 0.0002602424242424242,
      "loss": 0.7234,
      "step": 710
    },
    {
      "epoch": 1.44,
      "grad_norm": 3.1568715572357178,
      "learning_rate": 0.00025963636363636363,
      "loss": 0.5995,
      "step": 720
    },
    {
      "epoch": 1.46,
      "grad_norm": 3.613377809524536,
      "learning_rate": 0.000259030303030303,
      "loss": 0.8004,
      "step": 730
    },
    {
      "epoch": 1.48,
      "grad_norm": 2.4029664993286133,
      "learning_rate": 0.0002584242424242424,
      "loss": 0.693,
      "step": 740
    },
    {
      "epoch": 1.5,
      "grad_norm": 6.807441234588623,
      "learning_rate": 0.0002578181818181818,
      "loss": 0.7447,
      "step": 750
    },
    {
      "epoch": 1.52,
      "grad_norm": 3.988354444503784,
      "learning_rate": 0.00025721212121212117,
      "loss": 0.8224,
      "step": 760
    },
    {
      "epoch": 1.54,
      "grad_norm": 1.5825496912002563,
      "learning_rate": 0.0002566060606060606,
      "loss": 0.7412,
      "step": 770
    },
    {
      "epoch": 1.56,
      "grad_norm": 1.3022136688232422,
      "learning_rate": 0.000256,
      "loss": 0.555,
      "step": 780
    },
    {
      "epoch": 1.58,
      "grad_norm": 5.121576309204102,
      "learning_rate": 0.0002553939393939394,
      "loss": 0.6566,
      "step": 790
    },
    {
      "epoch": 1.6,
      "grad_norm": 4.232880592346191,
      "learning_rate": 0.00025478787878787876,
      "loss": 0.813,
      "step": 800
    },
    {
      "epoch": 1.6,
      "eval_loss": 0.8688493967056274,
      "eval_runtime": 8.2984,
      "eval_samples_per_second": 24.101,
      "eval_steps_per_second": 24.101,
      "step": 800
    },
    {
      "epoch": 1.62,
      "grad_norm": 3.1002039909362793,
      "learning_rate": 0.00025418181818181817,
      "loss": 0.6851,
      "step": 810
    },
    {
      "epoch": 1.6400000000000001,
      "grad_norm": 3.2227277755737305,
      "learning_rate": 0.0002535757575757576,
      "loss": 0.5887,
      "step": 820
    },
    {
      "epoch": 1.6600000000000001,
      "grad_norm": 4.122708797454834,
      "learning_rate": 0.00025296969696969693,
      "loss": 0.7246,
      "step": 830
    },
    {
      "epoch": 1.6800000000000002,
      "grad_norm": 3.771332263946533,
      "learning_rate": 0.00025236363636363634,
      "loss": 0.6856,
      "step": 840
    },
    {
      "epoch": 1.7,
      "grad_norm": 2.909932851791382,
      "learning_rate": 0.0002517575757575757,
      "loss": 0.7339,
      "step": 850
    },
    {
      "epoch": 1.72,
      "grad_norm": 4.394219398498535,
      "learning_rate": 0.0002511515151515151,
      "loss": 0.6652,
      "step": 860
    },
    {
      "epoch": 1.74,
      "grad_norm": 5.159900188446045,
      "learning_rate": 0.0002505454545454545,
      "loss": 0.6412,
      "step": 870
    },
    {
      "epoch": 1.76,
      "grad_norm": 5.160666465759277,
      "learning_rate": 0.00024993939393939393,
      "loss": 0.7446,
      "step": 880
    },
    {
      "epoch": 1.78,
      "grad_norm": 2.324875593185425,
      "learning_rate": 0.00024933333333333334,
      "loss": 0.5432,
      "step": 890
    },
    {
      "epoch": 1.8,
      "grad_norm": 3.86956787109375,
      "learning_rate": 0.0002487272727272727,
      "loss": 0.6488,
      "step": 900
    },
    {
      "epoch": 1.8,
      "eval_loss": 0.854634702205658,
      "eval_runtime": 8.3787,
      "eval_samples_per_second": 23.87,
      "eval_steps_per_second": 23.87,
      "step": 900
    },
    {
      "epoch": 1.8199999999999998,
      "grad_norm": 2.4557039737701416,
      "learning_rate": 0.0002481212121212121,
      "loss": 0.6504,
      "step": 910
    },
    {
      "epoch": 1.8399999999999999,
      "grad_norm": 4.3523101806640625,
      "learning_rate": 0.00024751515151515146,
      "loss": 0.7897,
      "step": 920
    },
    {
      "epoch": 1.8599999999999999,
      "grad_norm": 2.8304622173309326,
      "learning_rate": 0.0002469090909090909,
      "loss": 0.778,
      "step": 930
    },
    {
      "epoch": 1.88,
      "grad_norm": 5.540661811828613,
      "learning_rate": 0.0002463030303030303,
      "loss": 0.5879,
      "step": 940
    },
    {
      "epoch": 1.9,
      "grad_norm": 4.5477190017700195,
      "learning_rate": 0.00024569696969696964,
      "loss": 0.7551,
      "step": 950
    },
    {
      "epoch": 1.92,
      "grad_norm": 2.1680784225463867,
      "learning_rate": 0.0002450909090909091,
      "loss": 0.5968,
      "step": 960
    },
    {
      "epoch": 1.94,
      "grad_norm": 3.097700357437134,
      "learning_rate": 0.00024448484848484846,
      "loss": 0.9538,
      "step": 970
    },
    {
      "epoch": 1.96,
      "grad_norm": 4.526681900024414,
      "learning_rate": 0.00024387878787878787,
      "loss": 0.7777,
      "step": 980
    },
    {
      "epoch": 1.98,
      "grad_norm": 3.8203365802764893,
      "learning_rate": 0.00024327272727272725,
      "loss": 0.5724,
      "step": 990
    },
    {
      "epoch": 2.0,
      "grad_norm": 2.9786007404327393,
      "learning_rate": 0.00024266666666666664,
      "loss": 0.8393,
      "step": 1000
    },
    {
      "epoch": 2.0,
      "eval_loss": 0.8567561507225037,
      "eval_runtime": 8.3238,
      "eval_samples_per_second": 24.027,
      "eval_steps_per_second": 24.027,
      "step": 1000
    },
    {
      "epoch": 2.02,
      "grad_norm": 4.852372646331787,
      "learning_rate": 0.00024206060606060602,
      "loss": 0.4313,
      "step": 1010
    },
    {
      "epoch": 2.04,
      "grad_norm": 2.8096399307250977,
      "learning_rate": 0.00024145454545454543,
      "loss": 0.522,
      "step": 1020
    },
    {
      "epoch": 2.06,
      "grad_norm": 5.676760196685791,
      "learning_rate": 0.00024084848484848482,
      "loss": 0.6268,
      "step": 1030
    },
    {
      "epoch": 2.08,
      "grad_norm": 3.6747052669525146,
      "learning_rate": 0.00024024242424242423,
      "loss": 0.4996,
      "step": 1040
    },
    {
      "epoch": 2.1,
      "grad_norm": 3.23280668258667,
      "learning_rate": 0.00023963636363636364,
      "loss": 0.4505,
      "step": 1050
    },
    {
      "epoch": 2.12,
      "grad_norm": 2.6936984062194824,
      "learning_rate": 0.00023903030303030302,
      "loss": 0.5226,
      "step": 1060
    },
    {
      "epoch": 2.14,
      "grad_norm": 3.188169479370117,
      "learning_rate": 0.0002384242424242424,
      "loss": 0.4054,
      "step": 1070
    },
    {
      "epoch": 2.16,
      "grad_norm": 4.377176761627197,
      "learning_rate": 0.00023781818181818179,
      "loss": 0.6309,
      "step": 1080
    },
    {
      "epoch": 2.18,
      "grad_norm": 2.601099729537964,
      "learning_rate": 0.0002372121212121212,
      "loss": 0.4496,
      "step": 1090
    },
    {
      "epoch": 2.2,
      "grad_norm": 1.1995338201522827,
      "learning_rate": 0.00023660606060606058,
      "loss": 0.4066,
      "step": 1100
    },
    {
      "epoch": 2.2,
      "eval_loss": 0.96681809425354,
      "eval_runtime": 8.2666,
      "eval_samples_per_second": 24.194,
      "eval_steps_per_second": 24.194,
      "step": 1100
    },
    {
      "epoch": 2.22,
      "grad_norm": 5.214364051818848,
      "learning_rate": 0.00023599999999999996,
      "loss": 0.4523,
      "step": 1110
    },
    {
      "epoch": 2.24,
      "grad_norm": 2.7231826782226562,
      "learning_rate": 0.00023539393939393935,
      "loss": 0.507,
      "step": 1120
    },
    {
      "epoch": 2.26,
      "grad_norm": 1.715259075164795,
      "learning_rate": 0.00023478787878787878,
      "loss": 0.4633,
      "step": 1130
    },
    {
      "epoch": 2.2800000000000002,
      "grad_norm": 4.89074182510376,
      "learning_rate": 0.00023418181818181817,
      "loss": 0.5498,
      "step": 1140
    },
    {
      "epoch": 2.3,
      "grad_norm": 5.835556983947754,
      "learning_rate": 0.00023357575757575755,
      "loss": 0.5084,
      "step": 1150
    },
    {
      "epoch": 2.32,
      "grad_norm": 3.198038101196289,
      "learning_rate": 0.00023296969696969696,
      "loss": 0.4301,
      "step": 1160
    },
    {
      "epoch": 2.34,
      "grad_norm": 2.8619565963745117,
      "learning_rate": 0.00023236363636363634,
      "loss": 0.4827,
      "step": 1170
    },
    {
      "epoch": 2.36,
      "grad_norm": 4.367356300354004,
      "learning_rate": 0.00023175757575757573,
      "loss": 0.4673,
      "step": 1180
    },
    {
      "epoch": 2.38,
      "grad_norm": 2.270390510559082,
      "learning_rate": 0.0002311515151515151,
      "loss": 0.4775,
      "step": 1190
    },
    {
      "epoch": 2.4,
      "grad_norm": 3.75638747215271,
      "learning_rate": 0.00023054545454545452,
      "loss": 0.4472,
      "step": 1200
    },
    {
      "epoch": 2.4,
      "eval_loss": 0.9047857522964478,
      "eval_runtime": 8.3816,
      "eval_samples_per_second": 23.862,
      "eval_steps_per_second": 23.862,
      "step": 1200
    },
    {
      "epoch": 2.42,
      "grad_norm": 2.201381206512451,
      "learning_rate": 0.00022993939393939393,
      "loss": 0.3839,
      "step": 1210
    },
    {
      "epoch": 2.44,
      "grad_norm": 6.683726787567139,
      "learning_rate": 0.00022933333333333332,
      "loss": 0.634,
      "step": 1220
    },
    {
      "epoch": 2.46,
      "grad_norm": 5.531384468078613,
      "learning_rate": 0.00022872727272727273,
      "loss": 0.5144,
      "step": 1230
    },
    {
      "epoch": 2.48,
      "grad_norm": 2.717087507247925,
      "learning_rate": 0.0002281212121212121,
      "loss": 0.5596,
      "step": 1240
    },
    {
      "epoch": 2.5,
      "grad_norm": 3.9761810302734375,
      "learning_rate": 0.0002275151515151515,
      "loss": 0.5618,
      "step": 1250
    },
    {
      "epoch": 2.52,
      "grad_norm": 4.569090843200684,
      "learning_rate": 0.00022690909090909088,
      "loss": 0.6029,
      "step": 1260
    },
    {
      "epoch": 2.54,
      "grad_norm": 4.613070487976074,
      "learning_rate": 0.00022630303030303029,
      "loss": 0.5471,
      "step": 1270
    },
    {
      "epoch": 2.56,
      "grad_norm": 1.581824779510498,
      "learning_rate": 0.00022569696969696967,
      "loss": 0.4036,
      "step": 1280
    },
    {
      "epoch": 2.58,
      "grad_norm": 2.988905191421509,
      "learning_rate": 0.00022509090909090905,
      "loss": 0.416,
      "step": 1290
    },
    {
      "epoch": 2.6,
      "grad_norm": 3.9465646743774414,
      "learning_rate": 0.0002244848484848485,
      "loss": 0.58,
      "step": 1300
    },
    {
      "epoch": 2.6,
      "eval_loss": 0.9085794687271118,
      "eval_runtime": 8.4048,
      "eval_samples_per_second": 23.796,
      "eval_steps_per_second": 23.796,
      "step": 1300
    },
    {
      "epoch": 2.62,
      "grad_norm": 2.777984380722046,
      "learning_rate": 0.00022387878787878787,
      "loss": 0.5663,
      "step": 1310
    },
    {
      "epoch": 2.64,
      "grad_norm": 2.621227741241455,
      "learning_rate": 0.00022327272727272726,
      "loss": 0.4753,
      "step": 1320
    },
    {
      "epoch": 2.66,
      "grad_norm": 4.325503349304199,
      "learning_rate": 0.00022266666666666664,
      "loss": 0.5359,
      "step": 1330
    },
    {
      "epoch": 2.68,
      "grad_norm": 2.2264933586120605,
      "learning_rate": 0.00022206060606060605,
      "loss": 0.4895,
      "step": 1340
    },
    {
      "epoch": 2.7,
      "grad_norm": 2.2048897743225098,
      "learning_rate": 0.00022145454545454543,
      "loss": 0.4465,
      "step": 1350
    },
    {
      "epoch": 2.7199999999999998,
      "grad_norm": 5.001486301422119,
      "learning_rate": 0.00022084848484848482,
      "loss": 0.4991,
      "step": 1360
    },
    {
      "epoch": 2.74,
      "grad_norm": 3.272987127304077,
      "learning_rate": 0.0002202424242424242,
      "loss": 0.4869,
      "step": 1370
    },
    {
      "epoch": 2.76,
      "grad_norm": 4.558635711669922,
      "learning_rate": 0.00021963636363636364,
      "loss": 0.5516,
      "step": 1380
    },
    {
      "epoch": 2.7800000000000002,
      "grad_norm": 2.272073745727539,
      "learning_rate": 0.00021903030303030302,
      "loss": 0.5855,
      "step": 1390
    },
    {
      "epoch": 2.8,
      "grad_norm": 4.314586639404297,
      "learning_rate": 0.0002184242424242424,
      "loss": 0.539,
      "step": 1400
    },
    {
      "epoch": 2.8,
      "eval_loss": 0.9093004465103149,
      "eval_runtime": 8.3965,
      "eval_samples_per_second": 23.819,
      "eval_steps_per_second": 23.819,
      "step": 1400
    },
    {
      "epoch": 2.82,
      "grad_norm": 3.4608523845672607,
      "learning_rate": 0.00021781818181818181,
      "loss": 0.3813,
      "step": 1410
    },
    {
      "epoch": 2.84,
      "grad_norm": 4.146360397338867,
      "learning_rate": 0.0002172121212121212,
      "loss": 0.4093,
      "step": 1420
    },
    {
      "epoch": 2.86,
      "grad_norm": 3.781035900115967,
      "learning_rate": 0.00021660606060606058,
      "loss": 0.4775,
      "step": 1430
    },
    {
      "epoch": 2.88,
      "grad_norm": 3.1716604232788086,
      "learning_rate": 0.00021599999999999996,
      "loss": 0.3661,
      "step": 1440
    },
    {
      "epoch": 2.9,
      "grad_norm": 2.09185528755188,
      "learning_rate": 0.00021539393939393938,
      "loss": 0.3531,
      "step": 1450
    },
    {
      "epoch": 2.92,
      "grad_norm": 2.9692599773406982,
      "learning_rate": 0.00021478787878787876,
      "loss": 0.598,
      "step": 1460
    },
    {
      "epoch": 2.94,
      "grad_norm": 2.0218300819396973,
      "learning_rate": 0.00021418181818181817,
      "loss": 0.4403,
      "step": 1470
    },
    {
      "epoch": 2.96,
      "grad_norm": 4.335900783538818,
      "learning_rate": 0.00021357575757575758,
      "loss": 0.4449,
      "step": 1480
    },
    {
      "epoch": 2.98,
      "grad_norm": 3.455853223800659,
      "learning_rate": 0.00021296969696969696,
      "loss": 0.5524,
      "step": 1490
    },
    {
      "epoch": 3.0,
      "grad_norm": 4.9722089767456055,
      "learning_rate": 0.00021236363636363635,
      "loss": 0.6531,
      "step": 1500
    },
    {
      "epoch": 3.0,
      "eval_loss": 0.8820203542709351,
      "eval_runtime": 8.2638,
      "eval_samples_per_second": 24.202,
      "eval_steps_per_second": 24.202,
      "step": 1500
    },
    {
      "epoch": 3.02,
      "grad_norm": 1.9081685543060303,
      "learning_rate": 0.00021175757575757573,
      "loss": 0.3744,
      "step": 1510
    },
    {
      "epoch": 3.04,
      "grad_norm": 2.249363422393799,
      "learning_rate": 0.00021115151515151514,
      "loss": 0.3249,
      "step": 1520
    },
    {
      "epoch": 3.06,
      "grad_norm": 1.876820683479309,
      "learning_rate": 0.00021054545454545452,
      "loss": 0.3399,
      "step": 1530
    },
    {
      "epoch": 3.08,
      "grad_norm": 3.3700225353240967,
      "learning_rate": 0.0002099393939393939,
      "loss": 0.3342,
      "step": 1540
    },
    {
      "epoch": 3.1,
      "grad_norm": 3.164566993713379,
      "learning_rate": 0.00020933333333333334,
      "loss": 0.4562,
      "step": 1550
    },
    {
      "epoch": 3.12,
      "grad_norm": 3.6894004344940186,
      "learning_rate": 0.00020872727272727273,
      "loss": 0.3439,
      "step": 1560
    },
    {
      "epoch": 3.14,
      "grad_norm": 2.560781240463257,
      "learning_rate": 0.0002081212121212121,
      "loss": 0.3793,
      "step": 1570
    },
    {
      "epoch": 3.16,
      "grad_norm": 1.7197463512420654,
      "learning_rate": 0.0002075151515151515,
      "loss": 0.2934,
      "step": 1580
    },
    {
      "epoch": 3.18,
      "grad_norm": 2.9143757820129395,
      "learning_rate": 0.0002069090909090909,
      "loss": 0.3952,
      "step": 1590
    },
    {
      "epoch": 3.2,
      "grad_norm": 3.259028196334839,
      "learning_rate": 0.0002063030303030303,
      "loss": 0.4394,
      "step": 1600
    },
    {
      "epoch": 3.2,
      "eval_loss": 0.9660078287124634,
      "eval_runtime": 8.3114,
      "eval_samples_per_second": 24.063,
      "eval_steps_per_second": 24.063,
      "step": 1600
    },
    {
      "epoch": 3.22,
      "grad_norm": 1.890338659286499,
      "learning_rate": 0.00020569696969696967,
      "loss": 0.3517,
      "step": 1610
    },
    {
      "epoch": 3.24,
      "grad_norm": 2.9698727130889893,
      "learning_rate": 0.00020509090909090905,
      "loss": 0.313,
      "step": 1620
    },
    {
      "epoch": 3.26,
      "grad_norm": 1.5442240238189697,
      "learning_rate": 0.00020448484848484846,
      "loss": 0.3182,
      "step": 1630
    },
    {
      "epoch": 3.2800000000000002,
      "grad_norm": 3.252124071121216,
      "learning_rate": 0.00020387878787878788,
      "loss": 0.5186,
      "step": 1640
    },
    {
      "epoch": 3.3,
      "grad_norm": 1.5807175636291504,
      "learning_rate": 0.00020327272727272726,
      "loss": 0.3436,
      "step": 1650
    },
    {
      "epoch": 3.32,
      "grad_norm": 1.8653264045715332,
      "learning_rate": 0.00020266666666666664,
      "loss": 0.3495,
      "step": 1660
    },
    {
      "epoch": 3.34,
      "grad_norm": 2.207458019256592,
      "learning_rate": 0.00020206060606060605,
      "loss": 0.3053,
      "step": 1670
    },
    {
      "epoch": 3.36,
      "grad_norm": 3.1611359119415283,
      "learning_rate": 0.00020145454545454544,
      "loss": 0.3618,
      "step": 1680
    },
    {
      "epoch": 3.38,
      "grad_norm": 2.800058126449585,
      "learning_rate": 0.00020084848484848482,
      "loss": 0.4401,
      "step": 1690
    },
    {
      "epoch": 3.4,
      "grad_norm": 3.3246841430664062,
      "learning_rate": 0.0002002424242424242,
      "loss": 0.4043,
      "step": 1700
    },
    {
      "epoch": 3.4,
      "eval_loss": 0.9776403903961182,
      "eval_runtime": 8.284,
      "eval_samples_per_second": 24.143,
      "eval_steps_per_second": 24.143,
      "step": 1700
    },
    {
      "epoch": 3.42,
      "grad_norm": 4.14278507232666,
      "learning_rate": 0.0001996363636363636,
      "loss": 0.4077,
      "step": 1710
    },
    {
      "epoch": 3.44,
      "grad_norm": 2.821286678314209,
      "learning_rate": 0.00019903030303030302,
      "loss": 0.3162,
      "step": 1720
    },
    {
      "epoch": 3.46,
      "grad_norm": 2.114814519882202,
      "learning_rate": 0.0001984242424242424,
      "loss": 0.3932,
      "step": 1730
    },
    {
      "epoch": 3.48,
      "grad_norm": 0.872075080871582,
      "learning_rate": 0.00019781818181818182,
      "loss": 0.3802,
      "step": 1740
    },
    {
      "epoch": 3.5,
      "grad_norm": 2.5759146213531494,
      "learning_rate": 0.0001972121212121212,
      "loss": 0.3882,
      "step": 1750
    },
    {
      "epoch": 3.52,
      "grad_norm": 3.5928008556365967,
      "learning_rate": 0.00019660606060606058,
      "loss": 0.3833,
      "step": 1760
    },
    {
      "epoch": 3.54,
      "grad_norm": 1.930159330368042,
      "learning_rate": 0.00019599999999999997,
      "loss": 0.284,
      "step": 1770
    },
    {
      "epoch": 3.56,
      "grad_norm": 2.0219833850860596,
      "learning_rate": 0.00019539393939393938,
      "loss": 0.3391,
      "step": 1780
    },
    {
      "epoch": 3.58,
      "grad_norm": 1.3844850063323975,
      "learning_rate": 0.00019478787878787876,
      "loss": 0.2799,
      "step": 1790
    },
    {
      "epoch": 3.6,
      "grad_norm": 3.8515312671661377,
      "learning_rate": 0.00019418181818181814,
      "loss": 0.4003,
      "step": 1800
    },
    {
      "epoch": 3.6,
      "eval_loss": 0.9742173552513123,
      "eval_runtime": 8.2793,
      "eval_samples_per_second": 24.157,
      "eval_steps_per_second": 24.157,
      "step": 1800
    },
    {
      "epoch": 3.62,
      "grad_norm": 2.7370500564575195,
      "learning_rate": 0.00019357575757575758,
      "loss": 0.4016,
      "step": 1810
    },
    {
      "epoch": 3.64,
      "grad_norm": 2.4929206371307373,
      "learning_rate": 0.00019296969696969696,
      "loss": 0.4284,
      "step": 1820
    },
    {
      "epoch": 3.66,
      "grad_norm": 7.001133918762207,
      "learning_rate": 0.00019236363636363635,
      "loss": 0.3456,
      "step": 1830
    },
    {
      "epoch": 3.68,
      "grad_norm": 4.347954750061035,
      "learning_rate": 0.00019175757575757573,
      "loss": 0.33,
      "step": 1840
    },
    {
      "epoch": 3.7,
      "grad_norm": 3.5521605014801025,
      "learning_rate": 0.00019115151515151514,
      "loss": 0.3373,
      "step": 1850
    },
    {
      "epoch": 3.7199999999999998,
      "grad_norm": 2.71498966217041,
      "learning_rate": 0.00019054545454545452,
      "loss": 0.3751,
      "step": 1860
    },
    {
      "epoch": 3.74,
      "grad_norm": 1.975975751876831,
      "learning_rate": 0.0001899393939393939,
      "loss": 0.4654,
      "step": 1870
    },
    {
      "epoch": 3.76,
      "grad_norm": 2.1644210815429688,
      "learning_rate": 0.0001893333333333333,
      "loss": 0.3433,
      "step": 1880
    },
    {
      "epoch": 3.7800000000000002,
      "grad_norm": 2.831517219543457,
      "learning_rate": 0.00018872727272727273,
      "loss": 0.3867,
      "step": 1890
    },
    {
      "epoch": 3.8,
      "grad_norm": 2.305332899093628,
      "learning_rate": 0.0001881212121212121,
      "loss": 0.3983,
      "step": 1900
    },
    {
      "epoch": 3.8,
      "eval_loss": 0.980786144733429,
      "eval_runtime": 8.2885,
      "eval_samples_per_second": 24.13,
      "eval_steps_per_second": 24.13,
      "step": 1900
    },
    {
      "epoch": 3.82,
      "grad_norm": 3.620079755783081,
      "learning_rate": 0.0001875151515151515,
      "loss": 0.395,
      "step": 1910
    },
    {
      "epoch": 3.84,
      "grad_norm": 2.496638059616089,
      "learning_rate": 0.0001869090909090909,
      "loss": 0.3284,
      "step": 1920
    },
    {
      "epoch": 3.86,
      "grad_norm": 3.2754437923431396,
      "learning_rate": 0.0001863030303030303,
      "loss": 0.4081,
      "step": 1930
    },
    {
      "epoch": 3.88,
      "grad_norm": 2.4426636695861816,
      "learning_rate": 0.00018569696969696967,
      "loss": 0.3741,
      "step": 1940
    },
    {
      "epoch": 3.9,
      "grad_norm": 2.7102301120758057,
      "learning_rate": 0.00018509090909090906,
      "loss": 0.3771,
      "step": 1950
    },
    {
      "epoch": 3.92,
      "grad_norm": 6.751162052154541,
      "learning_rate": 0.00018448484848484847,
      "loss": 0.4156,
      "step": 1960
    },
    {
      "epoch": 3.94,
      "grad_norm": 3.590602159500122,
      "learning_rate": 0.00018387878787878785,
      "loss": 0.364,
      "step": 1970
    },
    {
      "epoch": 3.96,
      "grad_norm": 1.304194450378418,
      "learning_rate": 0.00018327272727272726,
      "loss": 0.4067,
      "step": 1980
    },
    {
      "epoch": 3.98,
      "grad_norm": 2.3025693893432617,
      "learning_rate": 0.00018266666666666667,
      "loss": 0.2989,
      "step": 1990
    },
    {
      "epoch": 4.0,
      "grad_norm": 3.6866490840911865,
      "learning_rate": 0.00018206060606060605,
      "loss": 0.355,
      "step": 2000
    },
    {
      "epoch": 4.0,
      "eval_loss": 0.9785643219947815,
      "eval_runtime": 8.2785,
      "eval_samples_per_second": 24.159,
      "eval_steps_per_second": 24.159,
      "step": 2000
    },
    {
      "epoch": 4.02,
      "grad_norm": 1.8491110801696777,
      "learning_rate": 0.00018145454545454544,
      "loss": 0.236,
      "step": 2010
    },
    {
      "epoch": 4.04,
      "grad_norm": 2.0237717628479004,
      "learning_rate": 0.00018084848484848482,
      "loss": 0.2743,
      "step": 2020
    },
    {
      "epoch": 4.06,
      "grad_norm": 2.474113702774048,
      "learning_rate": 0.00018024242424242423,
      "loss": 0.2427,
      "step": 2030
    },
    {
      "epoch": 4.08,
      "grad_norm": 1.8834803104400635,
      "learning_rate": 0.00017963636363636361,
      "loss": 0.2298,
      "step": 2040
    },
    {
      "epoch": 4.1,
      "grad_norm": 3.0445854663848877,
      "learning_rate": 0.000179030303030303,
      "loss": 0.2771,
      "step": 2050
    },
    {
      "epoch": 4.12,
      "grad_norm": 1.481652855873108,
      "learning_rate": 0.00017842424242424244,
      "loss": 0.2222,
      "step": 2060
    },
    {
      "epoch": 4.14,
      "grad_norm": 2.4490084648132324,
      "learning_rate": 0.00017781818181818182,
      "loss": 0.3049,
      "step": 2070
    },
    {
      "epoch": 4.16,
      "grad_norm": 3.2091329097747803,
      "learning_rate": 0.0001772121212121212,
      "loss": 0.2374,
      "step": 2080
    },
    {
      "epoch": 4.18,
      "grad_norm": 4.166685104370117,
      "learning_rate": 0.00017660606060606059,
      "loss": 0.2454,
      "step": 2090
    },
    {
      "epoch": 4.2,
      "grad_norm": 3.8221004009246826,
      "learning_rate": 0.000176,
      "loss": 0.357,
      "step": 2100
    },
    {
      "epoch": 4.2,
      "eval_loss": 1.0585620403289795,
      "eval_runtime": 8.3575,
      "eval_samples_per_second": 23.931,
      "eval_steps_per_second": 23.931,
      "step": 2100
    },
    {
      "epoch": 4.22,
      "grad_norm": 3.512897253036499,
      "learning_rate": 0.00017539393939393938,
      "loss": 0.3129,
      "step": 2110
    },
    {
      "epoch": 4.24,
      "grad_norm": 1.8597239255905151,
      "learning_rate": 0.00017478787878787876,
      "loss": 0.2474,
      "step": 2120
    },
    {
      "epoch": 4.26,
      "grad_norm": 2.6927244663238525,
      "learning_rate": 0.00017418181818181815,
      "loss": 0.2931,
      "step": 2130
    },
    {
      "epoch": 4.28,
      "grad_norm": 1.950226068496704,
      "learning_rate": 0.00017357575757575756,
      "loss": 0.2547,
      "step": 2140
    },
    {
      "epoch": 4.3,
      "grad_norm": 1.6488336324691772,
      "learning_rate": 0.00017296969696969697,
      "loss": 0.2728,
      "step": 2150
    },
    {
      "epoch": 4.32,
      "grad_norm": 2.023606538772583,
      "learning_rate": 0.00017236363636363635,
      "loss": 0.3131,
      "step": 2160
    },
    {
      "epoch": 4.34,
      "grad_norm": 2.1187195777893066,
      "learning_rate": 0.00017175757575757576,
      "loss": 0.2921,
      "step": 2170
    },
    {
      "epoch": 4.36,
      "grad_norm": 3.3390607833862305,
      "learning_rate": 0.00017115151515151514,
      "loss": 0.2952,
      "step": 2180
    },
    {
      "epoch": 4.38,
      "grad_norm": 2.1044132709503174,
      "learning_rate": 0.00017054545454545453,
      "loss": 0.3046,
      "step": 2190
    },
    {
      "epoch": 4.4,
      "grad_norm": 2.103407382965088,
      "learning_rate": 0.0001699393939393939,
      "loss": 0.3535,
      "step": 2200
    },
    {
      "epoch": 4.4,
      "eval_loss": 1.04744291305542,
      "eval_runtime": 8.295,
      "eval_samples_per_second": 24.111,
      "eval_steps_per_second": 24.111,
      "step": 2200
    },
    {
      "epoch": 4.42,
      "grad_norm": 2.4107186794281006,
      "learning_rate": 0.00016933333333333332,
      "loss": 0.3175,
      "step": 2210
    },
    {
      "epoch": 4.44,
      "grad_norm": 1.8312257528305054,
      "learning_rate": 0.0001687272727272727,
      "loss": 0.2894,
      "step": 2220
    },
    {
      "epoch": 4.46,
      "grad_norm": 5.350782871246338,
      "learning_rate": 0.0001681212121212121,
      "loss": 0.2943,
      "step": 2230
    },
    {
      "epoch": 4.48,
      "grad_norm": 1.4438714981079102,
      "learning_rate": 0.00016751515151515152,
      "loss": 0.2747,
      "step": 2240
    },
    {
      "epoch": 4.5,
      "grad_norm": 2.816915512084961,
      "learning_rate": 0.0001669090909090909,
      "loss": 0.2738,
      "step": 2250
    },
    {
      "epoch": 4.52,
      "grad_norm": 1.380785346031189,
      "learning_rate": 0.0001663030303030303,
      "loss": 0.3365,
      "step": 2260
    },
    {
      "epoch": 4.54,
      "grad_norm": 2.302946090698242,
      "learning_rate": 0.00016569696969696967,
      "loss": 0.2843,
      "step": 2270
    },
    {
      "epoch": 4.5600000000000005,
      "grad_norm": 1.7175633907318115,
      "learning_rate": 0.00016509090909090908,
      "loss": 0.2735,
      "step": 2280
    },
    {
      "epoch": 4.58,
      "grad_norm": 3.0243067741394043,
      "learning_rate": 0.00016448484848484847,
      "loss": 0.3322,
      "step": 2290
    },
    {
      "epoch": 4.6,
      "grad_norm": 2.7151122093200684,
      "learning_rate": 0.00016387878787878785,
      "loss": 0.2972,
      "step": 2300
    },
    {
      "epoch": 4.6,
      "eval_loss": 1.0326650142669678,
      "eval_runtime": 8.2971,
      "eval_samples_per_second": 24.105,
      "eval_steps_per_second": 24.105,
      "step": 2300
    },
    {
      "epoch": 4.62,
      "grad_norm": 3.400125503540039,
      "learning_rate": 0.00016327272727272723,
      "loss": 0.3217,
      "step": 2310
    },
    {
      "epoch": 4.64,
      "grad_norm": 3.4973578453063965,
      "learning_rate": 0.00016266666666666667,
      "loss": 0.307,
      "step": 2320
    },
    {
      "epoch": 4.66,
      "grad_norm": 1.68332040309906,
      "learning_rate": 0.00016206060606060606,
      "loss": 0.274,
      "step": 2330
    },
    {
      "epoch": 4.68,
      "grad_norm": 4.124138355255127,
      "learning_rate": 0.00016145454545454544,
      "loss": 0.3223,
      "step": 2340
    },
    {
      "epoch": 4.7,
      "grad_norm": 2.0325775146484375,
      "learning_rate": 0.00016084848484848485,
      "loss": 0.2468,
      "step": 2350
    },
    {
      "epoch": 4.72,
      "grad_norm": 3.3807852268218994,
      "learning_rate": 0.00016024242424242423,
      "loss": 0.3113,
      "step": 2360
    },
    {
      "epoch": 4.74,
      "grad_norm": 2.455920696258545,
      "learning_rate": 0.00015963636363636362,
      "loss": 0.3769,
      "step": 2370
    },
    {
      "epoch": 4.76,
      "grad_norm": 3.192748546600342,
      "learning_rate": 0.000159030303030303,
      "loss": 0.2989,
      "step": 2380
    },
    {
      "epoch": 4.78,
      "grad_norm": 3.610895872116089,
      "learning_rate": 0.0001584242424242424,
      "loss": 0.308,
      "step": 2390
    },
    {
      "epoch": 4.8,
      "grad_norm": 0.7758392691612244,
      "learning_rate": 0.0001578181818181818,
      "loss": 0.2238,
      "step": 2400
    },
    {
      "epoch": 4.8,
      "eval_loss": 1.0426901578903198,
      "eval_runtime": 8.2925,
      "eval_samples_per_second": 24.118,
      "eval_steps_per_second": 24.118,
      "step": 2400
    },
    {
      "epoch": 4.82,
      "grad_norm": 2.6392149925231934,
      "learning_rate": 0.0001572121212121212,
      "loss": 0.322,
      "step": 2410
    },
    {
      "epoch": 4.84,
      "grad_norm": 1.968040943145752,
      "learning_rate": 0.00015660606060606061,
      "loss": 0.2988,
      "step": 2420
    },
    {
      "epoch": 4.86,
      "grad_norm": 3.9199717044830322,
      "learning_rate": 0.000156,
      "loss": 0.3289,
      "step": 2430
    },
    {
      "epoch": 4.88,
      "grad_norm": 1.8012877702713013,
      "learning_rate": 0.00015539393939393938,
      "loss": 0.2681,
      "step": 2440
    },
    {
      "epoch": 4.9,
      "grad_norm": 3.7784523963928223,
      "learning_rate": 0.00015478787878787876,
      "loss": 0.374,
      "step": 2450
    },
    {
      "epoch": 4.92,
      "grad_norm": 5.202084064483643,
      "learning_rate": 0.00015418181818181817,
      "loss": 0.2598,
      "step": 2460
    },
    {
      "epoch": 4.9399999999999995,
      "grad_norm": 2.20080304145813,
      "learning_rate": 0.00015357575757575756,
      "loss": 0.3262,
      "step": 2470
    },
    {
      "epoch": 4.96,
      "grad_norm": 1.1455646753311157,
      "learning_rate": 0.00015296969696969694,
      "loss": 0.3098,
      "step": 2480
    },
    {
      "epoch": 4.98,
      "grad_norm": 3.1949846744537354,
      "learning_rate": 0.00015236363636363638,
      "loss": 0.2896,
      "step": 2490
    },
    {
      "epoch": 5.0,
      "grad_norm": 4.398914337158203,
      "learning_rate": 0.00015175757575757576,
      "loss": 0.2974,
      "step": 2500
    },
    {
      "epoch": 5.0,
      "eval_loss": 1.041783094406128,
      "eval_runtime": 8.294,
      "eval_samples_per_second": 24.114,
      "eval_steps_per_second": 24.114,
      "step": 2500
    },
    {
      "epoch": 5.02,
      "grad_norm": 2.016331911087036,
      "learning_rate": 0.00015115151515151515,
      "loss": 0.2656,
      "step": 2510
    },
    {
      "epoch": 5.04,
      "grad_norm": 2.865342378616333,
      "learning_rate": 0.00015054545454545453,
      "loss": 0.2114,
      "step": 2520
    },
    {
      "epoch": 5.06,
      "grad_norm": 3.2592954635620117,
      "learning_rate": 0.00014993939393939394,
      "loss": 0.1772,
      "step": 2530
    },
    {
      "epoch": 5.08,
      "grad_norm": 0.9740108251571655,
      "learning_rate": 0.00014933333333333332,
      "loss": 0.2521,
      "step": 2540
    },
    {
      "epoch": 5.1,
      "grad_norm": 1.588489294052124,
      "learning_rate": 0.0001487272727272727,
      "loss": 0.1855,
      "step": 2550
    },
    {
      "epoch": 5.12,
      "grad_norm": 1.6978524923324585,
      "learning_rate": 0.00014812121212121212,
      "loss": 0.2422,
      "step": 2560
    },
    {
      "epoch": 5.14,
      "grad_norm": 1.8029037714004517,
      "learning_rate": 0.0001475151515151515,
      "loss": 0.2405,
      "step": 2570
    },
    {
      "epoch": 5.16,
      "grad_norm": 1.9646121263504028,
      "learning_rate": 0.00014690909090909088,
      "loss": 0.195,
      "step": 2580
    },
    {
      "epoch": 5.18,
      "grad_norm": 4.746054649353027,
      "learning_rate": 0.0001463030303030303,
      "loss": 0.2188,
      "step": 2590
    },
    {
      "epoch": 5.2,
      "grad_norm": 1.068315863609314,
      "learning_rate": 0.0001456969696969697,
      "loss": 0.2361,
      "step": 2600
    },
    {
      "epoch": 5.2,
      "eval_loss": 1.1470791101455688,
      "eval_runtime": 8.3592,
      "eval_samples_per_second": 23.926,
      "eval_steps_per_second": 23.926,
      "step": 2600
    },
    {
      "epoch": 5.22,
      "grad_norm": 2.0547752380371094,
      "learning_rate": 0.0001450909090909091,
      "loss": 0.1995,
      "step": 2610
    },
    {
      "epoch": 5.24,
      "grad_norm": 3.0153703689575195,
      "learning_rate": 0.00014448484848484847,
      "loss": 0.287,
      "step": 2620
    },
    {
      "epoch": 5.26,
      "grad_norm": 2.7704825401306152,
      "learning_rate": 0.00014387878787878785,
      "loss": 0.2124,
      "step": 2630
    },
    {
      "epoch": 5.28,
      "grad_norm": 3.417245388031006,
      "learning_rate": 0.00014327272727272726,
      "loss": 0.2468,
      "step": 2640
    },
    {
      "epoch": 5.3,
      "grad_norm": 2.4958105087280273,
      "learning_rate": 0.00014266666666666665,
      "loss": 0.2639,
      "step": 2650
    },
    {
      "epoch": 5.32,
      "grad_norm": 6.24518346786499,
      "learning_rate": 0.00014206060606060606,
      "loss": 0.2354,
      "step": 2660
    },
    {
      "epoch": 5.34,
      "grad_norm": 2.356611728668213,
      "learning_rate": 0.00014145454545454544,
      "loss": 0.1937,
      "step": 2670
    },
    {
      "epoch": 5.36,
      "grad_norm": 4.983484268188477,
      "learning_rate": 0.00014084848484848485,
      "loss": 0.2194,
      "step": 2680
    },
    {
      "epoch": 5.38,
      "grad_norm": 2.1360573768615723,
      "learning_rate": 0.00014024242424242423,
      "loss": 0.2397,
      "step": 2690
    },
    {
      "epoch": 5.4,
      "grad_norm": 1.019100308418274,
      "learning_rate": 0.00013963636363636362,
      "loss": 0.237,
      "step": 2700
    },
    {
      "epoch": 5.4,
      "eval_loss": 1.12445068359375,
      "eval_runtime": 8.3887,
      "eval_samples_per_second": 23.842,
      "eval_steps_per_second": 23.842,
      "step": 2700
    },
    {
      "epoch": 5.42,
      "grad_norm": 8.048433303833008,
      "learning_rate": 0.000139030303030303,
      "loss": 0.2528,
      "step": 2710
    },
    {
      "epoch": 5.44,
      "grad_norm": 1.488078236579895,
      "learning_rate": 0.0001384242424242424,
      "loss": 0.2883,
      "step": 2720
    },
    {
      "epoch": 5.46,
      "grad_norm": 2.58583402633667,
      "learning_rate": 0.00013781818181818182,
      "loss": 0.1918,
      "step": 2730
    },
    {
      "epoch": 5.48,
      "grad_norm": 1.7826635837554932,
      "learning_rate": 0.0001372121212121212,
      "loss": 0.2354,
      "step": 2740
    },
    {
      "epoch": 5.5,
      "grad_norm": 2.4625980854034424,
      "learning_rate": 0.0001366060606060606,
      "loss": 0.194,
      "step": 2750
    },
    {
      "epoch": 5.52,
      "grad_norm": 0.9897831082344055,
      "learning_rate": 0.00013599999999999997,
      "loss": 0.232,
      "step": 2760
    },
    {
      "epoch": 5.54,
      "grad_norm": 2.909445285797119,
      "learning_rate": 0.00013539393939393938,
      "loss": 0.2682,
      "step": 2770
    },
    {
      "epoch": 5.5600000000000005,
      "grad_norm": 2.14131498336792,
      "learning_rate": 0.00013478787878787877,
      "loss": 0.206,
      "step": 2780
    },
    {
      "epoch": 5.58,
      "grad_norm": 4.590926647186279,
      "learning_rate": 0.00013418181818181818,
      "loss": 0.2761,
      "step": 2790
    },
    {
      "epoch": 5.6,
      "grad_norm": 1.283805251121521,
      "learning_rate": 0.00013357575757575756,
      "loss": 0.212,
      "step": 2800
    },
    {
      "epoch": 5.6,
      "eval_loss": 1.0451204776763916,
      "eval_runtime": 8.3077,
      "eval_samples_per_second": 24.074,
      "eval_steps_per_second": 24.074,
      "step": 2800
    },
    {
      "epoch": 5.62,
      "grad_norm": 2.487449884414673,
      "learning_rate": 0.00013296969696969697,
      "loss": 0.2381,
      "step": 2810
    },
    {
      "epoch": 5.64,
      "grad_norm": 3.0019009113311768,
      "learning_rate": 0.00013236363636363635,
      "loss": 0.2366,
      "step": 2820
    },
    {
      "epoch": 5.66,
      "grad_norm": 1.9614803791046143,
      "learning_rate": 0.00013175757575757574,
      "loss": 0.2388,
      "step": 2830
    },
    {
      "epoch": 5.68,
      "grad_norm": 3.7558717727661133,
      "learning_rate": 0.00013115151515151515,
      "loss": 0.2329,
      "step": 2840
    },
    {
      "epoch": 5.7,
      "grad_norm": 1.3780975341796875,
      "learning_rate": 0.00013054545454545453,
      "loss": 0.2288,
      "step": 2850
    },
    {
      "epoch": 5.72,
      "grad_norm": 1.0322576761245728,
      "learning_rate": 0.00012993939393939394,
      "loss": 0.2482,
      "step": 2860
    },
    {
      "epoch": 5.74,
      "grad_norm": 2.4888272285461426,
      "learning_rate": 0.00012933333333333332,
      "loss": 0.2862,
      "step": 2870
    },
    {
      "epoch": 5.76,
      "grad_norm": 4.517508506774902,
      "learning_rate": 0.0001287272727272727,
      "loss": 0.2315,
      "step": 2880
    },
    {
      "epoch": 5.78,
      "grad_norm": 1.1384340524673462,
      "learning_rate": 0.0001281212121212121,
      "loss": 0.2436,
      "step": 2890
    },
    {
      "epoch": 5.8,
      "grad_norm": 1.7308495044708252,
      "learning_rate": 0.0001275151515151515,
      "loss": 0.2275,
      "step": 2900
    },
    {
      "epoch": 5.8,
      "eval_loss": 1.1219840049743652,
      "eval_runtime": 8.3854,
      "eval_samples_per_second": 23.851,
      "eval_steps_per_second": 23.851,
      "step": 2900
    },
    {
      "epoch": 5.82,
      "grad_norm": 1.4115033149719238,
      "learning_rate": 0.0001269090909090909,
      "loss": 0.2408,
      "step": 2910
    },
    {
      "epoch": 5.84,
      "grad_norm": 2.1944539546966553,
      "learning_rate": 0.0001263030303030303,
      "loss": 0.2826,
      "step": 2920
    },
    {
      "epoch": 5.86,
      "grad_norm": 0.9970703125,
      "learning_rate": 0.00012569696969696968,
      "loss": 0.2573,
      "step": 2930
    },
    {
      "epoch": 5.88,
      "grad_norm": 5.727844715118408,
      "learning_rate": 0.0001250909090909091,
      "loss": 0.2582,
      "step": 2940
    },
    {
      "epoch": 5.9,
      "grad_norm": 1.6535955667495728,
      "learning_rate": 0.00012448484848484847,
      "loss": 0.2477,
      "step": 2950
    },
    {
      "epoch": 5.92,
      "grad_norm": 2.206785202026367,
      "learning_rate": 0.00012387878787878785,
      "loss": 0.2721,
      "step": 2960
    },
    {
      "epoch": 5.9399999999999995,
      "grad_norm": 2.219635486602783,
      "learning_rate": 0.00012327272727272727,
      "loss": 0.252,
      "step": 2970
    },
    {
      "epoch": 5.96,
      "grad_norm": 10.135674476623535,
      "learning_rate": 0.00012266666666666668,
      "loss": 0.3007,
      "step": 2980
    },
    {
      "epoch": 5.98,
      "grad_norm": 2.4980220794677734,
      "learning_rate": 0.00012206060606060606,
      "loss": 0.2425,
      "step": 2990
    },
    {
      "epoch": 6.0,
      "grad_norm": 0.9705609083175659,
      "learning_rate": 0.00012145454545454544,
      "loss": 0.2538,
      "step": 3000
    },
    {
      "epoch": 6.0,
      "eval_loss": 1.1168187856674194,
      "eval_runtime": 8.3143,
      "eval_samples_per_second": 24.055,
      "eval_steps_per_second": 24.055,
      "step": 3000
    },
    {
      "epoch": 6.02,
      "grad_norm": 1.315528154373169,
      "learning_rate": 0.00012084848484848484,
      "loss": 0.1889,
      "step": 3010
    },
    {
      "epoch": 6.04,
      "grad_norm": 1.7146183252334595,
      "learning_rate": 0.00012024242424242424,
      "loss": 0.1878,
      "step": 3020
    },
    {
      "epoch": 6.06,
      "grad_norm": 1.6597819328308105,
      "learning_rate": 0.00011963636363636363,
      "loss": 0.1803,
      "step": 3030
    },
    {
      "epoch": 6.08,
      "grad_norm": 2.146198034286499,
      "learning_rate": 0.00011903030303030302,
      "loss": 0.219,
      "step": 3040
    },
    {
      "epoch": 6.1,
      "grad_norm": 2.6347556114196777,
      "learning_rate": 0.00011842424242424241,
      "loss": 0.2072,
      "step": 3050
    },
    {
      "epoch": 6.12,
      "grad_norm": 1.6650524139404297,
      "learning_rate": 0.0001178181818181818,
      "loss": 0.1904,
      "step": 3060
    },
    {
      "epoch": 6.14,
      "grad_norm": 1.8509262800216675,
      "learning_rate": 0.00011721212121212121,
      "loss": 0.2085,
      "step": 3070
    },
    {
      "epoch": 6.16,
      "grad_norm": 1.169458031654358,
      "learning_rate": 0.0001166060606060606,
      "loss": 0.1485,
      "step": 3080
    },
    {
      "epoch": 6.18,
      "grad_norm": 2.9435179233551025,
      "learning_rate": 0.00011599999999999999,
      "loss": 0.1839,
      "step": 3090
    },
    {
      "epoch": 6.2,
      "grad_norm": 2.5582618713378906,
      "learning_rate": 0.00011539393939393938,
      "loss": 0.2036,
      "step": 3100
    },
    {
      "epoch": 6.2,
      "eval_loss": 1.169189691543579,
      "eval_runtime": 8.2954,
      "eval_samples_per_second": 24.11,
      "eval_steps_per_second": 24.11,
      "step": 3100
    },
    {
      "epoch": 6.22,
      "grad_norm": 1.7881265878677368,
      "learning_rate": 0.00011478787878787878,
      "loss": 0.1657,
      "step": 3110
    },
    {
      "epoch": 6.24,
      "grad_norm": 12.216320037841797,
      "learning_rate": 0.00011418181818181818,
      "loss": 0.1958,
      "step": 3120
    },
    {
      "epoch": 6.26,
      "grad_norm": 3.752549886703491,
      "learning_rate": 0.00011357575757575756,
      "loss": 0.2095,
      "step": 3130
    },
    {
      "epoch": 6.28,
      "grad_norm": 1.7942112684249878,
      "learning_rate": 0.00011296969696969696,
      "loss": 0.1953,
      "step": 3140
    },
    {
      "epoch": 6.3,
      "grad_norm": 2.6195836067199707,
      "learning_rate": 0.00011236363636363635,
      "loss": 0.1811,
      "step": 3150
    },
    {
      "epoch": 6.32,
      "grad_norm": 1.4511287212371826,
      "learning_rate": 0.00011175757575757575,
      "loss": 0.1927,
      "step": 3160
    },
    {
      "epoch": 6.34,
      "grad_norm": 1.8130640983581543,
      "learning_rate": 0.00011115151515151513,
      "loss": 0.1757,
      "step": 3170
    },
    {
      "epoch": 6.36,
      "grad_norm": 2.8221142292022705,
      "learning_rate": 0.00011054545454545453,
      "loss": 0.2223,
      "step": 3180
    },
    {
      "epoch": 6.38,
      "grad_norm": 2.9054317474365234,
      "learning_rate": 0.00010993939393939392,
      "loss": 0.2074,
      "step": 3190
    },
    {
      "epoch": 6.4,
      "grad_norm": 2.663262367248535,
      "learning_rate": 0.00010933333333333333,
      "loss": 0.2055,
      "step": 3200
    },
    {
      "epoch": 6.4,
      "eval_loss": 1.1804285049438477,
      "eval_runtime": 8.3006,
      "eval_samples_per_second": 24.095,
      "eval_steps_per_second": 24.095,
      "step": 3200
    },
    {
      "epoch": 6.42,
      "grad_norm": 1.9168604612350464,
      "learning_rate": 0.00010872727272727272,
      "loss": 0.1915,
      "step": 3210
    },
    {
      "epoch": 6.44,
      "grad_norm": 2.8729565143585205,
      "learning_rate": 0.0001081212121212121,
      "loss": 0.2137,
      "step": 3220
    },
    {
      "epoch": 6.46,
      "grad_norm": 2.7941408157348633,
      "learning_rate": 0.0001075151515151515,
      "loss": 0.2393,
      "step": 3230
    },
    {
      "epoch": 6.48,
      "grad_norm": 2.4669058322906494,
      "learning_rate": 0.0001069090909090909,
      "loss": 0.2684,
      "step": 3240
    },
    {
      "epoch": 6.5,
      "grad_norm": 5.875432014465332,
      "learning_rate": 0.0001063030303030303,
      "loss": 0.2211,
      "step": 3250
    },
    {
      "epoch": 6.52,
      "grad_norm": 0.7424483895301819,
      "learning_rate": 0.00010569696969696968,
      "loss": 0.1752,
      "step": 3260
    },
    {
      "epoch": 6.54,
      "grad_norm": 3.1022424697875977,
      "learning_rate": 0.00010509090909090908,
      "loss": 0.1896,
      "step": 3270
    },
    {
      "epoch": 6.5600000000000005,
      "grad_norm": 1.9953701496124268,
      "learning_rate": 0.00010448484848484849,
      "loss": 0.194,
      "step": 3280
    },
    {
      "epoch": 6.58,
      "grad_norm": 1.9859970808029175,
      "learning_rate": 0.00010387878787878787,
      "loss": 0.2086,
      "step": 3290
    },
    {
      "epoch": 6.6,
      "grad_norm": 2.1519899368286133,
      "learning_rate": 0.00010327272727272727,
      "loss": 0.2227,
      "step": 3300
    },
    {
      "epoch": 6.6,
      "eval_loss": 1.199540138244629,
      "eval_runtime": 8.2999,
      "eval_samples_per_second": 24.097,
      "eval_steps_per_second": 24.097,
      "step": 3300
    },
    {
      "epoch": 6.62,
      "grad_norm": 2.7893729209899902,
      "learning_rate": 0.00010266666666666665,
      "loss": 0.2067,
      "step": 3310
    },
    {
      "epoch": 6.64,
      "grad_norm": 2.0367045402526855,
      "learning_rate": 0.00010206060606060606,
      "loss": 0.2042,
      "step": 3320
    },
    {
      "epoch": 6.66,
      "grad_norm": 1.7490108013153076,
      "learning_rate": 0.00010145454545454544,
      "loss": 0.196,
      "step": 3330
    },
    {
      "epoch": 6.68,
      "grad_norm": 1.5302900075912476,
      "learning_rate": 0.00010084848484848484,
      "loss": 0.2012,
      "step": 3340
    },
    {
      "epoch": 6.7,
      "grad_norm": 1.0204384326934814,
      "learning_rate": 0.00010024242424242422,
      "loss": 0.2094,
      "step": 3350
    },
    {
      "epoch": 6.72,
      "grad_norm": 1.906189203262329,
      "learning_rate": 9.963636363636362e-05,
      "loss": 0.1873,
      "step": 3360
    },
    {
      "epoch": 6.74,
      "grad_norm": 2.515467405319214,
      "learning_rate": 9.903030303030303e-05,
      "loss": 0.2066,
      "step": 3370
    },
    {
      "epoch": 6.76,
      "grad_norm": 2.8450145721435547,
      "learning_rate": 9.842424242424241e-05,
      "loss": 0.2556,
      "step": 3380
    },
    {
      "epoch": 6.78,
      "grad_norm": 1.7062122821807861,
      "learning_rate": 9.781818181818181e-05,
      "loss": 0.1989,
      "step": 3390
    },
    {
      "epoch": 6.8,
      "grad_norm": 2.30839204788208,
      "learning_rate": 9.72121212121212e-05,
      "loss": 0.2257,
      "step": 3400
    },
    {
      "epoch": 6.8,
      "eval_loss": 1.1880488395690918,
      "eval_runtime": 8.2999,
      "eval_samples_per_second": 24.097,
      "eval_steps_per_second": 24.097,
      "step": 3400
    },
    {
      "epoch": 6.82,
      "grad_norm": 2.9925453662872314,
      "learning_rate": 9.66060606060606e-05,
      "loss": 0.1933,
      "step": 3410
    },
    {
      "epoch": 6.84,
      "grad_norm": 2.658310651779175,
      "learning_rate": 9.599999999999999e-05,
      "loss": 0.2141,
      "step": 3420
    },
    {
      "epoch": 6.86,
      "grad_norm": 1.5866678953170776,
      "learning_rate": 9.539393939393939e-05,
      "loss": 0.2347,
      "step": 3430
    },
    {
      "epoch": 6.88,
      "grad_norm": 4.097548484802246,
      "learning_rate": 9.478787878787877e-05,
      "loss": 0.2,
      "step": 3440
    },
    {
      "epoch": 6.9,
      "grad_norm": 3.5163023471832275,
      "learning_rate": 9.418181818181818e-05,
      "loss": 0.2262,
      "step": 3450
    },
    {
      "epoch": 6.92,
      "grad_norm": 3.412102222442627,
      "learning_rate": 9.357575757575758e-05,
      "loss": 0.2206,
      "step": 3460
    },
    {
      "epoch": 6.9399999999999995,
      "grad_norm": 1.4718878269195557,
      "learning_rate": 9.296969696969696e-05,
      "loss": 0.2099,
      "step": 3470
    },
    {
      "epoch": 6.96,
      "grad_norm": 2.0128889083862305,
      "learning_rate": 9.236363636363636e-05,
      "loss": 0.2088,
      "step": 3480
    },
    {
      "epoch": 6.98,
      "grad_norm": 2.536566972732544,
      "learning_rate": 9.175757575757575e-05,
      "loss": 0.2084,
      "step": 3490
    },
    {
      "epoch": 7.0,
      "grad_norm": 1.2100170850753784,
      "learning_rate": 9.115151515151515e-05,
      "loss": 0.1765,
      "step": 3500
    },
    {
      "epoch": 7.0,
      "eval_loss": 1.1797153949737549,
      "eval_runtime": 8.3077,
      "eval_samples_per_second": 24.074,
      "eval_steps_per_second": 24.074,
      "step": 3500
    },
    {
      "epoch": 7.02,
      "grad_norm": 1.0557528734207153,
      "learning_rate": 9.054545454545453e-05,
      "loss": 0.155,
      "step": 3510
    },
    {
      "epoch": 7.04,
      "grad_norm": 1.0583521127700806,
      "learning_rate": 8.993939393939393e-05,
      "loss": 0.1446,
      "step": 3520
    },
    {
      "epoch": 7.06,
      "grad_norm": 1.107073426246643,
      "learning_rate": 8.933333333333331e-05,
      "loss": 0.1551,
      "step": 3530
    },
    {
      "epoch": 7.08,
      "grad_norm": 1.9758297204971313,
      "learning_rate": 8.872727272727272e-05,
      "loss": 0.1527,
      "step": 3540
    },
    {
      "epoch": 7.1,
      "grad_norm": 2.3395683765411377,
      "learning_rate": 8.812121212121212e-05,
      "loss": 0.1713,
      "step": 3550
    },
    {
      "epoch": 7.12,
      "grad_norm": 1.6849232912063599,
      "learning_rate": 8.75151515151515e-05,
      "loss": 0.1626,
      "step": 3560
    },
    {
      "epoch": 7.14,
      "grad_norm": 1.6423723697662354,
      "learning_rate": 8.69090909090909e-05,
      "loss": 0.1613,
      "step": 3570
    },
    {
      "epoch": 7.16,
      "grad_norm": 1.9360092878341675,
      "learning_rate": 8.63030303030303e-05,
      "loss": 0.1719,
      "step": 3580
    },
    {
      "epoch": 7.18,
      "grad_norm": 1.0723118782043457,
      "learning_rate": 8.56969696969697e-05,
      "loss": 0.164,
      "step": 3590
    },
    {
      "epoch": 7.2,
      "grad_norm": 9.091663360595703,
      "learning_rate": 8.509090909090908e-05,
      "loss": 0.1806,
      "step": 3600
    },
    {
      "epoch": 7.2,
      "eval_loss": 1.2584962844848633,
      "eval_runtime": 8.3096,
      "eval_samples_per_second": 24.069,
      "eval_steps_per_second": 24.069,
      "step": 3600
    },
    {
      "epoch": 7.22,
      "grad_norm": 1.1237927675247192,
      "learning_rate": 8.448484848484848e-05,
      "loss": 0.2037,
      "step": 3610
    },
    {
      "epoch": 7.24,
      "grad_norm": 2.638829469680786,
      "learning_rate": 8.387878787878787e-05,
      "loss": 0.1736,
      "step": 3620
    },
    {
      "epoch": 7.26,
      "grad_norm": 6.929020881652832,
      "learning_rate": 8.327272727272727e-05,
      "loss": 0.1816,
      "step": 3630
    },
    {
      "epoch": 7.28,
      "grad_norm": 1.1218528747558594,
      "learning_rate": 8.266666666666665e-05,
      "loss": 0.1796,
      "step": 3640
    },
    {
      "epoch": 7.3,
      "grad_norm": 1.030897855758667,
      "learning_rate": 8.206060606060605e-05,
      "loss": 0.1748,
      "step": 3650
    },
    {
      "epoch": 7.32,
      "grad_norm": 1.414857029914856,
      "learning_rate": 8.145454545454546e-05,
      "loss": 0.171,
      "step": 3660
    },
    {
      "epoch": 7.34,
      "grad_norm": 1.1973655223846436,
      "learning_rate": 8.084848484848484e-05,
      "loss": 0.1495,
      "step": 3670
    },
    {
      "epoch": 7.36,
      "grad_norm": 1.8362908363342285,
      "learning_rate": 8.024242424242424e-05,
      "loss": 0.1817,
      "step": 3680
    },
    {
      "epoch": 7.38,
      "grad_norm": 2.546264171600342,
      "learning_rate": 7.963636363636362e-05,
      "loss": 0.1689,
      "step": 3690
    },
    {
      "epoch": 7.4,
      "grad_norm": 1.539771318435669,
      "learning_rate": 7.903030303030302e-05,
      "loss": 0.1618,
      "step": 3700
    },
    {
      "epoch": 7.4,
      "eval_loss": 1.2407121658325195,
      "eval_runtime": 8.2863,
      "eval_samples_per_second": 24.136,
      "eval_steps_per_second": 24.136,
      "step": 3700
    },
    {
      "epoch": 7.42,
      "grad_norm": 3.9286272525787354,
      "learning_rate": 7.842424242424242e-05,
      "loss": 0.1976,
      "step": 3710
    },
    {
      "epoch": 7.44,
      "grad_norm": 1.3189611434936523,
      "learning_rate": 7.781818181818181e-05,
      "loss": 0.1553,
      "step": 3720
    },
    {
      "epoch": 7.46,
      "grad_norm": 1.510886788368225,
      "learning_rate": 7.72121212121212e-05,
      "loss": 0.173,
      "step": 3730
    },
    {
      "epoch": 7.48,
      "grad_norm": 1.1833189725875854,
      "learning_rate": 7.66060606060606e-05,
      "loss": 0.1743,
      "step": 3740
    },
    {
      "epoch": 7.5,
      "grad_norm": 2.453373908996582,
      "learning_rate": 7.6e-05,
      "loss": 0.1974,
      "step": 3750
    },
    {
      "epoch": 7.52,
      "grad_norm": 1.8034898042678833,
      "learning_rate": 7.539393939393939e-05,
      "loss": 0.1629,
      "step": 3760
    },
    {
      "epoch": 7.54,
      "grad_norm": 2.502218008041382,
      "learning_rate": 7.478787878787878e-05,
      "loss": 0.1938,
      "step": 3770
    },
    {
      "epoch": 7.5600000000000005,
      "grad_norm": 3.441377878189087,
      "learning_rate": 7.418181818181818e-05,
      "loss": 0.1828,
      "step": 3780
    },
    {
      "epoch": 7.58,
      "grad_norm": 1.6569465398788452,
      "learning_rate": 7.357575757575756e-05,
      "loss": 0.188,
      "step": 3790
    },
    {
      "epoch": 7.6,
      "grad_norm": 1.6648451089859009,
      "learning_rate": 7.296969696969696e-05,
      "loss": 0.1791,
      "step": 3800
    },
    {
      "epoch": 7.6,
      "eval_loss": 1.2372300624847412,
      "eval_runtime": 8.2696,
      "eval_samples_per_second": 24.185,
      "eval_steps_per_second": 24.185,
      "step": 3800
    },
    {
      "epoch": 7.62,
      "grad_norm": 1.085084319114685,
      "learning_rate": 7.236363636363636e-05,
      "loss": 0.1927,
      "step": 3810
    },
    {
      "epoch": 7.64,
      "grad_norm": 3.0945005416870117,
      "learning_rate": 7.175757575757576e-05,
      "loss": 0.1748,
      "step": 3820
    },
    {
      "epoch": 7.66,
      "grad_norm": 2.3875010013580322,
      "learning_rate": 7.115151515151515e-05,
      "loss": 0.1815,
      "step": 3830
    },
    {
      "epoch": 7.68,
      "grad_norm": 2.1163933277130127,
      "learning_rate": 7.054545454545454e-05,
      "loss": 0.1782,
      "step": 3840
    },
    {
      "epoch": 7.7,
      "grad_norm": 3.3381295204162598,
      "learning_rate": 6.993939393939393e-05,
      "loss": 0.1704,
      "step": 3850
    },
    {
      "epoch": 7.72,
      "grad_norm": 1.6373205184936523,
      "learning_rate": 6.933333333333333e-05,
      "loss": 0.1891,
      "step": 3860
    },
    {
      "epoch": 7.74,
      "grad_norm": 1.4362329244613647,
      "learning_rate": 6.872727272727273e-05,
      "loss": 0.1866,
      "step": 3870
    },
    {
      "epoch": 7.76,
      "grad_norm": 0.9459831714630127,
      "learning_rate": 6.812121212121211e-05,
      "loss": 0.1845,
      "step": 3880
    },
    {
      "epoch": 7.78,
      "grad_norm": 3.358895778656006,
      "learning_rate": 6.75151515151515e-05,
      "loss": 0.1758,
      "step": 3890
    },
    {
      "epoch": 7.8,
      "grad_norm": 1.7781330347061157,
      "learning_rate": 6.69090909090909e-05,
      "loss": 0.1885,
      "step": 3900
    },
    {
      "epoch": 7.8,
      "eval_loss": 1.204095721244812,
      "eval_runtime": 8.2749,
      "eval_samples_per_second": 24.169,
      "eval_steps_per_second": 24.169,
      "step": 3900
    },
    {
      "epoch": 7.82,
      "grad_norm": 2.673851728439331,
      "learning_rate": 6.63030303030303e-05,
      "loss": 0.192,
      "step": 3910
    },
    {
      "epoch": 7.84,
      "grad_norm": 2.0801215171813965,
      "learning_rate": 6.569696969696968e-05,
      "loss": 0.184,
      "step": 3920
    },
    {
      "epoch": 7.86,
      "grad_norm": 1.569643259048462,
      "learning_rate": 6.50909090909091e-05,
      "loss": 0.1589,
      "step": 3930
    },
    {
      "epoch": 7.88,
      "grad_norm": 1.4159563779830933,
      "learning_rate": 6.448484848484848e-05,
      "loss": 0.1751,
      "step": 3940
    },
    {
      "epoch": 7.9,
      "grad_norm": 0.5386554598808289,
      "learning_rate": 6.387878787878787e-05,
      "loss": 0.1647,
      "step": 3950
    },
    {
      "epoch": 7.92,
      "grad_norm": 0.792267382144928,
      "learning_rate": 6.327272727272727e-05,
      "loss": 0.1639,
      "step": 3960
    },
    {
      "epoch": 7.9399999999999995,
      "grad_norm": 2.694902181625366,
      "learning_rate": 6.266666666666667e-05,
      "loss": 0.1767,
      "step": 3970
    },
    {
      "epoch": 7.96,
      "grad_norm": 1.5821677446365356,
      "learning_rate": 6.206060606060605e-05,
      "loss": 0.1869,
      "step": 3980
    },
    {
      "epoch": 7.98,
      "grad_norm": 1.4442542791366577,
      "learning_rate": 6.145454545454545e-05,
      "loss": 0.1677,
      "step": 3990
    },
    {
      "epoch": 8.0,
      "grad_norm": 2.843669891357422,
      "learning_rate": 6.0848484848484845e-05,
      "loss": 0.2178,
      "step": 4000
    },
    {
      "epoch": 8.0,
      "eval_loss": 1.216957926750183,
      "eval_runtime": 8.2892,
      "eval_samples_per_second": 24.128,
      "eval_steps_per_second": 24.128,
      "step": 4000
    },
    {
      "epoch": 8.02,
      "grad_norm": 1.6488317251205444,
      "learning_rate": 6.0242424242424235e-05,
      "loss": 0.1396,
      "step": 4010
    },
    {
      "epoch": 8.04,
      "grad_norm": 0.9426301121711731,
      "learning_rate": 5.963636363636363e-05,
      "loss": 0.1458,
      "step": 4020
    },
    {
      "epoch": 8.06,
      "grad_norm": 1.0575205087661743,
      "learning_rate": 5.903030303030302e-05,
      "loss": 0.1459,
      "step": 4030
    },
    {
      "epoch": 8.08,
      "grad_norm": 1.5230728387832642,
      "learning_rate": 5.842424242424242e-05,
      "loss": 0.1341,
      "step": 4040
    },
    {
      "epoch": 8.1,
      "grad_norm": 1.1524090766906738,
      "learning_rate": 5.781818181818181e-05,
      "loss": 0.1542,
      "step": 4050
    },
    {
      "epoch": 8.12,
      "grad_norm": 1.1053056716918945,
      "learning_rate": 5.721212121212121e-05,
      "loss": 0.1486,
      "step": 4060
    },
    {
      "epoch": 8.14,
      "grad_norm": 3.1217689514160156,
      "learning_rate": 5.66060606060606e-05,
      "loss": 0.13,
      "step": 4070
    },
    {
      "epoch": 8.16,
      "grad_norm": 3.0028634071350098,
      "learning_rate": 5.6e-05,
      "loss": 0.177,
      "step": 4080
    },
    {
      "epoch": 8.18,
      "grad_norm": 1.5032556056976318,
      "learning_rate": 5.539393939393939e-05,
      "loss": 0.1522,
      "step": 4090
    },
    {
      "epoch": 8.2,
      "grad_norm": 2.3050246238708496,
      "learning_rate": 5.4787878787878786e-05,
      "loss": 0.147,
      "step": 4100
    },
    {
      "epoch": 8.2,
      "eval_loss": 1.279866099357605,
      "eval_runtime": 8.3076,
      "eval_samples_per_second": 24.074,
      "eval_steps_per_second": 24.074,
      "step": 4100
    },
    {
      "epoch": 8.22,
      "grad_norm": 1.0584700107574463,
      "learning_rate": 5.4181818181818176e-05,
      "loss": 0.1373,
      "step": 4110
    },
    {
      "epoch": 8.24,
      "grad_norm": 1.3406814336776733,
      "learning_rate": 5.357575757575757e-05,
      "loss": 0.1661,
      "step": 4120
    },
    {
      "epoch": 8.26,
      "grad_norm": 1.387112021446228,
      "learning_rate": 5.296969696969696e-05,
      "loss": 0.1683,
      "step": 4130
    },
    {
      "epoch": 8.28,
      "grad_norm": 1.3889877796173096,
      "learning_rate": 5.236363636363636e-05,
      "loss": 0.1757,
      "step": 4140
    },
    {
      "epoch": 8.3,
      "grad_norm": 2.250617265701294,
      "learning_rate": 5.175757575757575e-05,
      "loss": 0.1459,
      "step": 4150
    },
    {
      "epoch": 8.32,
      "grad_norm": 1.501625657081604,
      "learning_rate": 5.115151515151514e-05,
      "loss": 0.1571,
      "step": 4160
    },
    {
      "epoch": 8.34,
      "grad_norm": 2.3244283199310303,
      "learning_rate": 5.0545454545454544e-05,
      "loss": 0.174,
      "step": 4170
    },
    {
      "epoch": 8.36,
      "grad_norm": 1.4789795875549316,
      "learning_rate": 4.9999999999999996e-05,
      "loss": 0.159,
      "step": 4180
    },
    {
      "epoch": 8.38,
      "grad_norm": 2.052640438079834,
      "learning_rate": 4.939393939393939e-05,
      "loss": 0.1539,
      "step": 4190
    },
    {
      "epoch": 8.4,
      "grad_norm": 1.396630883216858,
      "learning_rate": 4.878787878787878e-05,
      "loss": 0.1503,
      "step": 4200
    },
    {
      "epoch": 8.4,
      "eval_loss": 1.2922531366348267,
      "eval_runtime": 8.321,
      "eval_samples_per_second": 24.035,
      "eval_steps_per_second": 24.035,
      "step": 4200
    },
    {
      "epoch": 8.42,
      "grad_norm": 1.934179663658142,
      "learning_rate": 4.818181818181818e-05,
      "loss": 0.1489,
      "step": 4210
    },
    {
      "epoch": 8.44,
      "grad_norm": 1.6492558717727661,
      "learning_rate": 4.757575757575757e-05,
      "loss": 0.1773,
      "step": 4220
    },
    {
      "epoch": 8.46,
      "grad_norm": 1.270771861076355,
      "learning_rate": 4.6969696969696966e-05,
      "loss": 0.1569,
      "step": 4230
    },
    {
      "epoch": 8.48,
      "grad_norm": 1.621276617050171,
      "learning_rate": 4.6363636363636356e-05,
      "loss": 0.1608,
      "step": 4240
    },
    {
      "epoch": 8.5,
      "grad_norm": 1.710384488105774,
      "learning_rate": 4.575757575757576e-05,
      "loss": 0.155,
      "step": 4250
    },
    {
      "epoch": 8.52,
      "grad_norm": 2.35994553565979,
      "learning_rate": 4.515151515151515e-05,
      "loss": 0.1437,
      "step": 4260
    },
    {
      "epoch": 8.54,
      "grad_norm": 1.6499927043914795,
      "learning_rate": 4.454545454545455e-05,
      "loss": 0.1473,
      "step": 4270
    },
    {
      "epoch": 8.56,
      "grad_norm": 1.5886965990066528,
      "learning_rate": 4.393939393939394e-05,
      "loss": 0.1611,
      "step": 4280
    },
    {
      "epoch": 8.58,
      "grad_norm": 1.0344032049179077,
      "learning_rate": 4.333333333333333e-05,
      "loss": 0.1626,
      "step": 4290
    },
    {
      "epoch": 8.6,
      "grad_norm": 1.171900987625122,
      "learning_rate": 4.2727272727272724e-05,
      "loss": 0.1484,
      "step": 4300
    },
    {
      "epoch": 8.6,
      "eval_loss": 1.2983626127243042,
      "eval_runtime": 8.3353,
      "eval_samples_per_second": 23.994,
      "eval_steps_per_second": 23.994,
      "step": 4300
    },
    {
      "epoch": 8.62,
      "grad_norm": 0.9722713828086853,
      "learning_rate": 4.2121212121212114e-05,
      "loss": 0.1531,
      "step": 4310
    },
    {
      "epoch": 8.64,
      "grad_norm": 2.83231520652771,
      "learning_rate": 4.151515151515151e-05,
      "loss": 0.1902,
      "step": 4320
    },
    {
      "epoch": 8.66,
      "grad_norm": 3.20650315284729,
      "learning_rate": 4.09090909090909e-05,
      "loss": 0.1589,
      "step": 4330
    },
    {
      "epoch": 8.68,
      "grad_norm": 1.2530497312545776,
      "learning_rate": 4.03030303030303e-05,
      "loss": 0.1342,
      "step": 4340
    },
    {
      "epoch": 8.7,
      "grad_norm": 1.21558678150177,
      "learning_rate": 3.969696969696969e-05,
      "loss": 0.1429,
      "step": 4350
    },
    {
      "epoch": 8.72,
      "grad_norm": 1.5336549282073975,
      "learning_rate": 3.909090909090909e-05,
      "loss": 0.1661,
      "step": 4360
    },
    {
      "epoch": 8.74,
      "grad_norm": 3.5603537559509277,
      "learning_rate": 3.848484848484848e-05,
      "loss": 0.1524,
      "step": 4370
    },
    {
      "epoch": 8.76,
      "grad_norm": 2.1983590126037598,
      "learning_rate": 3.787878787878788e-05,
      "loss": 0.1219,
      "step": 4380
    },
    {
      "epoch": 8.78,
      "grad_norm": 2.002007246017456,
      "learning_rate": 3.727272727272727e-05,
      "loss": 0.1827,
      "step": 4390
    },
    {
      "epoch": 8.8,
      "grad_norm": 1.4147248268127441,
      "learning_rate": 3.666666666666666e-05,
      "loss": 0.1579,
      "step": 4400
    },
    {
      "epoch": 8.8,
      "eval_loss": 1.2945083379745483,
      "eval_runtime": 8.3376,
      "eval_samples_per_second": 23.988,
      "eval_steps_per_second": 23.988,
      "step": 4400
    },
    {
      "epoch": 8.82,
      "grad_norm": 3.0779197216033936,
      "learning_rate": 3.6060606060606056e-05,
      "loss": 0.1853,
      "step": 4410
    },
    {
      "epoch": 8.84,
      "grad_norm": 1.3204951286315918,
      "learning_rate": 3.545454545454545e-05,
      "loss": 0.157,
      "step": 4420
    },
    {
      "epoch": 8.86,
      "grad_norm": 0.8730218410491943,
      "learning_rate": 3.484848484848484e-05,
      "loss": 0.1767,
      "step": 4430
    },
    {
      "epoch": 8.88,
      "grad_norm": 1.693150520324707,
      "learning_rate": 3.424242424242424e-05,
      "loss": 0.1555,
      "step": 4440
    },
    {
      "epoch": 8.9,
      "grad_norm": 3.437899351119995,
      "learning_rate": 3.3636363636363636e-05,
      "loss": 0.1612,
      "step": 4450
    },
    {
      "epoch": 8.92,
      "grad_norm": 1.0831084251403809,
      "learning_rate": 3.3030303030303027e-05,
      "loss": 0.1495,
      "step": 4460
    },
    {
      "epoch": 8.94,
      "grad_norm": 1.6855430603027344,
      "learning_rate": 3.2424242424242423e-05,
      "loss": 0.1526,
      "step": 4470
    },
    {
      "epoch": 8.96,
      "grad_norm": 1.4066938161849976,
      "learning_rate": 3.1818181818181814e-05,
      "loss": 0.166,
      "step": 4480
    },
    {
      "epoch": 8.98,
      "grad_norm": 1.3868179321289062,
      "learning_rate": 3.121212121212121e-05,
      "loss": 0.14,
      "step": 4490
    },
    {
      "epoch": 9.0,
      "grad_norm": 2.647041082382202,
      "learning_rate": 3.060606060606061e-05,
      "loss": 0.1639,
      "step": 4500
    },
    {
      "epoch": 9.0,
      "eval_loss": 1.294573187828064,
      "eval_runtime": 8.2879,
      "eval_samples_per_second": 24.132,
      "eval_steps_per_second": 24.132,
      "step": 4500
    }
  ],
  "logging_steps": 10,
  "max_steps": 5000,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 10,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 1.3472250200064e+16,
  "train_batch_size": 1,
  "trial_name": null,
  "trial_params": null
}

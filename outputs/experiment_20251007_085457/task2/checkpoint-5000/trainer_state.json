{
  "best_global_step": null,
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 10.0,
  "eval_steps": 100,
  "global_step": 5000,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.02,
      "grad_norm": 31.824350357055664,
      "learning_rate": 2.9999999999999997e-05,
      "loss": 5.5089,
      "step": 10
    },
    {
      "epoch": 0.04,
      "grad_norm": 9.42630672454834,
      "learning_rate": 8.999999999999999e-05,
      "loss": 3.9961,
      "step": 20
    },
    {
      "epoch": 0.06,
      "grad_norm": 5.983250617980957,
      "learning_rate": 0.00015,
      "loss": 2.4585,
      "step": 30
    },
    {
      "epoch": 0.08,
      "grad_norm": 4.293997287750244,
      "learning_rate": 0.00020999999999999998,
      "loss": 1.647,
      "step": 40
    },
    {
      "epoch": 0.1,
      "grad_norm": 3.196378469467163,
      "learning_rate": 0.00027,
      "loss": 1.4489,
      "step": 50
    },
    {
      "epoch": 0.12,
      "grad_norm": 2.3730931282043457,
      "learning_rate": 0.00029969696969696965,
      "loss": 1.4916,
      "step": 60
    },
    {
      "epoch": 0.14,
      "grad_norm": 2.1573657989501953,
      "learning_rate": 0.00029909090909090906,
      "loss": 1.3983,
      "step": 70
    },
    {
      "epoch": 0.16,
      "grad_norm": 2.4373586177825928,
      "learning_rate": 0.00029848484848484847,
      "loss": 1.3191,
      "step": 80
    },
    {
      "epoch": 0.18,
      "grad_norm": 2.127647876739502,
      "learning_rate": 0.00029787878787878783,
      "loss": 1.2395,
      "step": 90
    },
    {
      "epoch": 0.2,
      "grad_norm": 2.762594223022461,
      "learning_rate": 0.00029727272727272724,
      "loss": 1.0642,
      "step": 100
    },
    {
      "epoch": 0.2,
      "eval_loss": 1.360715627670288,
      "eval_runtime": 8.4864,
      "eval_samples_per_second": 23.567,
      "eval_steps_per_second": 23.567,
      "step": 100
    },
    {
      "epoch": 0.22,
      "grad_norm": 3.4578042030334473,
      "learning_rate": 0.00029666666666666665,
      "loss": 1.1095,
      "step": 110
    },
    {
      "epoch": 0.24,
      "grad_norm": 2.9435534477233887,
      "learning_rate": 0.00029606060606060606,
      "loss": 1.3874,
      "step": 120
    },
    {
      "epoch": 0.26,
      "grad_norm": 2.344564199447632,
      "learning_rate": 0.0002954545454545454,
      "loss": 1.112,
      "step": 130
    },
    {
      "epoch": 0.28,
      "grad_norm": 1.8096864223480225,
      "learning_rate": 0.0002948484848484848,
      "loss": 1.0515,
      "step": 140
    },
    {
      "epoch": 0.3,
      "grad_norm": 3.379401922225952,
      "learning_rate": 0.00029424242424242424,
      "loss": 1.4242,
      "step": 150
    },
    {
      "epoch": 0.32,
      "grad_norm": 2.6481871604919434,
      "learning_rate": 0.0002936363636363636,
      "loss": 1.4446,
      "step": 160
    },
    {
      "epoch": 0.34,
      "grad_norm": 2.1773464679718018,
      "learning_rate": 0.000293030303030303,
      "loss": 1.382,
      "step": 170
    },
    {
      "epoch": 0.36,
      "grad_norm": 2.88419771194458,
      "learning_rate": 0.00029242424242424236,
      "loss": 1.1435,
      "step": 180
    },
    {
      "epoch": 0.38,
      "grad_norm": 2.7203867435455322,
      "learning_rate": 0.0002918181818181818,
      "loss": 1.3682,
      "step": 190
    },
    {
      "epoch": 0.4,
      "grad_norm": 2.5978047847747803,
      "learning_rate": 0.0002912121212121212,
      "loss": 1.1283,
      "step": 200
    },
    {
      "epoch": 0.4,
      "eval_loss": 1.2990139722824097,
      "eval_runtime": 8.3786,
      "eval_samples_per_second": 23.87,
      "eval_steps_per_second": 23.87,
      "step": 200
    },
    {
      "epoch": 0.42,
      "grad_norm": 1.7494685649871826,
      "learning_rate": 0.0002906060606060606,
      "loss": 1.3931,
      "step": 210
    },
    {
      "epoch": 0.44,
      "grad_norm": 1.5556150674819946,
      "learning_rate": 0.00029,
      "loss": 1.2002,
      "step": 220
    },
    {
      "epoch": 0.46,
      "grad_norm": 3.653916120529175,
      "learning_rate": 0.00028939393939393936,
      "loss": 1.3017,
      "step": 230
    },
    {
      "epoch": 0.48,
      "grad_norm": 1.8318575620651245,
      "learning_rate": 0.00028878787878787877,
      "loss": 1.2699,
      "step": 240
    },
    {
      "epoch": 0.5,
      "grad_norm": 2.543137311935425,
      "learning_rate": 0.0002881818181818181,
      "loss": 1.2567,
      "step": 250
    },
    {
      "epoch": 0.52,
      "grad_norm": 2.7390682697296143,
      "learning_rate": 0.00028757575757575753,
      "loss": 1.1145,
      "step": 260
    },
    {
      "epoch": 0.54,
      "grad_norm": 2.0575966835021973,
      "learning_rate": 0.00028696969696969695,
      "loss": 1.3846,
      "step": 270
    },
    {
      "epoch": 0.56,
      "grad_norm": 2.6980552673339844,
      "learning_rate": 0.00028636363636363636,
      "loss": 1.2071,
      "step": 280
    },
    {
      "epoch": 0.58,
      "grad_norm": 2.00356388092041,
      "learning_rate": 0.00028575757575757577,
      "loss": 1.2507,
      "step": 290
    },
    {
      "epoch": 0.6,
      "grad_norm": 1.7089440822601318,
      "learning_rate": 0.0002851515151515151,
      "loss": 1.3743,
      "step": 300
    },
    {
      "epoch": 0.6,
      "eval_loss": 1.2804358005523682,
      "eval_runtime": 8.3346,
      "eval_samples_per_second": 23.996,
      "eval_steps_per_second": 23.996,
      "step": 300
    },
    {
      "epoch": 0.62,
      "grad_norm": 2.2938170433044434,
      "learning_rate": 0.00028454545454545453,
      "loss": 1.2133,
      "step": 310
    },
    {
      "epoch": 0.64,
      "grad_norm": 2.5752294063568115,
      "learning_rate": 0.0002839393939393939,
      "loss": 1.0713,
      "step": 320
    },
    {
      "epoch": 0.66,
      "grad_norm": 1.7876880168914795,
      "learning_rate": 0.0002833333333333333,
      "loss": 1.2588,
      "step": 330
    },
    {
      "epoch": 0.68,
      "grad_norm": 2.5541703701019287,
      "learning_rate": 0.0002827272727272727,
      "loss": 1.282,
      "step": 340
    },
    {
      "epoch": 0.7,
      "grad_norm": 1.7459930181503296,
      "learning_rate": 0.00028212121212121207,
      "loss": 1.136,
      "step": 350
    },
    {
      "epoch": 0.72,
      "grad_norm": 1.9549219608306885,
      "learning_rate": 0.00028151515151515153,
      "loss": 1.1199,
      "step": 360
    },
    {
      "epoch": 0.74,
      "grad_norm": 3.0383317470550537,
      "learning_rate": 0.0002809090909090909,
      "loss": 1.3607,
      "step": 370
    },
    {
      "epoch": 0.76,
      "grad_norm": 2.574889659881592,
      "learning_rate": 0.0002803030303030303,
      "loss": 1.3495,
      "step": 380
    },
    {
      "epoch": 0.78,
      "grad_norm": 2.361762762069702,
      "learning_rate": 0.00027969696969696965,
      "loss": 1.4202,
      "step": 390
    },
    {
      "epoch": 0.8,
      "grad_norm": 2.3793270587921143,
      "learning_rate": 0.00027909090909090906,
      "loss": 1.1843,
      "step": 400
    },
    {
      "epoch": 0.8,
      "eval_loss": 1.270863652229309,
      "eval_runtime": 8.3143,
      "eval_samples_per_second": 24.055,
      "eval_steps_per_second": 24.055,
      "step": 400
    },
    {
      "epoch": 0.82,
      "grad_norm": 2.337578535079956,
      "learning_rate": 0.0002784848484848485,
      "loss": 1.1106,
      "step": 410
    },
    {
      "epoch": 0.84,
      "grad_norm": 1.8824033737182617,
      "learning_rate": 0.00027787878787878783,
      "loss": 1.0065,
      "step": 420
    },
    {
      "epoch": 0.86,
      "grad_norm": 2.707064151763916,
      "learning_rate": 0.00027727272727272724,
      "loss": 1.4389,
      "step": 430
    },
    {
      "epoch": 0.88,
      "grad_norm": 2.116318464279175,
      "learning_rate": 0.00027666666666666665,
      "loss": 1.2081,
      "step": 440
    },
    {
      "epoch": 0.9,
      "grad_norm": 2.0048270225524902,
      "learning_rate": 0.00027606060606060606,
      "loss": 1.3045,
      "step": 450
    },
    {
      "epoch": 0.92,
      "grad_norm": 3.0065903663635254,
      "learning_rate": 0.0002754545454545454,
      "loss": 1.1676,
      "step": 460
    },
    {
      "epoch": 0.94,
      "grad_norm": 2.3590192794799805,
      "learning_rate": 0.00027484848484848483,
      "loss": 1.2595,
      "step": 470
    },
    {
      "epoch": 0.96,
      "grad_norm": 2.038182020187378,
      "learning_rate": 0.00027424242424242424,
      "loss": 1.3478,
      "step": 480
    },
    {
      "epoch": 0.98,
      "grad_norm": 1.7706953287124634,
      "learning_rate": 0.0002736363636363636,
      "loss": 1.2568,
      "step": 490
    },
    {
      "epoch": 1.0,
      "grad_norm": 2.3388524055480957,
      "learning_rate": 0.000273030303030303,
      "loss": 1.4303,
      "step": 500
    },
    {
      "epoch": 1.0,
      "eval_loss": 1.261069416999817,
      "eval_runtime": 8.3529,
      "eval_samples_per_second": 23.944,
      "eval_steps_per_second": 23.944,
      "step": 500
    },
    {
      "epoch": 1.02,
      "grad_norm": 1.3708648681640625,
      "learning_rate": 0.0002724242424242424,
      "loss": 1.2149,
      "step": 510
    },
    {
      "epoch": 1.04,
      "grad_norm": 0.9790984392166138,
      "learning_rate": 0.00027181818181818177,
      "loss": 1.0835,
      "step": 520
    },
    {
      "epoch": 1.06,
      "grad_norm": 2.4457409381866455,
      "learning_rate": 0.0002712121212121212,
      "loss": 0.8753,
      "step": 530
    },
    {
      "epoch": 1.08,
      "grad_norm": 4.748011112213135,
      "learning_rate": 0.0002706060606060606,
      "loss": 0.9642,
      "step": 540
    },
    {
      "epoch": 1.1,
      "grad_norm": 2.3958899974823,
      "learning_rate": 0.00027,
      "loss": 0.9176,
      "step": 550
    },
    {
      "epoch": 1.12,
      "grad_norm": 1.9582551717758179,
      "learning_rate": 0.00026939393939393936,
      "loss": 1.0423,
      "step": 560
    },
    {
      "epoch": 1.1400000000000001,
      "grad_norm": 3.8515281677246094,
      "learning_rate": 0.00026878787878787877,
      "loss": 0.9892,
      "step": 570
    },
    {
      "epoch": 1.16,
      "grad_norm": 2.304800271987915,
      "learning_rate": 0.0002681818181818181,
      "loss": 0.9637,
      "step": 580
    },
    {
      "epoch": 1.18,
      "grad_norm": 2.859189510345459,
      "learning_rate": 0.00026757575757575754,
      "loss": 1.116,
      "step": 590
    },
    {
      "epoch": 1.2,
      "grad_norm": 2.550872564315796,
      "learning_rate": 0.00026696969696969695,
      "loss": 1.0276,
      "step": 600
    },
    {
      "epoch": 1.2,
      "eval_loss": 1.2968695163726807,
      "eval_runtime": 8.3504,
      "eval_samples_per_second": 23.951,
      "eval_steps_per_second": 23.951,
      "step": 600
    },
    {
      "epoch": 1.22,
      "grad_norm": 2.1616811752319336,
      "learning_rate": 0.00026636363636363636,
      "loss": 1.1896,
      "step": 610
    },
    {
      "epoch": 1.24,
      "grad_norm": 2.863703489303589,
      "learning_rate": 0.00026575757575757577,
      "loss": 0.9206,
      "step": 620
    },
    {
      "epoch": 1.26,
      "grad_norm": 3.0207579135894775,
      "learning_rate": 0.0002651515151515151,
      "loss": 1.1709,
      "step": 630
    },
    {
      "epoch": 1.28,
      "grad_norm": 2.7256388664245605,
      "learning_rate": 0.00026454545454545453,
      "loss": 0.936,
      "step": 640
    },
    {
      "epoch": 1.3,
      "grad_norm": 2.5601131916046143,
      "learning_rate": 0.0002639393939393939,
      "loss": 0.891,
      "step": 650
    },
    {
      "epoch": 1.32,
      "grad_norm": 2.8895103931427,
      "learning_rate": 0.0002633333333333333,
      "loss": 0.9954,
      "step": 660
    },
    {
      "epoch": 1.34,
      "grad_norm": 2.6374316215515137,
      "learning_rate": 0.0002627272727272727,
      "loss": 1.0042,
      "step": 670
    },
    {
      "epoch": 1.3599999999999999,
      "grad_norm": 2.2930941581726074,
      "learning_rate": 0.00026212121212121207,
      "loss": 1.1124,
      "step": 680
    },
    {
      "epoch": 1.38,
      "grad_norm": 2.507328510284424,
      "learning_rate": 0.0002615151515151515,
      "loss": 1.0318,
      "step": 690
    },
    {
      "epoch": 1.4,
      "grad_norm": 2.8318774700164795,
      "learning_rate": 0.0002609090909090909,
      "loss": 1.2262,
      "step": 700
    },
    {
      "epoch": 1.4,
      "eval_loss": 1.2741992473602295,
      "eval_runtime": 8.3526,
      "eval_samples_per_second": 23.945,
      "eval_steps_per_second": 23.945,
      "step": 700
    },
    {
      "epoch": 1.42,
      "grad_norm": 2.0267560482025146,
      "learning_rate": 0.0002603030303030303,
      "loss": 1.088,
      "step": 710
    },
    {
      "epoch": 1.44,
      "grad_norm": 2.453033208847046,
      "learning_rate": 0.00025969696969696966,
      "loss": 1.0366,
      "step": 720
    },
    {
      "epoch": 1.46,
      "grad_norm": 2.429091215133667,
      "learning_rate": 0.00025909090909090907,
      "loss": 1.1127,
      "step": 730
    },
    {
      "epoch": 1.48,
      "grad_norm": 1.6207212209701538,
      "learning_rate": 0.0002584848484848485,
      "loss": 0.8989,
      "step": 740
    },
    {
      "epoch": 1.5,
      "grad_norm": 2.4004316329956055,
      "learning_rate": 0.00025787878787878783,
      "loss": 0.9806,
      "step": 750
    },
    {
      "epoch": 1.52,
      "grad_norm": 2.9812750816345215,
      "learning_rate": 0.00025727272727272724,
      "loss": 0.9269,
      "step": 760
    },
    {
      "epoch": 1.54,
      "grad_norm": 2.0947089195251465,
      "learning_rate": 0.00025666666666666665,
      "loss": 1.0913,
      "step": 770
    },
    {
      "epoch": 1.56,
      "grad_norm": 2.138230800628662,
      "learning_rate": 0.000256060606060606,
      "loss": 0.9042,
      "step": 780
    },
    {
      "epoch": 1.58,
      "grad_norm": 2.7038917541503906,
      "learning_rate": 0.0002554545454545454,
      "loss": 1.0543,
      "step": 790
    },
    {
      "epoch": 1.6,
      "grad_norm": 2.3888869285583496,
      "learning_rate": 0.00025484848484848483,
      "loss": 1.1042,
      "step": 800
    },
    {
      "epoch": 1.6,
      "eval_loss": 1.2854729890823364,
      "eval_runtime": 8.3213,
      "eval_samples_per_second": 24.035,
      "eval_steps_per_second": 24.035,
      "step": 800
    },
    {
      "epoch": 1.62,
      "grad_norm": 2.05314302444458,
      "learning_rate": 0.00025424242424242424,
      "loss": 1.0548,
      "step": 810
    },
    {
      "epoch": 1.6400000000000001,
      "grad_norm": 2.6928727626800537,
      "learning_rate": 0.0002536363636363636,
      "loss": 1.0773,
      "step": 820
    },
    {
      "epoch": 1.6600000000000001,
      "grad_norm": 3.1522486209869385,
      "learning_rate": 0.000253030303030303,
      "loss": 1.176,
      "step": 830
    },
    {
      "epoch": 1.6800000000000002,
      "grad_norm": 3.4347009658813477,
      "learning_rate": 0.0002524242424242424,
      "loss": 1.2414,
      "step": 840
    },
    {
      "epoch": 1.7,
      "grad_norm": 2.991150140762329,
      "learning_rate": 0.0002518181818181818,
      "loss": 0.9109,
      "step": 850
    },
    {
      "epoch": 1.72,
      "grad_norm": 2.5516440868377686,
      "learning_rate": 0.0002512121212121212,
      "loss": 1.0493,
      "step": 860
    },
    {
      "epoch": 1.74,
      "grad_norm": 2.6884396076202393,
      "learning_rate": 0.0002506060606060606,
      "loss": 0.9384,
      "step": 870
    },
    {
      "epoch": 1.76,
      "grad_norm": 2.9700844287872314,
      "learning_rate": 0.00025,
      "loss": 1.1488,
      "step": 880
    },
    {
      "epoch": 1.78,
      "grad_norm": 2.4467318058013916,
      "learning_rate": 0.00024939393939393936,
      "loss": 1.0328,
      "step": 890
    },
    {
      "epoch": 1.8,
      "grad_norm": 2.7083218097686768,
      "learning_rate": 0.00024878787878787877,
      "loss": 0.9565,
      "step": 900
    },
    {
      "epoch": 1.8,
      "eval_loss": 1.2830439805984497,
      "eval_runtime": 8.3304,
      "eval_samples_per_second": 24.009,
      "eval_steps_per_second": 24.009,
      "step": 900
    },
    {
      "epoch": 1.8199999999999998,
      "grad_norm": 2.6939494609832764,
      "learning_rate": 0.0002481818181818182,
      "loss": 1.0046,
      "step": 910
    },
    {
      "epoch": 1.8399999999999999,
      "grad_norm": 3.655977725982666,
      "learning_rate": 0.00024757575757575754,
      "loss": 1.2062,
      "step": 920
    },
    {
      "epoch": 1.8599999999999999,
      "grad_norm": 2.671969413757324,
      "learning_rate": 0.00024696969696969695,
      "loss": 0.934,
      "step": 930
    },
    {
      "epoch": 1.88,
      "grad_norm": 2.76751971244812,
      "learning_rate": 0.0002463636363636363,
      "loss": 1.0385,
      "step": 940
    },
    {
      "epoch": 1.9,
      "grad_norm": 3.1029884815216064,
      "learning_rate": 0.0002457575757575757,
      "loss": 0.9276,
      "step": 950
    },
    {
      "epoch": 1.92,
      "grad_norm": 3.503100872039795,
      "learning_rate": 0.0002451515151515151,
      "loss": 0.9188,
      "step": 960
    },
    {
      "epoch": 1.94,
      "grad_norm": 3.6995465755462646,
      "learning_rate": 0.00024454545454545454,
      "loss": 0.8925,
      "step": 970
    },
    {
      "epoch": 1.96,
      "grad_norm": 2.917736291885376,
      "learning_rate": 0.00024393939393939392,
      "loss": 1.2804,
      "step": 980
    },
    {
      "epoch": 1.98,
      "grad_norm": 3.2525243759155273,
      "learning_rate": 0.0002433333333333333,
      "loss": 1.1743,
      "step": 990
    },
    {
      "epoch": 2.0,
      "grad_norm": 1.9313278198242188,
      "learning_rate": 0.0002427272727272727,
      "loss": 0.7956,
      "step": 1000
    },
    {
      "epoch": 2.0,
      "eval_loss": 1.2776482105255127,
      "eval_runtime": 8.4318,
      "eval_samples_per_second": 23.72,
      "eval_steps_per_second": 23.72,
      "step": 1000
    },
    {
      "epoch": 2.02,
      "grad_norm": 2.91316294670105,
      "learning_rate": 0.0002421212121212121,
      "loss": 0.6314,
      "step": 1010
    },
    {
      "epoch": 2.04,
      "grad_norm": 4.105724811553955,
      "learning_rate": 0.00024151515151515148,
      "loss": 0.6669,
      "step": 1020
    },
    {
      "epoch": 2.06,
      "grad_norm": 3.04040789604187,
      "learning_rate": 0.00024090909090909086,
      "loss": 0.8875,
      "step": 1030
    },
    {
      "epoch": 2.08,
      "grad_norm": 3.393908977508545,
      "learning_rate": 0.0002403030303030303,
      "loss": 0.7374,
      "step": 1040
    },
    {
      "epoch": 2.1,
      "grad_norm": 3.094515562057495,
      "learning_rate": 0.00023969696969696968,
      "loss": 0.6348,
      "step": 1050
    },
    {
      "epoch": 2.12,
      "grad_norm": 1.0621004104614258,
      "learning_rate": 0.00023909090909090907,
      "loss": 0.9505,
      "step": 1060
    },
    {
      "epoch": 2.14,
      "grad_norm": 2.919358968734741,
      "learning_rate": 0.00023848484848484848,
      "loss": 0.8165,
      "step": 1070
    },
    {
      "epoch": 2.16,
      "grad_norm": 2.7981016635894775,
      "learning_rate": 0.00023787878787878786,
      "loss": 0.82,
      "step": 1080
    },
    {
      "epoch": 2.18,
      "grad_norm": 3.150472640991211,
      "learning_rate": 0.00023727272727272724,
      "loss": 0.7364,
      "step": 1090
    },
    {
      "epoch": 2.2,
      "grad_norm": 3.0273427963256836,
      "learning_rate": 0.00023666666666666663,
      "loss": 0.662,
      "step": 1100
    },
    {
      "epoch": 2.2,
      "eval_loss": 1.3860788345336914,
      "eval_runtime": 8.3566,
      "eval_samples_per_second": 23.933,
      "eval_steps_per_second": 23.933,
      "step": 1100
    },
    {
      "epoch": 2.22,
      "grad_norm": 3.2370553016662598,
      "learning_rate": 0.00023606060606060604,
      "loss": 0.7568,
      "step": 1110
    },
    {
      "epoch": 2.24,
      "grad_norm": 4.4670000076293945,
      "learning_rate": 0.00023545454545454542,
      "loss": 0.7857,
      "step": 1120
    },
    {
      "epoch": 2.26,
      "grad_norm": 2.550950050354004,
      "learning_rate": 0.00023484848484848483,
      "loss": 0.6401,
      "step": 1130
    },
    {
      "epoch": 2.2800000000000002,
      "grad_norm": 3.073561429977417,
      "learning_rate": 0.00023424242424242424,
      "loss": 0.8434,
      "step": 1140
    },
    {
      "epoch": 2.3,
      "grad_norm": 5.147109031677246,
      "learning_rate": 0.00023363636363636363,
      "loss": 0.6898,
      "step": 1150
    },
    {
      "epoch": 2.32,
      "grad_norm": 2.6489923000335693,
      "learning_rate": 0.000233030303030303,
      "loss": 0.6969,
      "step": 1160
    },
    {
      "epoch": 2.34,
      "grad_norm": 2.568812608718872,
      "learning_rate": 0.0002324242424242424,
      "loss": 0.677,
      "step": 1170
    },
    {
      "epoch": 2.36,
      "grad_norm": 3.0784311294555664,
      "learning_rate": 0.0002318181818181818,
      "loss": 0.7871,
      "step": 1180
    },
    {
      "epoch": 2.38,
      "grad_norm": 3.4828903675079346,
      "learning_rate": 0.00023121212121212119,
      "loss": 0.8794,
      "step": 1190
    },
    {
      "epoch": 2.4,
      "grad_norm": 3.336667060852051,
      "learning_rate": 0.00023060606060606057,
      "loss": 0.7153,
      "step": 1200
    },
    {
      "epoch": 2.4,
      "eval_loss": 1.3979243040084839,
      "eval_runtime": 8.5258,
      "eval_samples_per_second": 23.458,
      "eval_steps_per_second": 23.458,
      "step": 1200
    },
    {
      "epoch": 2.42,
      "grad_norm": 3.896932601928711,
      "learning_rate": 0.00023,
      "loss": 0.7538,
      "step": 1210
    },
    {
      "epoch": 2.44,
      "grad_norm": 3.450413227081299,
      "learning_rate": 0.0002293939393939394,
      "loss": 0.7878,
      "step": 1220
    },
    {
      "epoch": 2.46,
      "grad_norm": 2.9157567024230957,
      "learning_rate": 0.00022878787878787877,
      "loss": 0.6784,
      "step": 1230
    },
    {
      "epoch": 2.48,
      "grad_norm": 2.4618024826049805,
      "learning_rate": 0.00022818181818181816,
      "loss": 0.7908,
      "step": 1240
    },
    {
      "epoch": 2.5,
      "grad_norm": 3.0021297931671143,
      "learning_rate": 0.00022757575757575757,
      "loss": 0.7291,
      "step": 1250
    },
    {
      "epoch": 2.52,
      "grad_norm": 2.5964064598083496,
      "learning_rate": 0.00022696969696969695,
      "loss": 0.7388,
      "step": 1260
    },
    {
      "epoch": 2.54,
      "grad_norm": 3.146303415298462,
      "learning_rate": 0.00022636363636363633,
      "loss": 0.8504,
      "step": 1270
    },
    {
      "epoch": 2.56,
      "grad_norm": 2.47408390045166,
      "learning_rate": 0.00022575757575757572,
      "loss": 0.7434,
      "step": 1280
    },
    {
      "epoch": 2.58,
      "grad_norm": 3.61098313331604,
      "learning_rate": 0.00022515151515151513,
      "loss": 0.8925,
      "step": 1290
    },
    {
      "epoch": 2.6,
      "grad_norm": 3.4083685874938965,
      "learning_rate": 0.00022454545454545454,
      "loss": 0.8258,
      "step": 1300
    },
    {
      "epoch": 2.6,
      "eval_loss": 1.3743782043457031,
      "eval_runtime": 8.4577,
      "eval_samples_per_second": 23.647,
      "eval_steps_per_second": 23.647,
      "step": 1300
    },
    {
      "epoch": 2.62,
      "grad_norm": 4.124070644378662,
      "learning_rate": 0.00022393939393939392,
      "loss": 0.7486,
      "step": 1310
    },
    {
      "epoch": 2.64,
      "grad_norm": 3.438279390335083,
      "learning_rate": 0.00022333333333333333,
      "loss": 0.8453,
      "step": 1320
    },
    {
      "epoch": 2.66,
      "grad_norm": 2.6075046062469482,
      "learning_rate": 0.00022272727272727272,
      "loss": 0.8372,
      "step": 1330
    },
    {
      "epoch": 2.68,
      "grad_norm": 2.885469436645508,
      "learning_rate": 0.0002221212121212121,
      "loss": 0.7674,
      "step": 1340
    },
    {
      "epoch": 2.7,
      "grad_norm": 3.034104824066162,
      "learning_rate": 0.00022151515151515148,
      "loss": 0.6562,
      "step": 1350
    },
    {
      "epoch": 2.7199999999999998,
      "grad_norm": 3.3568146228790283,
      "learning_rate": 0.0002209090909090909,
      "loss": 0.758,
      "step": 1360
    },
    {
      "epoch": 2.74,
      "grad_norm": 4.244499683380127,
      "learning_rate": 0.00022030303030303028,
      "loss": 0.7487,
      "step": 1370
    },
    {
      "epoch": 2.76,
      "grad_norm": 4.049652099609375,
      "learning_rate": 0.00021969696969696969,
      "loss": 0.7377,
      "step": 1380
    },
    {
      "epoch": 2.7800000000000002,
      "grad_norm": 5.362676620483398,
      "learning_rate": 0.0002190909090909091,
      "loss": 0.6957,
      "step": 1390
    },
    {
      "epoch": 2.8,
      "grad_norm": 3.6345643997192383,
      "learning_rate": 0.00021848484848484848,
      "loss": 0.7064,
      "step": 1400
    },
    {
      "epoch": 2.8,
      "eval_loss": 1.3924431800842285,
      "eval_runtime": 8.449,
      "eval_samples_per_second": 23.671,
      "eval_steps_per_second": 23.671,
      "step": 1400
    },
    {
      "epoch": 2.82,
      "grad_norm": 3.2775180339813232,
      "learning_rate": 0.00021787878787878786,
      "loss": 0.7809,
      "step": 1410
    },
    {
      "epoch": 2.84,
      "grad_norm": 2.144714593887329,
      "learning_rate": 0.00021727272727272725,
      "loss": 0.8092,
      "step": 1420
    },
    {
      "epoch": 2.86,
      "grad_norm": 3.1464736461639404,
      "learning_rate": 0.00021666666666666666,
      "loss": 0.7323,
      "step": 1430
    },
    {
      "epoch": 2.88,
      "grad_norm": 3.4985833168029785,
      "learning_rate": 0.00021606060606060604,
      "loss": 0.6972,
      "step": 1440
    },
    {
      "epoch": 2.9,
      "grad_norm": 2.623213529586792,
      "learning_rate": 0.00021545454545454542,
      "loss": 0.8287,
      "step": 1450
    },
    {
      "epoch": 2.92,
      "grad_norm": 2.604328155517578,
      "learning_rate": 0.0002148484848484848,
      "loss": 0.6772,
      "step": 1460
    },
    {
      "epoch": 2.94,
      "grad_norm": 2.6967990398406982,
      "learning_rate": 0.00021424242424242424,
      "loss": 0.745,
      "step": 1470
    },
    {
      "epoch": 2.96,
      "grad_norm": 2.955338954925537,
      "learning_rate": 0.00021363636363636363,
      "loss": 0.7361,
      "step": 1480
    },
    {
      "epoch": 2.98,
      "grad_norm": 4.40716028213501,
      "learning_rate": 0.000213030303030303,
      "loss": 0.8946,
      "step": 1490
    },
    {
      "epoch": 3.0,
      "grad_norm": 2.1960105895996094,
      "learning_rate": 0.00021242424242424242,
      "loss": 0.7309,
      "step": 1500
    },
    {
      "epoch": 3.0,
      "eval_loss": 1.3632663488388062,
      "eval_runtime": 8.4593,
      "eval_samples_per_second": 23.643,
      "eval_steps_per_second": 23.643,
      "step": 1500
    },
    {
      "epoch": 3.02,
      "grad_norm": 2.1437597274780273,
      "learning_rate": 0.0002118181818181818,
      "loss": 0.5703,
      "step": 1510
    },
    {
      "epoch": 3.04,
      "grad_norm": 3.9626271724700928,
      "learning_rate": 0.0002112121212121212,
      "loss": 0.5854,
      "step": 1520
    },
    {
      "epoch": 3.06,
      "grad_norm": 0.7698413729667664,
      "learning_rate": 0.00021060606060606057,
      "loss": 0.4236,
      "step": 1530
    },
    {
      "epoch": 3.08,
      "grad_norm": 3.7282826900482178,
      "learning_rate": 0.00020999999999999998,
      "loss": 0.5735,
      "step": 1540
    },
    {
      "epoch": 3.1,
      "grad_norm": 3.0883212089538574,
      "learning_rate": 0.0002093939393939394,
      "loss": 0.4093,
      "step": 1550
    },
    {
      "epoch": 3.12,
      "grad_norm": 1.1220310926437378,
      "learning_rate": 0.00020878787878787878,
      "loss": 0.4396,
      "step": 1560
    },
    {
      "epoch": 3.14,
      "grad_norm": 3.965778112411499,
      "learning_rate": 0.00020818181818181816,
      "loss": 0.4141,
      "step": 1570
    },
    {
      "epoch": 3.16,
      "grad_norm": 2.680436611175537,
      "learning_rate": 0.00020757575757575757,
      "loss": 0.5551,
      "step": 1580
    },
    {
      "epoch": 3.18,
      "grad_norm": 5.154988765716553,
      "learning_rate": 0.00020696969696969695,
      "loss": 0.5395,
      "step": 1590
    },
    {
      "epoch": 3.2,
      "grad_norm": 3.0943312644958496,
      "learning_rate": 0.00020636363636363634,
      "loss": 0.6132,
      "step": 1600
    },
    {
      "epoch": 3.2,
      "eval_loss": 1.5311596393585205,
      "eval_runtime": 8.4806,
      "eval_samples_per_second": 23.583,
      "eval_steps_per_second": 23.583,
      "step": 1600
    },
    {
      "epoch": 3.22,
      "grad_norm": 4.812530517578125,
      "learning_rate": 0.00020575757575757572,
      "loss": 0.4416,
      "step": 1610
    },
    {
      "epoch": 3.24,
      "grad_norm": 3.28930926322937,
      "learning_rate": 0.00020515151515151513,
      "loss": 0.4942,
      "step": 1620
    },
    {
      "epoch": 3.26,
      "grad_norm": 4.472158908843994,
      "learning_rate": 0.0002045454545454545,
      "loss": 0.4659,
      "step": 1630
    },
    {
      "epoch": 3.2800000000000002,
      "grad_norm": 4.291496276855469,
      "learning_rate": 0.00020393939393939392,
      "loss": 0.5663,
      "step": 1640
    },
    {
      "epoch": 3.3,
      "grad_norm": 4.5075459480285645,
      "learning_rate": 0.00020333333333333333,
      "loss": 0.6841,
      "step": 1650
    },
    {
      "epoch": 3.32,
      "grad_norm": 5.468049049377441,
      "learning_rate": 0.00020272727272727272,
      "loss": 0.5981,
      "step": 1660
    },
    {
      "epoch": 3.34,
      "grad_norm": 4.026059627532959,
      "learning_rate": 0.0002021212121212121,
      "loss": 0.5105,
      "step": 1670
    },
    {
      "epoch": 3.36,
      "grad_norm": 5.646727561950684,
      "learning_rate": 0.00020151515151515148,
      "loss": 0.5342,
      "step": 1680
    },
    {
      "epoch": 3.38,
      "grad_norm": 4.20444917678833,
      "learning_rate": 0.0002009090909090909,
      "loss": 0.5265,
      "step": 1690
    },
    {
      "epoch": 3.4,
      "grad_norm": 1.7735247611999512,
      "learning_rate": 0.00020030303030303028,
      "loss": 0.4617,
      "step": 1700
    },
    {
      "epoch": 3.4,
      "eval_loss": 1.491926670074463,
      "eval_runtime": 8.4758,
      "eval_samples_per_second": 23.597,
      "eval_steps_per_second": 23.597,
      "step": 1700
    },
    {
      "epoch": 3.42,
      "grad_norm": 2.3333394527435303,
      "learning_rate": 0.00019969696969696966,
      "loss": 0.5128,
      "step": 1710
    },
    {
      "epoch": 3.44,
      "grad_norm": 3.3781230449676514,
      "learning_rate": 0.0001990909090909091,
      "loss": 0.6037,
      "step": 1720
    },
    {
      "epoch": 3.46,
      "grad_norm": 3.0362024307250977,
      "learning_rate": 0.00019848484848484848,
      "loss": 0.4725,
      "step": 1730
    },
    {
      "epoch": 3.48,
      "grad_norm": 3.455279588699341,
      "learning_rate": 0.00019787878787878786,
      "loss": 0.4779,
      "step": 1740
    },
    {
      "epoch": 3.5,
      "grad_norm": 6.795024394989014,
      "learning_rate": 0.00019727272727272725,
      "loss": 0.5528,
      "step": 1750
    },
    {
      "epoch": 3.52,
      "grad_norm": 2.9591546058654785,
      "learning_rate": 0.00019666666666666666,
      "loss": 0.5896,
      "step": 1760
    },
    {
      "epoch": 3.54,
      "grad_norm": 3.8482024669647217,
      "learning_rate": 0.00019606060606060604,
      "loss": 0.4723,
      "step": 1770
    },
    {
      "epoch": 3.56,
      "grad_norm": 3.6950953006744385,
      "learning_rate": 0.00019545454545454543,
      "loss": 0.4395,
      "step": 1780
    },
    {
      "epoch": 3.58,
      "grad_norm": 5.394733428955078,
      "learning_rate": 0.0001948484848484848,
      "loss": 0.5509,
      "step": 1790
    },
    {
      "epoch": 3.6,
      "grad_norm": 5.22776460647583,
      "learning_rate": 0.00019424242424242422,
      "loss": 0.4117,
      "step": 1800
    },
    {
      "epoch": 3.6,
      "eval_loss": 1.5711897611618042,
      "eval_runtime": 8.3634,
      "eval_samples_per_second": 23.914,
      "eval_steps_per_second": 23.914,
      "step": 1800
    },
    {
      "epoch": 3.62,
      "grad_norm": 4.430499076843262,
      "learning_rate": 0.00019363636363636363,
      "loss": 0.5296,
      "step": 1810
    },
    {
      "epoch": 3.64,
      "grad_norm": 2.412476062774658,
      "learning_rate": 0.000193030303030303,
      "loss": 0.5045,
      "step": 1820
    },
    {
      "epoch": 3.66,
      "grad_norm": 3.003801107406616,
      "learning_rate": 0.00019242424242424242,
      "loss": 0.3685,
      "step": 1830
    },
    {
      "epoch": 3.68,
      "grad_norm": 0.5277070999145508,
      "learning_rate": 0.0001918181818181818,
      "loss": 0.5502,
      "step": 1840
    },
    {
      "epoch": 3.7,
      "grad_norm": 3.2132630348205566,
      "learning_rate": 0.0001912121212121212,
      "loss": 0.4833,
      "step": 1850
    },
    {
      "epoch": 3.7199999999999998,
      "grad_norm": 8.023280143737793,
      "learning_rate": 0.00019060606060606057,
      "loss": 0.6607,
      "step": 1860
    },
    {
      "epoch": 3.74,
      "grad_norm": 6.04006290435791,
      "learning_rate": 0.00018999999999999998,
      "loss": 0.6223,
      "step": 1870
    },
    {
      "epoch": 3.76,
      "grad_norm": 3.4238228797912598,
      "learning_rate": 0.00018939393939393937,
      "loss": 0.517,
      "step": 1880
    },
    {
      "epoch": 3.7800000000000002,
      "grad_norm": 2.470674514770508,
      "learning_rate": 0.00018878787878787878,
      "loss": 0.6008,
      "step": 1890
    },
    {
      "epoch": 3.8,
      "grad_norm": 5.923041343688965,
      "learning_rate": 0.0001881818181818182,
      "loss": 0.5458,
      "step": 1900
    },
    {
      "epoch": 3.8,
      "eval_loss": 1.5413662195205688,
      "eval_runtime": 8.4548,
      "eval_samples_per_second": 23.655,
      "eval_steps_per_second": 23.655,
      "step": 1900
    },
    {
      "epoch": 3.82,
      "grad_norm": 3.902082920074463,
      "learning_rate": 0.00018757575757575757,
      "loss": 0.3555,
      "step": 1910
    },
    {
      "epoch": 3.84,
      "grad_norm": 5.198898792266846,
      "learning_rate": 0.00018696969696969695,
      "loss": 0.5335,
      "step": 1920
    },
    {
      "epoch": 3.86,
      "grad_norm": 2.4850916862487793,
      "learning_rate": 0.00018636363636363634,
      "loss": 0.5696,
      "step": 1930
    },
    {
      "epoch": 3.88,
      "grad_norm": 3.8094375133514404,
      "learning_rate": 0.00018575757575757575,
      "loss": 0.4755,
      "step": 1940
    },
    {
      "epoch": 3.9,
      "grad_norm": 2.975269317626953,
      "learning_rate": 0.00018515151515151513,
      "loss": 0.6201,
      "step": 1950
    },
    {
      "epoch": 3.92,
      "grad_norm": 4.13555908203125,
      "learning_rate": 0.00018454545454545451,
      "loss": 0.6065,
      "step": 1960
    },
    {
      "epoch": 3.94,
      "grad_norm": 6.026971817016602,
      "learning_rate": 0.0001839393939393939,
      "loss": 0.5056,
      "step": 1970
    },
    {
      "epoch": 3.96,
      "grad_norm": 11.548721313476562,
      "learning_rate": 0.00018333333333333334,
      "loss": 0.6733,
      "step": 1980
    },
    {
      "epoch": 3.98,
      "grad_norm": 2.807055950164795,
      "learning_rate": 0.00018272727272727272,
      "loss": 0.4058,
      "step": 1990
    },
    {
      "epoch": 4.0,
      "grad_norm": 3.836930990219116,
      "learning_rate": 0.0001821212121212121,
      "loss": 0.4933,
      "step": 2000
    },
    {
      "epoch": 4.0,
      "eval_loss": 1.516929268836975,
      "eval_runtime": 8.3966,
      "eval_samples_per_second": 23.819,
      "eval_steps_per_second": 23.819,
      "step": 2000
    },
    {
      "epoch": 4.02,
      "grad_norm": 3.1321208477020264,
      "learning_rate": 0.0001815151515151515,
      "loss": 0.395,
      "step": 2010
    },
    {
      "epoch": 4.04,
      "grad_norm": 4.1933674812316895,
      "learning_rate": 0.0001809090909090909,
      "loss": 0.2893,
      "step": 2020
    },
    {
      "epoch": 4.06,
      "grad_norm": 4.849146366119385,
      "learning_rate": 0.00018030303030303028,
      "loss": 0.3594,
      "step": 2030
    },
    {
      "epoch": 4.08,
      "grad_norm": 4.172895908355713,
      "learning_rate": 0.00017969696969696966,
      "loss": 0.3833,
      "step": 2040
    },
    {
      "epoch": 4.1,
      "grad_norm": 5.038054466247559,
      "learning_rate": 0.00017909090909090907,
      "loss": 0.2922,
      "step": 2050
    },
    {
      "epoch": 4.12,
      "grad_norm": 2.8581275939941406,
      "learning_rate": 0.00017848484848484846,
      "loss": 0.2917,
      "step": 2060
    },
    {
      "epoch": 4.14,
      "grad_norm": 3.544133186340332,
      "learning_rate": 0.00017787878787878787,
      "loss": 0.2652,
      "step": 2070
    },
    {
      "epoch": 4.16,
      "grad_norm": 1.5198699235916138,
      "learning_rate": 0.00017727272727272728,
      "loss": 0.2177,
      "step": 2080
    },
    {
      "epoch": 4.18,
      "grad_norm": 5.879621505737305,
      "learning_rate": 0.00017666666666666666,
      "loss": 0.3707,
      "step": 2090
    },
    {
      "epoch": 4.2,
      "grad_norm": 2.3665595054626465,
      "learning_rate": 0.00017606060606060604,
      "loss": 0.2862,
      "step": 2100
    },
    {
      "epoch": 4.2,
      "eval_loss": 1.6796566247940063,
      "eval_runtime": 8.3844,
      "eval_samples_per_second": 23.854,
      "eval_steps_per_second": 23.854,
      "step": 2100
    },
    {
      "epoch": 4.22,
      "grad_norm": 6.048786163330078,
      "learning_rate": 0.00017545454545454543,
      "loss": 0.2432,
      "step": 2110
    },
    {
      "epoch": 4.24,
      "grad_norm": 2.67124342918396,
      "learning_rate": 0.00017484848484848484,
      "loss": 0.282,
      "step": 2120
    },
    {
      "epoch": 4.26,
      "grad_norm": 3.8301265239715576,
      "learning_rate": 0.00017424242424242422,
      "loss": 0.2304,
      "step": 2130
    },
    {
      "epoch": 4.28,
      "grad_norm": 3.1075520515441895,
      "learning_rate": 0.0001736363636363636,
      "loss": 0.3196,
      "step": 2140
    },
    {
      "epoch": 4.3,
      "grad_norm": 6.510507106781006,
      "learning_rate": 0.00017303030303030304,
      "loss": 0.3673,
      "step": 2150
    },
    {
      "epoch": 4.32,
      "grad_norm": 1.3601794242858887,
      "learning_rate": 0.00017242424242424242,
      "loss": 0.3776,
      "step": 2160
    },
    {
      "epoch": 4.34,
      "grad_norm": 3.0943398475646973,
      "learning_rate": 0.0001718181818181818,
      "loss": 0.2939,
      "step": 2170
    },
    {
      "epoch": 4.36,
      "grad_norm": 3.9552459716796875,
      "learning_rate": 0.0001712121212121212,
      "loss": 0.4041,
      "step": 2180
    },
    {
      "epoch": 4.38,
      "grad_norm": 1.6326022148132324,
      "learning_rate": 0.0001706060606060606,
      "loss": 0.3294,
      "step": 2190
    },
    {
      "epoch": 4.4,
      "grad_norm": 3.5226874351501465,
      "learning_rate": 0.00016999999999999999,
      "loss": 0.3365,
      "step": 2200
    },
    {
      "epoch": 4.4,
      "eval_loss": 1.6952760219573975,
      "eval_runtime": 8.4189,
      "eval_samples_per_second": 23.756,
      "eval_steps_per_second": 23.756,
      "step": 2200
    },
    {
      "epoch": 4.42,
      "grad_norm": 2.5350418090820312,
      "learning_rate": 0.00016939393939393937,
      "loss": 0.3894,
      "step": 2210
    },
    {
      "epoch": 4.44,
      "grad_norm": 4.286139965057373,
      "learning_rate": 0.00016878787878787875,
      "loss": 0.3761,
      "step": 2220
    },
    {
      "epoch": 4.46,
      "grad_norm": 3.6663248538970947,
      "learning_rate": 0.00016818181818181816,
      "loss": 0.248,
      "step": 2230
    },
    {
      "epoch": 4.48,
      "grad_norm": 6.222203731536865,
      "learning_rate": 0.00016757575757575757,
      "loss": 0.3357,
      "step": 2240
    },
    {
      "epoch": 4.5,
      "grad_norm": 3.3572537899017334,
      "learning_rate": 0.00016696969696969696,
      "loss": 0.3733,
      "step": 2250
    },
    {
      "epoch": 4.52,
      "grad_norm": 8.01194953918457,
      "learning_rate": 0.00016636363636363637,
      "loss": 0.3033,
      "step": 2260
    },
    {
      "epoch": 4.54,
      "grad_norm": 4.428007125854492,
      "learning_rate": 0.00016575757575757575,
      "loss": 0.3526,
      "step": 2270
    },
    {
      "epoch": 4.5600000000000005,
      "grad_norm": 4.5765790939331055,
      "learning_rate": 0.00016515151515151513,
      "loss": 0.5762,
      "step": 2280
    },
    {
      "epoch": 4.58,
      "grad_norm": 3.927077054977417,
      "learning_rate": 0.00016454545454545452,
      "loss": 0.3359,
      "step": 2290
    },
    {
      "epoch": 4.6,
      "grad_norm": 4.425536155700684,
      "learning_rate": 0.00016393939393939393,
      "loss": 0.3318,
      "step": 2300
    },
    {
      "epoch": 4.6,
      "eval_loss": 1.6568106412887573,
      "eval_runtime": 8.4187,
      "eval_samples_per_second": 23.757,
      "eval_steps_per_second": 23.757,
      "step": 2300
    },
    {
      "epoch": 4.62,
      "grad_norm": 4.758241653442383,
      "learning_rate": 0.0001633333333333333,
      "loss": 0.2538,
      "step": 2310
    },
    {
      "epoch": 4.64,
      "grad_norm": 2.222537040710449,
      "learning_rate": 0.00016272727272727272,
      "loss": 0.4707,
      "step": 2320
    },
    {
      "epoch": 4.66,
      "grad_norm": 2.8238611221313477,
      "learning_rate": 0.00016212121212121213,
      "loss": 0.3444,
      "step": 2330
    },
    {
      "epoch": 4.68,
      "grad_norm": 4.263259410858154,
      "learning_rate": 0.00016151515151515151,
      "loss": 0.3552,
      "step": 2340
    },
    {
      "epoch": 4.7,
      "grad_norm": 5.042794227600098,
      "learning_rate": 0.0001609090909090909,
      "loss": 0.4608,
      "step": 2350
    },
    {
      "epoch": 4.72,
      "grad_norm": 3.9903409481048584,
      "learning_rate": 0.00016030303030303028,
      "loss": 0.3587,
      "step": 2360
    },
    {
      "epoch": 4.74,
      "grad_norm": 4.852743148803711,
      "learning_rate": 0.0001596969696969697,
      "loss": 0.5766,
      "step": 2370
    },
    {
      "epoch": 4.76,
      "grad_norm": 3.0072689056396484,
      "learning_rate": 0.00015909090909090907,
      "loss": 0.3705,
      "step": 2380
    },
    {
      "epoch": 4.78,
      "grad_norm": 3.701612949371338,
      "learning_rate": 0.00015848484848484846,
      "loss": 0.3568,
      "step": 2390
    },
    {
      "epoch": 4.8,
      "grad_norm": 4.522389888763428,
      "learning_rate": 0.00015787878787878784,
      "loss": 0.4736,
      "step": 2400
    },
    {
      "epoch": 4.8,
      "eval_loss": 1.661820888519287,
      "eval_runtime": 8.3806,
      "eval_samples_per_second": 23.865,
      "eval_steps_per_second": 23.865,
      "step": 2400
    },
    {
      "epoch": 4.82,
      "grad_norm": 6.902163505554199,
      "learning_rate": 0.00015727272727272728,
      "loss": 0.3835,
      "step": 2410
    },
    {
      "epoch": 4.84,
      "grad_norm": 8.153924942016602,
      "learning_rate": 0.00015666666666666666,
      "loss": 0.4331,
      "step": 2420
    },
    {
      "epoch": 4.86,
      "grad_norm": 5.1488494873046875,
      "learning_rate": 0.00015606060606060605,
      "loss": 0.3575,
      "step": 2430
    },
    {
      "epoch": 4.88,
      "grad_norm": 3.384716749191284,
      "learning_rate": 0.00015545454545454546,
      "loss": 0.3436,
      "step": 2440
    },
    {
      "epoch": 4.9,
      "grad_norm": 4.047364711761475,
      "learning_rate": 0.00015484848484848484,
      "loss": 0.3025,
      "step": 2450
    },
    {
      "epoch": 4.92,
      "grad_norm": 4.1649932861328125,
      "learning_rate": 0.00015424242424242422,
      "loss": 0.3729,
      "step": 2460
    },
    {
      "epoch": 4.9399999999999995,
      "grad_norm": 0.6143434047698975,
      "learning_rate": 0.0001536363636363636,
      "loss": 0.3694,
      "step": 2470
    },
    {
      "epoch": 4.96,
      "grad_norm": 2.689258098602295,
      "learning_rate": 0.00015303030303030302,
      "loss": 0.3332,
      "step": 2480
    },
    {
      "epoch": 4.98,
      "grad_norm": 3.2013633251190186,
      "learning_rate": 0.00015242424242424243,
      "loss": 0.3663,
      "step": 2490
    },
    {
      "epoch": 5.0,
      "grad_norm": 4.757541656494141,
      "learning_rate": 0.0001518181818181818,
      "loss": 0.3475,
      "step": 2500
    },
    {
      "epoch": 5.0,
      "eval_loss": 1.7096421718597412,
      "eval_runtime": 8.458,
      "eval_samples_per_second": 23.646,
      "eval_steps_per_second": 23.646,
      "step": 2500
    },
    {
      "epoch": 5.02,
      "grad_norm": 5.287323474884033,
      "learning_rate": 0.00015121212121212122,
      "loss": 0.2484,
      "step": 2510
    },
    {
      "epoch": 5.04,
      "grad_norm": 1.7995449304580688,
      "learning_rate": 0.0001506060606060606,
      "loss": 0.2081,
      "step": 2520
    },
    {
      "epoch": 5.06,
      "grad_norm": 1.1097384691238403,
      "learning_rate": 0.00015,
      "loss": 0.2415,
      "step": 2530
    },
    {
      "epoch": 5.08,
      "grad_norm": 3.8298213481903076,
      "learning_rate": 0.00014939393939393937,
      "loss": 0.2067,
      "step": 2540
    },
    {
      "epoch": 5.1,
      "grad_norm": 5.510688304901123,
      "learning_rate": 0.00014878787878787875,
      "loss": 0.2705,
      "step": 2550
    },
    {
      "epoch": 5.12,
      "grad_norm": 1.0401365756988525,
      "learning_rate": 0.00014818181818181816,
      "loss": 0.2557,
      "step": 2560
    },
    {
      "epoch": 5.14,
      "grad_norm": 1.2408417463302612,
      "learning_rate": 0.00014757575757575757,
      "loss": 0.2339,
      "step": 2570
    },
    {
      "epoch": 5.16,
      "grad_norm": 1.992619276046753,
      "learning_rate": 0.00014696969696969696,
      "loss": 0.307,
      "step": 2580
    },
    {
      "epoch": 5.18,
      "grad_norm": 5.677030563354492,
      "learning_rate": 0.00014636363636363634,
      "loss": 0.3177,
      "step": 2590
    },
    {
      "epoch": 5.2,
      "grad_norm": 2.5262744426727295,
      "learning_rate": 0.00014575757575757575,
      "loss": 0.2279,
      "step": 2600
    },
    {
      "epoch": 5.2,
      "eval_loss": 1.876039743423462,
      "eval_runtime": 8.4904,
      "eval_samples_per_second": 23.556,
      "eval_steps_per_second": 23.556,
      "step": 2600
    },
    {
      "epoch": 5.22,
      "grad_norm": 3.9514670372009277,
      "learning_rate": 0.00014515151515151513,
      "loss": 0.2418,
      "step": 2610
    },
    {
      "epoch": 5.24,
      "grad_norm": 1.6211496591567993,
      "learning_rate": 0.00014454545454545452,
      "loss": 0.2149,
      "step": 2620
    },
    {
      "epoch": 5.26,
      "grad_norm": 2.9486918449401855,
      "learning_rate": 0.00014393939393939393,
      "loss": 0.2908,
      "step": 2630
    },
    {
      "epoch": 5.28,
      "grad_norm": 2.4662790298461914,
      "learning_rate": 0.00014333333333333334,
      "loss": 0.1777,
      "step": 2640
    },
    {
      "epoch": 5.3,
      "grad_norm": 5.037538528442383,
      "learning_rate": 0.00014272727272727272,
      "loss": 0.2114,
      "step": 2650
    },
    {
      "epoch": 5.32,
      "grad_norm": 2.869007110595703,
      "learning_rate": 0.0001421212121212121,
      "loss": 0.2124,
      "step": 2660
    },
    {
      "epoch": 5.34,
      "grad_norm": 2.921386241912842,
      "learning_rate": 0.0001415151515151515,
      "loss": 0.2904,
      "step": 2670
    },
    {
      "epoch": 5.36,
      "grad_norm": 3.552870273590088,
      "learning_rate": 0.0001409090909090909,
      "loss": 0.28,
      "step": 2680
    },
    {
      "epoch": 5.38,
      "grad_norm": 5.81317663192749,
      "learning_rate": 0.00014030303030303028,
      "loss": 0.266,
      "step": 2690
    },
    {
      "epoch": 5.4,
      "grad_norm": 4.074500560760498,
      "learning_rate": 0.0001396969696969697,
      "loss": 0.1875,
      "step": 2700
    },
    {
      "epoch": 5.4,
      "eval_loss": 1.8839232921600342,
      "eval_runtime": 8.4379,
      "eval_samples_per_second": 23.703,
      "eval_steps_per_second": 23.703,
      "step": 2700
    },
    {
      "epoch": 5.42,
      "grad_norm": 3.0882203578948975,
      "learning_rate": 0.00013909090909090908,
      "loss": 0.2021,
      "step": 2710
    },
    {
      "epoch": 5.44,
      "grad_norm": 5.797372817993164,
      "learning_rate": 0.00013848484848484846,
      "loss": 0.2391,
      "step": 2720
    },
    {
      "epoch": 5.46,
      "grad_norm": 7.453126907348633,
      "learning_rate": 0.00013787878787878787,
      "loss": 0.3094,
      "step": 2730
    },
    {
      "epoch": 5.48,
      "grad_norm": 4.62328577041626,
      "learning_rate": 0.00013727272727272725,
      "loss": 0.2373,
      "step": 2740
    },
    {
      "epoch": 5.5,
      "grad_norm": 2.516150951385498,
      "learning_rate": 0.00013666666666666666,
      "loss": 0.2372,
      "step": 2750
    },
    {
      "epoch": 5.52,
      "grad_norm": 5.5096025466918945,
      "learning_rate": 0.00013606060606060605,
      "loss": 0.2431,
      "step": 2760
    },
    {
      "epoch": 5.54,
      "grad_norm": 5.558870792388916,
      "learning_rate": 0.00013545454545454546,
      "loss": 0.2174,
      "step": 2770
    },
    {
      "epoch": 5.5600000000000005,
      "grad_norm": 2.975377082824707,
      "learning_rate": 0.00013484848484848484,
      "loss": 0.2137,
      "step": 2780
    },
    {
      "epoch": 5.58,
      "grad_norm": 4.470019340515137,
      "learning_rate": 0.00013424242424242422,
      "loss": 0.2283,
      "step": 2790
    },
    {
      "epoch": 5.6,
      "grad_norm": 6.677236080169678,
      "learning_rate": 0.0001336363636363636,
      "loss": 0.3759,
      "step": 2800
    },
    {
      "epoch": 5.6,
      "eval_loss": 1.852095365524292,
      "eval_runtime": 8.4684,
      "eval_samples_per_second": 23.617,
      "eval_steps_per_second": 23.617,
      "step": 2800
    },
    {
      "epoch": 5.62,
      "grad_norm": 7.015158653259277,
      "learning_rate": 0.00013303030303030302,
      "loss": 0.2583,
      "step": 2810
    },
    {
      "epoch": 5.64,
      "grad_norm": 4.672359943389893,
      "learning_rate": 0.00013242424242424243,
      "loss": 0.2785,
      "step": 2820
    },
    {
      "epoch": 5.66,
      "grad_norm": 4.238872528076172,
      "learning_rate": 0.0001318181818181818,
      "loss": 0.2399,
      "step": 2830
    },
    {
      "epoch": 5.68,
      "grad_norm": 8.566033363342285,
      "learning_rate": 0.00013127272727272727,
      "loss": 0.2517,
      "step": 2840
    },
    {
      "epoch": 5.7,
      "grad_norm": 1.9014710187911987,
      "learning_rate": 0.00013066666666666665,
      "loss": 0.2604,
      "step": 2850
    },
    {
      "epoch": 5.72,
      "grad_norm": 4.946078300476074,
      "learning_rate": 0.00013006060606060606,
      "loss": 0.1934,
      "step": 2860
    },
    {
      "epoch": 5.74,
      "grad_norm": 1.8114383220672607,
      "learning_rate": 0.00012945454545454545,
      "loss": 0.2033,
      "step": 2870
    },
    {
      "epoch": 5.76,
      "grad_norm": 0.7021611928939819,
      "learning_rate": 0.00012884848484848483,
      "loss": 0.2615,
      "step": 2880
    },
    {
      "epoch": 5.78,
      "grad_norm": 2.485339403152466,
      "learning_rate": 0.00012824242424242421,
      "loss": 0.1712,
      "step": 2890
    },
    {
      "epoch": 5.8,
      "grad_norm": 1.5681393146514893,
      "learning_rate": 0.00012763636363636362,
      "loss": 0.2034,
      "step": 2900
    },
    {
      "epoch": 5.8,
      "eval_loss": 1.8929286003112793,
      "eval_runtime": 8.4826,
      "eval_samples_per_second": 23.578,
      "eval_steps_per_second": 23.578,
      "step": 2900
    },
    {
      "epoch": 5.82,
      "grad_norm": 6.552243232727051,
      "learning_rate": 0.00012703030303030303,
      "loss": 0.2907,
      "step": 2910
    },
    {
      "epoch": 5.84,
      "grad_norm": 2.0107054710388184,
      "learning_rate": 0.00012642424242424242,
      "loss": 0.273,
      "step": 2920
    },
    {
      "epoch": 5.86,
      "grad_norm": 4.755746841430664,
      "learning_rate": 0.0001258181818181818,
      "loss": 0.2679,
      "step": 2930
    },
    {
      "epoch": 5.88,
      "grad_norm": 2.3394103050231934,
      "learning_rate": 0.0001252121212121212,
      "loss": 0.1978,
      "step": 2940
    },
    {
      "epoch": 5.9,
      "grad_norm": 6.44517183303833,
      "learning_rate": 0.0001246060606060606,
      "loss": 0.2952,
      "step": 2950
    },
    {
      "epoch": 5.92,
      "grad_norm": 3.1003735065460205,
      "learning_rate": 0.00012399999999999998,
      "loss": 0.3978,
      "step": 2960
    },
    {
      "epoch": 5.9399999999999995,
      "grad_norm": 3.652350902557373,
      "learning_rate": 0.0001233939393939394,
      "loss": 0.2262,
      "step": 2970
    },
    {
      "epoch": 5.96,
      "grad_norm": 5.359552383422852,
      "learning_rate": 0.00012278787878787877,
      "loss": 0.2675,
      "step": 2980
    },
    {
      "epoch": 5.98,
      "grad_norm": 2.390282392501831,
      "learning_rate": 0.00012218181818181818,
      "loss": 0.3447,
      "step": 2990
    },
    {
      "epoch": 6.0,
      "grad_norm": 8.202448844909668,
      "learning_rate": 0.00012157575757575757,
      "loss": 0.2452,
      "step": 3000
    },
    {
      "epoch": 6.0,
      "eval_loss": 1.801294207572937,
      "eval_runtime": 8.461,
      "eval_samples_per_second": 23.638,
      "eval_steps_per_second": 23.638,
      "step": 3000
    },
    {
      "epoch": 6.02,
      "grad_norm": 0.7370280027389526,
      "learning_rate": 0.00012096969696969695,
      "loss": 0.1541,
      "step": 3010
    },
    {
      "epoch": 6.04,
      "grad_norm": 7.987847328186035,
      "learning_rate": 0.00012036363636363635,
      "loss": 0.1379,
      "step": 3020
    },
    {
      "epoch": 6.06,
      "grad_norm": 2.4938700199127197,
      "learning_rate": 0.00011975757575757576,
      "loss": 0.2245,
      "step": 3030
    },
    {
      "epoch": 6.08,
      "grad_norm": 6.9393229484558105,
      "learning_rate": 0.00011915151515151514,
      "loss": 0.2021,
      "step": 3040
    },
    {
      "epoch": 6.1,
      "grad_norm": 3.029587745666504,
      "learning_rate": 0.00011854545454545454,
      "loss": 0.1398,
      "step": 3050
    },
    {
      "epoch": 6.12,
      "grad_norm": 1.6926524639129639,
      "learning_rate": 0.00011793939393939392,
      "loss": 0.174,
      "step": 3060
    },
    {
      "epoch": 6.14,
      "grad_norm": 1.6222727298736572,
      "learning_rate": 0.00011733333333333333,
      "loss": 0.1985,
      "step": 3070
    },
    {
      "epoch": 6.16,
      "grad_norm": 3.563782215118408,
      "learning_rate": 0.00011672727272727271,
      "loss": 0.2131,
      "step": 3080
    },
    {
      "epoch": 6.18,
      "grad_norm": 5.147577285766602,
      "learning_rate": 0.00011612121212121211,
      "loss": 0.1876,
      "step": 3090
    },
    {
      "epoch": 6.2,
      "grad_norm": 2.2088801860809326,
      "learning_rate": 0.0001155151515151515,
      "loss": 0.1568,
      "step": 3100
    },
    {
      "epoch": 6.2,
      "eval_loss": 2.0474274158477783,
      "eval_runtime": 8.4196,
      "eval_samples_per_second": 23.754,
      "eval_steps_per_second": 23.754,
      "step": 3100
    },
    {
      "epoch": 6.22,
      "grad_norm": 1.4514665603637695,
      "learning_rate": 0.0001149090909090909,
      "loss": 0.1961,
      "step": 3110
    },
    {
      "epoch": 6.24,
      "grad_norm": 7.1024956703186035,
      "learning_rate": 0.0001143030303030303,
      "loss": 0.1895,
      "step": 3120
    },
    {
      "epoch": 6.26,
      "grad_norm": 2.478421449661255,
      "learning_rate": 0.00011369696969696968,
      "loss": 0.1825,
      "step": 3130
    },
    {
      "epoch": 6.28,
      "grad_norm": 3.26662278175354,
      "learning_rate": 0.00011309090909090908,
      "loss": 0.168,
      "step": 3140
    },
    {
      "epoch": 6.3,
      "grad_norm": 2.6551380157470703,
      "learning_rate": 0.00011248484848484848,
      "loss": 0.1695,
      "step": 3150
    },
    {
      "epoch": 6.32,
      "grad_norm": 5.059490203857422,
      "learning_rate": 0.00011187878787878787,
      "loss": 0.2239,
      "step": 3160
    },
    {
      "epoch": 6.34,
      "grad_norm": 2.066511869430542,
      "learning_rate": 0.00011127272727272726,
      "loss": 0.219,
      "step": 3170
    },
    {
      "epoch": 6.36,
      "grad_norm": 2.249162197113037,
      "learning_rate": 0.00011066666666666666,
      "loss": 0.1989,
      "step": 3180
    },
    {
      "epoch": 6.38,
      "grad_norm": 1.3955051898956299,
      "learning_rate": 0.00011006060606060604,
      "loss": 0.176,
      "step": 3190
    },
    {
      "epoch": 6.4,
      "grad_norm": 1.3697041273117065,
      "learning_rate": 0.00010945454545454545,
      "loss": 0.1784,
      "step": 3200
    },
    {
      "epoch": 6.4,
      "eval_loss": 2.0225651264190674,
      "eval_runtime": 8.3868,
      "eval_samples_per_second": 23.847,
      "eval_steps_per_second": 23.847,
      "step": 3200
    },
    {
      "epoch": 6.42,
      "grad_norm": 6.1999616622924805,
      "learning_rate": 0.00010884848484848485,
      "loss": 0.1508,
      "step": 3210
    },
    {
      "epoch": 6.44,
      "grad_norm": 4.375104904174805,
      "learning_rate": 0.00010824242424242423,
      "loss": 0.232,
      "step": 3220
    },
    {
      "epoch": 6.46,
      "grad_norm": 3.2413227558135986,
      "learning_rate": 0.00010763636363636363,
      "loss": 0.1662,
      "step": 3230
    },
    {
      "epoch": 6.48,
      "grad_norm": 1.2305759191513062,
      "learning_rate": 0.00010703030303030302,
      "loss": 0.1753,
      "step": 3240
    },
    {
      "epoch": 6.5,
      "grad_norm": 4.1251912117004395,
      "learning_rate": 0.00010642424242424242,
      "loss": 0.2137,
      "step": 3250
    },
    {
      "epoch": 6.52,
      "grad_norm": 2.1269218921661377,
      "learning_rate": 0.0001058181818181818,
      "loss": 0.1832,
      "step": 3260
    },
    {
      "epoch": 6.54,
      "grad_norm": 4.309729099273682,
      "learning_rate": 0.0001052121212121212,
      "loss": 0.1534,
      "step": 3270
    },
    {
      "epoch": 6.5600000000000005,
      "grad_norm": 5.232161521911621,
      "learning_rate": 0.00010460606060606061,
      "loss": 0.161,
      "step": 3280
    },
    {
      "epoch": 6.58,
      "grad_norm": 1.2978709936141968,
      "learning_rate": 0.000104,
      "loss": 0.2366,
      "step": 3290
    },
    {
      "epoch": 6.6,
      "grad_norm": 7.128479957580566,
      "learning_rate": 0.00010339393939393939,
      "loss": 0.1412,
      "step": 3300
    },
    {
      "epoch": 6.6,
      "eval_loss": 2.1434221267700195,
      "eval_runtime": 8.3768,
      "eval_samples_per_second": 23.875,
      "eval_steps_per_second": 23.875,
      "step": 3300
    },
    {
      "epoch": 6.62,
      "grad_norm": 6.059098720550537,
      "learning_rate": 0.00010278787878787877,
      "loss": 0.2432,
      "step": 3310
    },
    {
      "epoch": 6.64,
      "grad_norm": 1.5276826620101929,
      "learning_rate": 0.00010218181818181817,
      "loss": 0.1389,
      "step": 3320
    },
    {
      "epoch": 6.66,
      "grad_norm": 3.0001113414764404,
      "learning_rate": 0.00010157575757575757,
      "loss": 0.1932,
      "step": 3330
    },
    {
      "epoch": 6.68,
      "grad_norm": 1.7885631322860718,
      "learning_rate": 0.00010096969696969696,
      "loss": 0.2163,
      "step": 3340
    },
    {
      "epoch": 6.7,
      "grad_norm": 0.8591942191123962,
      "learning_rate": 0.00010036363636363635,
      "loss": 0.1501,
      "step": 3350
    },
    {
      "epoch": 6.72,
      "grad_norm": 1.3356622457504272,
      "learning_rate": 9.975757575757574e-05,
      "loss": 0.1768,
      "step": 3360
    },
    {
      "epoch": 6.74,
      "grad_norm": 0.7447725534439087,
      "learning_rate": 9.915151515151515e-05,
      "loss": 0.1869,
      "step": 3370
    },
    {
      "epoch": 6.76,
      "grad_norm": 1.7330182790756226,
      "learning_rate": 9.854545454545454e-05,
      "loss": 0.2016,
      "step": 3380
    },
    {
      "epoch": 6.78,
      "grad_norm": 1.6138828992843628,
      "learning_rate": 9.793939393939394e-05,
      "loss": 0.2037,
      "step": 3390
    },
    {
      "epoch": 6.8,
      "grad_norm": 1.4907708168029785,
      "learning_rate": 9.733333333333332e-05,
      "loss": 0.1559,
      "step": 3400
    },
    {
      "epoch": 6.8,
      "eval_loss": 2.038118839263916,
      "eval_runtime": 8.3569,
      "eval_samples_per_second": 23.932,
      "eval_steps_per_second": 23.932,
      "step": 3400
    },
    {
      "epoch": 6.82,
      "grad_norm": 5.531501770019531,
      "learning_rate": 9.672727272727273e-05,
      "loss": 0.3182,
      "step": 3410
    },
    {
      "epoch": 6.84,
      "grad_norm": 5.400899410247803,
      "learning_rate": 9.612121212121211e-05,
      "loss": 0.2495,
      "step": 3420
    },
    {
      "epoch": 6.86,
      "grad_norm": 9.721686363220215,
      "learning_rate": 9.551515151515151e-05,
      "loss": 0.1675,
      "step": 3430
    },
    {
      "epoch": 6.88,
      "grad_norm": 4.230335712432861,
      "learning_rate": 9.490909090909089e-05,
      "loss": 0.1943,
      "step": 3440
    },
    {
      "epoch": 6.9,
      "grad_norm": 5.853532791137695,
      "learning_rate": 9.43030303030303e-05,
      "loss": 0.2042,
      "step": 3450
    },
    {
      "epoch": 6.92,
      "grad_norm": 3.5261600017547607,
      "learning_rate": 9.369696969696969e-05,
      "loss": 0.2031,
      "step": 3460
    },
    {
      "epoch": 6.9399999999999995,
      "grad_norm": 0.9207387566566467,
      "learning_rate": 9.309090909090908e-05,
      "loss": 0.2402,
      "step": 3470
    },
    {
      "epoch": 6.96,
      "grad_norm": 2.4508042335510254,
      "learning_rate": 9.248484848484847e-05,
      "loss": 0.2068,
      "step": 3480
    },
    {
      "epoch": 6.98,
      "grad_norm": 2.771409749984741,
      "learning_rate": 9.187878787878786e-05,
      "loss": 0.1759,
      "step": 3490
    },
    {
      "epoch": 7.0,
      "grad_norm": 2.416541576385498,
      "learning_rate": 9.127272727272727e-05,
      "loss": 0.1716,
      "step": 3500
    },
    {
      "epoch": 7.0,
      "eval_loss": 2.0118889808654785,
      "eval_runtime": 8.3719,
      "eval_samples_per_second": 23.89,
      "eval_steps_per_second": 23.89,
      "step": 3500
    },
    {
      "epoch": 7.02,
      "grad_norm": 1.1162500381469727,
      "learning_rate": 9.066666666666666e-05,
      "loss": 0.1533,
      "step": 3510
    },
    {
      "epoch": 7.04,
      "grad_norm": 2.7481906414031982,
      "learning_rate": 9.006060606060605e-05,
      "loss": 0.1457,
      "step": 3520
    },
    {
      "epoch": 7.06,
      "grad_norm": 2.2626025676727295,
      "learning_rate": 8.945454545454544e-05,
      "loss": 0.1749,
      "step": 3530
    },
    {
      "epoch": 7.08,
      "grad_norm": 1.1828244924545288,
      "learning_rate": 8.884848484848485e-05,
      "loss": 0.1508,
      "step": 3540
    },
    {
      "epoch": 7.1,
      "grad_norm": 1.5243964195251465,
      "learning_rate": 8.824242424242423e-05,
      "loss": 0.1586,
      "step": 3550
    },
    {
      "epoch": 7.12,
      "grad_norm": 2.9646692276000977,
      "learning_rate": 8.763636363636363e-05,
      "loss": 0.1356,
      "step": 3560
    },
    {
      "epoch": 7.14,
      "grad_norm": 12.946544647216797,
      "learning_rate": 8.703030303030301e-05,
      "loss": 0.136,
      "step": 3570
    },
    {
      "epoch": 7.16,
      "grad_norm": 1.765620231628418,
      "learning_rate": 8.642424242424242e-05,
      "loss": 0.1216,
      "step": 3580
    },
    {
      "epoch": 7.18,
      "grad_norm": 1.3147153854370117,
      "learning_rate": 8.581818181818182e-05,
      "loss": 0.157,
      "step": 3590
    },
    {
      "epoch": 7.2,
      "grad_norm": 1.3346877098083496,
      "learning_rate": 8.52121212121212e-05,
      "loss": 0.1306,
      "step": 3600
    },
    {
      "epoch": 7.2,
      "eval_loss": 2.213824987411499,
      "eval_runtime": 8.3646,
      "eval_samples_per_second": 23.91,
      "eval_steps_per_second": 23.91,
      "step": 3600
    },
    {
      "epoch": 7.22,
      "grad_norm": 0.7421168088912964,
      "learning_rate": 8.46060606060606e-05,
      "loss": 0.156,
      "step": 3610
    },
    {
      "epoch": 7.24,
      "grad_norm": 1.613105058670044,
      "learning_rate": 8.4e-05,
      "loss": 0.1638,
      "step": 3620
    },
    {
      "epoch": 7.26,
      "grad_norm": 1.2735650539398193,
      "learning_rate": 8.339393939393939e-05,
      "loss": 0.1282,
      "step": 3630
    },
    {
      "epoch": 7.28,
      "grad_norm": 1.0066286325454712,
      "learning_rate": 8.278787878787878e-05,
      "loss": 0.1299,
      "step": 3640
    },
    {
      "epoch": 7.3,
      "grad_norm": 7.267411708831787,
      "learning_rate": 8.218181818181817e-05,
      "loss": 0.1679,
      "step": 3650
    },
    {
      "epoch": 7.32,
      "grad_norm": 1.1597394943237305,
      "learning_rate": 8.157575757575756e-05,
      "loss": 0.1519,
      "step": 3660
    },
    {
      "epoch": 7.34,
      "grad_norm": 2.083855390548706,
      "learning_rate": 8.096969696969697e-05,
      "loss": 0.1705,
      "step": 3670
    },
    {
      "epoch": 7.36,
      "grad_norm": 2.796079635620117,
      "learning_rate": 8.036363636363636e-05,
      "loss": 0.1509,
      "step": 3680
    },
    {
      "epoch": 7.38,
      "grad_norm": 0.9493604302406311,
      "learning_rate": 7.975757575757575e-05,
      "loss": 0.1346,
      "step": 3690
    },
    {
      "epoch": 7.4,
      "grad_norm": 1.377395749092102,
      "learning_rate": 7.915151515151514e-05,
      "loss": 0.147,
      "step": 3700
    },
    {
      "epoch": 7.4,
      "eval_loss": 2.1454427242279053,
      "eval_runtime": 8.3906,
      "eval_samples_per_second": 23.836,
      "eval_steps_per_second": 23.836,
      "step": 3700
    },
    {
      "epoch": 7.42,
      "grad_norm": 0.8072552680969238,
      "learning_rate": 7.854545454545454e-05,
      "loss": 0.169,
      "step": 3710
    },
    {
      "epoch": 7.44,
      "grad_norm": 3.2766592502593994,
      "learning_rate": 7.793939393939394e-05,
      "loss": 0.1916,
      "step": 3720
    },
    {
      "epoch": 7.46,
      "grad_norm": 4.55908727645874,
      "learning_rate": 7.733333333333332e-05,
      "loss": 0.1386,
      "step": 3730
    },
    {
      "epoch": 7.48,
      "grad_norm": 7.480082988739014,
      "learning_rate": 7.672727272727272e-05,
      "loss": 0.1637,
      "step": 3740
    },
    {
      "epoch": 7.5,
      "grad_norm": 1.0142470598220825,
      "learning_rate": 7.612121212121213e-05,
      "loss": 0.1466,
      "step": 3750
    },
    {
      "epoch": 7.52,
      "grad_norm": 1.7953531742095947,
      "learning_rate": 7.551515151515151e-05,
      "loss": 0.1557,
      "step": 3760
    },
    {
      "epoch": 7.54,
      "grad_norm": 3.6105246543884277,
      "learning_rate": 7.490909090909091e-05,
      "loss": 0.1705,
      "step": 3770
    },
    {
      "epoch": 7.5600000000000005,
      "grad_norm": 0.9056478142738342,
      "learning_rate": 7.43030303030303e-05,
      "loss": 0.1388,
      "step": 3780
    },
    {
      "epoch": 7.58,
      "grad_norm": 1.584296703338623,
      "learning_rate": 7.369696969696969e-05,
      "loss": 0.193,
      "step": 3790
    },
    {
      "epoch": 7.6,
      "grad_norm": 3.8268463611602783,
      "learning_rate": 7.309090909090908e-05,
      "loss": 0.1249,
      "step": 3800
    },
    {
      "epoch": 7.6,
      "eval_loss": 2.17151141166687,
      "eval_runtime": 8.4946,
      "eval_samples_per_second": 23.544,
      "eval_steps_per_second": 23.544,
      "step": 3800
    },
    {
      "epoch": 7.62,
      "grad_norm": 0.8918410539627075,
      "learning_rate": 7.248484848484848e-05,
      "loss": 0.1449,
      "step": 3810
    },
    {
      "epoch": 7.64,
      "grad_norm": 1.4039084911346436,
      "learning_rate": 7.187878787878786e-05,
      "loss": 0.1521,
      "step": 3820
    },
    {
      "epoch": 7.66,
      "grad_norm": 1.0228874683380127,
      "learning_rate": 7.127272727272726e-05,
      "loss": 0.1313,
      "step": 3830
    },
    {
      "epoch": 7.68,
      "grad_norm": 0.7475129961967468,
      "learning_rate": 7.066666666666666e-05,
      "loss": 0.1881,
      "step": 3840
    },
    {
      "epoch": 7.7,
      "grad_norm": 1.586010456085205,
      "learning_rate": 7.006060606060606e-05,
      "loss": 0.1797,
      "step": 3850
    },
    {
      "epoch": 7.72,
      "grad_norm": 3.1128058433532715,
      "learning_rate": 6.945454545454545e-05,
      "loss": 0.1538,
      "step": 3860
    },
    {
      "epoch": 7.74,
      "grad_norm": 1.7577972412109375,
      "learning_rate": 6.884848484848485e-05,
      "loss": 0.1474,
      "step": 3870
    },
    {
      "epoch": 7.76,
      "grad_norm": 4.61221981048584,
      "learning_rate": 6.824242424242423e-05,
      "loss": 0.15,
      "step": 3880
    },
    {
      "epoch": 7.78,
      "grad_norm": 1.2712465524673462,
      "learning_rate": 6.763636363636363e-05,
      "loss": 0.1457,
      "step": 3890
    },
    {
      "epoch": 7.8,
      "grad_norm": 0.8782837986946106,
      "learning_rate": 6.703030303030303e-05,
      "loss": 0.1477,
      "step": 3900
    },
    {
      "epoch": 7.8,
      "eval_loss": 2.1542186737060547,
      "eval_runtime": 8.3866,
      "eval_samples_per_second": 23.848,
      "eval_steps_per_second": 23.848,
      "step": 3900
    },
    {
      "epoch": 7.82,
      "grad_norm": 0.8334134221076965,
      "learning_rate": 6.642424242424242e-05,
      "loss": 0.1514,
      "step": 3910
    },
    {
      "epoch": 7.84,
      "grad_norm": 1.041973352432251,
      "learning_rate": 6.58181818181818e-05,
      "loss": 0.1573,
      "step": 3920
    },
    {
      "epoch": 7.86,
      "grad_norm": 2.2821521759033203,
      "learning_rate": 6.52121212121212e-05,
      "loss": 0.1527,
      "step": 3930
    },
    {
      "epoch": 7.88,
      "grad_norm": 2.8250303268432617,
      "learning_rate": 6.46060606060606e-05,
      "loss": 0.1568,
      "step": 3940
    },
    {
      "epoch": 7.9,
      "grad_norm": 1.3897860050201416,
      "learning_rate": 6.4e-05,
      "loss": 0.1698,
      "step": 3950
    },
    {
      "epoch": 7.92,
      "grad_norm": 1.5415654182434082,
      "learning_rate": 6.33939393939394e-05,
      "loss": 0.1629,
      "step": 3960
    },
    {
      "epoch": 7.9399999999999995,
      "grad_norm": 1.2634462118148804,
      "learning_rate": 6.278787878787878e-05,
      "loss": 0.1692,
      "step": 3970
    },
    {
      "epoch": 7.96,
      "grad_norm": 1.1006306409835815,
      "learning_rate": 6.218181818181817e-05,
      "loss": 0.1349,
      "step": 3980
    },
    {
      "epoch": 7.98,
      "grad_norm": 1.529878854751587,
      "learning_rate": 6.157575757575757e-05,
      "loss": 0.159,
      "step": 3990
    },
    {
      "epoch": 8.0,
      "grad_norm": 0.7514742016792297,
      "learning_rate": 6.096969696969697e-05,
      "loss": 0.1607,
      "step": 4000
    },
    {
      "epoch": 8.0,
      "eval_loss": 2.124880075454712,
      "eval_runtime": 8.4766,
      "eval_samples_per_second": 23.594,
      "eval_steps_per_second": 23.594,
      "step": 4000
    },
    {
      "epoch": 8.02,
      "grad_norm": 0.7463371157646179,
      "learning_rate": 6.036363636363636e-05,
      "loss": 0.1279,
      "step": 4010
    },
    {
      "epoch": 8.04,
      "grad_norm": 1.1067456007003784,
      "learning_rate": 5.9757575757575755e-05,
      "loss": 0.1177,
      "step": 4020
    },
    {
      "epoch": 8.06,
      "grad_norm": 1.9795159101486206,
      "learning_rate": 5.9151515151515145e-05,
      "loss": 0.1127,
      "step": 4030
    },
    {
      "epoch": 8.08,
      "grad_norm": 0.9066483378410339,
      "learning_rate": 5.854545454545454e-05,
      "loss": 0.1163,
      "step": 4040
    },
    {
      "epoch": 8.1,
      "grad_norm": 0.6568546891212463,
      "learning_rate": 5.793939393939393e-05,
      "loss": 0.1469,
      "step": 4050
    },
    {
      "epoch": 8.12,
      "grad_norm": 1.0689212083816528,
      "learning_rate": 5.733333333333333e-05,
      "loss": 0.1103,
      "step": 4060
    },
    {
      "epoch": 8.14,
      "grad_norm": 3.0622074604034424,
      "learning_rate": 5.672727272727272e-05,
      "loss": 0.1619,
      "step": 4070
    },
    {
      "epoch": 8.16,
      "grad_norm": 0.45403268933296204,
      "learning_rate": 5.612121212121212e-05,
      "loss": 0.1209,
      "step": 4080
    },
    {
      "epoch": 8.18,
      "grad_norm": 1.0336592197418213,
      "learning_rate": 5.551515151515151e-05,
      "loss": 0.1145,
      "step": 4090
    },
    {
      "epoch": 8.2,
      "grad_norm": 0.7427955865859985,
      "learning_rate": 5.490909090909091e-05,
      "loss": 0.1066,
      "step": 4100
    },
    {
      "epoch": 8.2,
      "eval_loss": 2.3042614459991455,
      "eval_runtime": 8.4386,
      "eval_samples_per_second": 23.701,
      "eval_steps_per_second": 23.701,
      "step": 4100
    },
    {
      "epoch": 8.22,
      "grad_norm": 2.30058217048645,
      "learning_rate": 5.43030303030303e-05,
      "loss": 0.1209,
      "step": 4110
    },
    {
      "epoch": 8.24,
      "grad_norm": 1.029767394065857,
      "learning_rate": 5.369696969696969e-05,
      "loss": 0.1244,
      "step": 4120
    },
    {
      "epoch": 8.26,
      "grad_norm": 0.923023521900177,
      "learning_rate": 5.3090909090909087e-05,
      "loss": 0.1202,
      "step": 4130
    },
    {
      "epoch": 8.28,
      "grad_norm": 4.847641944885254,
      "learning_rate": 5.2484848484848477e-05,
      "loss": 0.1236,
      "step": 4140
    },
    {
      "epoch": 8.3,
      "grad_norm": 4.868232727050781,
      "learning_rate": 5.1878787878787873e-05,
      "loss": 0.1601,
      "step": 4150
    },
    {
      "epoch": 8.32,
      "grad_norm": 1.2452025413513184,
      "learning_rate": 5.1272727272727264e-05,
      "loss": 0.1121,
      "step": 4160
    },
    {
      "epoch": 8.34,
      "grad_norm": 4.274717807769775,
      "learning_rate": 5.066666666666666e-05,
      "loss": 0.154,
      "step": 4170
    },
    {
      "epoch": 8.36,
      "grad_norm": 0.6117078065872192,
      "learning_rate": 5.006060606060605e-05,
      "loss": 0.1471,
      "step": 4180
    },
    {
      "epoch": 8.38,
      "grad_norm": 3.376279830932617,
      "learning_rate": 4.9454545454545454e-05,
      "loss": 0.1382,
      "step": 4190
    },
    {
      "epoch": 8.4,
      "grad_norm": 0.9198293089866638,
      "learning_rate": 4.8848484848484844e-05,
      "loss": 0.1193,
      "step": 4200
    },
    {
      "epoch": 8.4,
      "eval_loss": 2.246289014816284,
      "eval_runtime": 8.4221,
      "eval_samples_per_second": 23.747,
      "eval_steps_per_second": 23.747,
      "step": 4200
    },
    {
      "epoch": 8.42,
      "grad_norm": 0.6275643706321716,
      "learning_rate": 4.824242424242424e-05,
      "loss": 0.1324,
      "step": 4210
    },
    {
      "epoch": 8.44,
      "grad_norm": 1.6417975425720215,
      "learning_rate": 4.763636363636363e-05,
      "loss": 0.1432,
      "step": 4220
    },
    {
      "epoch": 8.46,
      "grad_norm": 0.7623708248138428,
      "learning_rate": 4.703030303030303e-05,
      "loss": 0.1235,
      "step": 4230
    },
    {
      "epoch": 8.48,
      "grad_norm": 2.0199756622314453,
      "learning_rate": 4.642424242424242e-05,
      "loss": 0.1187,
      "step": 4240
    },
    {
      "epoch": 8.5,
      "grad_norm": 4.567035675048828,
      "learning_rate": 4.5818181818181815e-05,
      "loss": 0.1506,
      "step": 4250
    },
    {
      "epoch": 8.52,
      "grad_norm": 0.7870298624038696,
      "learning_rate": 4.5212121212121205e-05,
      "loss": 0.1241,
      "step": 4260
    },
    {
      "epoch": 8.54,
      "grad_norm": 1.267878532409668,
      "learning_rate": 4.460606060606061e-05,
      "loss": 0.1476,
      "step": 4270
    },
    {
      "epoch": 8.56,
      "grad_norm": 1.530141830444336,
      "learning_rate": 4.4e-05,
      "loss": 0.1241,
      "step": 4280
    },
    {
      "epoch": 8.58,
      "grad_norm": 0.7365348935127258,
      "learning_rate": 4.339393939393939e-05,
      "loss": 0.1404,
      "step": 4290
    },
    {
      "epoch": 8.6,
      "grad_norm": 0.736655056476593,
      "learning_rate": 4.2787878787878786e-05,
      "loss": 0.1137,
      "step": 4300
    },
    {
      "epoch": 8.6,
      "eval_loss": 2.301159143447876,
      "eval_runtime": 8.3858,
      "eval_samples_per_second": 23.85,
      "eval_steps_per_second": 23.85,
      "step": 4300
    },
    {
      "epoch": 8.62,
      "grad_norm": 2.6195785999298096,
      "learning_rate": 4.2181818181818176e-05,
      "loss": 0.1384,
      "step": 4310
    },
    {
      "epoch": 8.64,
      "grad_norm": 1.5439947843551636,
      "learning_rate": 4.157575757575757e-05,
      "loss": 0.1389,
      "step": 4320
    },
    {
      "epoch": 8.66,
      "grad_norm": 3.8811428546905518,
      "learning_rate": 4.096969696969696e-05,
      "loss": 0.1297,
      "step": 4330
    },
    {
      "epoch": 8.68,
      "grad_norm": 2.311326742172241,
      "learning_rate": 4.036363636363636e-05,
      "loss": 0.1216,
      "step": 4340
    },
    {
      "epoch": 8.7,
      "grad_norm": 0.7223787307739258,
      "learning_rate": 3.975757575757575e-05,
      "loss": 0.1281,
      "step": 4350
    },
    {
      "epoch": 8.72,
      "grad_norm": 1.6717041730880737,
      "learning_rate": 3.9151515151515153e-05,
      "loss": 0.1344,
      "step": 4360
    },
    {
      "epoch": 8.74,
      "grad_norm": 1.6043660640716553,
      "learning_rate": 3.8545454545454544e-05,
      "loss": 0.1267,
      "step": 4370
    },
    {
      "epoch": 8.76,
      "grad_norm": 1.3338974714279175,
      "learning_rate": 3.793939393939394e-05,
      "loss": 0.1233,
      "step": 4380
    },
    {
      "epoch": 8.78,
      "grad_norm": 0.7433081865310669,
      "learning_rate": 3.733333333333333e-05,
      "loss": 0.1308,
      "step": 4390
    },
    {
      "epoch": 8.8,
      "grad_norm": 1.2948853969573975,
      "learning_rate": 3.672727272727272e-05,
      "loss": 0.1178,
      "step": 4400
    },
    {
      "epoch": 8.8,
      "eval_loss": 2.2875256538391113,
      "eval_runtime": 8.4865,
      "eval_samples_per_second": 23.567,
      "eval_steps_per_second": 23.567,
      "step": 4400
    },
    {
      "epoch": 8.82,
      "grad_norm": 0.6912932395935059,
      "learning_rate": 3.612121212121212e-05,
      "loss": 0.1302,
      "step": 4410
    },
    {
      "epoch": 8.84,
      "grad_norm": 1.1016589403152466,
      "learning_rate": 3.5515151515151514e-05,
      "loss": 0.1515,
      "step": 4420
    },
    {
      "epoch": 8.86,
      "grad_norm": 3.325331687927246,
      "learning_rate": 3.4909090909090904e-05,
      "loss": 0.1414,
      "step": 4430
    },
    {
      "epoch": 8.88,
      "grad_norm": 0.5368275046348572,
      "learning_rate": 3.43030303030303e-05,
      "loss": 0.1188,
      "step": 4440
    },
    {
      "epoch": 8.9,
      "grad_norm": 2.701570987701416,
      "learning_rate": 3.369696969696969e-05,
      "loss": 0.1333,
      "step": 4450
    },
    {
      "epoch": 8.92,
      "grad_norm": 1.3828473091125488,
      "learning_rate": 3.309090909090909e-05,
      "loss": 0.1253,
      "step": 4460
    },
    {
      "epoch": 8.94,
      "grad_norm": 2.4192845821380615,
      "learning_rate": 3.2484848484848485e-05,
      "loss": 0.1141,
      "step": 4470
    },
    {
      "epoch": 8.96,
      "grad_norm": 1.898013710975647,
      "learning_rate": 3.1878787878787875e-05,
      "loss": 0.1262,
      "step": 4480
    },
    {
      "epoch": 8.98,
      "grad_norm": 2.3213346004486084,
      "learning_rate": 3.127272727272727e-05,
      "loss": 0.1324,
      "step": 4490
    },
    {
      "epoch": 9.0,
      "grad_norm": 1.0931369066238403,
      "learning_rate": 3.066666666666667e-05,
      "loss": 0.1214,
      "step": 4500
    },
    {
      "epoch": 9.0,
      "eval_loss": 2.260075330734253,
      "eval_runtime": 8.486,
      "eval_samples_per_second": 23.568,
      "eval_steps_per_second": 23.568,
      "step": 4500
    },
    {
      "epoch": 9.02,
      "grad_norm": 0.8907532095909119,
      "learning_rate": 3.006060606060606e-05,
      "loss": 0.1235,
      "step": 4510
    },
    {
      "epoch": 9.04,
      "grad_norm": 0.7493162751197815,
      "learning_rate": 2.945454545454545e-05,
      "loss": 0.1073,
      "step": 4520
    },
    {
      "epoch": 9.06,
      "grad_norm": 1.4098161458969116,
      "learning_rate": 2.8848484848484846e-05,
      "loss": 0.1141,
      "step": 4530
    },
    {
      "epoch": 9.08,
      "grad_norm": 0.5292153358459473,
      "learning_rate": 2.824242424242424e-05,
      "loss": 0.1145,
      "step": 4540
    },
    {
      "epoch": 9.1,
      "grad_norm": 0.9706442356109619,
      "learning_rate": 2.7636363636363633e-05,
      "loss": 0.1154,
      "step": 4550
    },
    {
      "epoch": 9.12,
      "grad_norm": 0.934942364692688,
      "learning_rate": 2.7030303030303026e-05,
      "loss": 0.1067,
      "step": 4560
    },
    {
      "epoch": 9.14,
      "grad_norm": 1.1863962411880493,
      "learning_rate": 2.642424242424242e-05,
      "loss": 0.126,
      "step": 4570
    },
    {
      "epoch": 9.16,
      "grad_norm": 0.8762186765670776,
      "learning_rate": 2.5818181818181817e-05,
      "loss": 0.1229,
      "step": 4580
    },
    {
      "epoch": 9.18,
      "grad_norm": 2.4164485931396484,
      "learning_rate": 2.521212121212121e-05,
      "loss": 0.112,
      "step": 4590
    },
    {
      "epoch": 9.2,
      "grad_norm": 0.6492701768875122,
      "learning_rate": 2.4606060606060604e-05,
      "loss": 0.1226,
      "step": 4600
    },
    {
      "epoch": 9.2,
      "eval_loss": 2.37736439704895,
      "eval_runtime": 8.3876,
      "eval_samples_per_second": 23.845,
      "eval_steps_per_second": 23.845,
      "step": 4600
    },
    {
      "epoch": 9.22,
      "grad_norm": 1.9175854921340942,
      "learning_rate": 2.3999999999999997e-05,
      "loss": 0.1157,
      "step": 4610
    },
    {
      "epoch": 9.24,
      "grad_norm": 1.5644586086273193,
      "learning_rate": 2.3393939393939394e-05,
      "loss": 0.1197,
      "step": 4620
    },
    {
      "epoch": 9.26,
      "grad_norm": 1.5195382833480835,
      "learning_rate": 2.2787878787878788e-05,
      "loss": 0.1367,
      "step": 4630
    },
    {
      "epoch": 9.28,
      "grad_norm": 1.2564451694488525,
      "learning_rate": 2.218181818181818e-05,
      "loss": 0.1107,
      "step": 4640
    },
    {
      "epoch": 9.3,
      "grad_norm": 0.8971363306045532,
      "learning_rate": 2.1575757575757575e-05,
      "loss": 0.1189,
      "step": 4650
    },
    {
      "epoch": 9.32,
      "grad_norm": 1.6908730268478394,
      "learning_rate": 2.0969696969696968e-05,
      "loss": 0.1047,
      "step": 4660
    },
    {
      "epoch": 9.34,
      "grad_norm": 3.3147504329681396,
      "learning_rate": 2.0363636363636365e-05,
      "loss": 0.1157,
      "step": 4670
    },
    {
      "epoch": 9.36,
      "grad_norm": 0.6936682462692261,
      "learning_rate": 1.9757575757575755e-05,
      "loss": 0.1017,
      "step": 4680
    },
    {
      "epoch": 9.38,
      "grad_norm": 1.0502070188522339,
      "learning_rate": 1.915151515151515e-05,
      "loss": 0.1094,
      "step": 4690
    },
    {
      "epoch": 9.4,
      "grad_norm": 3.323143720626831,
      "learning_rate": 1.8545454545454545e-05,
      "loss": 0.1203,
      "step": 4700
    },
    {
      "epoch": 9.4,
      "eval_loss": 2.39506459236145,
      "eval_runtime": 8.5033,
      "eval_samples_per_second": 23.52,
      "eval_steps_per_second": 23.52,
      "step": 4700
    },
    {
      "epoch": 9.42,
      "grad_norm": 1.508552074432373,
      "learning_rate": 1.793939393939394e-05,
      "loss": 0.1011,
      "step": 4710
    },
    {
      "epoch": 9.44,
      "grad_norm": 0.9181390404701233,
      "learning_rate": 1.7333333333333332e-05,
      "loss": 0.109,
      "step": 4720
    },
    {
      "epoch": 9.46,
      "grad_norm": 1.5489544868469238,
      "learning_rate": 1.6727272727272726e-05,
      "loss": 0.1128,
      "step": 4730
    },
    {
      "epoch": 9.48,
      "grad_norm": 0.9968689680099487,
      "learning_rate": 1.612121212121212e-05,
      "loss": 0.1077,
      "step": 4740
    },
    {
      "epoch": 9.5,
      "grad_norm": 0.980749249458313,
      "learning_rate": 1.5515151515151513e-05,
      "loss": 0.1128,
      "step": 4750
    },
    {
      "epoch": 9.52,
      "grad_norm": 0.8983404040336609,
      "learning_rate": 1.4909090909090908e-05,
      "loss": 0.1052,
      "step": 4760
    },
    {
      "epoch": 9.54,
      "grad_norm": 1.2565780878067017,
      "learning_rate": 1.4303030303030303e-05,
      "loss": 0.1112,
      "step": 4770
    },
    {
      "epoch": 9.56,
      "grad_norm": 1.2063263654708862,
      "learning_rate": 1.3696969696969697e-05,
      "loss": 0.1139,
      "step": 4780
    },
    {
      "epoch": 9.58,
      "grad_norm": 0.8626515865325928,
      "learning_rate": 1.309090909090909e-05,
      "loss": 0.1114,
      "step": 4790
    },
    {
      "epoch": 9.6,
      "grad_norm": 1.577629566192627,
      "learning_rate": 1.2484848484848483e-05,
      "loss": 0.1098,
      "step": 4800
    },
    {
      "epoch": 9.6,
      "eval_loss": 2.4127581119537354,
      "eval_runtime": 8.4246,
      "eval_samples_per_second": 23.74,
      "eval_steps_per_second": 23.74,
      "step": 4800
    },
    {
      "epoch": 9.62,
      "grad_norm": 2.0260329246520996,
      "learning_rate": 1.1878787878787877e-05,
      "loss": 0.1229,
      "step": 4810
    },
    {
      "epoch": 9.64,
      "grad_norm": 1.1620266437530518,
      "learning_rate": 1.1272727272727272e-05,
      "loss": 0.1213,
      "step": 4820
    },
    {
      "epoch": 9.66,
      "grad_norm": 1.1594765186309814,
      "learning_rate": 1.0666666666666666e-05,
      "loss": 0.1221,
      "step": 4830
    },
    {
      "epoch": 9.68,
      "grad_norm": 1.5436066389083862,
      "learning_rate": 1.006060606060606e-05,
      "loss": 0.109,
      "step": 4840
    },
    {
      "epoch": 9.7,
      "grad_norm": 0.8874432444572449,
      "learning_rate": 9.454545454545454e-06,
      "loss": 0.1276,
      "step": 4850
    },
    {
      "epoch": 9.72,
      "grad_norm": 2.1415152549743652,
      "learning_rate": 8.848484848484848e-06,
      "loss": 0.1083,
      "step": 4860
    },
    {
      "epoch": 9.74,
      "grad_norm": 0.8742021918296814,
      "learning_rate": 8.242424242424241e-06,
      "loss": 0.1171,
      "step": 4870
    },
    {
      "epoch": 9.76,
      "grad_norm": 0.9124682545661926,
      "learning_rate": 7.636363636363636e-06,
      "loss": 0.0997,
      "step": 4880
    },
    {
      "epoch": 9.78,
      "grad_norm": 0.9911447763442993,
      "learning_rate": 7.03030303030303e-06,
      "loss": 0.1089,
      "step": 4890
    },
    {
      "epoch": 9.8,
      "grad_norm": 2.4394948482513428,
      "learning_rate": 6.424242424242423e-06,
      "loss": 0.1162,
      "step": 4900
    },
    {
      "epoch": 9.8,
      "eval_loss": 2.3736259937286377,
      "eval_runtime": 8.4714,
      "eval_samples_per_second": 23.609,
      "eval_steps_per_second": 23.609,
      "step": 4900
    },
    {
      "epoch": 9.82,
      "grad_norm": 1.1568350791931152,
      "learning_rate": 5.818181818181818e-06,
      "loss": 0.1069,
      "step": 4910
    },
    {
      "epoch": 9.84,
      "grad_norm": 0.8604983687400818,
      "learning_rate": 5.212121212121212e-06,
      "loss": 0.1203,
      "step": 4920
    },
    {
      "epoch": 9.86,
      "grad_norm": 0.43454885482788086,
      "learning_rate": 4.6060606060606055e-06,
      "loss": 0.1016,
      "step": 4930
    },
    {
      "epoch": 9.88,
      "grad_norm": 0.6707099080085754,
      "learning_rate": 4e-06,
      "loss": 0.1086,
      "step": 4940
    },
    {
      "epoch": 9.9,
      "grad_norm": 1.3787683248519897,
      "learning_rate": 3.3939393939393937e-06,
      "loss": 0.1161,
      "step": 4950
    },
    {
      "epoch": 9.92,
      "grad_norm": 0.6500969529151917,
      "learning_rate": 2.787878787878788e-06,
      "loss": 0.1103,
      "step": 4960
    },
    {
      "epoch": 9.94,
      "grad_norm": 0.46197766065597534,
      "learning_rate": 2.1818181818181815e-06,
      "loss": 0.1093,
      "step": 4970
    },
    {
      "epoch": 9.96,
      "grad_norm": 1.9084885120391846,
      "learning_rate": 1.5757575757575756e-06,
      "loss": 0.1041,
      "step": 4980
    },
    {
      "epoch": 9.98,
      "grad_norm": 1.0458096265792847,
      "learning_rate": 9.696969696969695e-07,
      "loss": 0.1127,
      "step": 4990
    },
    {
      "epoch": 10.0,
      "grad_norm": 1.5519191026687622,
      "learning_rate": 3.636363636363636e-07,
      "loss": 0.112,
      "step": 5000
    },
    {
      "epoch": 10.0,
      "eval_loss": 2.3741655349731445,
      "eval_runtime": 8.4072,
      "eval_samples_per_second": 23.789,
      "eval_steps_per_second": 23.789,
      "step": 5000
    }
  ],
  "logging_steps": 10,
  "max_steps": 5000,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 10,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 1.496916688896e+16,
  "train_batch_size": 1,
  "trial_name": null,
  "trial_params": null
}

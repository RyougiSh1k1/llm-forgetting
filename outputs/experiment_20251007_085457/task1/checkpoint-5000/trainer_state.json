{
  "best_global_step": null,
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 10.0,
  "eval_steps": 100,
  "global_step": 5000,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.02,
      "grad_norm": 2.2511727809906006,
      "learning_rate": 4.2e-05,
      "loss": 2.6034,
      "step": 10
    },
    {
      "epoch": 0.04,
      "grad_norm": 4.773868083953857,
      "learning_rate": 0.000102,
      "loss": 2.3977,
      "step": 20
    },
    {
      "epoch": 0.06,
      "grad_norm": 3.6050310134887695,
      "learning_rate": 0.000162,
      "loss": 1.852,
      "step": 30
    },
    {
      "epoch": 0.08,
      "grad_norm": 3.722691059112549,
      "learning_rate": 0.00022199999999999998,
      "loss": 1.4581,
      "step": 40
    },
    {
      "epoch": 0.1,
      "grad_norm": 3.655315637588501,
      "learning_rate": 0.00028199999999999997,
      "loss": 1.417,
      "step": 50
    },
    {
      "epoch": 0.12,
      "grad_norm": 7.265434741973877,
      "learning_rate": 0.00029957575757575756,
      "loss": 1.2354,
      "step": 60
    },
    {
      "epoch": 0.14,
      "grad_norm": 3.547475576400757,
      "learning_rate": 0.0002989696969696969,
      "loss": 1.2735,
      "step": 70
    },
    {
      "epoch": 0.16,
      "grad_norm": 10.362601280212402,
      "learning_rate": 0.0002983636363636363,
      "loss": 1.0626,
      "step": 80
    },
    {
      "epoch": 0.18,
      "grad_norm": 2.8743669986724854,
      "learning_rate": 0.00029775757575757573,
      "loss": 1.1522,
      "step": 90
    },
    {
      "epoch": 0.2,
      "grad_norm": 4.51359748840332,
      "learning_rate": 0.00029715151515151514,
      "loss": 1.2619,
      "step": 100
    },
    {
      "epoch": 0.2,
      "eval_loss": 1.1337313652038574,
      "eval_runtime": 8.2524,
      "eval_samples_per_second": 24.235,
      "eval_steps_per_second": 24.235,
      "step": 100
    },
    {
      "epoch": 0.22,
      "grad_norm": 3.0023837089538574,
      "learning_rate": 0.00029654545454545455,
      "loss": 1.1211,
      "step": 110
    },
    {
      "epoch": 0.24,
      "grad_norm": 4.963870525360107,
      "learning_rate": 0.0002959393939393939,
      "loss": 0.9441,
      "step": 120
    },
    {
      "epoch": 0.26,
      "grad_norm": 2.9103307723999023,
      "learning_rate": 0.0002953333333333333,
      "loss": 1.3417,
      "step": 130
    },
    {
      "epoch": 0.28,
      "grad_norm": 2.9019715785980225,
      "learning_rate": 0.0002947272727272727,
      "loss": 1.2465,
      "step": 140
    },
    {
      "epoch": 0.3,
      "grad_norm": 2.495445728302002,
      "learning_rate": 0.0002941212121212121,
      "loss": 0.7378,
      "step": 150
    },
    {
      "epoch": 0.32,
      "grad_norm": 3.224771738052368,
      "learning_rate": 0.0002935151515151515,
      "loss": 0.8548,
      "step": 160
    },
    {
      "epoch": 0.34,
      "grad_norm": 6.899214267730713,
      "learning_rate": 0.00029296969696969693,
      "loss": 1.0573,
      "step": 170
    },
    {
      "epoch": 0.36,
      "grad_norm": 3.202373504638672,
      "learning_rate": 0.00029236363636363634,
      "loss": 1.2414,
      "step": 180
    },
    {
      "epoch": 0.38,
      "grad_norm": 1.9225226640701294,
      "learning_rate": 0.00029175757575757575,
      "loss": 1.0982,
      "step": 190
    },
    {
      "epoch": 0.4,
      "grad_norm": 3.8114991188049316,
      "learning_rate": 0.00029115151515151516,
      "loss": 0.8426,
      "step": 200
    },
    {
      "epoch": 0.4,
      "eval_loss": 0.8973168730735779,
      "eval_runtime": 8.2888,
      "eval_samples_per_second": 24.129,
      "eval_steps_per_second": 24.129,
      "step": 200
    },
    {
      "epoch": 0.42,
      "grad_norm": 4.027462959289551,
      "learning_rate": 0.0002905454545454545,
      "loss": 0.7349,
      "step": 210
    },
    {
      "epoch": 0.44,
      "grad_norm": 3.5556418895721436,
      "learning_rate": 0.0002899393939393939,
      "loss": 0.9778,
      "step": 220
    },
    {
      "epoch": 0.46,
      "grad_norm": 4.288957118988037,
      "learning_rate": 0.0002893333333333333,
      "loss": 0.7735,
      "step": 230
    },
    {
      "epoch": 0.48,
      "grad_norm": 4.435267925262451,
      "learning_rate": 0.0002887272727272727,
      "loss": 0.7632,
      "step": 240
    },
    {
      "epoch": 0.5,
      "grad_norm": 4.123228549957275,
      "learning_rate": 0.0002881212121212121,
      "loss": 0.9215,
      "step": 250
    },
    {
      "epoch": 0.52,
      "grad_norm": 5.542121887207031,
      "learning_rate": 0.00028751515151515146,
      "loss": 0.8693,
      "step": 260
    },
    {
      "epoch": 0.54,
      "grad_norm": 3.754556894302368,
      "learning_rate": 0.0002869090909090909,
      "loss": 0.9857,
      "step": 270
    },
    {
      "epoch": 0.56,
      "grad_norm": 4.165865421295166,
      "learning_rate": 0.0002863030303030303,
      "loss": 1.0554,
      "step": 280
    },
    {
      "epoch": 0.58,
      "grad_norm": 5.274984359741211,
      "learning_rate": 0.0002856969696969697,
      "loss": 0.9209,
      "step": 290
    },
    {
      "epoch": 0.6,
      "grad_norm": 3.226555109024048,
      "learning_rate": 0.00028509090909090905,
      "loss": 0.7464,
      "step": 300
    },
    {
      "epoch": 0.6,
      "eval_loss": 0.8952392339706421,
      "eval_runtime": 8.2983,
      "eval_samples_per_second": 24.101,
      "eval_steps_per_second": 24.101,
      "step": 300
    },
    {
      "epoch": 0.62,
      "grad_norm": 3.592118740081787,
      "learning_rate": 0.00028448484848484846,
      "loss": 1.0653,
      "step": 310
    },
    {
      "epoch": 0.64,
      "grad_norm": 4.597197532653809,
      "learning_rate": 0.00028387878787878787,
      "loss": 0.5948,
      "step": 320
    },
    {
      "epoch": 0.66,
      "grad_norm": 2.840104341506958,
      "learning_rate": 0.0002832727272727272,
      "loss": 0.6997,
      "step": 330
    },
    {
      "epoch": 0.68,
      "grad_norm": 2.1755430698394775,
      "learning_rate": 0.00028266666666666663,
      "loss": 1.0491,
      "step": 340
    },
    {
      "epoch": 0.7,
      "grad_norm": 1.7272785902023315,
      "learning_rate": 0.00028206060606060605,
      "loss": 0.8331,
      "step": 350
    },
    {
      "epoch": 0.72,
      "grad_norm": 4.946216106414795,
      "learning_rate": 0.00028145454545454546,
      "loss": 0.8739,
      "step": 360
    },
    {
      "epoch": 0.74,
      "grad_norm": 2.718625545501709,
      "learning_rate": 0.0002808484848484848,
      "loss": 0.8228,
      "step": 370
    },
    {
      "epoch": 0.76,
      "grad_norm": 3.346419095993042,
      "learning_rate": 0.0002802424242424242,
      "loss": 0.8724,
      "step": 380
    },
    {
      "epoch": 0.78,
      "grad_norm": 3.1708273887634277,
      "learning_rate": 0.00027963636363636363,
      "loss": 0.6606,
      "step": 390
    },
    {
      "epoch": 0.8,
      "grad_norm": 9.04194450378418,
      "learning_rate": 0.000279030303030303,
      "loss": 0.7621,
      "step": 400
    },
    {
      "epoch": 0.8,
      "eval_loss": 0.8908732533454895,
      "eval_runtime": 8.2775,
      "eval_samples_per_second": 24.162,
      "eval_steps_per_second": 24.162,
      "step": 400
    },
    {
      "epoch": 0.82,
      "grad_norm": 3.2932510375976562,
      "learning_rate": 0.0002784242424242424,
      "loss": 1.1014,
      "step": 410
    },
    {
      "epoch": 0.84,
      "grad_norm": 7.09868860244751,
      "learning_rate": 0.0002778181818181818,
      "loss": 0.8059,
      "step": 420
    },
    {
      "epoch": 0.86,
      "grad_norm": 1.9681912660598755,
      "learning_rate": 0.00027721212121212117,
      "loss": 0.6903,
      "step": 430
    },
    {
      "epoch": 0.88,
      "grad_norm": 4.36175012588501,
      "learning_rate": 0.0002766060606060606,
      "loss": 0.7209,
      "step": 440
    },
    {
      "epoch": 0.9,
      "grad_norm": 2.8932464122772217,
      "learning_rate": 0.000276,
      "loss": 0.728,
      "step": 450
    },
    {
      "epoch": 0.92,
      "grad_norm": 3.0677037239074707,
      "learning_rate": 0.0002753939393939394,
      "loss": 1.0054,
      "step": 460
    },
    {
      "epoch": 0.94,
      "grad_norm": 4.736158847808838,
      "learning_rate": 0.00027478787878787875,
      "loss": 0.7524,
      "step": 470
    },
    {
      "epoch": 0.96,
      "grad_norm": 2.257524013519287,
      "learning_rate": 0.00027418181818181816,
      "loss": 0.8987,
      "step": 480
    },
    {
      "epoch": 0.98,
      "grad_norm": 2.318575620651245,
      "learning_rate": 0.0002735757575757576,
      "loss": 0.9833,
      "step": 490
    },
    {
      "epoch": 1.0,
      "grad_norm": 6.551775932312012,
      "learning_rate": 0.00027296969696969693,
      "loss": 0.7959,
      "step": 500
    },
    {
      "epoch": 1.0,
      "eval_loss": 0.8731114864349365,
      "eval_runtime": 8.299,
      "eval_samples_per_second": 24.099,
      "eval_steps_per_second": 24.099,
      "step": 500
    },
    {
      "epoch": 1.02,
      "grad_norm": 5.138983249664307,
      "learning_rate": 0.00027236363636363634,
      "loss": 0.875,
      "step": 510
    },
    {
      "epoch": 1.04,
      "grad_norm": 9.117481231689453,
      "learning_rate": 0.0002717575757575757,
      "loss": 0.787,
      "step": 520
    },
    {
      "epoch": 1.06,
      "grad_norm": 2.3261590003967285,
      "learning_rate": 0.00027115151515151516,
      "loss": 0.5637,
      "step": 530
    },
    {
      "epoch": 1.08,
      "grad_norm": 4.2999773025512695,
      "learning_rate": 0.0002705454545454545,
      "loss": 0.7174,
      "step": 540
    },
    {
      "epoch": 1.1,
      "grad_norm": 2.2777106761932373,
      "learning_rate": 0.00026993939393939393,
      "loss": 0.6321,
      "step": 550
    },
    {
      "epoch": 1.12,
      "grad_norm": 2.0303149223327637,
      "learning_rate": 0.00026933333333333334,
      "loss": 0.6856,
      "step": 560
    },
    {
      "epoch": 1.1400000000000001,
      "grad_norm": 3.3024773597717285,
      "learning_rate": 0.0002687272727272727,
      "loss": 0.6244,
      "step": 570
    },
    {
      "epoch": 1.16,
      "grad_norm": 3.990339756011963,
      "learning_rate": 0.0002681212121212121,
      "loss": 0.8829,
      "step": 580
    },
    {
      "epoch": 1.18,
      "grad_norm": 2.4477756023406982,
      "learning_rate": 0.00026751515151515146,
      "loss": 0.6529,
      "step": 590
    },
    {
      "epoch": 1.2,
      "grad_norm": 2.6283507347106934,
      "learning_rate": 0.00026690909090909087,
      "loss": 0.5783,
      "step": 600
    },
    {
      "epoch": 1.2,
      "eval_loss": 0.8652321696281433,
      "eval_runtime": 8.3829,
      "eval_samples_per_second": 23.858,
      "eval_steps_per_second": 23.858,
      "step": 600
    },
    {
      "epoch": 1.22,
      "grad_norm": 5.153138637542725,
      "learning_rate": 0.0002663030303030303,
      "loss": 0.6472,
      "step": 610
    },
    {
      "epoch": 1.24,
      "grad_norm": 3.1104676723480225,
      "learning_rate": 0.0002656969696969697,
      "loss": 0.7599,
      "step": 620
    },
    {
      "epoch": 1.26,
      "grad_norm": 2.9498178958892822,
      "learning_rate": 0.00026509090909090905,
      "loss": 0.7133,
      "step": 630
    },
    {
      "epoch": 1.28,
      "grad_norm": 3.752657413482666,
      "learning_rate": 0.00026448484848484846,
      "loss": 0.6996,
      "step": 640
    },
    {
      "epoch": 1.3,
      "grad_norm": 4.218838691711426,
      "learning_rate": 0.00026387878787878787,
      "loss": 0.7696,
      "step": 650
    },
    {
      "epoch": 1.32,
      "grad_norm": 2.341731071472168,
      "learning_rate": 0.0002632727272727272,
      "loss": 0.5817,
      "step": 660
    },
    {
      "epoch": 1.34,
      "grad_norm": 1.8328883647918701,
      "learning_rate": 0.00026266666666666664,
      "loss": 0.763,
      "step": 670
    },
    {
      "epoch": 1.3599999999999999,
      "grad_norm": 3.2352511882781982,
      "learning_rate": 0.00026206060606060605,
      "loss": 0.8577,
      "step": 680
    },
    {
      "epoch": 1.38,
      "grad_norm": 3.377866268157959,
      "learning_rate": 0.0002614545454545454,
      "loss": 0.6071,
      "step": 690
    },
    {
      "epoch": 1.4,
      "grad_norm": 3.749785900115967,
      "learning_rate": 0.0002608484848484848,
      "loss": 0.6647,
      "step": 700
    },
    {
      "epoch": 1.4,
      "eval_loss": 0.8747158050537109,
      "eval_runtime": 8.3179,
      "eval_samples_per_second": 24.044,
      "eval_steps_per_second": 24.044,
      "step": 700
    },
    {
      "epoch": 1.42,
      "grad_norm": 2.099269390106201,
      "learning_rate": 0.0002602424242424242,
      "loss": 0.7129,
      "step": 710
    },
    {
      "epoch": 1.44,
      "grad_norm": 3.4405698776245117,
      "learning_rate": 0.00025963636363636363,
      "loss": 0.6123,
      "step": 720
    },
    {
      "epoch": 1.46,
      "grad_norm": 3.7527642250061035,
      "learning_rate": 0.000259030303030303,
      "loss": 0.8036,
      "step": 730
    },
    {
      "epoch": 1.48,
      "grad_norm": 2.5866050720214844,
      "learning_rate": 0.0002584242424242424,
      "loss": 0.6842,
      "step": 740
    },
    {
      "epoch": 1.5,
      "grad_norm": 6.201045036315918,
      "learning_rate": 0.0002578181818181818,
      "loss": 0.7504,
      "step": 750
    },
    {
      "epoch": 1.52,
      "grad_norm": 3.8257434368133545,
      "learning_rate": 0.00025721212121212117,
      "loss": 0.7989,
      "step": 760
    },
    {
      "epoch": 1.54,
      "grad_norm": 1.4584354162216187,
      "learning_rate": 0.0002566060606060606,
      "loss": 0.7415,
      "step": 770
    },
    {
      "epoch": 1.56,
      "grad_norm": 1.3426194190979004,
      "learning_rate": 0.000256,
      "loss": 0.5558,
      "step": 780
    },
    {
      "epoch": 1.58,
      "grad_norm": 5.226990222930908,
      "learning_rate": 0.0002553939393939394,
      "loss": 0.6532,
      "step": 790
    },
    {
      "epoch": 1.6,
      "grad_norm": 2.7712788581848145,
      "learning_rate": 0.00025478787878787876,
      "loss": 0.8081,
      "step": 800
    },
    {
      "epoch": 1.6,
      "eval_loss": 0.8592187762260437,
      "eval_runtime": 8.3457,
      "eval_samples_per_second": 23.964,
      "eval_steps_per_second": 23.964,
      "step": 800
    },
    {
      "epoch": 1.62,
      "grad_norm": 3.0162124633789062,
      "learning_rate": 0.00025418181818181817,
      "loss": 0.6875,
      "step": 810
    },
    {
      "epoch": 1.6400000000000001,
      "grad_norm": 3.79514741897583,
      "learning_rate": 0.0002535757575757576,
      "loss": 0.6112,
      "step": 820
    },
    {
      "epoch": 1.6600000000000001,
      "grad_norm": 3.3353190422058105,
      "learning_rate": 0.00025296969696969693,
      "loss": 0.6918,
      "step": 830
    },
    {
      "epoch": 1.6800000000000002,
      "grad_norm": 3.8897504806518555,
      "learning_rate": 0.00025236363636363634,
      "loss": 0.7048,
      "step": 840
    },
    {
      "epoch": 1.7,
      "grad_norm": 3.2121453285217285,
      "learning_rate": 0.0002517575757575757,
      "loss": 0.7357,
      "step": 850
    },
    {
      "epoch": 1.72,
      "grad_norm": 5.0209245681762695,
      "learning_rate": 0.0002511515151515151,
      "loss": 0.712,
      "step": 860
    },
    {
      "epoch": 1.74,
      "grad_norm": 3.647860527038574,
      "learning_rate": 0.0002505454545454545,
      "loss": 0.6334,
      "step": 870
    },
    {
      "epoch": 1.76,
      "grad_norm": 4.557573318481445,
      "learning_rate": 0.00024993939393939393,
      "loss": 0.7784,
      "step": 880
    },
    {
      "epoch": 1.78,
      "grad_norm": 2.0339863300323486,
      "learning_rate": 0.00024933333333333334,
      "loss": 0.5474,
      "step": 890
    },
    {
      "epoch": 1.8,
      "grad_norm": 3.2327513694763184,
      "learning_rate": 0.0002487272727272727,
      "loss": 0.6264,
      "step": 900
    },
    {
      "epoch": 1.8,
      "eval_loss": 0.852271556854248,
      "eval_runtime": 8.315,
      "eval_samples_per_second": 24.053,
      "eval_steps_per_second": 24.053,
      "step": 900
    },
    {
      "epoch": 1.8199999999999998,
      "grad_norm": 2.2342581748962402,
      "learning_rate": 0.0002481212121212121,
      "loss": 0.6564,
      "step": 910
    },
    {
      "epoch": 1.8399999999999999,
      "grad_norm": 4.5664215087890625,
      "learning_rate": 0.00024751515151515146,
      "loss": 0.8057,
      "step": 920
    },
    {
      "epoch": 1.8599999999999999,
      "grad_norm": 2.6748013496398926,
      "learning_rate": 0.0002469090909090909,
      "loss": 0.7544,
      "step": 930
    },
    {
      "epoch": 1.88,
      "grad_norm": 2.427497386932373,
      "learning_rate": 0.0002463030303030303,
      "loss": 0.6149,
      "step": 940
    },
    {
      "epoch": 1.9,
      "grad_norm": 4.569235801696777,
      "learning_rate": 0.00024569696969696964,
      "loss": 0.7327,
      "step": 950
    },
    {
      "epoch": 1.92,
      "grad_norm": 2.27266001701355,
      "learning_rate": 0.0002450909090909091,
      "loss": 0.6014,
      "step": 960
    },
    {
      "epoch": 1.94,
      "grad_norm": 4.166635036468506,
      "learning_rate": 0.00024448484848484846,
      "loss": 0.9613,
      "step": 970
    },
    {
      "epoch": 1.96,
      "grad_norm": 4.470602512359619,
      "learning_rate": 0.00024387878787878787,
      "loss": 0.7715,
      "step": 980
    },
    {
      "epoch": 1.98,
      "grad_norm": 4.07366943359375,
      "learning_rate": 0.00024327272727272725,
      "loss": 0.5662,
      "step": 990
    },
    {
      "epoch": 2.0,
      "grad_norm": 2.9081296920776367,
      "learning_rate": 0.00024266666666666664,
      "loss": 0.853,
      "step": 1000
    },
    {
      "epoch": 2.0,
      "eval_loss": 0.8504200577735901,
      "eval_runtime": 8.2964,
      "eval_samples_per_second": 24.107,
      "eval_steps_per_second": 24.107,
      "step": 1000
    },
    {
      "epoch": 2.02,
      "grad_norm": 3.5809760093688965,
      "learning_rate": 0.00024206060606060602,
      "loss": 0.4194,
      "step": 1010
    },
    {
      "epoch": 2.04,
      "grad_norm": 2.9925105571746826,
      "learning_rate": 0.00024145454545454543,
      "loss": 0.5179,
      "step": 1020
    },
    {
      "epoch": 2.06,
      "grad_norm": 5.513917922973633,
      "learning_rate": 0.00024084848484848482,
      "loss": 0.6138,
      "step": 1030
    },
    {
      "epoch": 2.08,
      "grad_norm": 3.58036208152771,
      "learning_rate": 0.00024024242424242423,
      "loss": 0.5212,
      "step": 1040
    },
    {
      "epoch": 2.1,
      "grad_norm": 2.732043981552124,
      "learning_rate": 0.00023963636363636364,
      "loss": 0.4535,
      "step": 1050
    },
    {
      "epoch": 2.12,
      "grad_norm": 2.7379050254821777,
      "learning_rate": 0.00023903030303030302,
      "loss": 0.5478,
      "step": 1060
    },
    {
      "epoch": 2.14,
      "grad_norm": 3.42253041267395,
      "learning_rate": 0.0002384242424242424,
      "loss": 0.4325,
      "step": 1070
    },
    {
      "epoch": 2.16,
      "grad_norm": 5.5502448081970215,
      "learning_rate": 0.00023781818181818179,
      "loss": 0.6608,
      "step": 1080
    },
    {
      "epoch": 2.18,
      "grad_norm": 2.517746686935425,
      "learning_rate": 0.0002372121212121212,
      "loss": 0.4662,
      "step": 1090
    },
    {
      "epoch": 2.2,
      "grad_norm": 1.7279407978057861,
      "learning_rate": 0.00023660606060606058,
      "loss": 0.3822,
      "step": 1100
    },
    {
      "epoch": 2.2,
      "eval_loss": 0.9356845021247864,
      "eval_runtime": 8.4238,
      "eval_samples_per_second": 23.742,
      "eval_steps_per_second": 23.742,
      "step": 1100
    },
    {
      "epoch": 2.22,
      "grad_norm": 3.121102809906006,
      "learning_rate": 0.00023599999999999996,
      "loss": 0.4537,
      "step": 1110
    },
    {
      "epoch": 2.24,
      "grad_norm": 2.0575995445251465,
      "learning_rate": 0.00023539393939393935,
      "loss": 0.4962,
      "step": 1120
    },
    {
      "epoch": 2.26,
      "grad_norm": 2.1458542346954346,
      "learning_rate": 0.00023478787878787878,
      "loss": 0.4553,
      "step": 1130
    },
    {
      "epoch": 2.2800000000000002,
      "grad_norm": 6.053376197814941,
      "learning_rate": 0.00023418181818181817,
      "loss": 0.5513,
      "step": 1140
    },
    {
      "epoch": 2.3,
      "grad_norm": 4.531216144561768,
      "learning_rate": 0.00023357575757575755,
      "loss": 0.4824,
      "step": 1150
    },
    {
      "epoch": 2.32,
      "grad_norm": 3.997192144393921,
      "learning_rate": 0.00023296969696969696,
      "loss": 0.4645,
      "step": 1160
    },
    {
      "epoch": 2.34,
      "grad_norm": 3.2494513988494873,
      "learning_rate": 0.00023236363636363634,
      "loss": 0.4893,
      "step": 1170
    },
    {
      "epoch": 2.36,
      "grad_norm": 4.557593822479248,
      "learning_rate": 0.00023175757575757573,
      "loss": 0.4629,
      "step": 1180
    },
    {
      "epoch": 2.38,
      "grad_norm": 4.442917823791504,
      "learning_rate": 0.0002311515151515151,
      "loss": 0.4654,
      "step": 1190
    },
    {
      "epoch": 2.4,
      "grad_norm": 3.9167420864105225,
      "learning_rate": 0.00023054545454545452,
      "loss": 0.4474,
      "step": 1200
    },
    {
      "epoch": 2.4,
      "eval_loss": 0.942618727684021,
      "eval_runtime": 8.3569,
      "eval_samples_per_second": 23.932,
      "eval_steps_per_second": 23.932,
      "step": 1200
    },
    {
      "epoch": 2.42,
      "grad_norm": 2.2708749771118164,
      "learning_rate": 0.00022993939393939393,
      "loss": 0.3749,
      "step": 1210
    },
    {
      "epoch": 2.44,
      "grad_norm": 6.625743389129639,
      "learning_rate": 0.00022933333333333332,
      "loss": 0.6592,
      "step": 1220
    },
    {
      "epoch": 2.46,
      "grad_norm": 4.702754974365234,
      "learning_rate": 0.00022872727272727273,
      "loss": 0.5552,
      "step": 1230
    },
    {
      "epoch": 2.48,
      "grad_norm": 2.6807355880737305,
      "learning_rate": 0.0002281212121212121,
      "loss": 0.5802,
      "step": 1240
    },
    {
      "epoch": 2.5,
      "grad_norm": 3.8690171241760254,
      "learning_rate": 0.0002275151515151515,
      "loss": 0.575,
      "step": 1250
    },
    {
      "epoch": 2.52,
      "grad_norm": 2.4643008708953857,
      "learning_rate": 0.00022690909090909088,
      "loss": 0.6014,
      "step": 1260
    },
    {
      "epoch": 2.54,
      "grad_norm": 4.601737022399902,
      "learning_rate": 0.00022630303030303029,
      "loss": 0.5584,
      "step": 1270
    },
    {
      "epoch": 2.56,
      "grad_norm": 2.0303359031677246,
      "learning_rate": 0.00022569696969696967,
      "loss": 0.4082,
      "step": 1280
    },
    {
      "epoch": 2.58,
      "grad_norm": 3.004260778427124,
      "learning_rate": 0.00022509090909090905,
      "loss": 0.3963,
      "step": 1290
    },
    {
      "epoch": 2.6,
      "grad_norm": 3.2213449478149414,
      "learning_rate": 0.0002244848484848485,
      "loss": 0.5846,
      "step": 1300
    },
    {
      "epoch": 2.6,
      "eval_loss": 0.9053459763526917,
      "eval_runtime": 8.3357,
      "eval_samples_per_second": 23.993,
      "eval_steps_per_second": 23.993,
      "step": 1300
    },
    {
      "epoch": 2.62,
      "grad_norm": 3.1458358764648438,
      "learning_rate": 0.00022387878787878787,
      "loss": 0.6049,
      "step": 1310
    },
    {
      "epoch": 2.64,
      "grad_norm": 2.399698495864868,
      "learning_rate": 0.00022327272727272726,
      "loss": 0.4811,
      "step": 1320
    },
    {
      "epoch": 2.66,
      "grad_norm": 5.323659896850586,
      "learning_rate": 0.00022266666666666664,
      "loss": 0.5436,
      "step": 1330
    },
    {
      "epoch": 2.68,
      "grad_norm": 2.141756534576416,
      "learning_rate": 0.00022206060606060605,
      "loss": 0.4753,
      "step": 1340
    },
    {
      "epoch": 2.7,
      "grad_norm": 2.4519927501678467,
      "learning_rate": 0.00022145454545454543,
      "loss": 0.4405,
      "step": 1350
    },
    {
      "epoch": 2.7199999999999998,
      "grad_norm": 3.3393256664276123,
      "learning_rate": 0.00022084848484848482,
      "loss": 0.4743,
      "step": 1360
    },
    {
      "epoch": 2.74,
      "grad_norm": 3.5423877239227295,
      "learning_rate": 0.0002202424242424242,
      "loss": 0.4931,
      "step": 1370
    },
    {
      "epoch": 2.76,
      "grad_norm": 4.888576984405518,
      "learning_rate": 0.00021963636363636364,
      "loss": 0.5669,
      "step": 1380
    },
    {
      "epoch": 2.7800000000000002,
      "grad_norm": 2.0944502353668213,
      "learning_rate": 0.00021903030303030302,
      "loss": 0.6434,
      "step": 1390
    },
    {
      "epoch": 2.8,
      "grad_norm": 4.375771522521973,
      "learning_rate": 0.0002184242424242424,
      "loss": 0.5411,
      "step": 1400
    },
    {
      "epoch": 2.8,
      "eval_loss": 0.8907141089439392,
      "eval_runtime": 8.3322,
      "eval_samples_per_second": 24.003,
      "eval_steps_per_second": 24.003,
      "step": 1400
    },
    {
      "epoch": 2.82,
      "grad_norm": 2.5300371646881104,
      "learning_rate": 0.00021781818181818181,
      "loss": 0.3852,
      "step": 1410
    },
    {
      "epoch": 2.84,
      "grad_norm": 4.600113868713379,
      "learning_rate": 0.0002172121212121212,
      "loss": 0.4377,
      "step": 1420
    },
    {
      "epoch": 2.86,
      "grad_norm": 3.3191168308258057,
      "learning_rate": 0.00021660606060606058,
      "loss": 0.4867,
      "step": 1430
    },
    {
      "epoch": 2.88,
      "grad_norm": 3.502610921859741,
      "learning_rate": 0.00021599999999999996,
      "loss": 0.3817,
      "step": 1440
    },
    {
      "epoch": 2.9,
      "grad_norm": 2.796595573425293,
      "learning_rate": 0.00021539393939393938,
      "loss": 0.3629,
      "step": 1450
    },
    {
      "epoch": 2.92,
      "grad_norm": 2.1033666133880615,
      "learning_rate": 0.00021478787878787876,
      "loss": 0.6304,
      "step": 1460
    },
    {
      "epoch": 2.94,
      "grad_norm": 1.8240290880203247,
      "learning_rate": 0.00021418181818181817,
      "loss": 0.4412,
      "step": 1470
    },
    {
      "epoch": 2.96,
      "grad_norm": 3.629551649093628,
      "learning_rate": 0.00021357575757575758,
      "loss": 0.458,
      "step": 1480
    },
    {
      "epoch": 2.98,
      "grad_norm": 2.568347692489624,
      "learning_rate": 0.00021296969696969696,
      "loss": 0.5893,
      "step": 1490
    },
    {
      "epoch": 3.0,
      "grad_norm": 4.459504127502441,
      "learning_rate": 0.00021236363636363635,
      "loss": 0.6304,
      "step": 1500
    },
    {
      "epoch": 3.0,
      "eval_loss": 0.8695231676101685,
      "eval_runtime": 8.3207,
      "eval_samples_per_second": 24.036,
      "eval_steps_per_second": 24.036,
      "step": 1500
    },
    {
      "epoch": 3.02,
      "grad_norm": 2.6297526359558105,
      "learning_rate": 0.00021175757575757573,
      "loss": 0.3946,
      "step": 1510
    },
    {
      "epoch": 3.04,
      "grad_norm": 2.2474982738494873,
      "learning_rate": 0.00021115151515151514,
      "loss": 0.3183,
      "step": 1520
    },
    {
      "epoch": 3.06,
      "grad_norm": 3.662205457687378,
      "learning_rate": 0.00021054545454545452,
      "loss": 0.3457,
      "step": 1530
    },
    {
      "epoch": 3.08,
      "grad_norm": 4.665997505187988,
      "learning_rate": 0.0002099393939393939,
      "loss": 0.3771,
      "step": 1540
    },
    {
      "epoch": 3.1,
      "grad_norm": 3.6154210567474365,
      "learning_rate": 0.00020933333333333334,
      "loss": 0.4419,
      "step": 1550
    },
    {
      "epoch": 3.12,
      "grad_norm": 5.703211784362793,
      "learning_rate": 0.00020872727272727273,
      "loss": 0.3339,
      "step": 1560
    },
    {
      "epoch": 3.14,
      "grad_norm": 2.5225586891174316,
      "learning_rate": 0.0002081212121212121,
      "loss": 0.3996,
      "step": 1570
    },
    {
      "epoch": 3.16,
      "grad_norm": 2.1186046600341797,
      "learning_rate": 0.0002075151515151515,
      "loss": 0.3423,
      "step": 1580
    },
    {
      "epoch": 3.18,
      "grad_norm": 4.530913352966309,
      "learning_rate": 0.0002069090909090909,
      "loss": 0.4015,
      "step": 1590
    },
    {
      "epoch": 3.2,
      "grad_norm": 2.4752233028411865,
      "learning_rate": 0.0002063030303030303,
      "loss": 0.4405,
      "step": 1600
    },
    {
      "epoch": 3.2,
      "eval_loss": 0.9327762126922607,
      "eval_runtime": 8.3378,
      "eval_samples_per_second": 23.987,
      "eval_steps_per_second": 23.987,
      "step": 1600
    },
    {
      "epoch": 3.22,
      "grad_norm": 2.164419651031494,
      "learning_rate": 0.00020569696969696967,
      "loss": 0.3497,
      "step": 1610
    },
    {
      "epoch": 3.24,
      "grad_norm": 2.110790729522705,
      "learning_rate": 0.00020509090909090905,
      "loss": 0.2944,
      "step": 1620
    },
    {
      "epoch": 3.26,
      "grad_norm": 2.035337209701538,
      "learning_rate": 0.00020448484848484846,
      "loss": 0.3214,
      "step": 1630
    },
    {
      "epoch": 3.2800000000000002,
      "grad_norm": 3.187574625015259,
      "learning_rate": 0.00020387878787878788,
      "loss": 0.5005,
      "step": 1640
    },
    {
      "epoch": 3.3,
      "grad_norm": 1.6629600524902344,
      "learning_rate": 0.00020327272727272726,
      "loss": 0.3936,
      "step": 1650
    },
    {
      "epoch": 3.32,
      "grad_norm": 1.634421706199646,
      "learning_rate": 0.00020266666666666664,
      "loss": 0.3386,
      "step": 1660
    },
    {
      "epoch": 3.34,
      "grad_norm": 2.981640338897705,
      "learning_rate": 0.00020206060606060605,
      "loss": 0.2849,
      "step": 1670
    },
    {
      "epoch": 3.36,
      "grad_norm": 3.1082098484039307,
      "learning_rate": 0.00020145454545454544,
      "loss": 0.3952,
      "step": 1680
    },
    {
      "epoch": 3.38,
      "grad_norm": 2.1415374279022217,
      "learning_rate": 0.00020084848484848482,
      "loss": 0.4623,
      "step": 1690
    },
    {
      "epoch": 3.4,
      "grad_norm": 2.1874425411224365,
      "learning_rate": 0.0002002424242424242,
      "loss": 0.4085,
      "step": 1700
    },
    {
      "epoch": 3.4,
      "eval_loss": 0.9656835794448853,
      "eval_runtime": 8.3327,
      "eval_samples_per_second": 24.002,
      "eval_steps_per_second": 24.002,
      "step": 1700
    },
    {
      "epoch": 3.42,
      "grad_norm": 3.92926025390625,
      "learning_rate": 0.0001996363636363636,
      "loss": 0.4089,
      "step": 1710
    },
    {
      "epoch": 3.44,
      "grad_norm": 2.707681655883789,
      "learning_rate": 0.00019903030303030302,
      "loss": 0.3113,
      "step": 1720
    },
    {
      "epoch": 3.46,
      "grad_norm": 2.037313938140869,
      "learning_rate": 0.0001984242424242424,
      "loss": 0.3693,
      "step": 1730
    },
    {
      "epoch": 3.48,
      "grad_norm": 1.0174750089645386,
      "learning_rate": 0.00019781818181818182,
      "loss": 0.3795,
      "step": 1740
    },
    {
      "epoch": 3.5,
      "grad_norm": 3.0851259231567383,
      "learning_rate": 0.0001972121212121212,
      "loss": 0.3749,
      "step": 1750
    },
    {
      "epoch": 3.52,
      "grad_norm": 4.152430534362793,
      "learning_rate": 0.00019660606060606058,
      "loss": 0.3769,
      "step": 1760
    },
    {
      "epoch": 3.54,
      "grad_norm": 2.0725696086883545,
      "learning_rate": 0.00019599999999999997,
      "loss": 0.3012,
      "step": 1770
    },
    {
      "epoch": 3.56,
      "grad_norm": 3.550067663192749,
      "learning_rate": 0.00019539393939393938,
      "loss": 0.3839,
      "step": 1780
    },
    {
      "epoch": 3.58,
      "grad_norm": 1.0635178089141846,
      "learning_rate": 0.00019478787878787876,
      "loss": 0.2691,
      "step": 1790
    },
    {
      "epoch": 3.6,
      "grad_norm": 4.290329933166504,
      "learning_rate": 0.00019418181818181814,
      "loss": 0.4066,
      "step": 1800
    },
    {
      "epoch": 3.6,
      "eval_loss": 0.9681349396705627,
      "eval_runtime": 8.3457,
      "eval_samples_per_second": 23.964,
      "eval_steps_per_second": 23.964,
      "step": 1800
    },
    {
      "epoch": 3.62,
      "grad_norm": 3.302159309387207,
      "learning_rate": 0.00019357575757575758,
      "loss": 0.4056,
      "step": 1810
    },
    {
      "epoch": 3.64,
      "grad_norm": 3.6148223876953125,
      "learning_rate": 0.00019296969696969696,
      "loss": 0.4272,
      "step": 1820
    },
    {
      "epoch": 3.66,
      "grad_norm": 2.9576611518859863,
      "learning_rate": 0.00019236363636363635,
      "loss": 0.3188,
      "step": 1830
    },
    {
      "epoch": 3.68,
      "grad_norm": 4.005944728851318,
      "learning_rate": 0.00019175757575757573,
      "loss": 0.3535,
      "step": 1840
    },
    {
      "epoch": 3.7,
      "grad_norm": 3.3105239868164062,
      "learning_rate": 0.00019115151515151514,
      "loss": 0.3585,
      "step": 1850
    },
    {
      "epoch": 3.7199999999999998,
      "grad_norm": 4.097350597381592,
      "learning_rate": 0.00019054545454545452,
      "loss": 0.4074,
      "step": 1860
    },
    {
      "epoch": 3.74,
      "grad_norm": 3.4246599674224854,
      "learning_rate": 0.0001899393939393939,
      "loss": 0.4651,
      "step": 1870
    },
    {
      "epoch": 3.76,
      "grad_norm": 2.4707441329956055,
      "learning_rate": 0.0001893333333333333,
      "loss": 0.3701,
      "step": 1880
    },
    {
      "epoch": 3.7800000000000002,
      "grad_norm": 2.6701161861419678,
      "learning_rate": 0.00018872727272727273,
      "loss": 0.3824,
      "step": 1890
    },
    {
      "epoch": 3.8,
      "grad_norm": 2.4352784156799316,
      "learning_rate": 0.0001881212121212121,
      "loss": 0.3954,
      "step": 1900
    },
    {
      "epoch": 3.8,
      "eval_loss": 0.9838346838951111,
      "eval_runtime": 8.3299,
      "eval_samples_per_second": 24.01,
      "eval_steps_per_second": 24.01,
      "step": 1900
    },
    {
      "epoch": 3.82,
      "grad_norm": 3.250626802444458,
      "learning_rate": 0.0001875151515151515,
      "loss": 0.4103,
      "step": 1910
    },
    {
      "epoch": 3.84,
      "grad_norm": 2.3288304805755615,
      "learning_rate": 0.0001869090909090909,
      "loss": 0.3464,
      "step": 1920
    },
    {
      "epoch": 3.86,
      "grad_norm": 6.006026268005371,
      "learning_rate": 0.0001863030303030303,
      "loss": 0.4188,
      "step": 1930
    },
    {
      "epoch": 3.88,
      "grad_norm": 3.810309410095215,
      "learning_rate": 0.00018569696969696967,
      "loss": 0.3805,
      "step": 1940
    },
    {
      "epoch": 3.9,
      "grad_norm": 2.681230068206787,
      "learning_rate": 0.00018509090909090906,
      "loss": 0.3924,
      "step": 1950
    },
    {
      "epoch": 3.92,
      "grad_norm": 3.935093879699707,
      "learning_rate": 0.00018448484848484847,
      "loss": 0.3962,
      "step": 1960
    },
    {
      "epoch": 3.94,
      "grad_norm": 3.6207900047302246,
      "learning_rate": 0.00018387878787878785,
      "loss": 0.374,
      "step": 1970
    },
    {
      "epoch": 3.96,
      "grad_norm": 1.9318711757659912,
      "learning_rate": 0.00018327272727272726,
      "loss": 0.4169,
      "step": 1980
    },
    {
      "epoch": 3.98,
      "grad_norm": 2.7746336460113525,
      "learning_rate": 0.00018266666666666667,
      "loss": 0.3149,
      "step": 1990
    },
    {
      "epoch": 4.0,
      "grad_norm": 2.939448356628418,
      "learning_rate": 0.00018206060606060605,
      "loss": 0.379,
      "step": 2000
    },
    {
      "epoch": 4.0,
      "eval_loss": 0.9611369371414185,
      "eval_runtime": 8.3877,
      "eval_samples_per_second": 23.844,
      "eval_steps_per_second": 23.844,
      "step": 2000
    },
    {
      "epoch": 4.02,
      "grad_norm": 1.3332947492599487,
      "learning_rate": 0.00018145454545454544,
      "loss": 0.2631,
      "step": 2010
    },
    {
      "epoch": 4.04,
      "grad_norm": 4.179871082305908,
      "learning_rate": 0.00018084848484848482,
      "loss": 0.2932,
      "step": 2020
    },
    {
      "epoch": 4.06,
      "grad_norm": 1.4422783851623535,
      "learning_rate": 0.00018024242424242423,
      "loss": 0.2655,
      "step": 2030
    },
    {
      "epoch": 4.08,
      "grad_norm": 2.30318284034729,
      "learning_rate": 0.00017963636363636361,
      "loss": 0.2373,
      "step": 2040
    },
    {
      "epoch": 4.1,
      "grad_norm": 3.07303786277771,
      "learning_rate": 0.000179030303030303,
      "loss": 0.2835,
      "step": 2050
    },
    {
      "epoch": 4.12,
      "grad_norm": 2.553778648376465,
      "learning_rate": 0.00017842424242424244,
      "loss": 0.2366,
      "step": 2060
    },
    {
      "epoch": 4.14,
      "grad_norm": 2.4354958534240723,
      "learning_rate": 0.00017781818181818182,
      "loss": 0.3239,
      "step": 2070
    },
    {
      "epoch": 4.16,
      "grad_norm": 2.670536994934082,
      "learning_rate": 0.0001772121212121212,
      "loss": 0.2411,
      "step": 2080
    },
    {
      "epoch": 4.18,
      "grad_norm": 2.8253989219665527,
      "learning_rate": 0.00017660606060606059,
      "loss": 0.2463,
      "step": 2090
    },
    {
      "epoch": 4.2,
      "grad_norm": 4.217393398284912,
      "learning_rate": 0.000176,
      "loss": 0.3486,
      "step": 2100
    },
    {
      "epoch": 4.2,
      "eval_loss": 1.0441066026687622,
      "eval_runtime": 8.3359,
      "eval_samples_per_second": 23.993,
      "eval_steps_per_second": 23.993,
      "step": 2100
    },
    {
      "epoch": 4.22,
      "grad_norm": 3.5752193927764893,
      "learning_rate": 0.00017539393939393938,
      "loss": 0.3187,
      "step": 2110
    },
    {
      "epoch": 4.24,
      "grad_norm": 2.2073049545288086,
      "learning_rate": 0.00017478787878787876,
      "loss": 0.2526,
      "step": 2120
    },
    {
      "epoch": 4.26,
      "grad_norm": 2.4299702644348145,
      "learning_rate": 0.00017418181818181815,
      "loss": 0.2947,
      "step": 2130
    },
    {
      "epoch": 4.28,
      "grad_norm": 2.1455540657043457,
      "learning_rate": 0.00017357575757575756,
      "loss": 0.2759,
      "step": 2140
    },
    {
      "epoch": 4.3,
      "grad_norm": 1.6407698392868042,
      "learning_rate": 0.00017296969696969697,
      "loss": 0.2738,
      "step": 2150
    },
    {
      "epoch": 4.32,
      "grad_norm": 2.027277946472168,
      "learning_rate": 0.00017236363636363635,
      "loss": 0.334,
      "step": 2160
    },
    {
      "epoch": 4.34,
      "grad_norm": 2.4129600524902344,
      "learning_rate": 0.00017175757575757576,
      "loss": 0.3297,
      "step": 2170
    },
    {
      "epoch": 4.36,
      "grad_norm": 2.386282205581665,
      "learning_rate": 0.00017115151515151514,
      "loss": 0.2889,
      "step": 2180
    },
    {
      "epoch": 4.38,
      "grad_norm": 2.013075828552246,
      "learning_rate": 0.00017054545454545453,
      "loss": 0.2832,
      "step": 2190
    },
    {
      "epoch": 4.4,
      "grad_norm": 2.5558526515960693,
      "learning_rate": 0.0001699393939393939,
      "loss": 0.3453,
      "step": 2200
    },
    {
      "epoch": 4.4,
      "eval_loss": 1.0138194561004639,
      "eval_runtime": 8.313,
      "eval_samples_per_second": 24.059,
      "eval_steps_per_second": 24.059,
      "step": 2200
    },
    {
      "epoch": 4.42,
      "grad_norm": 2.136449098587036,
      "learning_rate": 0.00016933333333333332,
      "loss": 0.3369,
      "step": 2210
    },
    {
      "epoch": 4.44,
      "grad_norm": 3.6632297039031982,
      "learning_rate": 0.0001687272727272727,
      "loss": 0.2891,
      "step": 2220
    },
    {
      "epoch": 4.46,
      "grad_norm": 2.314390182495117,
      "learning_rate": 0.0001681212121212121,
      "loss": 0.2585,
      "step": 2230
    },
    {
      "epoch": 4.48,
      "grad_norm": 2.329035997390747,
      "learning_rate": 0.00016751515151515152,
      "loss": 0.3087,
      "step": 2240
    },
    {
      "epoch": 4.5,
      "grad_norm": 4.049853324890137,
      "learning_rate": 0.0001669090909090909,
      "loss": 0.3012,
      "step": 2250
    },
    {
      "epoch": 4.52,
      "grad_norm": 1.589471459388733,
      "learning_rate": 0.00016636363636363637,
      "loss": 0.3324,
      "step": 2260
    },
    {
      "epoch": 4.54,
      "grad_norm": 2.313948631286621,
      "learning_rate": 0.00016575757575757575,
      "loss": 0.3051,
      "step": 2270
    },
    {
      "epoch": 4.5600000000000005,
      "grad_norm": 1.659326434135437,
      "learning_rate": 0.00016515151515151513,
      "loss": 0.2543,
      "step": 2280
    },
    {
      "epoch": 4.58,
      "grad_norm": 3.4450490474700928,
      "learning_rate": 0.00016454545454545452,
      "loss": 0.3177,
      "step": 2290
    },
    {
      "epoch": 4.6,
      "grad_norm": 3.693667411804199,
      "learning_rate": 0.00016393939393939393,
      "loss": 0.3091,
      "step": 2300
    },
    {
      "epoch": 4.6,
      "eval_loss": 1.0264062881469727,
      "eval_runtime": 8.4047,
      "eval_samples_per_second": 23.796,
      "eval_steps_per_second": 23.796,
      "step": 2300
    },
    {
      "epoch": 4.62,
      "grad_norm": 4.2777910232543945,
      "learning_rate": 0.0001633333333333333,
      "loss": 0.347,
      "step": 2310
    },
    {
      "epoch": 4.64,
      "grad_norm": 3.116302490234375,
      "learning_rate": 0.00016272727272727272,
      "loss": 0.2962,
      "step": 2320
    },
    {
      "epoch": 4.66,
      "grad_norm": 1.8759251832962036,
      "learning_rate": 0.00016212121212121213,
      "loss": 0.2709,
      "step": 2330
    },
    {
      "epoch": 4.68,
      "grad_norm": 3.7484495639801025,
      "learning_rate": 0.00016151515151515151,
      "loss": 0.316,
      "step": 2340
    },
    {
      "epoch": 4.7,
      "grad_norm": 1.7927577495574951,
      "learning_rate": 0.0001609090909090909,
      "loss": 0.2522,
      "step": 2350
    },
    {
      "epoch": 4.72,
      "grad_norm": 3.6244490146636963,
      "learning_rate": 0.00016030303030303028,
      "loss": 0.3197,
      "step": 2360
    },
    {
      "epoch": 4.74,
      "grad_norm": 2.8196773529052734,
      "learning_rate": 0.0001596969696969697,
      "loss": 0.3852,
      "step": 2370
    },
    {
      "epoch": 4.76,
      "grad_norm": 3.7789299488067627,
      "learning_rate": 0.00015909090909090907,
      "loss": 0.3186,
      "step": 2380
    },
    {
      "epoch": 4.78,
      "grad_norm": 2.1352384090423584,
      "learning_rate": 0.00015848484848484846,
      "loss": 0.3264,
      "step": 2390
    },
    {
      "epoch": 4.8,
      "grad_norm": 0.7774762511253357,
      "learning_rate": 0.00015787878787878784,
      "loss": 0.224,
      "step": 2400
    },
    {
      "epoch": 4.8,
      "eval_loss": 0.9986427426338196,
      "eval_runtime": 8.3201,
      "eval_samples_per_second": 24.038,
      "eval_steps_per_second": 24.038,
      "step": 2400
    },
    {
      "epoch": 4.82,
      "grad_norm": 1.9682050943374634,
      "learning_rate": 0.00015727272727272728,
      "loss": 0.3138,
      "step": 2410
    },
    {
      "epoch": 4.84,
      "grad_norm": 5.665769100189209,
      "learning_rate": 0.00015666666666666666,
      "loss": 0.3068,
      "step": 2420
    },
    {
      "epoch": 4.86,
      "grad_norm": 5.858758449554443,
      "learning_rate": 0.00015606060606060605,
      "loss": 0.3604,
      "step": 2430
    },
    {
      "epoch": 4.88,
      "grad_norm": 2.2613563537597656,
      "learning_rate": 0.00015545454545454546,
      "loss": 0.3013,
      "step": 2440
    },
    {
      "epoch": 4.9,
      "grad_norm": 1.7871335744857788,
      "learning_rate": 0.00015484848484848484,
      "loss": 0.3368,
      "step": 2450
    },
    {
      "epoch": 4.92,
      "grad_norm": 2.864511728286743,
      "learning_rate": 0.00015424242424242422,
      "loss": 0.2564,
      "step": 2460
    },
    {
      "epoch": 4.9399999999999995,
      "grad_norm": 10.543245315551758,
      "learning_rate": 0.0001536363636363636,
      "loss": 0.3403,
      "step": 2470
    },
    {
      "epoch": 4.96,
      "grad_norm": 1.7007492780685425,
      "learning_rate": 0.00015303030303030302,
      "loss": 0.3001,
      "step": 2480
    },
    {
      "epoch": 4.98,
      "grad_norm": 1.023666262626648,
      "learning_rate": 0.00015242424242424243,
      "loss": 0.3126,
      "step": 2490
    },
    {
      "epoch": 5.0,
      "grad_norm": 2.089975118637085,
      "learning_rate": 0.0001518181818181818,
      "loss": 0.2813,
      "step": 2500
    },
    {
      "epoch": 5.0,
      "eval_loss": 1.0140224695205688,
      "eval_runtime": 8.3272,
      "eval_samples_per_second": 24.018,
      "eval_steps_per_second": 24.018,
      "step": 2500
    },
    {
      "epoch": 5.02,
      "grad_norm": 2.1112654209136963,
      "learning_rate": 0.00015121212121212122,
      "loss": 0.2669,
      "step": 2510
    },
    {
      "epoch": 5.04,
      "grad_norm": 1.7217243909835815,
      "learning_rate": 0.0001506060606060606,
      "loss": 0.2138,
      "step": 2520
    },
    {
      "epoch": 5.06,
      "grad_norm": 2.375213146209717,
      "learning_rate": 0.00015,
      "loss": 0.1637,
      "step": 2530
    },
    {
      "epoch": 5.08,
      "grad_norm": 1.042202115058899,
      "learning_rate": 0.00014939393939393937,
      "loss": 0.2661,
      "step": 2540
    },
    {
      "epoch": 5.1,
      "grad_norm": 1.581146478652954,
      "learning_rate": 0.00014878787878787875,
      "loss": 0.199,
      "step": 2550
    },
    {
      "epoch": 5.12,
      "grad_norm": 5.07697057723999,
      "learning_rate": 0.00014818181818181816,
      "loss": 0.2628,
      "step": 2560
    },
    {
      "epoch": 5.14,
      "grad_norm": 2.173611879348755,
      "learning_rate": 0.00014757575757575757,
      "loss": 0.2282,
      "step": 2570
    },
    {
      "epoch": 5.16,
      "grad_norm": 1.976133942604065,
      "learning_rate": 0.00014696969696969696,
      "loss": 0.2165,
      "step": 2580
    },
    {
      "epoch": 5.18,
      "grad_norm": 4.5357136726379395,
      "learning_rate": 0.00014636363636363634,
      "loss": 0.2297,
      "step": 2590
    },
    {
      "epoch": 5.2,
      "grad_norm": 1.1031694412231445,
      "learning_rate": 0.00014575757575757575,
      "loss": 0.2498,
      "step": 2600
    },
    {
      "epoch": 5.2,
      "eval_loss": 1.0864075422286987,
      "eval_runtime": 8.3348,
      "eval_samples_per_second": 23.996,
      "eval_steps_per_second": 23.996,
      "step": 2600
    },
    {
      "epoch": 5.22,
      "grad_norm": 2.2781014442443848,
      "learning_rate": 0.00014515151515151513,
      "loss": 0.2259,
      "step": 2610
    },
    {
      "epoch": 5.24,
      "grad_norm": 2.815112352371216,
      "learning_rate": 0.00014454545454545452,
      "loss": 0.2996,
      "step": 2620
    },
    {
      "epoch": 5.26,
      "grad_norm": 1.7761561870574951,
      "learning_rate": 0.00014393939393939393,
      "loss": 0.2018,
      "step": 2630
    },
    {
      "epoch": 5.28,
      "grad_norm": 2.4631009101867676,
      "learning_rate": 0.00014333333333333334,
      "loss": 0.2347,
      "step": 2640
    },
    {
      "epoch": 5.3,
      "grad_norm": 2.4567394256591797,
      "learning_rate": 0.00014272727272727272,
      "loss": 0.261,
      "step": 2650
    },
    {
      "epoch": 5.32,
      "grad_norm": 1.9613604545593262,
      "learning_rate": 0.0001421212121212121,
      "loss": 0.2195,
      "step": 2660
    },
    {
      "epoch": 5.34,
      "grad_norm": 2.3257675170898438,
      "learning_rate": 0.0001415151515151515,
      "loss": 0.2081,
      "step": 2670
    },
    {
      "epoch": 5.36,
      "grad_norm": 3.2632176876068115,
      "learning_rate": 0.0001409090909090909,
      "loss": 0.2191,
      "step": 2680
    },
    {
      "epoch": 5.38,
      "grad_norm": 2.2984023094177246,
      "learning_rate": 0.00014030303030303028,
      "loss": 0.2409,
      "step": 2690
    },
    {
      "epoch": 5.4,
      "grad_norm": 1.131927251815796,
      "learning_rate": 0.0001396969696969697,
      "loss": 0.232,
      "step": 2700
    },
    {
      "epoch": 5.4,
      "eval_loss": 1.0997990369796753,
      "eval_runtime": 8.3331,
      "eval_samples_per_second": 24.001,
      "eval_steps_per_second": 24.001,
      "step": 2700
    },
    {
      "epoch": 5.42,
      "grad_norm": 1.9342515468597412,
      "learning_rate": 0.00013909090909090908,
      "loss": 0.2615,
      "step": 2710
    },
    {
      "epoch": 5.44,
      "grad_norm": 1.7081663608551025,
      "learning_rate": 0.00013848484848484846,
      "loss": 0.2706,
      "step": 2720
    },
    {
      "epoch": 5.46,
      "grad_norm": 2.704444169998169,
      "learning_rate": 0.00013787878787878787,
      "loss": 0.2075,
      "step": 2730
    },
    {
      "epoch": 5.48,
      "grad_norm": 1.7241761684417725,
      "learning_rate": 0.00013727272727272725,
      "loss": 0.2562,
      "step": 2740
    },
    {
      "epoch": 5.5,
      "grad_norm": 2.0706799030303955,
      "learning_rate": 0.00013666666666666666,
      "loss": 0.2119,
      "step": 2750
    },
    {
      "epoch": 5.52,
      "grad_norm": 1.633657455444336,
      "learning_rate": 0.00013606060606060605,
      "loss": 0.2362,
      "step": 2760
    },
    {
      "epoch": 5.54,
      "grad_norm": 2.856724977493286,
      "learning_rate": 0.00013545454545454546,
      "loss": 0.2543,
      "step": 2770
    },
    {
      "epoch": 5.5600000000000005,
      "grad_norm": 2.3801350593566895,
      "learning_rate": 0.00013484848484848484,
      "loss": 0.2089,
      "step": 2780
    },
    {
      "epoch": 5.58,
      "grad_norm": 2.177673816680908,
      "learning_rate": 0.00013424242424242422,
      "loss": 0.2764,
      "step": 2790
    },
    {
      "epoch": 5.6,
      "grad_norm": 0.986478328704834,
      "learning_rate": 0.0001336363636363636,
      "loss": 0.2039,
      "step": 2800
    },
    {
      "epoch": 5.6,
      "eval_loss": 1.0589585304260254,
      "eval_runtime": 8.4019,
      "eval_samples_per_second": 23.804,
      "eval_steps_per_second": 23.804,
      "step": 2800
    },
    {
      "epoch": 5.62,
      "grad_norm": 2.206556558609009,
      "learning_rate": 0.00013303030303030302,
      "loss": 0.2502,
      "step": 2810
    },
    {
      "epoch": 5.64,
      "grad_norm": 2.106151580810547,
      "learning_rate": 0.00013242424242424243,
      "loss": 0.2532,
      "step": 2820
    },
    {
      "epoch": 5.66,
      "grad_norm": 1.8537718057632446,
      "learning_rate": 0.0001318181818181818,
      "loss": 0.2405,
      "step": 2830
    },
    {
      "epoch": 5.68,
      "grad_norm": 3.298710346221924,
      "learning_rate": 0.0001312121212121212,
      "loss": 0.228,
      "step": 2840
    },
    {
      "epoch": 5.7,
      "grad_norm": 1.5846985578536987,
      "learning_rate": 0.00013060606060606058,
      "loss": 0.2282,
      "step": 2850
    },
    {
      "epoch": 5.72,
      "grad_norm": 1.3110532760620117,
      "learning_rate": 0.00013,
      "loss": 0.2429,
      "step": 2860
    },
    {
      "epoch": 5.74,
      "grad_norm": 7.686670780181885,
      "learning_rate": 0.00012939393939393937,
      "loss": 0.3012,
      "step": 2870
    },
    {
      "epoch": 5.76,
      "grad_norm": 4.528292179107666,
      "learning_rate": 0.00012878787878787878,
      "loss": 0.2391,
      "step": 2880
    },
    {
      "epoch": 5.78,
      "grad_norm": 1.2104166746139526,
      "learning_rate": 0.00012818181818181817,
      "loss": 0.2455,
      "step": 2890
    },
    {
      "epoch": 5.8,
      "grad_norm": 1.6511170864105225,
      "learning_rate": 0.00012757575757575758,
      "loss": 0.238,
      "step": 2900
    },
    {
      "epoch": 5.8,
      "eval_loss": 1.0672383308410645,
      "eval_runtime": 8.4122,
      "eval_samples_per_second": 23.775,
      "eval_steps_per_second": 23.775,
      "step": 2900
    },
    {
      "epoch": 5.82,
      "grad_norm": 2.569519281387329,
      "learning_rate": 0.00012696969696969696,
      "loss": 0.2561,
      "step": 2910
    },
    {
      "epoch": 5.84,
      "grad_norm": 1.6116472482681274,
      "learning_rate": 0.00012636363636363634,
      "loss": 0.3028,
      "step": 2920
    },
    {
      "epoch": 5.86,
      "grad_norm": 1.0259124040603638,
      "learning_rate": 0.00012575757575757575,
      "loss": 0.2514,
      "step": 2930
    },
    {
      "epoch": 5.88,
      "grad_norm": 3.991391897201538,
      "learning_rate": 0.00012515151515151514,
      "loss": 0.2519,
      "step": 2940
    },
    {
      "epoch": 5.9,
      "grad_norm": 1.6369550228118896,
      "learning_rate": 0.00012454545454545455,
      "loss": 0.2317,
      "step": 2950
    },
    {
      "epoch": 5.92,
      "grad_norm": 2.801466703414917,
      "learning_rate": 0.00012393939393939393,
      "loss": 0.2636,
      "step": 2960
    },
    {
      "epoch": 5.9399999999999995,
      "grad_norm": 3.049546241760254,
      "learning_rate": 0.0001233333333333333,
      "loss": 0.2864,
      "step": 2970
    },
    {
      "epoch": 5.96,
      "grad_norm": 3.1773416996002197,
      "learning_rate": 0.00012272727272727272,
      "loss": 0.2642,
      "step": 2980
    },
    {
      "epoch": 5.98,
      "grad_norm": 2.9717230796813965,
      "learning_rate": 0.0001221212121212121,
      "loss": 0.2482,
      "step": 2990
    },
    {
      "epoch": 6.0,
      "grad_norm": 1.0414397716522217,
      "learning_rate": 0.0001215151515151515,
      "loss": 0.2551,
      "step": 3000
    },
    {
      "epoch": 6.0,
      "eval_loss": 1.085388422012329,
      "eval_runtime": 8.3292,
      "eval_samples_per_second": 24.012,
      "eval_steps_per_second": 24.012,
      "step": 3000
    },
    {
      "epoch": 6.02,
      "grad_norm": 3.6321821212768555,
      "learning_rate": 0.0001209090909090909,
      "loss": 0.1875,
      "step": 3010
    },
    {
      "epoch": 6.04,
      "grad_norm": 1.9988349676132202,
      "learning_rate": 0.00012030303030303028,
      "loss": 0.1941,
      "step": 3020
    },
    {
      "epoch": 6.06,
      "grad_norm": 1.7687026262283325,
      "learning_rate": 0.0001196969696969697,
      "loss": 0.1832,
      "step": 3030
    },
    {
      "epoch": 6.08,
      "grad_norm": 1.7663296461105347,
      "learning_rate": 0.00011909090909090908,
      "loss": 0.2039,
      "step": 3040
    },
    {
      "epoch": 6.1,
      "grad_norm": 12.050395965576172,
      "learning_rate": 0.00011848484848484847,
      "loss": 0.22,
      "step": 3050
    },
    {
      "epoch": 6.12,
      "grad_norm": 1.6147102117538452,
      "learning_rate": 0.00011787878787878786,
      "loss": 0.192,
      "step": 3060
    },
    {
      "epoch": 6.14,
      "grad_norm": 3.6090474128723145,
      "learning_rate": 0.00011727272727272727,
      "loss": 0.1987,
      "step": 3070
    },
    {
      "epoch": 6.16,
      "grad_norm": 1.4646332263946533,
      "learning_rate": 0.00011666666666666665,
      "loss": 0.141,
      "step": 3080
    },
    {
      "epoch": 6.18,
      "grad_norm": 3.8648741245269775,
      "learning_rate": 0.00011606060606060605,
      "loss": 0.2086,
      "step": 3090
    },
    {
      "epoch": 6.2,
      "grad_norm": 3.1034252643585205,
      "learning_rate": 0.00011545454545454543,
      "loss": 0.2023,
      "step": 3100
    },
    {
      "epoch": 6.2,
      "eval_loss": 1.152288556098938,
      "eval_runtime": 8.3372,
      "eval_samples_per_second": 23.989,
      "eval_steps_per_second": 23.989,
      "step": 3100
    },
    {
      "epoch": 6.22,
      "grad_norm": 4.595242977142334,
      "learning_rate": 0.00011484848484848484,
      "loss": 0.1818,
      "step": 3110
    },
    {
      "epoch": 6.24,
      "grad_norm": 10.436177253723145,
      "learning_rate": 0.00011424242424242424,
      "loss": 0.1849,
      "step": 3120
    },
    {
      "epoch": 6.26,
      "grad_norm": 5.149130821228027,
      "learning_rate": 0.00011363636363636362,
      "loss": 0.2222,
      "step": 3130
    },
    {
      "epoch": 6.28,
      "grad_norm": 1.9245375394821167,
      "learning_rate": 0.00011303030303030302,
      "loss": 0.1946,
      "step": 3140
    },
    {
      "epoch": 6.3,
      "grad_norm": 1.6105403900146484,
      "learning_rate": 0.00011242424242424242,
      "loss": 0.2134,
      "step": 3150
    },
    {
      "epoch": 6.32,
      "grad_norm": 1.7072235345840454,
      "learning_rate": 0.00011181818181818181,
      "loss": 0.179,
      "step": 3160
    },
    {
      "epoch": 6.34,
      "grad_norm": 1.5052521228790283,
      "learning_rate": 0.0001112121212121212,
      "loss": 0.1752,
      "step": 3170
    },
    {
      "epoch": 6.36,
      "grad_norm": 4.260927677154541,
      "learning_rate": 0.0001106060606060606,
      "loss": 0.2399,
      "step": 3180
    },
    {
      "epoch": 6.38,
      "grad_norm": 2.050706148147583,
      "learning_rate": 0.00010999999999999998,
      "loss": 0.2074,
      "step": 3190
    },
    {
      "epoch": 6.4,
      "grad_norm": 2.0384721755981445,
      "learning_rate": 0.00010939393939393939,
      "loss": 0.202,
      "step": 3200
    },
    {
      "epoch": 6.4,
      "eval_loss": 1.1509796380996704,
      "eval_runtime": 8.3261,
      "eval_samples_per_second": 24.021,
      "eval_steps_per_second": 24.021,
      "step": 3200
    },
    {
      "epoch": 6.42,
      "grad_norm": 2.2026619911193848,
      "learning_rate": 0.00010878787878787878,
      "loss": 0.1961,
      "step": 3210
    },
    {
      "epoch": 6.44,
      "grad_norm": 3.4435038566589355,
      "learning_rate": 0.00010818181818181817,
      "loss": 0.2152,
      "step": 3220
    },
    {
      "epoch": 6.46,
      "grad_norm": 4.340250492095947,
      "learning_rate": 0.00010757575757575756,
      "loss": 0.2371,
      "step": 3230
    },
    {
      "epoch": 6.48,
      "grad_norm": 2.1762566566467285,
      "learning_rate": 0.00010696969696969696,
      "loss": 0.29,
      "step": 3240
    },
    {
      "epoch": 6.5,
      "grad_norm": 5.7612199783325195,
      "learning_rate": 0.00010636363636363636,
      "loss": 0.2391,
      "step": 3250
    },
    {
      "epoch": 6.52,
      "grad_norm": 0.8296952843666077,
      "learning_rate": 0.00010575757575757574,
      "loss": 0.1765,
      "step": 3260
    },
    {
      "epoch": 6.54,
      "grad_norm": 2.4020543098449707,
      "learning_rate": 0.00010515151515151514,
      "loss": 0.1876,
      "step": 3270
    },
    {
      "epoch": 6.5600000000000005,
      "grad_norm": 2.6353065967559814,
      "learning_rate": 0.00010454545454545455,
      "loss": 0.2069,
      "step": 3280
    },
    {
      "epoch": 6.58,
      "grad_norm": 2.2253668308258057,
      "learning_rate": 0.00010393939393939393,
      "loss": 0.1975,
      "step": 3290
    },
    {
      "epoch": 6.6,
      "grad_norm": 2.6245343685150146,
      "learning_rate": 0.00010333333333333333,
      "loss": 0.2383,
      "step": 3300
    },
    {
      "epoch": 6.6,
      "eval_loss": 1.1649595499038696,
      "eval_runtime": 8.3331,
      "eval_samples_per_second": 24.001,
      "eval_steps_per_second": 24.001,
      "step": 3300
    },
    {
      "epoch": 6.62,
      "grad_norm": 3.292478322982788,
      "learning_rate": 0.00010272727272727271,
      "loss": 0.201,
      "step": 3310
    },
    {
      "epoch": 6.64,
      "grad_norm": 2.2087042331695557,
      "learning_rate": 0.00010212121212121212,
      "loss": 0.1985,
      "step": 3320
    },
    {
      "epoch": 6.66,
      "grad_norm": 2.0926008224487305,
      "learning_rate": 0.0001015151515151515,
      "loss": 0.2095,
      "step": 3330
    },
    {
      "epoch": 6.68,
      "grad_norm": 1.3600084781646729,
      "learning_rate": 0.0001009090909090909,
      "loss": 0.2115,
      "step": 3340
    },
    {
      "epoch": 6.7,
      "grad_norm": 1.0086894035339355,
      "learning_rate": 0.00010030303030303029,
      "loss": 0.2034,
      "step": 3350
    },
    {
      "epoch": 6.72,
      "grad_norm": 3.3708908557891846,
      "learning_rate": 9.969696969696968e-05,
      "loss": 0.2011,
      "step": 3360
    },
    {
      "epoch": 6.74,
      "grad_norm": 1.9081335067749023,
      "learning_rate": 9.90909090909091e-05,
      "loss": 0.2082,
      "step": 3370
    },
    {
      "epoch": 6.76,
      "grad_norm": 2.6338422298431396,
      "learning_rate": 9.848484848484848e-05,
      "loss": 0.2626,
      "step": 3380
    },
    {
      "epoch": 6.78,
      "grad_norm": 1.8207870721817017,
      "learning_rate": 9.787878787878787e-05,
      "loss": 0.1984,
      "step": 3390
    },
    {
      "epoch": 6.8,
      "grad_norm": 2.7177724838256836,
      "learning_rate": 9.727272727272726e-05,
      "loss": 0.2286,
      "step": 3400
    },
    {
      "epoch": 6.8,
      "eval_loss": 1.1661536693572998,
      "eval_runtime": 8.3376,
      "eval_samples_per_second": 23.988,
      "eval_steps_per_second": 23.988,
      "step": 3400
    },
    {
      "epoch": 6.82,
      "grad_norm": 1.8418068885803223,
      "learning_rate": 9.666666666666667e-05,
      "loss": 0.18,
      "step": 3410
    },
    {
      "epoch": 6.84,
      "grad_norm": 2.7165801525115967,
      "learning_rate": 9.606060606060605e-05,
      "loss": 0.2215,
      "step": 3420
    },
    {
      "epoch": 6.86,
      "grad_norm": 1.6032962799072266,
      "learning_rate": 9.545454545454545e-05,
      "loss": 0.2428,
      "step": 3430
    },
    {
      "epoch": 6.88,
      "grad_norm": 1.1781784296035767,
      "learning_rate": 9.484848484848483e-05,
      "loss": 0.1852,
      "step": 3440
    },
    {
      "epoch": 6.9,
      "grad_norm": 3.244135618209839,
      "learning_rate": 9.424242424242424e-05,
      "loss": 0.2287,
      "step": 3450
    },
    {
      "epoch": 6.92,
      "grad_norm": 2.791438579559326,
      "learning_rate": 9.363636363636364e-05,
      "loss": 0.1933,
      "step": 3460
    },
    {
      "epoch": 6.9399999999999995,
      "grad_norm": 1.2119780778884888,
      "learning_rate": 9.303030303030302e-05,
      "loss": 0.2036,
      "step": 3470
    },
    {
      "epoch": 6.96,
      "grad_norm": 2.280001640319824,
      "learning_rate": 9.242424242424242e-05,
      "loss": 0.2071,
      "step": 3480
    },
    {
      "epoch": 6.98,
      "grad_norm": 2.5275113582611084,
      "learning_rate": 9.18181818181818e-05,
      "loss": 0.2264,
      "step": 3490
    },
    {
      "epoch": 7.0,
      "grad_norm": 1.3752521276474,
      "learning_rate": 9.121212121212121e-05,
      "loss": 0.1823,
      "step": 3500
    },
    {
      "epoch": 7.0,
      "eval_loss": 1.1535518169403076,
      "eval_runtime": 8.3467,
      "eval_samples_per_second": 23.962,
      "eval_steps_per_second": 23.962,
      "step": 3500
    },
    {
      "epoch": 7.02,
      "grad_norm": 1.1945000886917114,
      "learning_rate": 9.06060606060606e-05,
      "loss": 0.1429,
      "step": 3510
    },
    {
      "epoch": 7.04,
      "grad_norm": 1.5722275972366333,
      "learning_rate": 8.999999999999999e-05,
      "loss": 0.1553,
      "step": 3520
    },
    {
      "epoch": 7.06,
      "grad_norm": 1.017081379890442,
      "learning_rate": 8.939393939393938e-05,
      "loss": 0.1752,
      "step": 3530
    },
    {
      "epoch": 7.08,
      "grad_norm": 2.2014658451080322,
      "learning_rate": 8.878787878787879e-05,
      "loss": 0.1587,
      "step": 3540
    },
    {
      "epoch": 7.1,
      "grad_norm": 1.4954549074172974,
      "learning_rate": 8.818181818181817e-05,
      "loss": 0.1629,
      "step": 3550
    },
    {
      "epoch": 7.12,
      "grad_norm": 2.046098232269287,
      "learning_rate": 8.757575757575757e-05,
      "loss": 0.1683,
      "step": 3560
    },
    {
      "epoch": 7.14,
      "grad_norm": 1.5346652269363403,
      "learning_rate": 8.696969696969695e-05,
      "loss": 0.1601,
      "step": 3570
    },
    {
      "epoch": 7.16,
      "grad_norm": 2.1241888999938965,
      "learning_rate": 8.636363636363636e-05,
      "loss": 0.1747,
      "step": 3580
    },
    {
      "epoch": 7.18,
      "grad_norm": 1.0855093002319336,
      "learning_rate": 8.575757575757576e-05,
      "loss": 0.1622,
      "step": 3590
    },
    {
      "epoch": 7.2,
      "grad_norm": 3.721693992614746,
      "learning_rate": 8.515151515151514e-05,
      "loss": 0.1782,
      "step": 3600
    },
    {
      "epoch": 7.2,
      "eval_loss": 1.203413963317871,
      "eval_runtime": 8.3419,
      "eval_samples_per_second": 23.975,
      "eval_steps_per_second": 23.975,
      "step": 3600
    },
    {
      "epoch": 7.22,
      "grad_norm": 1.1172124147415161,
      "learning_rate": 8.454545454545454e-05,
      "loss": 0.2107,
      "step": 3610
    },
    {
      "epoch": 7.24,
      "grad_norm": 2.2519540786743164,
      "learning_rate": 8.393939393939393e-05,
      "loss": 0.1714,
      "step": 3620
    },
    {
      "epoch": 7.26,
      "grad_norm": 1.7098959684371948,
      "learning_rate": 8.333333333333333e-05,
      "loss": 0.173,
      "step": 3630
    },
    {
      "epoch": 7.28,
      "grad_norm": 1.1739403009414673,
      "learning_rate": 8.272727272727271e-05,
      "loss": 0.1856,
      "step": 3640
    },
    {
      "epoch": 7.3,
      "grad_norm": 1.070357084274292,
      "learning_rate": 8.212121212121211e-05,
      "loss": 0.1664,
      "step": 3650
    },
    {
      "epoch": 7.32,
      "grad_norm": 1.6278456449508667,
      "learning_rate": 8.15151515151515e-05,
      "loss": 0.1747,
      "step": 3660
    },
    {
      "epoch": 7.34,
      "grad_norm": 1.4046584367752075,
      "learning_rate": 8.09090909090909e-05,
      "loss": 0.1658,
      "step": 3670
    },
    {
      "epoch": 7.36,
      "grad_norm": 1.9324586391448975,
      "learning_rate": 8.03030303030303e-05,
      "loss": 0.1839,
      "step": 3680
    },
    {
      "epoch": 7.38,
      "grad_norm": 3.2833962440490723,
      "learning_rate": 7.969696969696968e-05,
      "loss": 0.1626,
      "step": 3690
    },
    {
      "epoch": 7.4,
      "grad_norm": 1.2836428880691528,
      "learning_rate": 7.909090909090908e-05,
      "loss": 0.1598,
      "step": 3700
    },
    {
      "epoch": 7.4,
      "eval_loss": 1.1909360885620117,
      "eval_runtime": 8.3456,
      "eval_samples_per_second": 23.965,
      "eval_steps_per_second": 23.965,
      "step": 3700
    },
    {
      "epoch": 7.42,
      "grad_norm": 3.652061939239502,
      "learning_rate": 7.848484848484848e-05,
      "loss": 0.202,
      "step": 3710
    },
    {
      "epoch": 7.44,
      "grad_norm": 1.5311691761016846,
      "learning_rate": 7.787878787878788e-05,
      "loss": 0.1618,
      "step": 3720
    },
    {
      "epoch": 7.46,
      "grad_norm": 1.5589596033096313,
      "learning_rate": 7.727272727272726e-05,
      "loss": 0.1887,
      "step": 3730
    },
    {
      "epoch": 7.48,
      "grad_norm": 1.2051923274993896,
      "learning_rate": 7.666666666666666e-05,
      "loss": 0.1858,
      "step": 3740
    },
    {
      "epoch": 7.5,
      "grad_norm": 4.079371452331543,
      "learning_rate": 7.606060606060607e-05,
      "loss": 0.2164,
      "step": 3750
    },
    {
      "epoch": 7.52,
      "grad_norm": 1.8346792459487915,
      "learning_rate": 7.545454545454545e-05,
      "loss": 0.1688,
      "step": 3760
    },
    {
      "epoch": 7.54,
      "grad_norm": 2.3416385650634766,
      "learning_rate": 7.484848484848485e-05,
      "loss": 0.2022,
      "step": 3770
    },
    {
      "epoch": 7.5600000000000005,
      "grad_norm": 2.368255376815796,
      "learning_rate": 7.424242424242424e-05,
      "loss": 0.1732,
      "step": 3780
    },
    {
      "epoch": 7.58,
      "grad_norm": 1.7178747653961182,
      "learning_rate": 7.363636363636363e-05,
      "loss": 0.1813,
      "step": 3790
    },
    {
      "epoch": 7.6,
      "grad_norm": 1.2613987922668457,
      "learning_rate": 7.303030303030302e-05,
      "loss": 0.1918,
      "step": 3800
    },
    {
      "epoch": 7.6,
      "eval_loss": 1.2195472717285156,
      "eval_runtime": 8.3259,
      "eval_samples_per_second": 24.022,
      "eval_steps_per_second": 24.022,
      "step": 3800
    },
    {
      "epoch": 7.62,
      "grad_norm": 1.4817379713058472,
      "learning_rate": 7.242424242424242e-05,
      "loss": 0.2094,
      "step": 3810
    },
    {
      "epoch": 7.64,
      "grad_norm": 3.2810866832733154,
      "learning_rate": 7.18181818181818e-05,
      "loss": 0.1869,
      "step": 3820
    },
    {
      "epoch": 7.66,
      "grad_norm": 2.2356350421905518,
      "learning_rate": 7.12121212121212e-05,
      "loss": 0.2006,
      "step": 3830
    },
    {
      "epoch": 7.68,
      "grad_norm": 2.7508134841918945,
      "learning_rate": 7.06060606060606e-05,
      "loss": 0.1913,
      "step": 3840
    },
    {
      "epoch": 7.7,
      "grad_norm": 1.7342240810394287,
      "learning_rate": 7e-05,
      "loss": 0.1663,
      "step": 3850
    },
    {
      "epoch": 7.72,
      "grad_norm": 1.423599362373352,
      "learning_rate": 6.939393939393939e-05,
      "loss": 0.1801,
      "step": 3860
    },
    {
      "epoch": 7.74,
      "grad_norm": 1.7825926542282104,
      "learning_rate": 6.878787878787879e-05,
      "loss": 0.1802,
      "step": 3870
    },
    {
      "epoch": 7.76,
      "grad_norm": 1.1498764753341675,
      "learning_rate": 6.818181818181817e-05,
      "loss": 0.1862,
      "step": 3880
    },
    {
      "epoch": 7.78,
      "grad_norm": 2.1546897888183594,
      "learning_rate": 6.757575757575757e-05,
      "loss": 0.1707,
      "step": 3890
    },
    {
      "epoch": 7.8,
      "grad_norm": 1.5357309579849243,
      "learning_rate": 6.696969696969696e-05,
      "loss": 0.1785,
      "step": 3900
    },
    {
      "epoch": 7.8,
      "eval_loss": 1.210950255393982,
      "eval_runtime": 8.3479,
      "eval_samples_per_second": 23.958,
      "eval_steps_per_second": 23.958,
      "step": 3900
    },
    {
      "epoch": 7.82,
      "grad_norm": 5.183403491973877,
      "learning_rate": 6.636363636363636e-05,
      "loss": 0.1998,
      "step": 3910
    },
    {
      "epoch": 7.84,
      "grad_norm": 1.0408952236175537,
      "learning_rate": 6.575757575757574e-05,
      "loss": 0.1907,
      "step": 3920
    },
    {
      "epoch": 7.86,
      "grad_norm": 1.7490168809890747,
      "learning_rate": 6.515151515151516e-05,
      "loss": 0.1632,
      "step": 3930
    },
    {
      "epoch": 7.88,
      "grad_norm": 1.4780783653259277,
      "learning_rate": 6.454545454545454e-05,
      "loss": 0.1882,
      "step": 3940
    },
    {
      "epoch": 7.9,
      "grad_norm": 0.5191852450370789,
      "learning_rate": 6.393939393939394e-05,
      "loss": 0.1725,
      "step": 3950
    },
    {
      "epoch": 7.92,
      "grad_norm": 0.9359263181686401,
      "learning_rate": 6.333333333333333e-05,
      "loss": 0.1666,
      "step": 3960
    },
    {
      "epoch": 7.9399999999999995,
      "grad_norm": 2.863131046295166,
      "learning_rate": 6.272727272727272e-05,
      "loss": 0.1851,
      "step": 3970
    },
    {
      "epoch": 7.96,
      "grad_norm": 2.21274733543396,
      "learning_rate": 6.212121212121211e-05,
      "loss": 0.1925,
      "step": 3980
    },
    {
      "epoch": 7.98,
      "grad_norm": 1.3522522449493408,
      "learning_rate": 6.151515151515151e-05,
      "loss": 0.1737,
      "step": 3990
    },
    {
      "epoch": 8.0,
      "grad_norm": 2.8196072578430176,
      "learning_rate": 6.0909090909090906e-05,
      "loss": 0.2098,
      "step": 4000
    },
    {
      "epoch": 8.0,
      "eval_loss": 1.2148131132125854,
      "eval_runtime": 8.3358,
      "eval_samples_per_second": 23.993,
      "eval_steps_per_second": 23.993,
      "step": 4000
    },
    {
      "epoch": 8.02,
      "grad_norm": 1.672774076461792,
      "learning_rate": 6.0303030303030296e-05,
      "loss": 0.1385,
      "step": 4010
    },
    {
      "epoch": 8.04,
      "grad_norm": 1.3057085275650024,
      "learning_rate": 5.969696969696969e-05,
      "loss": 0.1475,
      "step": 4020
    },
    {
      "epoch": 8.06,
      "grad_norm": 0.8795260190963745,
      "learning_rate": 5.909090909090908e-05,
      "loss": 0.1531,
      "step": 4030
    },
    {
      "epoch": 8.08,
      "grad_norm": 1.5940529108047485,
      "learning_rate": 5.848484848484848e-05,
      "loss": 0.1438,
      "step": 4040
    },
    {
      "epoch": 8.1,
      "grad_norm": 0.9426223635673523,
      "learning_rate": 5.787878787878787e-05,
      "loss": 0.147,
      "step": 4050
    },
    {
      "epoch": 8.12,
      "grad_norm": 1.0039881467819214,
      "learning_rate": 5.727272727272727e-05,
      "loss": 0.1411,
      "step": 4060
    },
    {
      "epoch": 8.14,
      "grad_norm": 2.335683584213257,
      "learning_rate": 5.666666666666666e-05,
      "loss": 0.1374,
      "step": 4070
    },
    {
      "epoch": 8.16,
      "grad_norm": 1.8124772310256958,
      "learning_rate": 5.606060606060606e-05,
      "loss": 0.18,
      "step": 4080
    },
    {
      "epoch": 8.18,
      "grad_norm": 1.8645762205123901,
      "learning_rate": 5.545454545454545e-05,
      "loss": 0.1557,
      "step": 4090
    },
    {
      "epoch": 8.2,
      "grad_norm": 2.000684976577759,
      "learning_rate": 5.484848484848485e-05,
      "loss": 0.1514,
      "step": 4100
    },
    {
      "epoch": 8.2,
      "eval_loss": 1.2706984281539917,
      "eval_runtime": 8.3422,
      "eval_samples_per_second": 23.975,
      "eval_steps_per_second": 23.975,
      "step": 4100
    },
    {
      "epoch": 8.22,
      "grad_norm": 1.0820106267929077,
      "learning_rate": 5.424242424242424e-05,
      "loss": 0.1414,
      "step": 4110
    },
    {
      "epoch": 8.24,
      "grad_norm": 1.7028555870056152,
      "learning_rate": 5.3636363636363635e-05,
      "loss": 0.1611,
      "step": 4120
    },
    {
      "epoch": 8.26,
      "grad_norm": 1.993655800819397,
      "learning_rate": 5.3030303030303025e-05,
      "loss": 0.1773,
      "step": 4130
    },
    {
      "epoch": 8.28,
      "grad_norm": 1.5990642309188843,
      "learning_rate": 5.2424242424242415e-05,
      "loss": 0.1849,
      "step": 4140
    },
    {
      "epoch": 8.3,
      "grad_norm": 1.9378433227539062,
      "learning_rate": 5.181818181818181e-05,
      "loss": 0.1493,
      "step": 4150
    },
    {
      "epoch": 8.32,
      "grad_norm": 1.4463043212890625,
      "learning_rate": 5.12121212121212e-05,
      "loss": 0.1576,
      "step": 4160
    },
    {
      "epoch": 8.34,
      "grad_norm": 2.337656259536743,
      "learning_rate": 5.0606060606060606e-05,
      "loss": 0.1728,
      "step": 4170
    },
    {
      "epoch": 8.36,
      "grad_norm": 1.7464724779129028,
      "learning_rate": 4.9999999999999996e-05,
      "loss": 0.1552,
      "step": 4180
    },
    {
      "epoch": 8.38,
      "grad_norm": 4.518442630767822,
      "learning_rate": 4.939393939393939e-05,
      "loss": 0.1584,
      "step": 4190
    },
    {
      "epoch": 8.4,
      "grad_norm": 1.8613719940185547,
      "learning_rate": 4.878787878787878e-05,
      "loss": 0.1522,
      "step": 4200
    },
    {
      "epoch": 8.4,
      "eval_loss": 1.254386305809021,
      "eval_runtime": 8.3435,
      "eval_samples_per_second": 23.971,
      "eval_steps_per_second": 23.971,
      "step": 4200
    },
    {
      "epoch": 8.42,
      "grad_norm": 1.8207746744155884,
      "learning_rate": 4.818181818181818e-05,
      "loss": 0.1457,
      "step": 4210
    },
    {
      "epoch": 8.44,
      "grad_norm": 1.5005693435668945,
      "learning_rate": 4.757575757575757e-05,
      "loss": 0.1813,
      "step": 4220
    },
    {
      "epoch": 8.46,
      "grad_norm": 1.31057870388031,
      "learning_rate": 4.6969696969696966e-05,
      "loss": 0.1498,
      "step": 4230
    },
    {
      "epoch": 8.48,
      "grad_norm": 1.9995744228363037,
      "learning_rate": 4.6363636363636356e-05,
      "loss": 0.1592,
      "step": 4240
    },
    {
      "epoch": 8.5,
      "grad_norm": 2.1053173542022705,
      "learning_rate": 4.575757575757576e-05,
      "loss": 0.1536,
      "step": 4250
    },
    {
      "epoch": 8.52,
      "grad_norm": 2.3534202575683594,
      "learning_rate": 4.515151515151515e-05,
      "loss": 0.1455,
      "step": 4260
    },
    {
      "epoch": 8.54,
      "grad_norm": 1.703054428100586,
      "learning_rate": 4.454545454545455e-05,
      "loss": 0.1466,
      "step": 4270
    },
    {
      "epoch": 8.56,
      "grad_norm": 2.733873128890991,
      "learning_rate": 4.393939393939394e-05,
      "loss": 0.1615,
      "step": 4280
    },
    {
      "epoch": 8.58,
      "grad_norm": 1.2847932577133179,
      "learning_rate": 4.333333333333333e-05,
      "loss": 0.1663,
      "step": 4290
    },
    {
      "epoch": 8.6,
      "grad_norm": 1.1120575666427612,
      "learning_rate": 4.2727272727272724e-05,
      "loss": 0.1497,
      "step": 4300
    },
    {
      "epoch": 8.6,
      "eval_loss": 1.2881088256835938,
      "eval_runtime": 8.4229,
      "eval_samples_per_second": 23.745,
      "eval_steps_per_second": 23.745,
      "step": 4300
    },
    {
      "epoch": 8.62,
      "grad_norm": 1.136388897895813,
      "learning_rate": 4.2121212121212114e-05,
      "loss": 0.1526,
      "step": 4310
    },
    {
      "epoch": 8.64,
      "grad_norm": 2.861452102661133,
      "learning_rate": 4.151515151515151e-05,
      "loss": 0.1888,
      "step": 4320
    },
    {
      "epoch": 8.66,
      "grad_norm": 3.2295236587524414,
      "learning_rate": 4.09090909090909e-05,
      "loss": 0.1579,
      "step": 4330
    },
    {
      "epoch": 8.68,
      "grad_norm": 1.419442892074585,
      "learning_rate": 4.03030303030303e-05,
      "loss": 0.1364,
      "step": 4340
    },
    {
      "epoch": 8.7,
      "grad_norm": 1.2500115633010864,
      "learning_rate": 3.969696969696969e-05,
      "loss": 0.1449,
      "step": 4350
    },
    {
      "epoch": 8.72,
      "grad_norm": 1.5020976066589355,
      "learning_rate": 3.909090909090909e-05,
      "loss": 0.1705,
      "step": 4360
    },
    {
      "epoch": 8.74,
      "grad_norm": 1.1348373889923096,
      "learning_rate": 3.848484848484848e-05,
      "loss": 0.1576,
      "step": 4370
    },
    {
      "epoch": 8.76,
      "grad_norm": 2.2911758422851562,
      "learning_rate": 3.787878787878788e-05,
      "loss": 0.1297,
      "step": 4380
    },
    {
      "epoch": 8.78,
      "grad_norm": 2.344435453414917,
      "learning_rate": 3.727272727272727e-05,
      "loss": 0.1769,
      "step": 4390
    },
    {
      "epoch": 8.8,
      "grad_norm": 1.1734857559204102,
      "learning_rate": 3.666666666666666e-05,
      "loss": 0.1571,
      "step": 4400
    },
    {
      "epoch": 8.8,
      "eval_loss": 1.2777208089828491,
      "eval_runtime": 8.3229,
      "eval_samples_per_second": 24.03,
      "eval_steps_per_second": 24.03,
      "step": 4400
    },
    {
      "epoch": 8.82,
      "grad_norm": 3.2502124309539795,
      "learning_rate": 3.6060606060606056e-05,
      "loss": 0.19,
      "step": 4410
    },
    {
      "epoch": 8.84,
      "grad_norm": 1.5358213186264038,
      "learning_rate": 3.545454545454545e-05,
      "loss": 0.1602,
      "step": 4420
    },
    {
      "epoch": 8.86,
      "grad_norm": 0.9191920161247253,
      "learning_rate": 3.484848484848484e-05,
      "loss": 0.1804,
      "step": 4430
    },
    {
      "epoch": 8.88,
      "grad_norm": 1.8229926824569702,
      "learning_rate": 3.424242424242424e-05,
      "loss": 0.1555,
      "step": 4440
    },
    {
      "epoch": 8.9,
      "grad_norm": 3.5754928588867188,
      "learning_rate": 3.3636363636363636e-05,
      "loss": 0.1569,
      "step": 4450
    },
    {
      "epoch": 8.92,
      "grad_norm": 1.1584365367889404,
      "learning_rate": 3.3030303030303027e-05,
      "loss": 0.1576,
      "step": 4460
    },
    {
      "epoch": 8.94,
      "grad_norm": 1.5911364555358887,
      "learning_rate": 3.2424242424242423e-05,
      "loss": 0.1554,
      "step": 4470
    },
    {
      "epoch": 8.96,
      "grad_norm": 1.4509332180023193,
      "learning_rate": 3.1818181818181814e-05,
      "loss": 0.1674,
      "step": 4480
    },
    {
      "epoch": 8.98,
      "grad_norm": 1.4341949224472046,
      "learning_rate": 3.121212121212121e-05,
      "loss": 0.135,
      "step": 4490
    },
    {
      "epoch": 9.0,
      "grad_norm": 2.8583028316497803,
      "learning_rate": 3.060606060606061e-05,
      "loss": 0.1744,
      "step": 4500
    },
    {
      "epoch": 9.0,
      "eval_loss": 1.277148962020874,
      "eval_runtime": 8.4405,
      "eval_samples_per_second": 23.695,
      "eval_steps_per_second": 23.695,
      "step": 4500
    },
    {
      "epoch": 9.02,
      "grad_norm": 0.9229913949966431,
      "learning_rate": 2.9999999999999997e-05,
      "loss": 0.1482,
      "step": 4510
    },
    {
      "epoch": 9.04,
      "grad_norm": 1.0804098844528198,
      "learning_rate": 2.9393939393939394e-05,
      "loss": 0.1248,
      "step": 4520
    },
    {
      "epoch": 9.06,
      "grad_norm": 1.0594463348388672,
      "learning_rate": 2.8787878787878784e-05,
      "loss": 0.1436,
      "step": 4530
    },
    {
      "epoch": 9.08,
      "grad_norm": 1.1439040899276733,
      "learning_rate": 2.8181818181818178e-05,
      "loss": 0.1256,
      "step": 4540
    },
    {
      "epoch": 9.1,
      "grad_norm": 1.3235050439834595,
      "learning_rate": 2.757575757575757e-05,
      "loss": 0.1461,
      "step": 4550
    },
    {
      "epoch": 9.12,
      "grad_norm": 1.2511661052703857,
      "learning_rate": 2.6969696969696965e-05,
      "loss": 0.1486,
      "step": 4560
    },
    {
      "epoch": 9.14,
      "grad_norm": 1.3707096576690674,
      "learning_rate": 2.636363636363636e-05,
      "loss": 0.1408,
      "step": 4570
    },
    {
      "epoch": 9.16,
      "grad_norm": 0.8050544261932373,
      "learning_rate": 2.5757575757575755e-05,
      "loss": 0.1379,
      "step": 4580
    },
    {
      "epoch": 9.18,
      "grad_norm": 1.6821174621582031,
      "learning_rate": 2.515151515151515e-05,
      "loss": 0.1431,
      "step": 4590
    },
    {
      "epoch": 9.2,
      "grad_norm": 0.8282965421676636,
      "learning_rate": 2.4545454545454542e-05,
      "loss": 0.1434,
      "step": 4600
    },
    {
      "epoch": 9.2,
      "eval_loss": 1.3330157995224,
      "eval_runtime": 8.4506,
      "eval_samples_per_second": 23.667,
      "eval_steps_per_second": 23.667,
      "step": 4600
    },
    {
      "epoch": 9.22,
      "grad_norm": 1.3424266576766968,
      "learning_rate": 2.393939393939394e-05,
      "loss": 0.1424,
      "step": 4610
    },
    {
      "epoch": 9.24,
      "grad_norm": 1.419264316558838,
      "learning_rate": 2.3333333333333332e-05,
      "loss": 0.1404,
      "step": 4620
    },
    {
      "epoch": 9.26,
      "grad_norm": 3.8995039463043213,
      "learning_rate": 2.2727272727272726e-05,
      "loss": 0.1333,
      "step": 4630
    },
    {
      "epoch": 9.28,
      "grad_norm": 1.5029324293136597,
      "learning_rate": 2.212121212121212e-05,
      "loss": 0.1285,
      "step": 4640
    },
    {
      "epoch": 9.3,
      "grad_norm": 1.504645824432373,
      "learning_rate": 2.1515151515151513e-05,
      "loss": 0.1339,
      "step": 4650
    },
    {
      "epoch": 9.32,
      "grad_norm": 1.1713128089904785,
      "learning_rate": 2.090909090909091e-05,
      "loss": 0.1403,
      "step": 4660
    },
    {
      "epoch": 9.34,
      "grad_norm": 1.4018378257751465,
      "learning_rate": 2.0303030303030303e-05,
      "loss": 0.1437,
      "step": 4670
    },
    {
      "epoch": 9.36,
      "grad_norm": 1.3948087692260742,
      "learning_rate": 1.9696969696969697e-05,
      "loss": 0.1404,
      "step": 4680
    },
    {
      "epoch": 9.38,
      "grad_norm": 1.218001365661621,
      "learning_rate": 1.9090909090909087e-05,
      "loss": 0.1406,
      "step": 4690
    },
    {
      "epoch": 9.4,
      "grad_norm": 2.0435545444488525,
      "learning_rate": 1.8484848484848484e-05,
      "loss": 0.1577,
      "step": 4700
    },
    {
      "epoch": 9.4,
      "eval_loss": 1.3437304496765137,
      "eval_runtime": 8.3236,
      "eval_samples_per_second": 24.028,
      "eval_steps_per_second": 24.028,
      "step": 4700
    },
    {
      "epoch": 9.42,
      "grad_norm": 3.2863540649414062,
      "learning_rate": 1.7878787878787877e-05,
      "loss": 0.1362,
      "step": 4710
    },
    {
      "epoch": 9.44,
      "grad_norm": 1.4360600709915161,
      "learning_rate": 1.727272727272727e-05,
      "loss": 0.1557,
      "step": 4720
    },
    {
      "epoch": 9.46,
      "grad_norm": 1.214193344116211,
      "learning_rate": 1.6666666666666664e-05,
      "loss": 0.1456,
      "step": 4730
    },
    {
      "epoch": 9.48,
      "grad_norm": 1.4018694162368774,
      "learning_rate": 1.6060606060606058e-05,
      "loss": 0.1469,
      "step": 4740
    },
    {
      "epoch": 9.5,
      "grad_norm": 1.0118944644927979,
      "learning_rate": 1.5454545454545454e-05,
      "loss": 0.1473,
      "step": 4750
    },
    {
      "epoch": 9.52,
      "grad_norm": 1.4924219846725464,
      "learning_rate": 1.4848484848484846e-05,
      "loss": 0.1371,
      "step": 4760
    },
    {
      "epoch": 9.54,
      "grad_norm": 1.892042875289917,
      "learning_rate": 1.4242424242424241e-05,
      "loss": 0.1485,
      "step": 4770
    },
    {
      "epoch": 9.56,
      "grad_norm": 1.112506628036499,
      "learning_rate": 1.3636363636363635e-05,
      "loss": 0.1347,
      "step": 4780
    },
    {
      "epoch": 9.58,
      "grad_norm": 1.4861838817596436,
      "learning_rate": 1.303030303030303e-05,
      "loss": 0.137,
      "step": 4790
    },
    {
      "epoch": 9.6,
      "grad_norm": 0.9964631199836731,
      "learning_rate": 1.2424242424242424e-05,
      "loss": 0.1352,
      "step": 4800
    },
    {
      "epoch": 9.6,
      "eval_loss": 1.3395202159881592,
      "eval_runtime": 8.4444,
      "eval_samples_per_second": 23.684,
      "eval_steps_per_second": 23.684,
      "step": 4800
    },
    {
      "epoch": 9.62,
      "grad_norm": 2.0905377864837646,
      "learning_rate": 1.1818181818181817e-05,
      "loss": 0.1486,
      "step": 4810
    },
    {
      "epoch": 9.64,
      "grad_norm": 1.4148833751678467,
      "learning_rate": 1.121212121212121e-05,
      "loss": 0.1433,
      "step": 4820
    },
    {
      "epoch": 9.66,
      "grad_norm": 1.37214994430542,
      "learning_rate": 1.0606060606060604e-05,
      "loss": 0.1461,
      "step": 4830
    },
    {
      "epoch": 9.68,
      "grad_norm": 2.462761402130127,
      "learning_rate": 9.999999999999999e-06,
      "loss": 0.1302,
      "step": 4840
    },
    {
      "epoch": 9.7,
      "grad_norm": 1.281131386756897,
      "learning_rate": 9.393939393939393e-06,
      "loss": 0.1267,
      "step": 4850
    },
    {
      "epoch": 9.72,
      "grad_norm": 2.6119847297668457,
      "learning_rate": 8.787878787878788e-06,
      "loss": 0.1377,
      "step": 4860
    },
    {
      "epoch": 9.74,
      "grad_norm": 1.7625659704208374,
      "learning_rate": 8.181818181818181e-06,
      "loss": 0.178,
      "step": 4870
    },
    {
      "epoch": 9.76,
      "grad_norm": 1.5958341360092163,
      "learning_rate": 7.575757575757575e-06,
      "loss": 0.1396,
      "step": 4880
    },
    {
      "epoch": 9.78,
      "grad_norm": 1.6013226509094238,
      "learning_rate": 6.969696969696969e-06,
      "loss": 0.1381,
      "step": 4890
    },
    {
      "epoch": 9.8,
      "grad_norm": 1.561085820198059,
      "learning_rate": 6.363636363636363e-06,
      "loss": 0.1306,
      "step": 4900
    },
    {
      "epoch": 9.8,
      "eval_loss": 1.339156150817871,
      "eval_runtime": 8.343,
      "eval_samples_per_second": 23.972,
      "eval_steps_per_second": 23.972,
      "step": 4900
    },
    {
      "epoch": 9.82,
      "grad_norm": 1.6695011854171753,
      "learning_rate": 5.757575757575757e-06,
      "loss": 0.1409,
      "step": 4910
    },
    {
      "epoch": 9.84,
      "grad_norm": 1.9434778690338135,
      "learning_rate": 5.151515151515151e-06,
      "loss": 0.1444,
      "step": 4920
    },
    {
      "epoch": 9.86,
      "grad_norm": 1.0116825103759766,
      "learning_rate": 4.5454545454545455e-06,
      "loss": 0.125,
      "step": 4930
    },
    {
      "epoch": 9.88,
      "grad_norm": 3.004246950149536,
      "learning_rate": 3.939393939393939e-06,
      "loss": 0.1551,
      "step": 4940
    },
    {
      "epoch": 9.9,
      "grad_norm": 1.6262094974517822,
      "learning_rate": 3.3333333333333333e-06,
      "loss": 0.149,
      "step": 4950
    },
    {
      "epoch": 9.92,
      "grad_norm": 1.3179367780685425,
      "learning_rate": 2.727272727272727e-06,
      "loss": 0.148,
      "step": 4960
    },
    {
      "epoch": 9.94,
      "grad_norm": 1.3214936256408691,
      "learning_rate": 2.121212121212121e-06,
      "loss": 0.1221,
      "step": 4970
    },
    {
      "epoch": 9.96,
      "grad_norm": 1.8671666383743286,
      "learning_rate": 1.5151515151515152e-06,
      "loss": 0.1537,
      "step": 4980
    },
    {
      "epoch": 9.98,
      "grad_norm": 1.6034241914749146,
      "learning_rate": 9.09090909090909e-07,
      "loss": 0.1351,
      "step": 4990
    },
    {
      "epoch": 10.0,
      "grad_norm": 1.3602533340454102,
      "learning_rate": 3.03030303030303e-07,
      "loss": 0.1379,
      "step": 5000
    },
    {
      "epoch": 10.0,
      "eval_loss": 1.3390387296676636,
      "eval_runtime": 8.3204,
      "eval_samples_per_second": 24.037,
      "eval_steps_per_second": 24.037,
      "step": 5000
    }
  ],
  "logging_steps": 10,
  "max_steps": 5000,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 10,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 1.496916688896e+16,
  "train_batch_size": 1,
  "trial_name": null,
  "trial_params": null
}

{
  "config": {
    "model": "meta-llama/Llama-2-7b-hf",
    "task1": "scienceqa",
    "task2": "fomc",
    "batch_size": 1,
    "num_epochs": 10,
    "lora_r": 2,
    "lora_alpha": 4
  },
  "accuracy_after_task1": {
    "scienceqa_accuracy": 0.72,
    "fomc_accuracy": 0.3
  },
  "accuracy_after_task2": {
    "scienceqa_accuracy": 0.7,
    "fomc_accuracy": 0.68
  },
  "forgetting_metrics": {
    "task1_acc_before": 0.72,
    "task1_acc_after": 0.7,
    "task2_acc_after": 0.68,
    "absolute_forgetting": 0.020000000000000018,
    "relative_forgetting_pct": 2.7777777777777803,
    "backward_transfer": -0.020000000000000018,
    "avg_accuracy": 0.69
  },
  "landscape_task1_after_task1": {
    "lambda_max_lora": 0.0,
    "eigenvalues_lora": [
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0
    ],
    "lora_param_norm": 23.374364852905273,
    "lora_displacement": 0.0,
    "lora_dimension": 4997120,
    "forgetting_bound": null
  },
  "landscape_task1_after_task2": {
    "lambda_max_lora": 0.0,
    "eigenvalues_lora": [
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0
    ],
    "lora_param_norm": 30.127016067504883,
    "lora_displacement": 18.532817840576172,
    "lora_dimension": 4997120,
    "forgetting_bound": 0.0
  },
  "landscape_task2_after_task1": {
    "lambda_max_lora": 0.0,
    "eigenvalues_lora": [
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0
    ],
    "lora_param_norm": 23.374364852905273,
    "lora_displacement": 0.0,
    "lora_dimension": 4997120,
    "forgetting_bound": null
  },
  "landscape_task2_after_task2": {
    "lambda_max_lora": 0.0,
    "eigenvalues_lora": [
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0,
      0.0
    ],
    "lora_param_norm": 30.127016067504883,
    "lora_displacement": 18.532817840576172,
    "lora_dimension": 4997120,
    "forgetting_bound": 0.0
  }
}
{
  "best_global_step": null,
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 9.0,
  "eval_steps": 100,
  "global_step": 4500,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.02,
      "grad_norm": 26.049318313598633,
      "learning_rate": 2.9999999999999997e-05,
      "loss": 4.8824,
      "step": 10
    },
    {
      "epoch": 0.04,
      "grad_norm": 10.26529312133789,
      "learning_rate": 8.999999999999999e-05,
      "loss": 3.7717,
      "step": 20
    },
    {
      "epoch": 0.06,
      "grad_norm": 5.907961845397949,
      "learning_rate": 0.00015,
      "loss": 2.4543,
      "step": 30
    },
    {
      "epoch": 0.08,
      "grad_norm": 4.2482781410217285,
      "learning_rate": 0.00020999999999999998,
      "loss": 1.6403,
      "step": 40
    },
    {
      "epoch": 0.1,
      "grad_norm": 3.0503053665161133,
      "learning_rate": 0.00027,
      "loss": 1.4266,
      "step": 50
    },
    {
      "epoch": 0.12,
      "grad_norm": 3.3197720050811768,
      "learning_rate": 0.00029969696969696965,
      "loss": 1.5053,
      "step": 60
    },
    {
      "epoch": 0.14,
      "grad_norm": 2.136949300765991,
      "learning_rate": 0.00029909090909090906,
      "loss": 1.422,
      "step": 70
    },
    {
      "epoch": 0.16,
      "grad_norm": 2.593052625656128,
      "learning_rate": 0.00029848484848484847,
      "loss": 1.3056,
      "step": 80
    },
    {
      "epoch": 0.18,
      "grad_norm": 2.126377820968628,
      "learning_rate": 0.00029787878787878783,
      "loss": 1.252,
      "step": 90
    },
    {
      "epoch": 0.2,
      "grad_norm": 2.5942373275756836,
      "learning_rate": 0.00029727272727272724,
      "loss": 1.0537,
      "step": 100
    },
    {
      "epoch": 0.2,
      "eval_loss": 1.3547751903533936,
      "eval_runtime": 8.6001,
      "eval_samples_per_second": 23.256,
      "eval_steps_per_second": 23.256,
      "step": 100
    },
    {
      "epoch": 0.22,
      "grad_norm": 3.3150694370269775,
      "learning_rate": 0.00029666666666666665,
      "loss": 1.1213,
      "step": 110
    },
    {
      "epoch": 0.24,
      "grad_norm": 2.5793282985687256,
      "learning_rate": 0.00029606060606060606,
      "loss": 1.3835,
      "step": 120
    },
    {
      "epoch": 0.26,
      "grad_norm": 2.273935556411743,
      "learning_rate": 0.0002954545454545454,
      "loss": 1.1058,
      "step": 130
    },
    {
      "epoch": 0.28,
      "grad_norm": 1.8729498386383057,
      "learning_rate": 0.0002948484848484848,
      "loss": 1.0732,
      "step": 140
    },
    {
      "epoch": 0.3,
      "grad_norm": 3.505542278289795,
      "learning_rate": 0.00029424242424242424,
      "loss": 1.4173,
      "step": 150
    },
    {
      "epoch": 0.32,
      "grad_norm": 2.3639140129089355,
      "learning_rate": 0.0002936363636363636,
      "loss": 1.457,
      "step": 160
    },
    {
      "epoch": 0.34,
      "grad_norm": 2.1847710609436035,
      "learning_rate": 0.000293030303030303,
      "loss": 1.3954,
      "step": 170
    },
    {
      "epoch": 0.36,
      "grad_norm": 2.865457773208618,
      "learning_rate": 0.00029242424242424236,
      "loss": 1.1676,
      "step": 180
    },
    {
      "epoch": 0.38,
      "grad_norm": 2.3839385509490967,
      "learning_rate": 0.0002918181818181818,
      "loss": 1.354,
      "step": 190
    },
    {
      "epoch": 0.4,
      "grad_norm": 2.2938926219940186,
      "learning_rate": 0.0002912121212121212,
      "loss": 1.124,
      "step": 200
    },
    {
      "epoch": 0.4,
      "eval_loss": 1.291048288345337,
      "eval_runtime": 8.4036,
      "eval_samples_per_second": 23.799,
      "eval_steps_per_second": 23.799,
      "step": 200
    },
    {
      "epoch": 0.42,
      "grad_norm": 2.145146608352661,
      "learning_rate": 0.0002906060606060606,
      "loss": 1.3869,
      "step": 210
    },
    {
      "epoch": 0.44,
      "grad_norm": 1.5309244394302368,
      "learning_rate": 0.00029,
      "loss": 1.205,
      "step": 220
    },
    {
      "epoch": 0.46,
      "grad_norm": 2.415611743927002,
      "learning_rate": 0.00028939393939393936,
      "loss": 1.3021,
      "step": 230
    },
    {
      "epoch": 0.48,
      "grad_norm": 1.7607393264770508,
      "learning_rate": 0.00028878787878787877,
      "loss": 1.2676,
      "step": 240
    },
    {
      "epoch": 0.5,
      "grad_norm": 2.5084002017974854,
      "learning_rate": 0.0002881818181818181,
      "loss": 1.2412,
      "step": 250
    },
    {
      "epoch": 0.52,
      "grad_norm": 3.1341564655303955,
      "learning_rate": 0.00028757575757575753,
      "loss": 1.1161,
      "step": 260
    },
    {
      "epoch": 0.54,
      "grad_norm": 1.8249989748001099,
      "learning_rate": 0.00028696969696969695,
      "loss": 1.389,
      "step": 270
    },
    {
      "epoch": 0.56,
      "grad_norm": 2.615098237991333,
      "learning_rate": 0.00028636363636363636,
      "loss": 1.2106,
      "step": 280
    },
    {
      "epoch": 0.58,
      "grad_norm": 2.0893003940582275,
      "learning_rate": 0.00028575757575757577,
      "loss": 1.2436,
      "step": 290
    },
    {
      "epoch": 0.6,
      "grad_norm": 1.6398838758468628,
      "learning_rate": 0.0002851515151515151,
      "loss": 1.3991,
      "step": 300
    },
    {
      "epoch": 0.6,
      "eval_loss": 1.2796106338500977,
      "eval_runtime": 8.3552,
      "eval_samples_per_second": 23.937,
      "eval_steps_per_second": 23.937,
      "step": 300
    },
    {
      "epoch": 0.62,
      "grad_norm": 2.2764205932617188,
      "learning_rate": 0.00028454545454545453,
      "loss": 1.2243,
      "step": 310
    },
    {
      "epoch": 0.64,
      "grad_norm": 2.12050199508667,
      "learning_rate": 0.0002839393939393939,
      "loss": 1.073,
      "step": 320
    },
    {
      "epoch": 0.66,
      "grad_norm": 1.8832188844680786,
      "learning_rate": 0.0002833333333333333,
      "loss": 1.2532,
      "step": 330
    },
    {
      "epoch": 0.68,
      "grad_norm": 2.996569871902466,
      "learning_rate": 0.0002827272727272727,
      "loss": 1.2845,
      "step": 340
    },
    {
      "epoch": 0.7,
      "grad_norm": 1.603899598121643,
      "learning_rate": 0.00028212121212121207,
      "loss": 1.1417,
      "step": 350
    },
    {
      "epoch": 0.72,
      "grad_norm": 2.39369797706604,
      "learning_rate": 0.00028151515151515153,
      "loss": 1.1325,
      "step": 360
    },
    {
      "epoch": 0.74,
      "grad_norm": 2.616600751876831,
      "learning_rate": 0.0002809090909090909,
      "loss": 1.3764,
      "step": 370
    },
    {
      "epoch": 0.76,
      "grad_norm": 2.546180248260498,
      "learning_rate": 0.0002803030303030303,
      "loss": 1.3511,
      "step": 380
    },
    {
      "epoch": 0.78,
      "grad_norm": 2.450580358505249,
      "learning_rate": 0.00027969696969696965,
      "loss": 1.4215,
      "step": 390
    },
    {
      "epoch": 0.8,
      "grad_norm": 1.8165998458862305,
      "learning_rate": 0.00027909090909090906,
      "loss": 1.2055,
      "step": 400
    },
    {
      "epoch": 0.8,
      "eval_loss": 1.2687002420425415,
      "eval_runtime": 8.357,
      "eval_samples_per_second": 23.932,
      "eval_steps_per_second": 23.932,
      "step": 400
    },
    {
      "epoch": 0.82,
      "grad_norm": 1.9740097522735596,
      "learning_rate": 0.0002784848484848485,
      "loss": 1.1035,
      "step": 410
    },
    {
      "epoch": 0.84,
      "grad_norm": 1.9291691780090332,
      "learning_rate": 0.00027787878787878783,
      "loss": 1.0057,
      "step": 420
    },
    {
      "epoch": 0.86,
      "grad_norm": 2.309022903442383,
      "learning_rate": 0.00027727272727272724,
      "loss": 1.4248,
      "step": 430
    },
    {
      "epoch": 0.88,
      "grad_norm": 2.2821807861328125,
      "learning_rate": 0.00027666666666666665,
      "loss": 1.2071,
      "step": 440
    },
    {
      "epoch": 0.9,
      "grad_norm": 2.103238582611084,
      "learning_rate": 0.00027606060606060606,
      "loss": 1.2817,
      "step": 450
    },
    {
      "epoch": 0.92,
      "grad_norm": 3.3015031814575195,
      "learning_rate": 0.0002754545454545454,
      "loss": 1.1733,
      "step": 460
    },
    {
      "epoch": 0.94,
      "grad_norm": 1.3836177587509155,
      "learning_rate": 0.00027484848484848483,
      "loss": 1.2399,
      "step": 470
    },
    {
      "epoch": 0.96,
      "grad_norm": 1.904789686203003,
      "learning_rate": 0.00027424242424242424,
      "loss": 1.3306,
      "step": 480
    },
    {
      "epoch": 0.98,
      "grad_norm": 1.613769292831421,
      "learning_rate": 0.0002736363636363636,
      "loss": 1.2404,
      "step": 490
    },
    {
      "epoch": 1.0,
      "grad_norm": 2.4955756664276123,
      "learning_rate": 0.000273030303030303,
      "loss": 1.446,
      "step": 500
    },
    {
      "epoch": 1.0,
      "eval_loss": 1.2571989297866821,
      "eval_runtime": 8.3423,
      "eval_samples_per_second": 23.974,
      "eval_steps_per_second": 23.974,
      "step": 500
    },
    {
      "epoch": 1.02,
      "grad_norm": 1.760948896408081,
      "learning_rate": 0.0002724242424242424,
      "loss": 1.2137,
      "step": 510
    },
    {
      "epoch": 1.04,
      "grad_norm": 0.9789495468139648,
      "learning_rate": 0.00027181818181818177,
      "loss": 1.0976,
      "step": 520
    },
    {
      "epoch": 1.06,
      "grad_norm": 2.215381622314453,
      "learning_rate": 0.0002712121212121212,
      "loss": 0.8897,
      "step": 530
    },
    {
      "epoch": 1.08,
      "grad_norm": 4.313071250915527,
      "learning_rate": 0.0002706060606060606,
      "loss": 0.9405,
      "step": 540
    },
    {
      "epoch": 1.1,
      "grad_norm": 2.1357438564300537,
      "learning_rate": 0.00027,
      "loss": 0.9053,
      "step": 550
    },
    {
      "epoch": 1.12,
      "grad_norm": 2.215902328491211,
      "learning_rate": 0.00026939393939393936,
      "loss": 1.0422,
      "step": 560
    },
    {
      "epoch": 1.1400000000000001,
      "grad_norm": 2.932194471359253,
      "learning_rate": 0.00026878787878787877,
      "loss": 1.0001,
      "step": 570
    },
    {
      "epoch": 1.16,
      "grad_norm": 2.2130656242370605,
      "learning_rate": 0.0002681818181818181,
      "loss": 0.9609,
      "step": 580
    },
    {
      "epoch": 1.18,
      "grad_norm": 2.804023265838623,
      "learning_rate": 0.00026757575757575754,
      "loss": 1.1127,
      "step": 590
    },
    {
      "epoch": 1.2,
      "grad_norm": 2.6368842124938965,
      "learning_rate": 0.00026696969696969695,
      "loss": 1.0317,
      "step": 600
    },
    {
      "epoch": 1.2,
      "eval_loss": 1.2958353757858276,
      "eval_runtime": 8.5423,
      "eval_samples_per_second": 23.413,
      "eval_steps_per_second": 23.413,
      "step": 600
    },
    {
      "epoch": 1.22,
      "grad_norm": 2.276369094848633,
      "learning_rate": 0.00026636363636363636,
      "loss": 1.1698,
      "step": 610
    },
    {
      "epoch": 1.24,
      "grad_norm": 2.4842605590820312,
      "learning_rate": 0.00026575757575757577,
      "loss": 0.8818,
      "step": 620
    },
    {
      "epoch": 1.26,
      "grad_norm": 2.952479124069214,
      "learning_rate": 0.0002651515151515151,
      "loss": 1.1736,
      "step": 630
    },
    {
      "epoch": 1.28,
      "grad_norm": 2.8841776847839355,
      "learning_rate": 0.00026454545454545453,
      "loss": 0.9577,
      "step": 640
    },
    {
      "epoch": 1.3,
      "grad_norm": 2.206927537918091,
      "learning_rate": 0.0002639393939393939,
      "loss": 0.9146,
      "step": 650
    },
    {
      "epoch": 1.32,
      "grad_norm": 2.8532845973968506,
      "learning_rate": 0.0002633333333333333,
      "loss": 0.993,
      "step": 660
    },
    {
      "epoch": 1.34,
      "grad_norm": 2.832883834838867,
      "learning_rate": 0.0002627272727272727,
      "loss": 1.0002,
      "step": 670
    },
    {
      "epoch": 1.3599999999999999,
      "grad_norm": 2.2763490676879883,
      "learning_rate": 0.00026212121212121207,
      "loss": 1.0985,
      "step": 680
    },
    {
      "epoch": 1.38,
      "grad_norm": 2.623610734939575,
      "learning_rate": 0.0002615151515151515,
      "loss": 1.0433,
      "step": 690
    },
    {
      "epoch": 1.4,
      "grad_norm": 2.796053171157837,
      "learning_rate": 0.0002609090909090909,
      "loss": 1.2074,
      "step": 700
    },
    {
      "epoch": 1.4,
      "eval_loss": 1.2843937873840332,
      "eval_runtime": 8.8501,
      "eval_samples_per_second": 22.599,
      "eval_steps_per_second": 22.599,
      "step": 700
    },
    {
      "epoch": 1.42,
      "grad_norm": 2.129312515258789,
      "learning_rate": 0.0002603030303030303,
      "loss": 1.0706,
      "step": 710
    },
    {
      "epoch": 1.44,
      "grad_norm": 2.302719831466675,
      "learning_rate": 0.00025969696969696966,
      "loss": 1.0311,
      "step": 720
    },
    {
      "epoch": 1.46,
      "grad_norm": 2.4583988189697266,
      "learning_rate": 0.00025909090909090907,
      "loss": 1.0972,
      "step": 730
    },
    {
      "epoch": 1.48,
      "grad_norm": 1.5851361751556396,
      "learning_rate": 0.0002584848484848485,
      "loss": 0.9154,
      "step": 740
    },
    {
      "epoch": 1.5,
      "grad_norm": 2.0361907482147217,
      "learning_rate": 0.00025787878787878783,
      "loss": 0.9897,
      "step": 750
    },
    {
      "epoch": 1.52,
      "grad_norm": 2.711927890777588,
      "learning_rate": 0.00025727272727272724,
      "loss": 0.9283,
      "step": 760
    },
    {
      "epoch": 1.54,
      "grad_norm": 2.347952365875244,
      "learning_rate": 0.00025666666666666665,
      "loss": 1.0683,
      "step": 770
    },
    {
      "epoch": 1.56,
      "grad_norm": 2.2021045684814453,
      "learning_rate": 0.000256060606060606,
      "loss": 0.9092,
      "step": 780
    },
    {
      "epoch": 1.58,
      "grad_norm": 2.5664870738983154,
      "learning_rate": 0.0002554545454545454,
      "loss": 1.0591,
      "step": 790
    },
    {
      "epoch": 1.6,
      "grad_norm": 2.6369149684906006,
      "learning_rate": 0.00025484848484848483,
      "loss": 1.08,
      "step": 800
    },
    {
      "epoch": 1.6,
      "eval_loss": 1.2865666151046753,
      "eval_runtime": 8.3561,
      "eval_samples_per_second": 23.935,
      "eval_steps_per_second": 23.935,
      "step": 800
    },
    {
      "epoch": 1.62,
      "grad_norm": 2.1308388710021973,
      "learning_rate": 0.00025424242424242424,
      "loss": 1.0614,
      "step": 810
    },
    {
      "epoch": 1.6400000000000001,
      "grad_norm": 2.8131823539733887,
      "learning_rate": 0.0002536363636363636,
      "loss": 1.0705,
      "step": 820
    },
    {
      "epoch": 1.6600000000000001,
      "grad_norm": 3.4113383293151855,
      "learning_rate": 0.000253030303030303,
      "loss": 1.1934,
      "step": 830
    },
    {
      "epoch": 1.6800000000000002,
      "grad_norm": 3.748579740524292,
      "learning_rate": 0.0002524242424242424,
      "loss": 1.2459,
      "step": 840
    },
    {
      "epoch": 1.7,
      "grad_norm": 2.759856700897217,
      "learning_rate": 0.0002518181818181818,
      "loss": 0.92,
      "step": 850
    },
    {
      "epoch": 1.72,
      "grad_norm": 2.279228687286377,
      "learning_rate": 0.0002512121212121212,
      "loss": 1.0674,
      "step": 860
    },
    {
      "epoch": 1.74,
      "grad_norm": 2.334242820739746,
      "learning_rate": 0.0002506060606060606,
      "loss": 0.94,
      "step": 870
    },
    {
      "epoch": 1.76,
      "grad_norm": 2.853041648864746,
      "learning_rate": 0.00025,
      "loss": 1.1391,
      "step": 880
    },
    {
      "epoch": 1.78,
      "grad_norm": 2.3188822269439697,
      "learning_rate": 0.00024939393939393936,
      "loss": 1.0267,
      "step": 890
    },
    {
      "epoch": 1.8,
      "grad_norm": 2.4473764896392822,
      "learning_rate": 0.00024878787878787877,
      "loss": 0.9458,
      "step": 900
    },
    {
      "epoch": 1.8,
      "eval_loss": 1.289709210395813,
      "eval_runtime": 8.4177,
      "eval_samples_per_second": 23.759,
      "eval_steps_per_second": 23.759,
      "step": 900
    },
    {
      "epoch": 1.8199999999999998,
      "grad_norm": 2.9531967639923096,
      "learning_rate": 0.0002481818181818182,
      "loss": 0.9923,
      "step": 910
    },
    {
      "epoch": 1.8399999999999999,
      "grad_norm": 4.309259414672852,
      "learning_rate": 0.00024757575757575754,
      "loss": 1.1787,
      "step": 920
    },
    {
      "epoch": 1.8599999999999999,
      "grad_norm": 2.395488739013672,
      "learning_rate": 0.00024696969696969695,
      "loss": 0.9373,
      "step": 930
    },
    {
      "epoch": 1.88,
      "grad_norm": 3.885772705078125,
      "learning_rate": 0.0002463636363636363,
      "loss": 1.0263,
      "step": 940
    },
    {
      "epoch": 1.9,
      "grad_norm": 3.585111141204834,
      "learning_rate": 0.0002457575757575757,
      "loss": 0.9415,
      "step": 950
    },
    {
      "epoch": 1.92,
      "grad_norm": 2.7253878116607666,
      "learning_rate": 0.0002451515151515151,
      "loss": 0.9004,
      "step": 960
    },
    {
      "epoch": 1.94,
      "grad_norm": 4.144951820373535,
      "learning_rate": 0.00024454545454545454,
      "loss": 0.89,
      "step": 970
    },
    {
      "epoch": 1.96,
      "grad_norm": 4.3148016929626465,
      "learning_rate": 0.00024393939393939392,
      "loss": 1.2428,
      "step": 980
    },
    {
      "epoch": 1.98,
      "grad_norm": 3.1632020473480225,
      "learning_rate": 0.0002433333333333333,
      "loss": 1.176,
      "step": 990
    },
    {
      "epoch": 2.0,
      "grad_norm": 2.321979284286499,
      "learning_rate": 0.0002427272727272727,
      "loss": 0.7946,
      "step": 1000
    },
    {
      "epoch": 2.0,
      "eval_loss": 1.287865161895752,
      "eval_runtime": 8.356,
      "eval_samples_per_second": 23.935,
      "eval_steps_per_second": 23.935,
      "step": 1000
    },
    {
      "epoch": 2.02,
      "grad_norm": 3.0714664459228516,
      "learning_rate": 0.0002421212121212121,
      "loss": 0.6031,
      "step": 1010
    },
    {
      "epoch": 2.04,
      "grad_norm": 4.105406284332275,
      "learning_rate": 0.00024151515151515148,
      "loss": 0.6855,
      "step": 1020
    },
    {
      "epoch": 2.06,
      "grad_norm": 3.1805601119995117,
      "learning_rate": 0.00024090909090909086,
      "loss": 0.8787,
      "step": 1030
    },
    {
      "epoch": 2.08,
      "grad_norm": 3.7331483364105225,
      "learning_rate": 0.0002403030303030303,
      "loss": 0.7147,
      "step": 1040
    },
    {
      "epoch": 2.1,
      "grad_norm": 2.9453959465026855,
      "learning_rate": 0.00023969696969696968,
      "loss": 0.6251,
      "step": 1050
    },
    {
      "epoch": 2.12,
      "grad_norm": 0.3641398251056671,
      "learning_rate": 0.00023909090909090907,
      "loss": 0.9435,
      "step": 1060
    },
    {
      "epoch": 2.14,
      "grad_norm": 3.144404172897339,
      "learning_rate": 0.00023848484848484848,
      "loss": 0.7765,
      "step": 1070
    },
    {
      "epoch": 2.16,
      "grad_norm": 3.2732417583465576,
      "learning_rate": 0.00023787878787878786,
      "loss": 0.8234,
      "step": 1080
    },
    {
      "epoch": 2.18,
      "grad_norm": 4.028213977813721,
      "learning_rate": 0.00023727272727272724,
      "loss": 0.7513,
      "step": 1090
    },
    {
      "epoch": 2.2,
      "grad_norm": 3.539799213409424,
      "learning_rate": 0.00023666666666666663,
      "loss": 0.66,
      "step": 1100
    },
    {
      "epoch": 2.2,
      "eval_loss": 1.3925567865371704,
      "eval_runtime": 8.8382,
      "eval_samples_per_second": 22.629,
      "eval_steps_per_second": 22.629,
      "step": 1100
    },
    {
      "epoch": 2.22,
      "grad_norm": 4.00037145614624,
      "learning_rate": 0.00023606060606060604,
      "loss": 0.7806,
      "step": 1110
    },
    {
      "epoch": 2.24,
      "grad_norm": 3.4806442260742188,
      "learning_rate": 0.00023545454545454542,
      "loss": 0.776,
      "step": 1120
    },
    {
      "epoch": 2.26,
      "grad_norm": 2.0891990661621094,
      "learning_rate": 0.00023484848484848483,
      "loss": 0.6631,
      "step": 1130
    },
    {
      "epoch": 2.2800000000000002,
      "grad_norm": 3.438289165496826,
      "learning_rate": 0.00023424242424242424,
      "loss": 0.8765,
      "step": 1140
    },
    {
      "epoch": 2.3,
      "grad_norm": 4.233081340789795,
      "learning_rate": 0.00023363636363636363,
      "loss": 0.6873,
      "step": 1150
    },
    {
      "epoch": 2.32,
      "grad_norm": 3.318523406982422,
      "learning_rate": 0.000233030303030303,
      "loss": 0.6977,
      "step": 1160
    },
    {
      "epoch": 2.34,
      "grad_norm": 1.6470147371292114,
      "learning_rate": 0.0002324242424242424,
      "loss": 0.6669,
      "step": 1170
    },
    {
      "epoch": 2.36,
      "grad_norm": 3.5754106044769287,
      "learning_rate": 0.0002318181818181818,
      "loss": 0.8214,
      "step": 1180
    },
    {
      "epoch": 2.38,
      "grad_norm": 3.63022518157959,
      "learning_rate": 0.00023121212121212119,
      "loss": 0.8597,
      "step": 1190
    },
    {
      "epoch": 2.4,
      "grad_norm": 3.363173007965088,
      "learning_rate": 0.00023060606060606057,
      "loss": 0.7101,
      "step": 1200
    },
    {
      "epoch": 2.4,
      "eval_loss": 1.3723886013031006,
      "eval_runtime": 8.6054,
      "eval_samples_per_second": 23.241,
      "eval_steps_per_second": 23.241,
      "step": 1200
    },
    {
      "epoch": 2.42,
      "grad_norm": 3.15641188621521,
      "learning_rate": 0.00023,
      "loss": 0.7447,
      "step": 1210
    },
    {
      "epoch": 2.44,
      "grad_norm": 3.4231719970703125,
      "learning_rate": 0.0002293939393939394,
      "loss": 0.7688,
      "step": 1220
    },
    {
      "epoch": 2.46,
      "grad_norm": 3.392895221710205,
      "learning_rate": 0.00022878787878787877,
      "loss": 0.6958,
      "step": 1230
    },
    {
      "epoch": 2.48,
      "grad_norm": 1.8024896383285522,
      "learning_rate": 0.00022818181818181816,
      "loss": 0.7576,
      "step": 1240
    },
    {
      "epoch": 2.5,
      "grad_norm": 3.356431245803833,
      "learning_rate": 0.00022757575757575757,
      "loss": 0.7385,
      "step": 1250
    },
    {
      "epoch": 2.52,
      "grad_norm": 2.1466445922851562,
      "learning_rate": 0.00022696969696969695,
      "loss": 0.7429,
      "step": 1260
    },
    {
      "epoch": 2.54,
      "grad_norm": 2.73905611038208,
      "learning_rate": 0.00022636363636363633,
      "loss": 0.8235,
      "step": 1270
    },
    {
      "epoch": 2.56,
      "grad_norm": 3.0559144020080566,
      "learning_rate": 0.00022575757575757572,
      "loss": 0.7354,
      "step": 1280
    },
    {
      "epoch": 2.58,
      "grad_norm": 4.508711338043213,
      "learning_rate": 0.00022515151515151513,
      "loss": 0.8878,
      "step": 1290
    },
    {
      "epoch": 2.6,
      "grad_norm": 3.8682749271392822,
      "learning_rate": 0.00022454545454545454,
      "loss": 0.8448,
      "step": 1300
    },
    {
      "epoch": 2.6,
      "eval_loss": 1.3869839906692505,
      "eval_runtime": 8.7612,
      "eval_samples_per_second": 22.828,
      "eval_steps_per_second": 22.828,
      "step": 1300
    },
    {
      "epoch": 2.62,
      "grad_norm": 4.0005669593811035,
      "learning_rate": 0.00022393939393939392,
      "loss": 0.739,
      "step": 1310
    },
    {
      "epoch": 2.64,
      "grad_norm": 3.3153440952301025,
      "learning_rate": 0.00022333333333333333,
      "loss": 0.818,
      "step": 1320
    },
    {
      "epoch": 2.66,
      "grad_norm": 2.7387478351593018,
      "learning_rate": 0.00022272727272727272,
      "loss": 0.8402,
      "step": 1330
    },
    {
      "epoch": 2.68,
      "grad_norm": 3.30220627784729,
      "learning_rate": 0.0002221212121212121,
      "loss": 0.7623,
      "step": 1340
    },
    {
      "epoch": 2.7,
      "grad_norm": 3.4089889526367188,
      "learning_rate": 0.00022151515151515148,
      "loss": 0.6398,
      "step": 1350
    },
    {
      "epoch": 2.7199999999999998,
      "grad_norm": 3.369248151779175,
      "learning_rate": 0.0002209090909090909,
      "loss": 0.7584,
      "step": 1360
    },
    {
      "epoch": 2.74,
      "grad_norm": 2.9976415634155273,
      "learning_rate": 0.00022030303030303028,
      "loss": 0.7873,
      "step": 1370
    },
    {
      "epoch": 2.76,
      "grad_norm": 3.925710916519165,
      "learning_rate": 0.00021969696969696969,
      "loss": 0.7525,
      "step": 1380
    },
    {
      "epoch": 2.7800000000000002,
      "grad_norm": 4.399627208709717,
      "learning_rate": 0.0002190909090909091,
      "loss": 0.7066,
      "step": 1390
    },
    {
      "epoch": 2.8,
      "grad_norm": 3.981506824493408,
      "learning_rate": 0.00021848484848484848,
      "loss": 0.7151,
      "step": 1400
    },
    {
      "epoch": 2.8,
      "eval_loss": 1.4055085182189941,
      "eval_runtime": 8.6018,
      "eval_samples_per_second": 23.251,
      "eval_steps_per_second": 23.251,
      "step": 1400
    },
    {
      "epoch": 2.82,
      "grad_norm": 3.5221107006073,
      "learning_rate": 0.00021787878787878786,
      "loss": 0.7843,
      "step": 1410
    },
    {
      "epoch": 2.84,
      "grad_norm": 2.585894823074341,
      "learning_rate": 0.00021727272727272725,
      "loss": 0.7994,
      "step": 1420
    },
    {
      "epoch": 2.86,
      "grad_norm": 3.6655826568603516,
      "learning_rate": 0.00021666666666666666,
      "loss": 0.7454,
      "step": 1430
    },
    {
      "epoch": 2.88,
      "grad_norm": 3.2865822315216064,
      "learning_rate": 0.00021606060606060604,
      "loss": 0.6772,
      "step": 1440
    },
    {
      "epoch": 2.9,
      "grad_norm": 3.154222249984741,
      "learning_rate": 0.00021545454545454542,
      "loss": 0.7818,
      "step": 1450
    },
    {
      "epoch": 2.92,
      "grad_norm": 2.6056034564971924,
      "learning_rate": 0.0002148484848484848,
      "loss": 0.7156,
      "step": 1460
    },
    {
      "epoch": 2.94,
      "grad_norm": 2.274062395095825,
      "learning_rate": 0.00021424242424242424,
      "loss": 0.7262,
      "step": 1470
    },
    {
      "epoch": 2.96,
      "grad_norm": 2.749673366546631,
      "learning_rate": 0.00021363636363636363,
      "loss": 0.7654,
      "step": 1480
    },
    {
      "epoch": 2.98,
      "grad_norm": 3.7699527740478516,
      "learning_rate": 0.000213030303030303,
      "loss": 0.8887,
      "step": 1490
    },
    {
      "epoch": 3.0,
      "grad_norm": 2.1688425540924072,
      "learning_rate": 0.00021242424242424242,
      "loss": 0.7397,
      "step": 1500
    },
    {
      "epoch": 3.0,
      "eval_loss": 1.3665612936019897,
      "eval_runtime": 8.6229,
      "eval_samples_per_second": 23.194,
      "eval_steps_per_second": 23.194,
      "step": 1500
    },
    {
      "epoch": 3.02,
      "grad_norm": 2.7243924140930176,
      "learning_rate": 0.0002118181818181818,
      "loss": 0.5968,
      "step": 1510
    },
    {
      "epoch": 3.04,
      "grad_norm": 4.8115363121032715,
      "learning_rate": 0.0002112121212121212,
      "loss": 0.589,
      "step": 1520
    },
    {
      "epoch": 3.06,
      "grad_norm": 0.7446580529212952,
      "learning_rate": 0.00021060606060606057,
      "loss": 0.4185,
      "step": 1530
    },
    {
      "epoch": 3.08,
      "grad_norm": 3.7533459663391113,
      "learning_rate": 0.00020999999999999998,
      "loss": 0.6141,
      "step": 1540
    },
    {
      "epoch": 3.1,
      "grad_norm": 4.6358962059021,
      "learning_rate": 0.0002093939393939394,
      "loss": 0.4036,
      "step": 1550
    },
    {
      "epoch": 3.12,
      "grad_norm": 1.5556796789169312,
      "learning_rate": 0.00020878787878787878,
      "loss": 0.4429,
      "step": 1560
    },
    {
      "epoch": 3.14,
      "grad_norm": 6.383337020874023,
      "learning_rate": 0.00020818181818181816,
      "loss": 0.3879,
      "step": 1570
    },
    {
      "epoch": 3.16,
      "grad_norm": 1.924317479133606,
      "learning_rate": 0.00020757575757575757,
      "loss": 0.5177,
      "step": 1580
    },
    {
      "epoch": 3.18,
      "grad_norm": 4.869483470916748,
      "learning_rate": 0.00020696969696969695,
      "loss": 0.5129,
      "step": 1590
    },
    {
      "epoch": 3.2,
      "grad_norm": 3.137240409851074,
      "learning_rate": 0.00020636363636363634,
      "loss": 0.5925,
      "step": 1600
    },
    {
      "epoch": 3.2,
      "eval_loss": 1.5771087408065796,
      "eval_runtime": 8.6046,
      "eval_samples_per_second": 23.243,
      "eval_steps_per_second": 23.243,
      "step": 1600
    },
    {
      "epoch": 3.22,
      "grad_norm": 6.088298320770264,
      "learning_rate": 0.00020575757575757572,
      "loss": 0.4711,
      "step": 1610
    },
    {
      "epoch": 3.24,
      "grad_norm": 3.2081379890441895,
      "learning_rate": 0.00020515151515151513,
      "loss": 0.5117,
      "step": 1620
    },
    {
      "epoch": 3.26,
      "grad_norm": 4.077174186706543,
      "learning_rate": 0.0002045454545454545,
      "loss": 0.479,
      "step": 1630
    },
    {
      "epoch": 3.2800000000000002,
      "grad_norm": 3.325282335281372,
      "learning_rate": 0.00020393939393939392,
      "loss": 0.5746,
      "step": 1640
    },
    {
      "epoch": 3.3,
      "grad_norm": 4.323032855987549,
      "learning_rate": 0.00020333333333333333,
      "loss": 0.671,
      "step": 1650
    },
    {
      "epoch": 3.32,
      "grad_norm": 5.547306060791016,
      "learning_rate": 0.00020272727272727272,
      "loss": 0.605,
      "step": 1660
    },
    {
      "epoch": 3.34,
      "grad_norm": 4.0228590965271,
      "learning_rate": 0.0002021212121212121,
      "loss": 0.4782,
      "step": 1670
    },
    {
      "epoch": 3.36,
      "grad_norm": 4.310633182525635,
      "learning_rate": 0.00020151515151515148,
      "loss": 0.5321,
      "step": 1680
    },
    {
      "epoch": 3.38,
      "grad_norm": 3.488055467605591,
      "learning_rate": 0.0002009090909090909,
      "loss": 0.5593,
      "step": 1690
    },
    {
      "epoch": 3.4,
      "grad_norm": 2.081519365310669,
      "learning_rate": 0.00020030303030303028,
      "loss": 0.4876,
      "step": 1700
    },
    {
      "epoch": 3.4,
      "eval_loss": 1.5381430387496948,
      "eval_runtime": 8.3328,
      "eval_samples_per_second": 24.001,
      "eval_steps_per_second": 24.001,
      "step": 1700
    },
    {
      "epoch": 3.42,
      "grad_norm": 0.37584277987480164,
      "learning_rate": 0.00019969696969696966,
      "loss": 0.4885,
      "step": 1710
    },
    {
      "epoch": 3.44,
      "grad_norm": 3.288295269012451,
      "learning_rate": 0.0001990909090909091,
      "loss": 0.6081,
      "step": 1720
    },
    {
      "epoch": 3.46,
      "grad_norm": 3.361853837966919,
      "learning_rate": 0.00019848484848484848,
      "loss": 0.4769,
      "step": 1730
    },
    {
      "epoch": 3.48,
      "grad_norm": 3.1514270305633545,
      "learning_rate": 0.00019787878787878786,
      "loss": 0.4749,
      "step": 1740
    },
    {
      "epoch": 3.5,
      "grad_norm": 4.578436851501465,
      "learning_rate": 0.00019727272727272725,
      "loss": 0.5706,
      "step": 1750
    },
    {
      "epoch": 3.52,
      "grad_norm": 2.2992489337921143,
      "learning_rate": 0.00019666666666666666,
      "loss": 0.5951,
      "step": 1760
    },
    {
      "epoch": 3.54,
      "grad_norm": 3.0407016277313232,
      "learning_rate": 0.00019606060606060604,
      "loss": 0.4665,
      "step": 1770
    },
    {
      "epoch": 3.56,
      "grad_norm": 2.8656187057495117,
      "learning_rate": 0.00019545454545454543,
      "loss": 0.4698,
      "step": 1780
    },
    {
      "epoch": 3.58,
      "grad_norm": 5.542179584503174,
      "learning_rate": 0.0001948484848484848,
      "loss": 0.5659,
      "step": 1790
    },
    {
      "epoch": 3.6,
      "grad_norm": 5.150173187255859,
      "learning_rate": 0.00019424242424242422,
      "loss": 0.3912,
      "step": 1800
    },
    {
      "epoch": 3.6,
      "eval_loss": 1.5876611471176147,
      "eval_runtime": 8.3552,
      "eval_samples_per_second": 23.937,
      "eval_steps_per_second": 23.937,
      "step": 1800
    },
    {
      "epoch": 3.62,
      "grad_norm": 5.587698936462402,
      "learning_rate": 0.00019363636363636363,
      "loss": 0.5246,
      "step": 1810
    },
    {
      "epoch": 3.64,
      "grad_norm": 5.019087314605713,
      "learning_rate": 0.000193030303030303,
      "loss": 0.5314,
      "step": 1820
    },
    {
      "epoch": 3.66,
      "grad_norm": 2.089993476867676,
      "learning_rate": 0.00019242424242424242,
      "loss": 0.3697,
      "step": 1830
    },
    {
      "epoch": 3.68,
      "grad_norm": 1.0703431367874146,
      "learning_rate": 0.0001918181818181818,
      "loss": 0.5303,
      "step": 1840
    },
    {
      "epoch": 3.7,
      "grad_norm": 1.5947494506835938,
      "learning_rate": 0.0001912121212121212,
      "loss": 0.4685,
      "step": 1850
    },
    {
      "epoch": 3.7199999999999998,
      "grad_norm": 4.70174503326416,
      "learning_rate": 0.00019060606060606057,
      "loss": 0.6428,
      "step": 1860
    },
    {
      "epoch": 3.74,
      "grad_norm": 5.692582607269287,
      "learning_rate": 0.00018999999999999998,
      "loss": 0.6316,
      "step": 1870
    },
    {
      "epoch": 3.76,
      "grad_norm": 3.5362939834594727,
      "learning_rate": 0.00018939393939393937,
      "loss": 0.4731,
      "step": 1880
    },
    {
      "epoch": 3.7800000000000002,
      "grad_norm": 4.059176445007324,
      "learning_rate": 0.00018878787878787878,
      "loss": 0.6102,
      "step": 1890
    },
    {
      "epoch": 3.8,
      "grad_norm": 4.966440200805664,
      "learning_rate": 0.0001881818181818182,
      "loss": 0.5322,
      "step": 1900
    },
    {
      "epoch": 3.8,
      "eval_loss": 1.5311070680618286,
      "eval_runtime": 8.517,
      "eval_samples_per_second": 23.482,
      "eval_steps_per_second": 23.482,
      "step": 1900
    },
    {
      "epoch": 3.82,
      "grad_norm": 4.59326171875,
      "learning_rate": 0.00018757575757575757,
      "loss": 0.4091,
      "step": 1910
    },
    {
      "epoch": 3.84,
      "grad_norm": 5.117733955383301,
      "learning_rate": 0.00018696969696969695,
      "loss": 0.5544,
      "step": 1920
    },
    {
      "epoch": 3.86,
      "grad_norm": 2.4001810550689697,
      "learning_rate": 0.00018636363636363634,
      "loss": 0.5233,
      "step": 1930
    },
    {
      "epoch": 3.88,
      "grad_norm": 4.499606609344482,
      "learning_rate": 0.00018575757575757575,
      "loss": 0.4866,
      "step": 1940
    },
    {
      "epoch": 3.9,
      "grad_norm": 4.7469587326049805,
      "learning_rate": 0.00018515151515151513,
      "loss": 0.656,
      "step": 1950
    },
    {
      "epoch": 3.92,
      "grad_norm": 4.911047458648682,
      "learning_rate": 0.00018454545454545451,
      "loss": 0.6023,
      "step": 1960
    },
    {
      "epoch": 3.94,
      "grad_norm": 3.8196420669555664,
      "learning_rate": 0.0001839393939393939,
      "loss": 0.487,
      "step": 1970
    },
    {
      "epoch": 3.96,
      "grad_norm": 11.70684814453125,
      "learning_rate": 0.00018333333333333334,
      "loss": 0.6721,
      "step": 1980
    },
    {
      "epoch": 3.98,
      "grad_norm": 3.455779552459717,
      "learning_rate": 0.00018272727272727272,
      "loss": 0.4329,
      "step": 1990
    },
    {
      "epoch": 4.0,
      "grad_norm": 3.283916473388672,
      "learning_rate": 0.0001821212121212121,
      "loss": 0.5001,
      "step": 2000
    },
    {
      "epoch": 4.0,
      "eval_loss": 1.5152883529663086,
      "eval_runtime": 8.5564,
      "eval_samples_per_second": 23.374,
      "eval_steps_per_second": 23.374,
      "step": 2000
    },
    {
      "epoch": 4.02,
      "grad_norm": 2.8836350440979004,
      "learning_rate": 0.0001815151515151515,
      "loss": 0.4051,
      "step": 2010
    },
    {
      "epoch": 4.04,
      "grad_norm": 2.074934959411621,
      "learning_rate": 0.0001809090909090909,
      "loss": 0.2864,
      "step": 2020
    },
    {
      "epoch": 4.06,
      "grad_norm": 4.191931247711182,
      "learning_rate": 0.00018030303030303028,
      "loss": 0.3691,
      "step": 2030
    },
    {
      "epoch": 4.08,
      "grad_norm": 4.081726551055908,
      "learning_rate": 0.00017969696969696966,
      "loss": 0.4052,
      "step": 2040
    },
    {
      "epoch": 4.1,
      "grad_norm": 5.643499374389648,
      "learning_rate": 0.00017909090909090907,
      "loss": 0.2907,
      "step": 2050
    },
    {
      "epoch": 4.12,
      "grad_norm": 1.3225493431091309,
      "learning_rate": 0.00017848484848484846,
      "loss": 0.3208,
      "step": 2060
    },
    {
      "epoch": 4.14,
      "grad_norm": 4.417630672454834,
      "learning_rate": 0.00017787878787878787,
      "loss": 0.2331,
      "step": 2070
    },
    {
      "epoch": 4.16,
      "grad_norm": 1.4838417768478394,
      "learning_rate": 0.00017727272727272728,
      "loss": 0.242,
      "step": 2080
    },
    {
      "epoch": 4.18,
      "grad_norm": 8.151931762695312,
      "learning_rate": 0.00017666666666666666,
      "loss": 0.3707,
      "step": 2090
    },
    {
      "epoch": 4.2,
      "grad_norm": 2.0093367099761963,
      "learning_rate": 0.00017606060606060604,
      "loss": 0.302,
      "step": 2100
    },
    {
      "epoch": 4.2,
      "eval_loss": 1.6721323728561401,
      "eval_runtime": 8.4146,
      "eval_samples_per_second": 23.768,
      "eval_steps_per_second": 23.768,
      "step": 2100
    },
    {
      "epoch": 4.22,
      "grad_norm": 3.354480504989624,
      "learning_rate": 0.00017545454545454543,
      "loss": 0.265,
      "step": 2110
    },
    {
      "epoch": 4.24,
      "grad_norm": 3.6855225563049316,
      "learning_rate": 0.00017484848484848484,
      "loss": 0.2846,
      "step": 2120
    },
    {
      "epoch": 4.26,
      "grad_norm": 3.985383987426758,
      "learning_rate": 0.00017424242424242422,
      "loss": 0.2278,
      "step": 2130
    },
    {
      "epoch": 4.28,
      "grad_norm": 3.813966751098633,
      "learning_rate": 0.0001736363636363636,
      "loss": 0.3707,
      "step": 2140
    },
    {
      "epoch": 4.3,
      "grad_norm": 7.246571063995361,
      "learning_rate": 0.00017303030303030304,
      "loss": 0.3427,
      "step": 2150
    },
    {
      "epoch": 4.32,
      "grad_norm": 1.8319685459136963,
      "learning_rate": 0.00017242424242424242,
      "loss": 0.3899,
      "step": 2160
    },
    {
      "epoch": 4.34,
      "grad_norm": 4.501228332519531,
      "learning_rate": 0.0001718181818181818,
      "loss": 0.2746,
      "step": 2170
    },
    {
      "epoch": 4.36,
      "grad_norm": 2.536245346069336,
      "learning_rate": 0.0001712121212121212,
      "loss": 0.4089,
      "step": 2180
    },
    {
      "epoch": 4.38,
      "grad_norm": 2.8286542892456055,
      "learning_rate": 0.0001706060606060606,
      "loss": 0.3408,
      "step": 2190
    },
    {
      "epoch": 4.4,
      "grad_norm": 3.074740171432495,
      "learning_rate": 0.00016999999999999999,
      "loss": 0.3355,
      "step": 2200
    },
    {
      "epoch": 4.4,
      "eval_loss": 1.6891056299209595,
      "eval_runtime": 8.3504,
      "eval_samples_per_second": 23.951,
      "eval_steps_per_second": 23.951,
      "step": 2200
    },
    {
      "epoch": 4.42,
      "grad_norm": 5.622828483581543,
      "learning_rate": 0.00016939393939393937,
      "loss": 0.3811,
      "step": 2210
    },
    {
      "epoch": 4.44,
      "grad_norm": 4.271538734436035,
      "learning_rate": 0.00016878787878787875,
      "loss": 0.3529,
      "step": 2220
    },
    {
      "epoch": 4.46,
      "grad_norm": 5.261038303375244,
      "learning_rate": 0.00016818181818181816,
      "loss": 0.2434,
      "step": 2230
    },
    {
      "epoch": 4.48,
      "grad_norm": 4.349186420440674,
      "learning_rate": 0.00016757575757575757,
      "loss": 0.3261,
      "step": 2240
    },
    {
      "epoch": 4.5,
      "grad_norm": 7.100224494934082,
      "learning_rate": 0.00016696969696969696,
      "loss": 0.3611,
      "step": 2250
    },
    {
      "epoch": 4.52,
      "grad_norm": 5.5341386795043945,
      "learning_rate": 0.00016636363636363637,
      "loss": 0.3127,
      "step": 2260
    },
    {
      "epoch": 4.54,
      "grad_norm": 3.216064453125,
      "learning_rate": 0.00016575757575757575,
      "loss": 0.3486,
      "step": 2270
    },
    {
      "epoch": 4.5600000000000005,
      "grad_norm": 6.036974906921387,
      "learning_rate": 0.00016515151515151513,
      "loss": 0.5734,
      "step": 2280
    },
    {
      "epoch": 4.58,
      "grad_norm": 13.322968482971191,
      "learning_rate": 0.00016454545454545452,
      "loss": 0.3634,
      "step": 2290
    },
    {
      "epoch": 4.6,
      "grad_norm": 5.77263879776001,
      "learning_rate": 0.00016393939393939393,
      "loss": 0.3548,
      "step": 2300
    },
    {
      "epoch": 4.6,
      "eval_loss": 1.6843606233596802,
      "eval_runtime": 8.5231,
      "eval_samples_per_second": 23.466,
      "eval_steps_per_second": 23.466,
      "step": 2300
    },
    {
      "epoch": 4.62,
      "grad_norm": 2.8293261528015137,
      "learning_rate": 0.0001633333333333333,
      "loss": 0.2482,
      "step": 2310
    },
    {
      "epoch": 4.64,
      "grad_norm": 3.7528512477874756,
      "learning_rate": 0.00016272727272727272,
      "loss": 0.4783,
      "step": 2320
    },
    {
      "epoch": 4.66,
      "grad_norm": 3.961250066757202,
      "learning_rate": 0.00016212121212121213,
      "loss": 0.3957,
      "step": 2330
    },
    {
      "epoch": 4.68,
      "grad_norm": 5.722551345825195,
      "learning_rate": 0.00016151515151515151,
      "loss": 0.3363,
      "step": 2340
    },
    {
      "epoch": 4.7,
      "grad_norm": 3.1807029247283936,
      "learning_rate": 0.0001609090909090909,
      "loss": 0.4382,
      "step": 2350
    },
    {
      "epoch": 4.72,
      "grad_norm": 5.143856048583984,
      "learning_rate": 0.00016030303030303028,
      "loss": 0.3784,
      "step": 2360
    },
    {
      "epoch": 4.74,
      "grad_norm": 5.239649295806885,
      "learning_rate": 0.0001596969696969697,
      "loss": 0.5789,
      "step": 2370
    },
    {
      "epoch": 4.76,
      "grad_norm": 1.5543807744979858,
      "learning_rate": 0.00015909090909090907,
      "loss": 0.385,
      "step": 2380
    },
    {
      "epoch": 4.78,
      "grad_norm": 3.2433054447174072,
      "learning_rate": 0.00015848484848484846,
      "loss": 0.3572,
      "step": 2390
    },
    {
      "epoch": 4.8,
      "grad_norm": 5.5027642250061035,
      "learning_rate": 0.00015787878787878784,
      "loss": 0.4824,
      "step": 2400
    },
    {
      "epoch": 4.8,
      "eval_loss": 1.6812199354171753,
      "eval_runtime": 8.344,
      "eval_samples_per_second": 23.969,
      "eval_steps_per_second": 23.969,
      "step": 2400
    },
    {
      "epoch": 4.82,
      "grad_norm": 5.680185317993164,
      "learning_rate": 0.00015727272727272728,
      "loss": 0.3699,
      "step": 2410
    },
    {
      "epoch": 4.84,
      "grad_norm": 7.282294273376465,
      "learning_rate": 0.00015666666666666666,
      "loss": 0.4437,
      "step": 2420
    },
    {
      "epoch": 4.86,
      "grad_norm": 4.842986106872559,
      "learning_rate": 0.00015606060606060605,
      "loss": 0.4008,
      "step": 2430
    },
    {
      "epoch": 4.88,
      "grad_norm": 5.638546943664551,
      "learning_rate": 0.00015545454545454546,
      "loss": 0.3303,
      "step": 2440
    },
    {
      "epoch": 4.9,
      "grad_norm": 4.4457502365112305,
      "learning_rate": 0.00015484848484848484,
      "loss": 0.3127,
      "step": 2450
    },
    {
      "epoch": 4.92,
      "grad_norm": 4.4613471031188965,
      "learning_rate": 0.00015424242424242422,
      "loss": 0.3671,
      "step": 2460
    },
    {
      "epoch": 4.9399999999999995,
      "grad_norm": 0.7128256559371948,
      "learning_rate": 0.0001536363636363636,
      "loss": 0.3875,
      "step": 2470
    },
    {
      "epoch": 4.96,
      "grad_norm": 13.834397315979004,
      "learning_rate": 0.00015303030303030302,
      "loss": 0.3369,
      "step": 2480
    },
    {
      "epoch": 4.98,
      "grad_norm": 3.0749001502990723,
      "learning_rate": 0.00015242424242424243,
      "loss": 0.3483,
      "step": 2490
    },
    {
      "epoch": 5.0,
      "grad_norm": 6.854934215545654,
      "learning_rate": 0.0001518181818181818,
      "loss": 0.3949,
      "step": 2500
    },
    {
      "epoch": 5.0,
      "eval_loss": 1.6385128498077393,
      "eval_runtime": 8.8607,
      "eval_samples_per_second": 22.572,
      "eval_steps_per_second": 22.572,
      "step": 2500
    },
    {
      "epoch": 5.02,
      "grad_norm": 5.221047878265381,
      "learning_rate": 0.00015121212121212122,
      "loss": 0.2456,
      "step": 2510
    },
    {
      "epoch": 5.04,
      "grad_norm": 3.450674533843994,
      "learning_rate": 0.0001506060606060606,
      "loss": 0.2436,
      "step": 2520
    },
    {
      "epoch": 5.06,
      "grad_norm": 0.9579916000366211,
      "learning_rate": 0.00015,
      "loss": 0.2529,
      "step": 2530
    },
    {
      "epoch": 5.08,
      "grad_norm": 2.6204512119293213,
      "learning_rate": 0.00014939393939393937,
      "loss": 0.2206,
      "step": 2540
    },
    {
      "epoch": 5.1,
      "grad_norm": 4.714933395385742,
      "learning_rate": 0.00014878787878787875,
      "loss": 0.2832,
      "step": 2550
    },
    {
      "epoch": 5.12,
      "grad_norm": 4.112908840179443,
      "learning_rate": 0.00014818181818181816,
      "loss": 0.2356,
      "step": 2560
    },
    {
      "epoch": 5.14,
      "grad_norm": 1.659694790840149,
      "learning_rate": 0.00014757575757575757,
      "loss": 0.2503,
      "step": 2570
    },
    {
      "epoch": 5.16,
      "grad_norm": 7.841254234313965,
      "learning_rate": 0.00014696969696969696,
      "loss": 0.3355,
      "step": 2580
    },
    {
      "epoch": 5.18,
      "grad_norm": 1.253078818321228,
      "learning_rate": 0.00014636363636363634,
      "loss": 0.3395,
      "step": 2590
    },
    {
      "epoch": 5.2,
      "grad_norm": 2.4434783458709717,
      "learning_rate": 0.00014575757575757575,
      "loss": 0.2058,
      "step": 2600
    },
    {
      "epoch": 5.2,
      "eval_loss": 1.8143011331558228,
      "eval_runtime": 8.3889,
      "eval_samples_per_second": 23.841,
      "eval_steps_per_second": 23.841,
      "step": 2600
    },
    {
      "epoch": 5.22,
      "grad_norm": 2.3470914363861084,
      "learning_rate": 0.00014515151515151513,
      "loss": 0.2188,
      "step": 2610
    },
    {
      "epoch": 5.24,
      "grad_norm": 0.6751739978790283,
      "learning_rate": 0.00014454545454545452,
      "loss": 0.2391,
      "step": 2620
    },
    {
      "epoch": 5.26,
      "grad_norm": 1.1010725498199463,
      "learning_rate": 0.00014393939393939393,
      "loss": 0.2581,
      "step": 2630
    },
    {
      "epoch": 5.28,
      "grad_norm": 3.290465831756592,
      "learning_rate": 0.00014333333333333334,
      "loss": 0.1707,
      "step": 2640
    },
    {
      "epoch": 5.3,
      "grad_norm": 3.1689579486846924,
      "learning_rate": 0.00014272727272727272,
      "loss": 0.2183,
      "step": 2650
    },
    {
      "epoch": 5.32,
      "grad_norm": 11.413520812988281,
      "learning_rate": 0.0001421212121212121,
      "loss": 0.2902,
      "step": 2660
    },
    {
      "epoch": 5.34,
      "grad_norm": 3.610501766204834,
      "learning_rate": 0.0001415151515151515,
      "loss": 0.283,
      "step": 2670
    },
    {
      "epoch": 5.36,
      "grad_norm": 3.307816743850708,
      "learning_rate": 0.0001409090909090909,
      "loss": 0.2559,
      "step": 2680
    },
    {
      "epoch": 5.38,
      "grad_norm": 3.577791929244995,
      "learning_rate": 0.00014030303030303028,
      "loss": 0.2706,
      "step": 2690
    },
    {
      "epoch": 5.4,
      "grad_norm": 1.8686861991882324,
      "learning_rate": 0.0001396969696969697,
      "loss": 0.197,
      "step": 2700
    },
    {
      "epoch": 5.4,
      "eval_loss": 1.8709734678268433,
      "eval_runtime": 8.8639,
      "eval_samples_per_second": 22.563,
      "eval_steps_per_second": 22.563,
      "step": 2700
    },
    {
      "epoch": 5.42,
      "grad_norm": 1.9374616146087646,
      "learning_rate": 0.00013909090909090908,
      "loss": 0.2027,
      "step": 2710
    },
    {
      "epoch": 5.44,
      "grad_norm": 5.982975482940674,
      "learning_rate": 0.00013848484848484846,
      "loss": 0.213,
      "step": 2720
    },
    {
      "epoch": 5.46,
      "grad_norm": 1.0048937797546387,
      "learning_rate": 0.00013787878787878787,
      "loss": 0.2744,
      "step": 2730
    },
    {
      "epoch": 5.48,
      "grad_norm": 4.066627502441406,
      "learning_rate": 0.00013727272727272725,
      "loss": 0.2388,
      "step": 2740
    },
    {
      "epoch": 5.5,
      "grad_norm": 2.6684350967407227,
      "learning_rate": 0.00013666666666666666,
      "loss": 0.2243,
      "step": 2750
    },
    {
      "epoch": 5.52,
      "grad_norm": 6.309863567352295,
      "learning_rate": 0.00013606060606060605,
      "loss": 0.1939,
      "step": 2760
    },
    {
      "epoch": 5.54,
      "grad_norm": 2.868911027908325,
      "learning_rate": 0.00013545454545454546,
      "loss": 0.2131,
      "step": 2770
    },
    {
      "epoch": 5.5600000000000005,
      "grad_norm": 4.25172233581543,
      "learning_rate": 0.00013484848484848484,
      "loss": 0.2336,
      "step": 2780
    },
    {
      "epoch": 5.58,
      "grad_norm": 3.917006492614746,
      "learning_rate": 0.00013424242424242422,
      "loss": 0.2539,
      "step": 2790
    },
    {
      "epoch": 5.6,
      "grad_norm": 8.472702026367188,
      "learning_rate": 0.0001336363636363636,
      "loss": 0.3607,
      "step": 2800
    },
    {
      "epoch": 5.6,
      "eval_loss": 1.8195741176605225,
      "eval_runtime": 8.368,
      "eval_samples_per_second": 23.901,
      "eval_steps_per_second": 23.901,
      "step": 2800
    },
    {
      "epoch": 5.62,
      "grad_norm": 8.261674880981445,
      "learning_rate": 0.00013303030303030302,
      "loss": 0.241,
      "step": 2810
    },
    {
      "epoch": 5.64,
      "grad_norm": 5.124539375305176,
      "learning_rate": 0.00013242424242424243,
      "loss": 0.2675,
      "step": 2820
    },
    {
      "epoch": 5.66,
      "grad_norm": 4.690890789031982,
      "learning_rate": 0.0001318181818181818,
      "loss": 0.2863,
      "step": 2830
    },
    {
      "epoch": 5.68,
      "grad_norm": 2.5690958499908447,
      "learning_rate": 0.0001312121212121212,
      "loss": 0.2285,
      "step": 2840
    },
    {
      "epoch": 5.7,
      "grad_norm": 5.00034236907959,
      "learning_rate": 0.00013060606060606058,
      "loss": 0.2382,
      "step": 2850
    },
    {
      "epoch": 5.72,
      "grad_norm": 6.322993755340576,
      "learning_rate": 0.00013,
      "loss": 0.2448,
      "step": 2860
    },
    {
      "epoch": 5.74,
      "grad_norm": 5.997263431549072,
      "learning_rate": 0.00012939393939393937,
      "loss": 0.2306,
      "step": 2870
    },
    {
      "epoch": 5.76,
      "grad_norm": 3.399876832962036,
      "learning_rate": 0.00012878787878787878,
      "loss": 0.2658,
      "step": 2880
    },
    {
      "epoch": 5.78,
      "grad_norm": 4.086543083190918,
      "learning_rate": 0.00012818181818181817,
      "loss": 0.1994,
      "step": 2890
    },
    {
      "epoch": 5.8,
      "grad_norm": 5.624755382537842,
      "learning_rate": 0.00012757575757575758,
      "loss": 0.215,
      "step": 2900
    },
    {
      "epoch": 5.8,
      "eval_loss": 1.8710873126983643,
      "eval_runtime": 8.3444,
      "eval_samples_per_second": 23.968,
      "eval_steps_per_second": 23.968,
      "step": 2900
    },
    {
      "epoch": 5.82,
      "grad_norm": 3.029149293899536,
      "learning_rate": 0.00012696969696969696,
      "loss": 0.2693,
      "step": 2910
    },
    {
      "epoch": 5.84,
      "grad_norm": 5.433009147644043,
      "learning_rate": 0.00012636363636363634,
      "loss": 0.2747,
      "step": 2920
    },
    {
      "epoch": 5.86,
      "grad_norm": 5.245200157165527,
      "learning_rate": 0.00012575757575757575,
      "loss": 0.2376,
      "step": 2930
    },
    {
      "epoch": 5.88,
      "grad_norm": 1.7759596109390259,
      "learning_rate": 0.00012515151515151514,
      "loss": 0.2324,
      "step": 2940
    },
    {
      "epoch": 5.9,
      "grad_norm": 8.280299186706543,
      "learning_rate": 0.00012454545454545455,
      "loss": 0.3058,
      "step": 2950
    },
    {
      "epoch": 5.92,
      "grad_norm": 6.036457061767578,
      "learning_rate": 0.00012393939393939393,
      "loss": 0.4512,
      "step": 2960
    },
    {
      "epoch": 5.9399999999999995,
      "grad_norm": 3.292898178100586,
      "learning_rate": 0.0001233333333333333,
      "loss": 0.2529,
      "step": 2970
    },
    {
      "epoch": 5.96,
      "grad_norm": 4.046395778656006,
      "learning_rate": 0.00012272727272727272,
      "loss": 0.2789,
      "step": 2980
    },
    {
      "epoch": 5.98,
      "grad_norm": 3.8402957916259766,
      "learning_rate": 0.0001221212121212121,
      "loss": 0.3012,
      "step": 2990
    },
    {
      "epoch": 6.0,
      "grad_norm": 5.400630950927734,
      "learning_rate": 0.0001215151515151515,
      "loss": 0.2575,
      "step": 3000
    },
    {
      "epoch": 6.0,
      "eval_loss": 1.8531122207641602,
      "eval_runtime": 8.3281,
      "eval_samples_per_second": 24.015,
      "eval_steps_per_second": 24.015,
      "step": 3000
    },
    {
      "epoch": 6.02,
      "grad_norm": 0.9655468463897705,
      "learning_rate": 0.0001209090909090909,
      "loss": 0.1532,
      "step": 3010
    },
    {
      "epoch": 6.04,
      "grad_norm": 3.1896913051605225,
      "learning_rate": 0.00012030303030303028,
      "loss": 0.1712,
      "step": 3020
    },
    {
      "epoch": 6.06,
      "grad_norm": 8.00375747680664,
      "learning_rate": 0.0001196969696969697,
      "loss": 0.1869,
      "step": 3030
    },
    {
      "epoch": 6.08,
      "grad_norm": 7.621281623840332,
      "learning_rate": 0.00011909090909090908,
      "loss": 0.2055,
      "step": 3040
    },
    {
      "epoch": 6.1,
      "grad_norm": 3.237809896469116,
      "learning_rate": 0.00011848484848484847,
      "loss": 0.1447,
      "step": 3050
    },
    {
      "epoch": 6.12,
      "grad_norm": 3.4907524585723877,
      "learning_rate": 0.00011787878787878786,
      "loss": 0.2007,
      "step": 3060
    },
    {
      "epoch": 6.14,
      "grad_norm": 1.4104597568511963,
      "learning_rate": 0.00011727272727272727,
      "loss": 0.2112,
      "step": 3070
    },
    {
      "epoch": 6.16,
      "grad_norm": 2.5342938899993896,
      "learning_rate": 0.00011666666666666665,
      "loss": 0.2127,
      "step": 3080
    },
    {
      "epoch": 6.18,
      "grad_norm": 5.684229850769043,
      "learning_rate": 0.00011606060606060605,
      "loss": 0.1933,
      "step": 3090
    },
    {
      "epoch": 6.2,
      "grad_norm": 1.2936527729034424,
      "learning_rate": 0.00011545454545454543,
      "loss": 0.1361,
      "step": 3100
    },
    {
      "epoch": 6.2,
      "eval_loss": 2.0624260902404785,
      "eval_runtime": 8.4432,
      "eval_samples_per_second": 23.688,
      "eval_steps_per_second": 23.688,
      "step": 3100
    },
    {
      "epoch": 6.22,
      "grad_norm": 1.6704365015029907,
      "learning_rate": 0.00011484848484848484,
      "loss": 0.2099,
      "step": 3110
    },
    {
      "epoch": 6.24,
      "grad_norm": 1.802523136138916,
      "learning_rate": 0.00011424242424242424,
      "loss": 0.1873,
      "step": 3120
    },
    {
      "epoch": 6.26,
      "grad_norm": 2.2219293117523193,
      "learning_rate": 0.00011363636363636362,
      "loss": 0.2024,
      "step": 3130
    },
    {
      "epoch": 6.28,
      "grad_norm": 7.32590913772583,
      "learning_rate": 0.00011303030303030302,
      "loss": 0.1866,
      "step": 3140
    },
    {
      "epoch": 6.3,
      "grad_norm": 3.3759074211120605,
      "learning_rate": 0.00011242424242424242,
      "loss": 0.1787,
      "step": 3150
    },
    {
      "epoch": 6.32,
      "grad_norm": 0.9378736019134521,
      "learning_rate": 0.00011181818181818181,
      "loss": 0.2159,
      "step": 3160
    },
    {
      "epoch": 6.34,
      "grad_norm": 2.491582155227661,
      "learning_rate": 0.0001112121212121212,
      "loss": 0.2419,
      "step": 3170
    },
    {
      "epoch": 6.36,
      "grad_norm": 2.991133213043213,
      "learning_rate": 0.0001106060606060606,
      "loss": 0.197,
      "step": 3180
    },
    {
      "epoch": 6.38,
      "grad_norm": 2.6814675331115723,
      "learning_rate": 0.00010999999999999998,
      "loss": 0.1887,
      "step": 3190
    },
    {
      "epoch": 6.4,
      "grad_norm": 1.430761694908142,
      "learning_rate": 0.00010939393939393939,
      "loss": 0.1853,
      "step": 3200
    },
    {
      "epoch": 6.4,
      "eval_loss": 1.9652618169784546,
      "eval_runtime": 8.3585,
      "eval_samples_per_second": 23.928,
      "eval_steps_per_second": 23.928,
      "step": 3200
    },
    {
      "epoch": 6.42,
      "grad_norm": 3.72148060798645,
      "learning_rate": 0.00010878787878787878,
      "loss": 0.1482,
      "step": 3210
    },
    {
      "epoch": 6.44,
      "grad_norm": 5.249420166015625,
      "learning_rate": 0.00010818181818181817,
      "loss": 0.2394,
      "step": 3220
    },
    {
      "epoch": 6.46,
      "grad_norm": 2.1033971309661865,
      "learning_rate": 0.00010757575757575756,
      "loss": 0.168,
      "step": 3230
    },
    {
      "epoch": 6.48,
      "grad_norm": 1.6149687767028809,
      "learning_rate": 0.00010696969696969696,
      "loss": 0.1993,
      "step": 3240
    },
    {
      "epoch": 6.5,
      "grad_norm": 2.7693324089050293,
      "learning_rate": 0.00010636363636363636,
      "loss": 0.2108,
      "step": 3250
    },
    {
      "epoch": 6.52,
      "grad_norm": 1.7361115217208862,
      "learning_rate": 0.00010575757575757574,
      "loss": 0.1856,
      "step": 3260
    },
    {
      "epoch": 6.54,
      "grad_norm": 3.3986740112304688,
      "learning_rate": 0.00010515151515151514,
      "loss": 0.1594,
      "step": 3270
    },
    {
      "epoch": 6.5600000000000005,
      "grad_norm": 2.270587921142578,
      "learning_rate": 0.00010454545454545455,
      "loss": 0.1729,
      "step": 3280
    },
    {
      "epoch": 6.58,
      "grad_norm": 5.4180498123168945,
      "learning_rate": 0.00010393939393939393,
      "loss": 0.2303,
      "step": 3290
    },
    {
      "epoch": 6.6,
      "grad_norm": 1.424638032913208,
      "learning_rate": 0.00010333333333333333,
      "loss": 0.1573,
      "step": 3300
    },
    {
      "epoch": 6.6,
      "eval_loss": 2.0123047828674316,
      "eval_runtime": 8.7949,
      "eval_samples_per_second": 22.741,
      "eval_steps_per_second": 22.741,
      "step": 3300
    },
    {
      "epoch": 6.62,
      "grad_norm": 2.735577344894409,
      "learning_rate": 0.00010272727272727271,
      "loss": 0.2286,
      "step": 3310
    },
    {
      "epoch": 6.64,
      "grad_norm": 1.2728763818740845,
      "learning_rate": 0.00010212121212121212,
      "loss": 0.1302,
      "step": 3320
    },
    {
      "epoch": 6.66,
      "grad_norm": 2.203389883041382,
      "learning_rate": 0.0001015151515151515,
      "loss": 0.1876,
      "step": 3330
    },
    {
      "epoch": 6.68,
      "grad_norm": 2.4178454875946045,
      "learning_rate": 0.0001009090909090909,
      "loss": 0.2023,
      "step": 3340
    },
    {
      "epoch": 6.7,
      "grad_norm": 0.4785681366920471,
      "learning_rate": 0.00010030303030303029,
      "loss": 0.1512,
      "step": 3350
    },
    {
      "epoch": 6.72,
      "grad_norm": 1.7473864555358887,
      "learning_rate": 9.969696969696968e-05,
      "loss": 0.1772,
      "step": 3360
    },
    {
      "epoch": 6.74,
      "grad_norm": 2.55521559715271,
      "learning_rate": 9.90909090909091e-05,
      "loss": 0.1885,
      "step": 3370
    },
    {
      "epoch": 6.76,
      "grad_norm": 2.832502603530884,
      "learning_rate": 9.848484848484848e-05,
      "loss": 0.2044,
      "step": 3380
    },
    {
      "epoch": 6.78,
      "grad_norm": 1.465308427810669,
      "learning_rate": 9.787878787878787e-05,
      "loss": 0.1904,
      "step": 3390
    },
    {
      "epoch": 6.8,
      "grad_norm": 2.423096179962158,
      "learning_rate": 9.727272727272726e-05,
      "loss": 0.165,
      "step": 3400
    },
    {
      "epoch": 6.8,
      "eval_loss": 2.0452911853790283,
      "eval_runtime": 8.3687,
      "eval_samples_per_second": 23.899,
      "eval_steps_per_second": 23.899,
      "step": 3400
    },
    {
      "epoch": 6.82,
      "grad_norm": 4.133260726928711,
      "learning_rate": 9.666666666666667e-05,
      "loss": 0.3126,
      "step": 3410
    },
    {
      "epoch": 6.84,
      "grad_norm": 5.486469745635986,
      "learning_rate": 9.606060606060605e-05,
      "loss": 0.2343,
      "step": 3420
    },
    {
      "epoch": 6.86,
      "grad_norm": 3.0724568367004395,
      "learning_rate": 9.545454545454545e-05,
      "loss": 0.1757,
      "step": 3430
    },
    {
      "epoch": 6.88,
      "grad_norm": 3.8927481174468994,
      "learning_rate": 9.484848484848483e-05,
      "loss": 0.1948,
      "step": 3440
    },
    {
      "epoch": 6.9,
      "grad_norm": 2.974194049835205,
      "learning_rate": 9.424242424242424e-05,
      "loss": 0.224,
      "step": 3450
    },
    {
      "epoch": 6.92,
      "grad_norm": 4.451396942138672,
      "learning_rate": 9.363636363636364e-05,
      "loss": 0.2122,
      "step": 3460
    },
    {
      "epoch": 6.9399999999999995,
      "grad_norm": 1.422258734703064,
      "learning_rate": 9.303030303030302e-05,
      "loss": 0.2537,
      "step": 3470
    },
    {
      "epoch": 6.96,
      "grad_norm": 2.6672110557556152,
      "learning_rate": 9.242424242424242e-05,
      "loss": 0.2027,
      "step": 3480
    },
    {
      "epoch": 6.98,
      "grad_norm": 2.969348669052124,
      "learning_rate": 9.18181818181818e-05,
      "loss": 0.1745,
      "step": 3490
    },
    {
      "epoch": 7.0,
      "grad_norm": 2.5304114818573,
      "learning_rate": 9.121212121212121e-05,
      "loss": 0.175,
      "step": 3500
    },
    {
      "epoch": 7.0,
      "eval_loss": 2.0329577922821045,
      "eval_runtime": 8.3688,
      "eval_samples_per_second": 23.898,
      "eval_steps_per_second": 23.898,
      "step": 3500
    },
    {
      "epoch": 7.02,
      "grad_norm": 2.675968885421753,
      "learning_rate": 9.06060606060606e-05,
      "loss": 0.1447,
      "step": 3510
    },
    {
      "epoch": 7.04,
      "grad_norm": 3.26834774017334,
      "learning_rate": 8.999999999999999e-05,
      "loss": 0.1363,
      "step": 3520
    },
    {
      "epoch": 7.06,
      "grad_norm": 1.0293238162994385,
      "learning_rate": 8.939393939393938e-05,
      "loss": 0.1971,
      "step": 3530
    },
    {
      "epoch": 7.08,
      "grad_norm": 5.741629600524902,
      "learning_rate": 8.878787878787879e-05,
      "loss": 0.1295,
      "step": 3540
    },
    {
      "epoch": 7.1,
      "grad_norm": 0.8707239627838135,
      "learning_rate": 8.818181818181817e-05,
      "loss": 0.1577,
      "step": 3550
    },
    {
      "epoch": 7.12,
      "grad_norm": 3.017075777053833,
      "learning_rate": 8.757575757575757e-05,
      "loss": 0.148,
      "step": 3560
    },
    {
      "epoch": 7.14,
      "grad_norm": 0.8195666670799255,
      "learning_rate": 8.696969696969695e-05,
      "loss": 0.1394,
      "step": 3570
    },
    {
      "epoch": 7.16,
      "grad_norm": 5.59354305267334,
      "learning_rate": 8.636363636363636e-05,
      "loss": 0.1355,
      "step": 3580
    },
    {
      "epoch": 7.18,
      "grad_norm": 1.3462861776351929,
      "learning_rate": 8.575757575757576e-05,
      "loss": 0.1528,
      "step": 3590
    },
    {
      "epoch": 7.2,
      "grad_norm": 2.1119930744171143,
      "learning_rate": 8.515151515151514e-05,
      "loss": 0.1349,
      "step": 3600
    },
    {
      "epoch": 7.2,
      "eval_loss": 2.169825792312622,
      "eval_runtime": 8.8023,
      "eval_samples_per_second": 22.721,
      "eval_steps_per_second": 22.721,
      "step": 3600
    },
    {
      "epoch": 7.22,
      "grad_norm": 0.8875986933708191,
      "learning_rate": 8.454545454545454e-05,
      "loss": 0.1585,
      "step": 3610
    },
    {
      "epoch": 7.24,
      "grad_norm": 1.299261450767517,
      "learning_rate": 8.393939393939393e-05,
      "loss": 0.1799,
      "step": 3620
    },
    {
      "epoch": 7.26,
      "grad_norm": 1.5639450550079346,
      "learning_rate": 8.333333333333333e-05,
      "loss": 0.1286,
      "step": 3630
    },
    {
      "epoch": 7.28,
      "grad_norm": 1.063613772392273,
      "learning_rate": 8.272727272727271e-05,
      "loss": 0.1346,
      "step": 3640
    },
    {
      "epoch": 7.3,
      "grad_norm": 2.7782678604125977,
      "learning_rate": 8.212121212121211e-05,
      "loss": 0.1564,
      "step": 3650
    },
    {
      "epoch": 7.32,
      "grad_norm": 1.9100470542907715,
      "learning_rate": 8.15151515151515e-05,
      "loss": 0.145,
      "step": 3660
    },
    {
      "epoch": 7.34,
      "grad_norm": 1.8802683353424072,
      "learning_rate": 8.09090909090909e-05,
      "loss": 0.1439,
      "step": 3670
    },
    {
      "epoch": 7.36,
      "grad_norm": 1.7493374347686768,
      "learning_rate": 8.03030303030303e-05,
      "loss": 0.1484,
      "step": 3680
    },
    {
      "epoch": 7.38,
      "grad_norm": 1.6293076276779175,
      "learning_rate": 7.969696969696968e-05,
      "loss": 0.1551,
      "step": 3690
    },
    {
      "epoch": 7.4,
      "grad_norm": 2.2423651218414307,
      "learning_rate": 7.909090909090908e-05,
      "loss": 0.1436,
      "step": 3700
    },
    {
      "epoch": 7.4,
      "eval_loss": 2.089285373687744,
      "eval_runtime": 8.6358,
      "eval_samples_per_second": 23.16,
      "eval_steps_per_second": 23.16,
      "step": 3700
    },
    {
      "epoch": 7.42,
      "grad_norm": 0.8178065419197083,
      "learning_rate": 7.848484848484848e-05,
      "loss": 0.1798,
      "step": 3710
    },
    {
      "epoch": 7.44,
      "grad_norm": 2.8966224193573,
      "learning_rate": 7.787878787878788e-05,
      "loss": 0.1743,
      "step": 3720
    },
    {
      "epoch": 7.46,
      "grad_norm": 2.2933316230773926,
      "learning_rate": 7.727272727272726e-05,
      "loss": 0.1369,
      "step": 3730
    },
    {
      "epoch": 7.48,
      "grad_norm": 4.960962772369385,
      "learning_rate": 7.666666666666666e-05,
      "loss": 0.1522,
      "step": 3740
    },
    {
      "epoch": 7.5,
      "grad_norm": 0.6090860366821289,
      "learning_rate": 7.606060606060607e-05,
      "loss": 0.1499,
      "step": 3750
    },
    {
      "epoch": 7.52,
      "grad_norm": 3.2578248977661133,
      "learning_rate": 7.545454545454545e-05,
      "loss": 0.1523,
      "step": 3760
    },
    {
      "epoch": 7.54,
      "grad_norm": 5.810858249664307,
      "learning_rate": 7.484848484848485e-05,
      "loss": 0.1659,
      "step": 3770
    },
    {
      "epoch": 7.5600000000000005,
      "grad_norm": 3.3260223865509033,
      "learning_rate": 7.43030303030303e-05,
      "loss": 0.1387,
      "step": 3780
    },
    {
      "epoch": 7.58,
      "grad_norm": 1.1515662670135498,
      "learning_rate": 7.369696969696969e-05,
      "loss": 0.1731,
      "step": 3790
    },
    {
      "epoch": 7.6,
      "grad_norm": 0.9098124504089355,
      "learning_rate": 7.309090909090908e-05,
      "loss": 0.1231,
      "step": 3800
    },
    {
      "epoch": 7.6,
      "eval_loss": 2.1540987491607666,
      "eval_runtime": 8.3554,
      "eval_samples_per_second": 23.937,
      "eval_steps_per_second": 23.937,
      "step": 3800
    },
    {
      "epoch": 7.62,
      "grad_norm": 1.7151139974594116,
      "learning_rate": 7.248484848484848e-05,
      "loss": 0.1461,
      "step": 3810
    },
    {
      "epoch": 7.64,
      "grad_norm": 0.9879603385925293,
      "learning_rate": 7.187878787878786e-05,
      "loss": 0.1344,
      "step": 3820
    },
    {
      "epoch": 7.66,
      "grad_norm": 0.5156095623970032,
      "learning_rate": 7.127272727272726e-05,
      "loss": 0.1304,
      "step": 3830
    },
    {
      "epoch": 7.68,
      "grad_norm": 0.7794612646102905,
      "learning_rate": 7.066666666666666e-05,
      "loss": 0.1592,
      "step": 3840
    },
    {
      "epoch": 7.7,
      "grad_norm": 1.716934323310852,
      "learning_rate": 7.006060606060606e-05,
      "loss": 0.1695,
      "step": 3850
    },
    {
      "epoch": 7.72,
      "grad_norm": 2.4694738388061523,
      "learning_rate": 6.945454545454545e-05,
      "loss": 0.1474,
      "step": 3860
    },
    {
      "epoch": 7.74,
      "grad_norm": 2.7735908031463623,
      "learning_rate": 6.884848484848485e-05,
      "loss": 0.1598,
      "step": 3870
    },
    {
      "epoch": 7.76,
      "grad_norm": 0.9013411998748779,
      "learning_rate": 6.824242424242423e-05,
      "loss": 0.1479,
      "step": 3880
    },
    {
      "epoch": 7.78,
      "grad_norm": 0.8947390913963318,
      "learning_rate": 6.763636363636363e-05,
      "loss": 0.1326,
      "step": 3890
    },
    {
      "epoch": 7.8,
      "grad_norm": 1.0301114320755005,
      "learning_rate": 6.703030303030303e-05,
      "loss": 0.1528,
      "step": 3900
    },
    {
      "epoch": 7.8,
      "eval_loss": 2.1107373237609863,
      "eval_runtime": 8.3204,
      "eval_samples_per_second": 24.037,
      "eval_steps_per_second": 24.037,
      "step": 3900
    },
    {
      "epoch": 7.82,
      "grad_norm": 0.6105033755302429,
      "learning_rate": 6.642424242424242e-05,
      "loss": 0.1626,
      "step": 3910
    },
    {
      "epoch": 7.84,
      "grad_norm": 0.9863420128822327,
      "learning_rate": 6.58181818181818e-05,
      "loss": 0.16,
      "step": 3920
    },
    {
      "epoch": 7.86,
      "grad_norm": 3.100722074508667,
      "learning_rate": 6.52121212121212e-05,
      "loss": 0.1657,
      "step": 3930
    },
    {
      "epoch": 7.88,
      "grad_norm": 2.9594972133636475,
      "learning_rate": 6.46060606060606e-05,
      "loss": 0.1521,
      "step": 3940
    },
    {
      "epoch": 7.9,
      "grad_norm": 1.2739495038986206,
      "learning_rate": 6.4e-05,
      "loss": 0.1409,
      "step": 3950
    },
    {
      "epoch": 7.92,
      "grad_norm": 1.7376285791397095,
      "learning_rate": 6.33939393939394e-05,
      "loss": 0.1672,
      "step": 3960
    },
    {
      "epoch": 7.9399999999999995,
      "grad_norm": 1.7470803260803223,
      "learning_rate": 6.278787878787878e-05,
      "loss": 0.1741,
      "step": 3970
    },
    {
      "epoch": 7.96,
      "grad_norm": 1.723791480064392,
      "learning_rate": 6.218181818181817e-05,
      "loss": 0.1561,
      "step": 3980
    },
    {
      "epoch": 7.98,
      "grad_norm": 1.513826847076416,
      "learning_rate": 6.157575757575757e-05,
      "loss": 0.1512,
      "step": 3990
    },
    {
      "epoch": 8.0,
      "grad_norm": 1.759451985359192,
      "learning_rate": 6.096969696969697e-05,
      "loss": 0.1614,
      "step": 4000
    },
    {
      "epoch": 8.0,
      "eval_loss": 2.1045732498168945,
      "eval_runtime": 8.2986,
      "eval_samples_per_second": 24.1,
      "eval_steps_per_second": 24.1,
      "step": 4000
    },
    {
      "epoch": 8.02,
      "grad_norm": 1.090739369392395,
      "learning_rate": 6.036363636363636e-05,
      "loss": 0.1352,
      "step": 4010
    },
    {
      "epoch": 8.04,
      "grad_norm": 1.7213054895401,
      "learning_rate": 5.9757575757575755e-05,
      "loss": 0.1169,
      "step": 4020
    },
    {
      "epoch": 8.06,
      "grad_norm": 1.2779806852340698,
      "learning_rate": 5.9151515151515145e-05,
      "loss": 0.1184,
      "step": 4030
    },
    {
      "epoch": 8.08,
      "grad_norm": 2.9450771808624268,
      "learning_rate": 5.854545454545454e-05,
      "loss": 0.1161,
      "step": 4040
    },
    {
      "epoch": 8.1,
      "grad_norm": 1.2732911109924316,
      "learning_rate": 5.793939393939393e-05,
      "loss": 0.1371,
      "step": 4050
    },
    {
      "epoch": 8.12,
      "grad_norm": 1.0391422510147095,
      "learning_rate": 5.733333333333333e-05,
      "loss": 0.1064,
      "step": 4060
    },
    {
      "epoch": 8.14,
      "grad_norm": 1.5969408750534058,
      "learning_rate": 5.672727272727272e-05,
      "loss": 0.1754,
      "step": 4070
    },
    {
      "epoch": 8.16,
      "grad_norm": 0.8012144565582275,
      "learning_rate": 5.612121212121212e-05,
      "loss": 0.1137,
      "step": 4080
    },
    {
      "epoch": 8.18,
      "grad_norm": 1.5628560781478882,
      "learning_rate": 5.551515151515151e-05,
      "loss": 0.096,
      "step": 4090
    },
    {
      "epoch": 8.2,
      "grad_norm": 0.7022452354431152,
      "learning_rate": 5.490909090909091e-05,
      "loss": 0.1176,
      "step": 4100
    },
    {
      "epoch": 8.2,
      "eval_loss": 2.268113613128662,
      "eval_runtime": 8.402,
      "eval_samples_per_second": 23.804,
      "eval_steps_per_second": 23.804,
      "step": 4100
    },
    {
      "epoch": 8.22,
      "grad_norm": 8.794649124145508,
      "learning_rate": 5.43030303030303e-05,
      "loss": 0.128,
      "step": 4110
    },
    {
      "epoch": 8.24,
      "grad_norm": 1.5267058610916138,
      "learning_rate": 5.369696969696969e-05,
      "loss": 0.1198,
      "step": 4120
    },
    {
      "epoch": 8.26,
      "grad_norm": 1.0566723346710205,
      "learning_rate": 5.3090909090909087e-05,
      "loss": 0.1198,
      "step": 4130
    },
    {
      "epoch": 8.28,
      "grad_norm": 3.161817789077759,
      "learning_rate": 5.2484848484848477e-05,
      "loss": 0.1241,
      "step": 4140
    },
    {
      "epoch": 8.3,
      "grad_norm": 1.576990008354187,
      "learning_rate": 5.1878787878787873e-05,
      "loss": 0.1463,
      "step": 4150
    },
    {
      "epoch": 8.32,
      "grad_norm": 1.4911913871765137,
      "learning_rate": 5.1272727272727264e-05,
      "loss": 0.1097,
      "step": 4160
    },
    {
      "epoch": 8.34,
      "grad_norm": 4.988444805145264,
      "learning_rate": 5.066666666666666e-05,
      "loss": 0.1462,
      "step": 4170
    },
    {
      "epoch": 8.36,
      "grad_norm": 1.1277645826339722,
      "learning_rate": 5.006060606060605e-05,
      "loss": 0.1329,
      "step": 4180
    },
    {
      "epoch": 8.38,
      "grad_norm": 4.601812839508057,
      "learning_rate": 4.9454545454545454e-05,
      "loss": 0.1333,
      "step": 4190
    },
    {
      "epoch": 8.4,
      "grad_norm": 1.0746920108795166,
      "learning_rate": 4.8848484848484844e-05,
      "loss": 0.1236,
      "step": 4200
    },
    {
      "epoch": 8.4,
      "eval_loss": 2.2821314334869385,
      "eval_runtime": 8.4345,
      "eval_samples_per_second": 23.712,
      "eval_steps_per_second": 23.712,
      "step": 4200
    },
    {
      "epoch": 8.42,
      "grad_norm": 1.057081937789917,
      "learning_rate": 4.824242424242424e-05,
      "loss": 0.1332,
      "step": 4210
    },
    {
      "epoch": 8.44,
      "grad_norm": 0.6756753921508789,
      "learning_rate": 4.763636363636363e-05,
      "loss": 0.1325,
      "step": 4220
    },
    {
      "epoch": 8.46,
      "grad_norm": 1.0287448167800903,
      "learning_rate": 4.703030303030303e-05,
      "loss": 0.1233,
      "step": 4230
    },
    {
      "epoch": 8.48,
      "grad_norm": 2.020484209060669,
      "learning_rate": 4.642424242424242e-05,
      "loss": 0.1306,
      "step": 4240
    },
    {
      "epoch": 8.5,
      "grad_norm": 5.3053717613220215,
      "learning_rate": 4.5818181818181815e-05,
      "loss": 0.1437,
      "step": 4250
    },
    {
      "epoch": 8.52,
      "grad_norm": 0.9969813823699951,
      "learning_rate": 4.5212121212121205e-05,
      "loss": 0.1318,
      "step": 4260
    },
    {
      "epoch": 8.54,
      "grad_norm": 1.2767350673675537,
      "learning_rate": 4.460606060606061e-05,
      "loss": 0.1331,
      "step": 4270
    },
    {
      "epoch": 8.56,
      "grad_norm": 2.627978563308716,
      "learning_rate": 4.4e-05,
      "loss": 0.1234,
      "step": 4280
    },
    {
      "epoch": 8.58,
      "grad_norm": 0.7922617197036743,
      "learning_rate": 4.339393939393939e-05,
      "loss": 0.1326,
      "step": 4290
    },
    {
      "epoch": 8.6,
      "grad_norm": 1.7917746305465698,
      "learning_rate": 4.2787878787878786e-05,
      "loss": 0.1199,
      "step": 4300
    },
    {
      "epoch": 8.6,
      "eval_loss": 2.2981457710266113,
      "eval_runtime": 8.4073,
      "eval_samples_per_second": 23.789,
      "eval_steps_per_second": 23.789,
      "step": 4300
    },
    {
      "epoch": 8.62,
      "grad_norm": 4.266905784606934,
      "learning_rate": 4.2181818181818176e-05,
      "loss": 0.1542,
      "step": 4310
    },
    {
      "epoch": 8.64,
      "grad_norm": 1.096891164779663,
      "learning_rate": 4.157575757575757e-05,
      "loss": 0.1395,
      "step": 4320
    },
    {
      "epoch": 8.66,
      "grad_norm": 4.007757663726807,
      "learning_rate": 4.096969696969696e-05,
      "loss": 0.1332,
      "step": 4330
    },
    {
      "epoch": 8.68,
      "grad_norm": 1.102019190788269,
      "learning_rate": 4.036363636363636e-05,
      "loss": 0.1246,
      "step": 4340
    },
    {
      "epoch": 8.7,
      "grad_norm": 0.8138383030891418,
      "learning_rate": 3.975757575757575e-05,
      "loss": 0.1369,
      "step": 4350
    },
    {
      "epoch": 8.72,
      "grad_norm": 2.026643753051758,
      "learning_rate": 3.9151515151515153e-05,
      "loss": 0.1253,
      "step": 4360
    },
    {
      "epoch": 8.74,
      "grad_norm": 1.8518520593643188,
      "learning_rate": 3.8545454545454544e-05,
      "loss": 0.1269,
      "step": 4370
    },
    {
      "epoch": 8.76,
      "grad_norm": 2.3180413246154785,
      "learning_rate": 3.793939393939394e-05,
      "loss": 0.1258,
      "step": 4380
    },
    {
      "epoch": 8.78,
      "grad_norm": 1.5542556047439575,
      "learning_rate": 3.733333333333333e-05,
      "loss": 0.1574,
      "step": 4390
    },
    {
      "epoch": 8.8,
      "grad_norm": 1.3214339017868042,
      "learning_rate": 3.672727272727272e-05,
      "loss": 0.1191,
      "step": 4400
    },
    {
      "epoch": 8.8,
      "eval_loss": 2.2584946155548096,
      "eval_runtime": 8.3498,
      "eval_samples_per_second": 23.953,
      "eval_steps_per_second": 23.953,
      "step": 4400
    },
    {
      "epoch": 8.82,
      "grad_norm": 0.8434103727340698,
      "learning_rate": 3.612121212121212e-05,
      "loss": 0.1293,
      "step": 4410
    },
    {
      "epoch": 8.84,
      "grad_norm": 1.6935852766036987,
      "learning_rate": 3.5515151515151514e-05,
      "loss": 0.1326,
      "step": 4420
    },
    {
      "epoch": 8.86,
      "grad_norm": 2.7329747676849365,
      "learning_rate": 3.4909090909090904e-05,
      "loss": 0.1262,
      "step": 4430
    },
    {
      "epoch": 8.88,
      "grad_norm": 0.708152174949646,
      "learning_rate": 3.43030303030303e-05,
      "loss": 0.1169,
      "step": 4440
    },
    {
      "epoch": 8.9,
      "grad_norm": 1.2436912059783936,
      "learning_rate": 3.369696969696969e-05,
      "loss": 0.1223,
      "step": 4450
    },
    {
      "epoch": 8.92,
      "grad_norm": 1.7047154903411865,
      "learning_rate": 3.309090909090909e-05,
      "loss": 0.1185,
      "step": 4460
    },
    {
      "epoch": 8.94,
      "grad_norm": 1.1361315250396729,
      "learning_rate": 3.2484848484848485e-05,
      "loss": 0.1229,
      "step": 4470
    },
    {
      "epoch": 8.96,
      "grad_norm": 0.7390918135643005,
      "learning_rate": 3.1878787878787875e-05,
      "loss": 0.1127,
      "step": 4480
    },
    {
      "epoch": 8.98,
      "grad_norm": 1.9744549989700317,
      "learning_rate": 3.127272727272727e-05,
      "loss": 0.1321,
      "step": 4490
    },
    {
      "epoch": 9.0,
      "grad_norm": 1.1999372243881226,
      "learning_rate": 3.066666666666667e-05,
      "loss": 0.1279,
      "step": 4500
    },
    {
      "epoch": 9.0,
      "eval_loss": 2.2799625396728516,
      "eval_runtime": 8.307,
      "eval_samples_per_second": 24.076,
      "eval_steps_per_second": 24.076,
      "step": 4500
    }
  ],
  "logging_steps": 10,
  "max_steps": 5000,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 10,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 1.3472250200064e+16,
  "train_batch_size": 1,
  "trial_name": null,
  "trial_params": null
}

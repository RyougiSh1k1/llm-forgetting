{
  "best_global_step": null,
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 10.0,
  "eval_steps": 100,
  "global_step": 5000,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.02,
      "grad_norm": 25.349210739135742,
      "learning_rate": 2.9999999999999997e-05,
      "loss": 5.0433,
      "step": 10
    },
    {
      "epoch": 0.04,
      "grad_norm": 8.247949600219727,
      "learning_rate": 8.999999999999999e-05,
      "loss": 3.8266,
      "step": 20
    },
    {
      "epoch": 0.06,
      "grad_norm": 5.613943099975586,
      "learning_rate": 0.00015,
      "loss": 2.4,
      "step": 30
    },
    {
      "epoch": 0.08,
      "grad_norm": 3.748228073120117,
      "learning_rate": 0.00020999999999999998,
      "loss": 1.6202,
      "step": 40
    },
    {
      "epoch": 0.1,
      "grad_norm": 2.793632984161377,
      "learning_rate": 0.00027,
      "loss": 1.4163,
      "step": 50
    },
    {
      "epoch": 0.12,
      "grad_norm": 2.3882157802581787,
      "learning_rate": 0.00029969696969696965,
      "loss": 1.4864,
      "step": 60
    },
    {
      "epoch": 0.14,
      "grad_norm": 2.076529026031494,
      "learning_rate": 0.00029909090909090906,
      "loss": 1.4232,
      "step": 70
    },
    {
      "epoch": 0.16,
      "grad_norm": 2.576641321182251,
      "learning_rate": 0.00029848484848484847,
      "loss": 1.3009,
      "step": 80
    },
    {
      "epoch": 0.18,
      "grad_norm": 2.0867292881011963,
      "learning_rate": 0.00029787878787878783,
      "loss": 1.2525,
      "step": 90
    },
    {
      "epoch": 0.2,
      "grad_norm": 2.7795917987823486,
      "learning_rate": 0.00029727272727272724,
      "loss": 1.0546,
      "step": 100
    },
    {
      "epoch": 0.2,
      "eval_loss": 1.3596066236495972,
      "eval_runtime": 8.3353,
      "eval_samples_per_second": 23.994,
      "eval_steps_per_second": 23.994,
      "step": 100
    },
    {
      "epoch": 0.22,
      "grad_norm": 3.207601547241211,
      "learning_rate": 0.00029666666666666665,
      "loss": 1.1095,
      "step": 110
    },
    {
      "epoch": 0.24,
      "grad_norm": 2.575007915496826,
      "learning_rate": 0.00029606060606060606,
      "loss": 1.3878,
      "step": 120
    },
    {
      "epoch": 0.26,
      "grad_norm": 2.565793514251709,
      "learning_rate": 0.0002954545454545454,
      "loss": 1.1256,
      "step": 130
    },
    {
      "epoch": 0.28,
      "grad_norm": 1.8884550333023071,
      "learning_rate": 0.0002948484848484848,
      "loss": 1.0559,
      "step": 140
    },
    {
      "epoch": 0.3,
      "grad_norm": 4.030649662017822,
      "learning_rate": 0.00029424242424242424,
      "loss": 1.4206,
      "step": 150
    },
    {
      "epoch": 0.32,
      "grad_norm": 2.6898818016052246,
      "learning_rate": 0.0002936363636363636,
      "loss": 1.4477,
      "step": 160
    },
    {
      "epoch": 0.34,
      "grad_norm": 2.162308931350708,
      "learning_rate": 0.000293030303030303,
      "loss": 1.3788,
      "step": 170
    },
    {
      "epoch": 0.36,
      "grad_norm": 3.0426511764526367,
      "learning_rate": 0.00029242424242424236,
      "loss": 1.1601,
      "step": 180
    },
    {
      "epoch": 0.38,
      "grad_norm": 2.6069750785827637,
      "learning_rate": 0.0002918181818181818,
      "loss": 1.3717,
      "step": 190
    },
    {
      "epoch": 0.4,
      "grad_norm": 2.664135694503784,
      "learning_rate": 0.0002912121212121212,
      "loss": 1.1382,
      "step": 200
    },
    {
      "epoch": 0.4,
      "eval_loss": 1.2916253805160522,
      "eval_runtime": 8.4991,
      "eval_samples_per_second": 23.532,
      "eval_steps_per_second": 23.532,
      "step": 200
    },
    {
      "epoch": 0.42,
      "grad_norm": 1.810271978378296,
      "learning_rate": 0.0002906060606060606,
      "loss": 1.3928,
      "step": 210
    },
    {
      "epoch": 0.44,
      "grad_norm": 1.5159372091293335,
      "learning_rate": 0.00029,
      "loss": 1.199,
      "step": 220
    },
    {
      "epoch": 0.46,
      "grad_norm": 4.958166599273682,
      "learning_rate": 0.00028939393939393936,
      "loss": 1.3111,
      "step": 230
    },
    {
      "epoch": 0.48,
      "grad_norm": 1.9103690385818481,
      "learning_rate": 0.00028878787878787877,
      "loss": 1.2635,
      "step": 240
    },
    {
      "epoch": 0.5,
      "grad_norm": 2.512094736099243,
      "learning_rate": 0.0002881818181818181,
      "loss": 1.2381,
      "step": 250
    },
    {
      "epoch": 0.52,
      "grad_norm": 2.854055404663086,
      "learning_rate": 0.00028757575757575753,
      "loss": 1.1152,
      "step": 260
    },
    {
      "epoch": 0.54,
      "grad_norm": 1.9668301343917847,
      "learning_rate": 0.00028696969696969695,
      "loss": 1.3933,
      "step": 270
    },
    {
      "epoch": 0.56,
      "grad_norm": 2.9839372634887695,
      "learning_rate": 0.00028636363636363636,
      "loss": 1.2125,
      "step": 280
    },
    {
      "epoch": 0.58,
      "grad_norm": 1.9625545740127563,
      "learning_rate": 0.00028575757575757577,
      "loss": 1.2353,
      "step": 290
    },
    {
      "epoch": 0.6,
      "grad_norm": 1.5072054862976074,
      "learning_rate": 0.0002851515151515151,
      "loss": 1.3781,
      "step": 300
    },
    {
      "epoch": 0.6,
      "eval_loss": 1.279215931892395,
      "eval_runtime": 8.3595,
      "eval_samples_per_second": 23.925,
      "eval_steps_per_second": 23.925,
      "step": 300
    },
    {
      "epoch": 0.62,
      "grad_norm": 2.0658812522888184,
      "learning_rate": 0.00028454545454545453,
      "loss": 1.2095,
      "step": 310
    },
    {
      "epoch": 0.64,
      "grad_norm": 2.658223867416382,
      "learning_rate": 0.0002839393939393939,
      "loss": 1.0712,
      "step": 320
    },
    {
      "epoch": 0.66,
      "grad_norm": 1.9128103256225586,
      "learning_rate": 0.0002833333333333333,
      "loss": 1.2637,
      "step": 330
    },
    {
      "epoch": 0.68,
      "grad_norm": 2.9373300075531006,
      "learning_rate": 0.0002827272727272727,
      "loss": 1.293,
      "step": 340
    },
    {
      "epoch": 0.7,
      "grad_norm": 1.6809237003326416,
      "learning_rate": 0.00028212121212121207,
      "loss": 1.139,
      "step": 350
    },
    {
      "epoch": 0.72,
      "grad_norm": 2.2266783714294434,
      "learning_rate": 0.00028151515151515153,
      "loss": 1.1025,
      "step": 360
    },
    {
      "epoch": 0.74,
      "grad_norm": 2.9510135650634766,
      "learning_rate": 0.0002809090909090909,
      "loss": 1.3605,
      "step": 370
    },
    {
      "epoch": 0.76,
      "grad_norm": 2.6443374156951904,
      "learning_rate": 0.0002803030303030303,
      "loss": 1.3559,
      "step": 380
    },
    {
      "epoch": 0.78,
      "grad_norm": 3.1326353549957275,
      "learning_rate": 0.00027969696969696965,
      "loss": 1.4146,
      "step": 390
    },
    {
      "epoch": 0.8,
      "grad_norm": 1.9781583547592163,
      "learning_rate": 0.00027909090909090906,
      "loss": 1.1956,
      "step": 400
    },
    {
      "epoch": 0.8,
      "eval_loss": 1.267492413520813,
      "eval_runtime": 8.8754,
      "eval_samples_per_second": 22.534,
      "eval_steps_per_second": 22.534,
      "step": 400
    },
    {
      "epoch": 0.82,
      "grad_norm": 1.8695012331008911,
      "learning_rate": 0.0002784848484848485,
      "loss": 1.1218,
      "step": 410
    },
    {
      "epoch": 0.84,
      "grad_norm": 1.954998254776001,
      "learning_rate": 0.00027787878787878783,
      "loss": 1.0112,
      "step": 420
    },
    {
      "epoch": 0.86,
      "grad_norm": 2.1456501483917236,
      "learning_rate": 0.00027727272727272724,
      "loss": 1.4315,
      "step": 430
    },
    {
      "epoch": 0.88,
      "grad_norm": 2.066840887069702,
      "learning_rate": 0.00027666666666666665,
      "loss": 1.2171,
      "step": 440
    },
    {
      "epoch": 0.9,
      "grad_norm": 2.348802328109741,
      "learning_rate": 0.00027606060606060606,
      "loss": 1.2882,
      "step": 450
    },
    {
      "epoch": 0.92,
      "grad_norm": 2.951953411102295,
      "learning_rate": 0.0002754545454545454,
      "loss": 1.1597,
      "step": 460
    },
    {
      "epoch": 0.94,
      "grad_norm": 1.5631873607635498,
      "learning_rate": 0.00027484848484848483,
      "loss": 1.2508,
      "step": 470
    },
    {
      "epoch": 0.96,
      "grad_norm": 1.8864728212356567,
      "learning_rate": 0.00027424242424242424,
      "loss": 1.324,
      "step": 480
    },
    {
      "epoch": 0.98,
      "grad_norm": 1.7264447212219238,
      "learning_rate": 0.0002736363636363636,
      "loss": 1.2364,
      "step": 490
    },
    {
      "epoch": 1.0,
      "grad_norm": 2.3259613513946533,
      "learning_rate": 0.000273030303030303,
      "loss": 1.4147,
      "step": 500
    },
    {
      "epoch": 1.0,
      "eval_loss": 1.2594783306121826,
      "eval_runtime": 8.4615,
      "eval_samples_per_second": 23.636,
      "eval_steps_per_second": 23.636,
      "step": 500
    },
    {
      "epoch": 1.02,
      "grad_norm": 1.669371247291565,
      "learning_rate": 0.0002724242424242424,
      "loss": 1.2134,
      "step": 510
    },
    {
      "epoch": 1.04,
      "grad_norm": 1.0264397859573364,
      "learning_rate": 0.00027181818181818177,
      "loss": 1.1048,
      "step": 520
    },
    {
      "epoch": 1.06,
      "grad_norm": 2.288961410522461,
      "learning_rate": 0.0002712121212121212,
      "loss": 0.9011,
      "step": 530
    },
    {
      "epoch": 1.08,
      "grad_norm": 4.552875518798828,
      "learning_rate": 0.0002706060606060606,
      "loss": 0.9418,
      "step": 540
    },
    {
      "epoch": 1.1,
      "grad_norm": 2.188218355178833,
      "learning_rate": 0.00027,
      "loss": 0.9191,
      "step": 550
    },
    {
      "epoch": 1.12,
      "grad_norm": 1.9990516901016235,
      "learning_rate": 0.00026939393939393936,
      "loss": 1.0536,
      "step": 560
    },
    {
      "epoch": 1.1400000000000001,
      "grad_norm": 2.7779462337493896,
      "learning_rate": 0.00026878787878787877,
      "loss": 0.9922,
      "step": 570
    },
    {
      "epoch": 1.16,
      "grad_norm": 2.278768301010132,
      "learning_rate": 0.0002681818181818181,
      "loss": 0.9731,
      "step": 580
    },
    {
      "epoch": 1.18,
      "grad_norm": 2.795851945877075,
      "learning_rate": 0.00026757575757575754,
      "loss": 1.1303,
      "step": 590
    },
    {
      "epoch": 1.2,
      "grad_norm": 2.5328965187072754,
      "learning_rate": 0.00026696969696969695,
      "loss": 1.0133,
      "step": 600
    },
    {
      "epoch": 1.2,
      "eval_loss": 1.2853693962097168,
      "eval_runtime": 8.3352,
      "eval_samples_per_second": 23.995,
      "eval_steps_per_second": 23.995,
      "step": 600
    },
    {
      "epoch": 1.22,
      "grad_norm": 2.6596999168395996,
      "learning_rate": 0.00026636363636363636,
      "loss": 1.1754,
      "step": 610
    },
    {
      "epoch": 1.24,
      "grad_norm": 2.526540994644165,
      "learning_rate": 0.00026575757575757577,
      "loss": 0.8765,
      "step": 620
    },
    {
      "epoch": 1.26,
      "grad_norm": 2.788606882095337,
      "learning_rate": 0.0002651515151515151,
      "loss": 1.1787,
      "step": 630
    },
    {
      "epoch": 1.28,
      "grad_norm": 2.411342144012451,
      "learning_rate": 0.00026454545454545453,
      "loss": 0.9562,
      "step": 640
    },
    {
      "epoch": 1.3,
      "grad_norm": 2.156608819961548,
      "learning_rate": 0.0002639393939393939,
      "loss": 0.8968,
      "step": 650
    },
    {
      "epoch": 1.32,
      "grad_norm": 3.140981674194336,
      "learning_rate": 0.0002633333333333333,
      "loss": 0.9909,
      "step": 660
    },
    {
      "epoch": 1.34,
      "grad_norm": 2.701436758041382,
      "learning_rate": 0.0002627272727272727,
      "loss": 1.0145,
      "step": 670
    },
    {
      "epoch": 1.3599999999999999,
      "grad_norm": 2.5790884494781494,
      "learning_rate": 0.00026212121212121207,
      "loss": 1.087,
      "step": 680
    },
    {
      "epoch": 1.38,
      "grad_norm": 2.94697642326355,
      "learning_rate": 0.0002615151515151515,
      "loss": 1.0295,
      "step": 690
    },
    {
      "epoch": 1.4,
      "grad_norm": 2.7160849571228027,
      "learning_rate": 0.0002609090909090909,
      "loss": 1.1985,
      "step": 700
    },
    {
      "epoch": 1.4,
      "eval_loss": 1.2853213548660278,
      "eval_runtime": 8.3856,
      "eval_samples_per_second": 23.851,
      "eval_steps_per_second": 23.851,
      "step": 700
    },
    {
      "epoch": 1.42,
      "grad_norm": 2.2395639419555664,
      "learning_rate": 0.0002603030303030303,
      "loss": 1.0866,
      "step": 710
    },
    {
      "epoch": 1.44,
      "grad_norm": 2.3234140872955322,
      "learning_rate": 0.00025969696969696966,
      "loss": 1.0408,
      "step": 720
    },
    {
      "epoch": 1.46,
      "grad_norm": 2.517504930496216,
      "learning_rate": 0.00025909090909090907,
      "loss": 1.0948,
      "step": 730
    },
    {
      "epoch": 1.48,
      "grad_norm": 1.5926563739776611,
      "learning_rate": 0.0002584848484848485,
      "loss": 0.9064,
      "step": 740
    },
    {
      "epoch": 1.5,
      "grad_norm": 2.1302073001861572,
      "learning_rate": 0.00025787878787878783,
      "loss": 0.9857,
      "step": 750
    },
    {
      "epoch": 1.52,
      "grad_norm": 2.5310871601104736,
      "learning_rate": 0.00025727272727272724,
      "loss": 0.9298,
      "step": 760
    },
    {
      "epoch": 1.54,
      "grad_norm": 1.7492084503173828,
      "learning_rate": 0.00025666666666666665,
      "loss": 1.0558,
      "step": 770
    },
    {
      "epoch": 1.56,
      "grad_norm": 2.11689829826355,
      "learning_rate": 0.000256060606060606,
      "loss": 0.8808,
      "step": 780
    },
    {
      "epoch": 1.58,
      "grad_norm": 2.871718168258667,
      "learning_rate": 0.0002554545454545454,
      "loss": 1.0678,
      "step": 790
    },
    {
      "epoch": 1.6,
      "grad_norm": 2.795128583908081,
      "learning_rate": 0.00025484848484848483,
      "loss": 1.0747,
      "step": 800
    },
    {
      "epoch": 1.6,
      "eval_loss": 1.2937506437301636,
      "eval_runtime": 8.3299,
      "eval_samples_per_second": 24.01,
      "eval_steps_per_second": 24.01,
      "step": 800
    },
    {
      "epoch": 1.62,
      "grad_norm": 1.946648359298706,
      "learning_rate": 0.00025424242424242424,
      "loss": 1.0636,
      "step": 810
    },
    {
      "epoch": 1.6400000000000001,
      "grad_norm": 2.8347461223602295,
      "learning_rate": 0.0002536363636363636,
      "loss": 1.0821,
      "step": 820
    },
    {
      "epoch": 1.6600000000000001,
      "grad_norm": 3.068524122238159,
      "learning_rate": 0.000253030303030303,
      "loss": 1.2,
      "step": 830
    },
    {
      "epoch": 1.6800000000000002,
      "grad_norm": 3.3724241256713867,
      "learning_rate": 0.0002524242424242424,
      "loss": 1.2556,
      "step": 840
    },
    {
      "epoch": 1.7,
      "grad_norm": 2.5947182178497314,
      "learning_rate": 0.0002518181818181818,
      "loss": 0.9061,
      "step": 850
    },
    {
      "epoch": 1.72,
      "grad_norm": 2.496260643005371,
      "learning_rate": 0.0002512121212121212,
      "loss": 1.0395,
      "step": 860
    },
    {
      "epoch": 1.74,
      "grad_norm": 2.5586814880371094,
      "learning_rate": 0.0002506060606060606,
      "loss": 0.95,
      "step": 870
    },
    {
      "epoch": 1.76,
      "grad_norm": 3.0402841567993164,
      "learning_rate": 0.00025,
      "loss": 1.1531,
      "step": 880
    },
    {
      "epoch": 1.78,
      "grad_norm": 2.9428632259368896,
      "learning_rate": 0.00024939393939393936,
      "loss": 1.0282,
      "step": 890
    },
    {
      "epoch": 1.8,
      "grad_norm": 3.7486937046051025,
      "learning_rate": 0.00024878787878787877,
      "loss": 0.9604,
      "step": 900
    },
    {
      "epoch": 1.8,
      "eval_loss": 1.2862533330917358,
      "eval_runtime": 8.3884,
      "eval_samples_per_second": 23.843,
      "eval_steps_per_second": 23.843,
      "step": 900
    },
    {
      "epoch": 1.8199999999999998,
      "grad_norm": 3.1254916191101074,
      "learning_rate": 0.0002481818181818182,
      "loss": 0.9926,
      "step": 910
    },
    {
      "epoch": 1.8399999999999999,
      "grad_norm": 3.634042739868164,
      "learning_rate": 0.00024757575757575754,
      "loss": 1.1757,
      "step": 920
    },
    {
      "epoch": 1.8599999999999999,
      "grad_norm": 2.2292826175689697,
      "learning_rate": 0.00024696969696969695,
      "loss": 0.9371,
      "step": 930
    },
    {
      "epoch": 1.88,
      "grad_norm": 2.347569227218628,
      "learning_rate": 0.0002463636363636363,
      "loss": 1.0254,
      "step": 940
    },
    {
      "epoch": 1.9,
      "grad_norm": 3.2723817825317383,
      "learning_rate": 0.0002457575757575757,
      "loss": 0.9264,
      "step": 950
    },
    {
      "epoch": 1.92,
      "grad_norm": 2.4531641006469727,
      "learning_rate": 0.0002451515151515151,
      "loss": 0.9242,
      "step": 960
    },
    {
      "epoch": 1.94,
      "grad_norm": 3.528850555419922,
      "learning_rate": 0.00024454545454545454,
      "loss": 0.8664,
      "step": 970
    },
    {
      "epoch": 1.96,
      "grad_norm": 3.793440341949463,
      "learning_rate": 0.00024393939393939392,
      "loss": 1.2517,
      "step": 980
    },
    {
      "epoch": 1.98,
      "grad_norm": 3.285083770751953,
      "learning_rate": 0.0002433333333333333,
      "loss": 1.1512,
      "step": 990
    },
    {
      "epoch": 2.0,
      "grad_norm": 2.190075397491455,
      "learning_rate": 0.0002427272727272727,
      "loss": 0.7796,
      "step": 1000
    },
    {
      "epoch": 2.0,
      "eval_loss": 1.2845404148101807,
      "eval_runtime": 8.3656,
      "eval_samples_per_second": 23.907,
      "eval_steps_per_second": 23.907,
      "step": 1000
    },
    {
      "epoch": 2.02,
      "grad_norm": 3.1324520111083984,
      "learning_rate": 0.0002421212121212121,
      "loss": 0.6277,
      "step": 1010
    },
    {
      "epoch": 2.04,
      "grad_norm": 3.4116320610046387,
      "learning_rate": 0.00024151515151515148,
      "loss": 0.6351,
      "step": 1020
    },
    {
      "epoch": 2.06,
      "grad_norm": 2.9594857692718506,
      "learning_rate": 0.00024090909090909086,
      "loss": 0.8766,
      "step": 1030
    },
    {
      "epoch": 2.08,
      "grad_norm": 3.919593572616577,
      "learning_rate": 0.0002403030303030303,
      "loss": 0.7471,
      "step": 1040
    },
    {
      "epoch": 2.1,
      "grad_norm": 3.0571916103363037,
      "learning_rate": 0.00023969696969696968,
      "loss": 0.6336,
      "step": 1050
    },
    {
      "epoch": 2.12,
      "grad_norm": 0.28564760088920593,
      "learning_rate": 0.00023909090909090907,
      "loss": 0.9329,
      "step": 1060
    },
    {
      "epoch": 2.14,
      "grad_norm": 3.594905138015747,
      "learning_rate": 0.00023848484848484848,
      "loss": 0.7923,
      "step": 1070
    },
    {
      "epoch": 2.16,
      "grad_norm": 2.962433338165283,
      "learning_rate": 0.00023787878787878786,
      "loss": 0.8405,
      "step": 1080
    },
    {
      "epoch": 2.18,
      "grad_norm": 2.5653655529022217,
      "learning_rate": 0.00023727272727272724,
      "loss": 0.7496,
      "step": 1090
    },
    {
      "epoch": 2.2,
      "grad_norm": 3.739870309829712,
      "learning_rate": 0.00023666666666666663,
      "loss": 0.6565,
      "step": 1100
    },
    {
      "epoch": 2.2,
      "eval_loss": 1.3892951011657715,
      "eval_runtime": 8.3334,
      "eval_samples_per_second": 24.0,
      "eval_steps_per_second": 24.0,
      "step": 1100
    },
    {
      "epoch": 2.22,
      "grad_norm": 3.26163911819458,
      "learning_rate": 0.00023606060606060604,
      "loss": 0.7547,
      "step": 1110
    },
    {
      "epoch": 2.24,
      "grad_norm": 4.025454998016357,
      "learning_rate": 0.00023545454545454542,
      "loss": 0.7643,
      "step": 1120
    },
    {
      "epoch": 2.26,
      "grad_norm": 2.643848180770874,
      "learning_rate": 0.00023484848484848483,
      "loss": 0.6469,
      "step": 1130
    },
    {
      "epoch": 2.2800000000000002,
      "grad_norm": 2.925096273422241,
      "learning_rate": 0.00023424242424242424,
      "loss": 0.8413,
      "step": 1140
    },
    {
      "epoch": 2.3,
      "grad_norm": 3.946078062057495,
      "learning_rate": 0.00023363636363636363,
      "loss": 0.6746,
      "step": 1150
    },
    {
      "epoch": 2.32,
      "grad_norm": 3.4118800163269043,
      "learning_rate": 0.000233030303030303,
      "loss": 0.6858,
      "step": 1160
    },
    {
      "epoch": 2.34,
      "grad_norm": 1.919691562652588,
      "learning_rate": 0.0002324242424242424,
      "loss": 0.6812,
      "step": 1170
    },
    {
      "epoch": 2.36,
      "grad_norm": 3.692431926727295,
      "learning_rate": 0.0002318181818181818,
      "loss": 0.8005,
      "step": 1180
    },
    {
      "epoch": 2.38,
      "grad_norm": 3.350700616836548,
      "learning_rate": 0.00023121212121212119,
      "loss": 0.8501,
      "step": 1190
    },
    {
      "epoch": 2.4,
      "grad_norm": 3.4369099140167236,
      "learning_rate": 0.00023060606060606057,
      "loss": 0.7136,
      "step": 1200
    },
    {
      "epoch": 2.4,
      "eval_loss": 1.3909574747085571,
      "eval_runtime": 8.3877,
      "eval_samples_per_second": 23.844,
      "eval_steps_per_second": 23.844,
      "step": 1200
    },
    {
      "epoch": 2.42,
      "grad_norm": 3.503222942352295,
      "learning_rate": 0.00023,
      "loss": 0.734,
      "step": 1210
    },
    {
      "epoch": 2.44,
      "grad_norm": 4.36083459854126,
      "learning_rate": 0.0002293939393939394,
      "loss": 0.7673,
      "step": 1220
    },
    {
      "epoch": 2.46,
      "grad_norm": 3.3899552822113037,
      "learning_rate": 0.00022878787878787877,
      "loss": 0.7063,
      "step": 1230
    },
    {
      "epoch": 2.48,
      "grad_norm": 1.8264899253845215,
      "learning_rate": 0.00022818181818181816,
      "loss": 0.7598,
      "step": 1240
    },
    {
      "epoch": 2.5,
      "grad_norm": 3.8755242824554443,
      "learning_rate": 0.00022757575757575757,
      "loss": 0.7573,
      "step": 1250
    },
    {
      "epoch": 2.52,
      "grad_norm": 2.688654661178589,
      "learning_rate": 0.00022696969696969695,
      "loss": 0.7378,
      "step": 1260
    },
    {
      "epoch": 2.54,
      "grad_norm": 2.799341917037964,
      "learning_rate": 0.00022636363636363633,
      "loss": 0.8121,
      "step": 1270
    },
    {
      "epoch": 2.56,
      "grad_norm": 2.872551202774048,
      "learning_rate": 0.00022575757575757572,
      "loss": 0.7389,
      "step": 1280
    },
    {
      "epoch": 2.58,
      "grad_norm": 4.3582563400268555,
      "learning_rate": 0.00022515151515151513,
      "loss": 0.8773,
      "step": 1290
    },
    {
      "epoch": 2.6,
      "grad_norm": 4.788611888885498,
      "learning_rate": 0.00022454545454545454,
      "loss": 0.8776,
      "step": 1300
    },
    {
      "epoch": 2.6,
      "eval_loss": 1.386929988861084,
      "eval_runtime": 8.3599,
      "eval_samples_per_second": 23.924,
      "eval_steps_per_second": 23.924,
      "step": 1300
    },
    {
      "epoch": 2.62,
      "grad_norm": 5.009270191192627,
      "learning_rate": 0.00022393939393939392,
      "loss": 0.719,
      "step": 1310
    },
    {
      "epoch": 2.64,
      "grad_norm": 4.024045467376709,
      "learning_rate": 0.00022333333333333333,
      "loss": 0.837,
      "step": 1320
    },
    {
      "epoch": 2.66,
      "grad_norm": 2.54252552986145,
      "learning_rate": 0.00022272727272727272,
      "loss": 0.8401,
      "step": 1330
    },
    {
      "epoch": 2.68,
      "grad_norm": 3.442775011062622,
      "learning_rate": 0.0002221212121212121,
      "loss": 0.7529,
      "step": 1340
    },
    {
      "epoch": 2.7,
      "grad_norm": 3.558438777923584,
      "learning_rate": 0.00022151515151515148,
      "loss": 0.637,
      "step": 1350
    },
    {
      "epoch": 2.7199999999999998,
      "grad_norm": 3.7280194759368896,
      "learning_rate": 0.0002209090909090909,
      "loss": 0.7619,
      "step": 1360
    },
    {
      "epoch": 2.74,
      "grad_norm": 2.7958757877349854,
      "learning_rate": 0.00022030303030303028,
      "loss": 0.7367,
      "step": 1370
    },
    {
      "epoch": 2.76,
      "grad_norm": 4.607316017150879,
      "learning_rate": 0.00021969696969696969,
      "loss": 0.8062,
      "step": 1380
    },
    {
      "epoch": 2.7800000000000002,
      "grad_norm": 3.9291908740997314,
      "learning_rate": 0.0002190909090909091,
      "loss": 0.7116,
      "step": 1390
    },
    {
      "epoch": 2.8,
      "grad_norm": 4.222602367401123,
      "learning_rate": 0.00021848484848484848,
      "loss": 0.7077,
      "step": 1400
    },
    {
      "epoch": 2.8,
      "eval_loss": 1.3882009983062744,
      "eval_runtime": 8.3353,
      "eval_samples_per_second": 23.994,
      "eval_steps_per_second": 23.994,
      "step": 1400
    },
    {
      "epoch": 2.82,
      "grad_norm": 3.521101474761963,
      "learning_rate": 0.00021787878787878786,
      "loss": 0.7691,
      "step": 1410
    },
    {
      "epoch": 2.84,
      "grad_norm": 2.4061777591705322,
      "learning_rate": 0.00021727272727272725,
      "loss": 0.7808,
      "step": 1420
    },
    {
      "epoch": 2.86,
      "grad_norm": 4.045500755310059,
      "learning_rate": 0.00021666666666666666,
      "loss": 0.7189,
      "step": 1430
    },
    {
      "epoch": 2.88,
      "grad_norm": 3.5012946128845215,
      "learning_rate": 0.00021606060606060604,
      "loss": 0.673,
      "step": 1440
    },
    {
      "epoch": 2.9,
      "grad_norm": 2.7918293476104736,
      "learning_rate": 0.00021545454545454542,
      "loss": 0.7593,
      "step": 1450
    },
    {
      "epoch": 2.92,
      "grad_norm": 2.812391757965088,
      "learning_rate": 0.0002148484848484848,
      "loss": 0.7136,
      "step": 1460
    },
    {
      "epoch": 2.94,
      "grad_norm": 2.2350873947143555,
      "learning_rate": 0.00021424242424242424,
      "loss": 0.7532,
      "step": 1470
    },
    {
      "epoch": 2.96,
      "grad_norm": 2.475221872329712,
      "learning_rate": 0.00021363636363636363,
      "loss": 0.7635,
      "step": 1480
    },
    {
      "epoch": 2.98,
      "grad_norm": 3.4959628582000732,
      "learning_rate": 0.000213030303030303,
      "loss": 0.8744,
      "step": 1490
    },
    {
      "epoch": 3.0,
      "grad_norm": 2.4487476348876953,
      "learning_rate": 0.00021242424242424242,
      "loss": 0.7142,
      "step": 1500
    },
    {
      "epoch": 3.0,
      "eval_loss": 1.3778338432312012,
      "eval_runtime": 8.3282,
      "eval_samples_per_second": 24.015,
      "eval_steps_per_second": 24.015,
      "step": 1500
    },
    {
      "epoch": 3.02,
      "grad_norm": 2.6435954570770264,
      "learning_rate": 0.0002118181818181818,
      "loss": 0.5777,
      "step": 1510
    },
    {
      "epoch": 3.04,
      "grad_norm": 4.579988479614258,
      "learning_rate": 0.0002112121212121212,
      "loss": 0.5746,
      "step": 1520
    },
    {
      "epoch": 3.06,
      "grad_norm": 1.0156795978546143,
      "learning_rate": 0.00021060606060606057,
      "loss": 0.4143,
      "step": 1530
    },
    {
      "epoch": 3.08,
      "grad_norm": 3.509937286376953,
      "learning_rate": 0.00020999999999999998,
      "loss": 0.6095,
      "step": 1540
    },
    {
      "epoch": 3.1,
      "grad_norm": 4.1116485595703125,
      "learning_rate": 0.0002093939393939394,
      "loss": 0.4161,
      "step": 1550
    },
    {
      "epoch": 3.12,
      "grad_norm": 1.9072844982147217,
      "learning_rate": 0.00020878787878787878,
      "loss": 0.4468,
      "step": 1560
    },
    {
      "epoch": 3.14,
      "grad_norm": 4.804091930389404,
      "learning_rate": 0.00020818181818181816,
      "loss": 0.3822,
      "step": 1570
    },
    {
      "epoch": 3.16,
      "grad_norm": 2.3386292457580566,
      "learning_rate": 0.00020757575757575757,
      "loss": 0.5257,
      "step": 1580
    },
    {
      "epoch": 3.18,
      "grad_norm": 2.865323305130005,
      "learning_rate": 0.00020696969696969695,
      "loss": 0.5533,
      "step": 1590
    },
    {
      "epoch": 3.2,
      "grad_norm": 2.773206949234009,
      "learning_rate": 0.00020636363636363634,
      "loss": 0.6263,
      "step": 1600
    },
    {
      "epoch": 3.2,
      "eval_loss": 1.5386830568313599,
      "eval_runtime": 8.4058,
      "eval_samples_per_second": 23.793,
      "eval_steps_per_second": 23.793,
      "step": 1600
    },
    {
      "epoch": 3.22,
      "grad_norm": 6.429783821105957,
      "learning_rate": 0.00020575757575757572,
      "loss": 0.4139,
      "step": 1610
    },
    {
      "epoch": 3.24,
      "grad_norm": 2.902677536010742,
      "learning_rate": 0.00020515151515151513,
      "loss": 0.5042,
      "step": 1620
    },
    {
      "epoch": 3.26,
      "grad_norm": 5.810480117797852,
      "learning_rate": 0.0002045454545454545,
      "loss": 0.5038,
      "step": 1630
    },
    {
      "epoch": 3.2800000000000002,
      "grad_norm": 4.167741298675537,
      "learning_rate": 0.00020393939393939392,
      "loss": 0.5563,
      "step": 1640
    },
    {
      "epoch": 3.3,
      "grad_norm": 5.563358306884766,
      "learning_rate": 0.00020333333333333333,
      "loss": 0.6252,
      "step": 1650
    },
    {
      "epoch": 3.32,
      "grad_norm": 6.904043674468994,
      "learning_rate": 0.00020272727272727272,
      "loss": 0.568,
      "step": 1660
    },
    {
      "epoch": 3.34,
      "grad_norm": 4.373402118682861,
      "learning_rate": 0.0002021212121212121,
      "loss": 0.4928,
      "step": 1670
    },
    {
      "epoch": 3.36,
      "grad_norm": 5.802759170532227,
      "learning_rate": 0.00020151515151515148,
      "loss": 0.5074,
      "step": 1680
    },
    {
      "epoch": 3.38,
      "grad_norm": 6.2749342918396,
      "learning_rate": 0.0002009090909090909,
      "loss": 0.5369,
      "step": 1690
    },
    {
      "epoch": 3.4,
      "grad_norm": 1.5893086194992065,
      "learning_rate": 0.00020030303030303028,
      "loss": 0.454,
      "step": 1700
    },
    {
      "epoch": 3.4,
      "eval_loss": 1.5365568399429321,
      "eval_runtime": 8.3665,
      "eval_samples_per_second": 23.905,
      "eval_steps_per_second": 23.905,
      "step": 1700
    },
    {
      "epoch": 3.42,
      "grad_norm": 0.4693582355976105,
      "learning_rate": 0.00019969696969696966,
      "loss": 0.4955,
      "step": 1710
    },
    {
      "epoch": 3.44,
      "grad_norm": 4.063600540161133,
      "learning_rate": 0.0001990909090909091,
      "loss": 0.6224,
      "step": 1720
    },
    {
      "epoch": 3.46,
      "grad_norm": 2.286931276321411,
      "learning_rate": 0.00019848484848484848,
      "loss": 0.4347,
      "step": 1730
    },
    {
      "epoch": 3.48,
      "grad_norm": 2.933286428451538,
      "learning_rate": 0.00019787878787878786,
      "loss": 0.496,
      "step": 1740
    },
    {
      "epoch": 3.5,
      "grad_norm": 5.129678726196289,
      "learning_rate": 0.00019727272727272725,
      "loss": 0.5373,
      "step": 1750
    },
    {
      "epoch": 3.52,
      "grad_norm": 2.1214375495910645,
      "learning_rate": 0.00019666666666666666,
      "loss": 0.5714,
      "step": 1760
    },
    {
      "epoch": 3.54,
      "grad_norm": 4.059969902038574,
      "learning_rate": 0.00019606060606060604,
      "loss": 0.4451,
      "step": 1770
    },
    {
      "epoch": 3.56,
      "grad_norm": 4.0500898361206055,
      "learning_rate": 0.00019545454545454543,
      "loss": 0.4876,
      "step": 1780
    },
    {
      "epoch": 3.58,
      "grad_norm": 6.754268646240234,
      "learning_rate": 0.0001948484848484848,
      "loss": 0.5674,
      "step": 1790
    },
    {
      "epoch": 3.6,
      "grad_norm": 5.569523811340332,
      "learning_rate": 0.00019424242424242422,
      "loss": 0.4191,
      "step": 1800
    },
    {
      "epoch": 3.6,
      "eval_loss": 1.5766873359680176,
      "eval_runtime": 8.3397,
      "eval_samples_per_second": 23.982,
      "eval_steps_per_second": 23.982,
      "step": 1800
    },
    {
      "epoch": 3.62,
      "grad_norm": 5.321545124053955,
      "learning_rate": 0.00019363636363636363,
      "loss": 0.52,
      "step": 1810
    },
    {
      "epoch": 3.64,
      "grad_norm": 2.366734743118286,
      "learning_rate": 0.000193030303030303,
      "loss": 0.4828,
      "step": 1820
    },
    {
      "epoch": 3.66,
      "grad_norm": 2.742500066757202,
      "learning_rate": 0.00019242424242424242,
      "loss": 0.374,
      "step": 1830
    },
    {
      "epoch": 3.68,
      "grad_norm": 0.7633702158927917,
      "learning_rate": 0.0001918181818181818,
      "loss": 0.5354,
      "step": 1840
    },
    {
      "epoch": 3.7,
      "grad_norm": 1.9522584676742554,
      "learning_rate": 0.0001912121212121212,
      "loss": 0.4614,
      "step": 1850
    },
    {
      "epoch": 3.7199999999999998,
      "grad_norm": 6.704347133636475,
      "learning_rate": 0.00019060606060606057,
      "loss": 0.6326,
      "step": 1860
    },
    {
      "epoch": 3.74,
      "grad_norm": 6.037225723266602,
      "learning_rate": 0.00018999999999999998,
      "loss": 0.6384,
      "step": 1870
    },
    {
      "epoch": 3.76,
      "grad_norm": 3.617547035217285,
      "learning_rate": 0.00018939393939393937,
      "loss": 0.4879,
      "step": 1880
    },
    {
      "epoch": 3.7800000000000002,
      "grad_norm": 2.896275043487549,
      "learning_rate": 0.00018878787878787878,
      "loss": 0.6213,
      "step": 1890
    },
    {
      "epoch": 3.8,
      "grad_norm": 6.1432085037231445,
      "learning_rate": 0.0001881818181818182,
      "loss": 0.5269,
      "step": 1900
    },
    {
      "epoch": 3.8,
      "eval_loss": 1.5522783994674683,
      "eval_runtime": 8.4126,
      "eval_samples_per_second": 23.774,
      "eval_steps_per_second": 23.774,
      "step": 1900
    },
    {
      "epoch": 3.82,
      "grad_norm": 4.438217639923096,
      "learning_rate": 0.00018757575757575757,
      "loss": 0.3975,
      "step": 1910
    },
    {
      "epoch": 3.84,
      "grad_norm": 4.886573791503906,
      "learning_rate": 0.00018696969696969695,
      "loss": 0.5408,
      "step": 1920
    },
    {
      "epoch": 3.86,
      "grad_norm": 1.8969122171401978,
      "learning_rate": 0.00018636363636363634,
      "loss": 0.5348,
      "step": 1930
    },
    {
      "epoch": 3.88,
      "grad_norm": 4.737802982330322,
      "learning_rate": 0.00018575757575757575,
      "loss": 0.475,
      "step": 1940
    },
    {
      "epoch": 3.9,
      "grad_norm": 3.4137251377105713,
      "learning_rate": 0.00018515151515151513,
      "loss": 0.6367,
      "step": 1950
    },
    {
      "epoch": 3.92,
      "grad_norm": 4.672784328460693,
      "learning_rate": 0.00018454545454545451,
      "loss": 0.614,
      "step": 1960
    },
    {
      "epoch": 3.94,
      "grad_norm": 4.148665428161621,
      "learning_rate": 0.0001839393939393939,
      "loss": 0.526,
      "step": 1970
    },
    {
      "epoch": 3.96,
      "grad_norm": 4.262580871582031,
      "learning_rate": 0.00018333333333333334,
      "loss": 0.6206,
      "step": 1980
    },
    {
      "epoch": 3.98,
      "grad_norm": 3.268765449523926,
      "learning_rate": 0.00018272727272727272,
      "loss": 0.4154,
      "step": 1990
    },
    {
      "epoch": 4.0,
      "grad_norm": 4.223918914794922,
      "learning_rate": 0.0001821212121212121,
      "loss": 0.479,
      "step": 2000
    },
    {
      "epoch": 4.0,
      "eval_loss": 1.5597418546676636,
      "eval_runtime": 8.4307,
      "eval_samples_per_second": 23.723,
      "eval_steps_per_second": 23.723,
      "step": 2000
    },
    {
      "epoch": 4.02,
      "grad_norm": 3.9738287925720215,
      "learning_rate": 0.0001815151515151515,
      "loss": 0.397,
      "step": 2010
    },
    {
      "epoch": 4.04,
      "grad_norm": 2.26273775100708,
      "learning_rate": 0.0001809090909090909,
      "loss": 0.2951,
      "step": 2020
    },
    {
      "epoch": 4.06,
      "grad_norm": 5.783168792724609,
      "learning_rate": 0.00018030303030303028,
      "loss": 0.3241,
      "step": 2030
    },
    {
      "epoch": 4.08,
      "grad_norm": 5.052071571350098,
      "learning_rate": 0.00017969696969696966,
      "loss": 0.4199,
      "step": 2040
    },
    {
      "epoch": 4.1,
      "grad_norm": 5.371066570281982,
      "learning_rate": 0.00017909090909090907,
      "loss": 0.2722,
      "step": 2050
    },
    {
      "epoch": 4.12,
      "grad_norm": 1.978455901145935,
      "learning_rate": 0.00017848484848484846,
      "loss": 0.2819,
      "step": 2060
    },
    {
      "epoch": 4.14,
      "grad_norm": 3.4644203186035156,
      "learning_rate": 0.00017787878787878787,
      "loss": 0.2292,
      "step": 2070
    },
    {
      "epoch": 4.16,
      "grad_norm": 2.1827125549316406,
      "learning_rate": 0.00017727272727272728,
      "loss": 0.2703,
      "step": 2080
    },
    {
      "epoch": 4.18,
      "grad_norm": 5.717787742614746,
      "learning_rate": 0.00017666666666666666,
      "loss": 0.4177,
      "step": 2090
    },
    {
      "epoch": 4.2,
      "grad_norm": 2.667250871658325,
      "learning_rate": 0.00017606060606060604,
      "loss": 0.2782,
      "step": 2100
    },
    {
      "epoch": 4.2,
      "eval_loss": 1.6866742372512817,
      "eval_runtime": 8.3603,
      "eval_samples_per_second": 23.923,
      "eval_steps_per_second": 23.923,
      "step": 2100
    },
    {
      "epoch": 4.22,
      "grad_norm": 3.904754638671875,
      "learning_rate": 0.00017545454545454543,
      "loss": 0.2643,
      "step": 2110
    },
    {
      "epoch": 4.24,
      "grad_norm": 1.4887795448303223,
      "learning_rate": 0.00017484848484848484,
      "loss": 0.2745,
      "step": 2120
    },
    {
      "epoch": 4.26,
      "grad_norm": 3.118490219116211,
      "learning_rate": 0.00017424242424242422,
      "loss": 0.2372,
      "step": 2130
    },
    {
      "epoch": 4.28,
      "grad_norm": 3.830453395843506,
      "learning_rate": 0.0001736363636363636,
      "loss": 0.322,
      "step": 2140
    },
    {
      "epoch": 4.3,
      "grad_norm": 7.160752296447754,
      "learning_rate": 0.00017303030303030304,
      "loss": 0.3694,
      "step": 2150
    },
    {
      "epoch": 4.32,
      "grad_norm": 2.6791491508483887,
      "learning_rate": 0.00017242424242424242,
      "loss": 0.3756,
      "step": 2160
    },
    {
      "epoch": 4.34,
      "grad_norm": 3.9895145893096924,
      "learning_rate": 0.0001718181818181818,
      "loss": 0.299,
      "step": 2170
    },
    {
      "epoch": 4.36,
      "grad_norm": 7.127518653869629,
      "learning_rate": 0.0001712121212121212,
      "loss": 0.4045,
      "step": 2180
    },
    {
      "epoch": 4.38,
      "grad_norm": 2.2890384197235107,
      "learning_rate": 0.0001706060606060606,
      "loss": 0.3192,
      "step": 2190
    },
    {
      "epoch": 4.4,
      "grad_norm": 7.664177417755127,
      "learning_rate": 0.00016999999999999999,
      "loss": 0.3552,
      "step": 2200
    },
    {
      "epoch": 4.4,
      "eval_loss": 1.7328152656555176,
      "eval_runtime": 8.352,
      "eval_samples_per_second": 23.946,
      "eval_steps_per_second": 23.946,
      "step": 2200
    },
    {
      "epoch": 4.42,
      "grad_norm": 5.589788913726807,
      "learning_rate": 0.00016939393939393937,
      "loss": 0.4022,
      "step": 2210
    },
    {
      "epoch": 4.44,
      "grad_norm": 4.379596710205078,
      "learning_rate": 0.00016878787878787875,
      "loss": 0.3448,
      "step": 2220
    },
    {
      "epoch": 4.46,
      "grad_norm": 2.765749931335449,
      "learning_rate": 0.00016818181818181816,
      "loss": 0.2394,
      "step": 2230
    },
    {
      "epoch": 4.48,
      "grad_norm": 3.4047515392303467,
      "learning_rate": 0.00016757575757575757,
      "loss": 0.3269,
      "step": 2240
    },
    {
      "epoch": 4.5,
      "grad_norm": 2.6190273761749268,
      "learning_rate": 0.00016703030303030303,
      "loss": 0.3485,
      "step": 2250
    },
    {
      "epoch": 4.52,
      "grad_norm": 4.311880588531494,
      "learning_rate": 0.00016642424242424241,
      "loss": 0.2671,
      "step": 2260
    },
    {
      "epoch": 4.54,
      "grad_norm": 2.749936103820801,
      "learning_rate": 0.0001658181818181818,
      "loss": 0.3544,
      "step": 2270
    },
    {
      "epoch": 4.5600000000000005,
      "grad_norm": 5.413321018218994,
      "learning_rate": 0.0001652121212121212,
      "loss": 0.5868,
      "step": 2280
    },
    {
      "epoch": 4.58,
      "grad_norm": 2.1100733280181885,
      "learning_rate": 0.0001646060606060606,
      "loss": 0.3376,
      "step": 2290
    },
    {
      "epoch": 4.6,
      "grad_norm": 6.5458831787109375,
      "learning_rate": 0.00016399999999999997,
      "loss": 0.3581,
      "step": 2300
    },
    {
      "epoch": 4.6,
      "eval_loss": 1.7577885389328003,
      "eval_runtime": 8.3926,
      "eval_samples_per_second": 23.831,
      "eval_steps_per_second": 23.831,
      "step": 2300
    },
    {
      "epoch": 4.62,
      "grad_norm": 5.779486179351807,
      "learning_rate": 0.00016339393939393936,
      "loss": 0.2972,
      "step": 2310
    },
    {
      "epoch": 4.64,
      "grad_norm": 2.851691484451294,
      "learning_rate": 0.0001627878787878788,
      "loss": 0.4775,
      "step": 2320
    },
    {
      "epoch": 4.66,
      "grad_norm": 2.9348506927490234,
      "learning_rate": 0.00016218181818181818,
      "loss": 0.359,
      "step": 2330
    },
    {
      "epoch": 4.68,
      "grad_norm": 6.068667888641357,
      "learning_rate": 0.00016157575757575756,
      "loss": 0.313,
      "step": 2340
    },
    {
      "epoch": 4.7,
      "grad_norm": 3.0579617023468018,
      "learning_rate": 0.00016096969696969697,
      "loss": 0.4291,
      "step": 2350
    },
    {
      "epoch": 4.72,
      "grad_norm": 3.9520044326782227,
      "learning_rate": 0.00016036363636363636,
      "loss": 0.3365,
      "step": 2360
    },
    {
      "epoch": 4.74,
      "grad_norm": 3.1700167655944824,
      "learning_rate": 0.00015975757575757574,
      "loss": 0.5454,
      "step": 2370
    },
    {
      "epoch": 4.76,
      "grad_norm": 1.1616315841674805,
      "learning_rate": 0.00015915151515151512,
      "loss": 0.3693,
      "step": 2380
    },
    {
      "epoch": 4.78,
      "grad_norm": 3.9788806438446045,
      "learning_rate": 0.00015854545454545453,
      "loss": 0.3569,
      "step": 2390
    },
    {
      "epoch": 4.8,
      "grad_norm": 5.20399284362793,
      "learning_rate": 0.00015793939393939392,
      "loss": 0.4595,
      "step": 2400
    },
    {
      "epoch": 4.8,
      "eval_loss": 1.6809794902801514,
      "eval_runtime": 8.383,
      "eval_samples_per_second": 23.858,
      "eval_steps_per_second": 23.858,
      "step": 2400
    },
    {
      "epoch": 4.82,
      "grad_norm": 4.228253364562988,
      "learning_rate": 0.00015733333333333333,
      "loss": 0.3729,
      "step": 2410
    },
    {
      "epoch": 4.84,
      "grad_norm": 5.803012847900391,
      "learning_rate": 0.0001567272727272727,
      "loss": 0.4159,
      "step": 2420
    },
    {
      "epoch": 4.86,
      "grad_norm": 6.261714935302734,
      "learning_rate": 0.00015612121212121212,
      "loss": 0.3733,
      "step": 2430
    },
    {
      "epoch": 4.88,
      "grad_norm": 3.6369831562042236,
      "learning_rate": 0.0001555151515151515,
      "loss": 0.3477,
      "step": 2440
    },
    {
      "epoch": 4.9,
      "grad_norm": 3.7697913646698,
      "learning_rate": 0.0001549090909090909,
      "loss": 0.3174,
      "step": 2450
    },
    {
      "epoch": 4.92,
      "grad_norm": 3.969805955886841,
      "learning_rate": 0.00015430303030303027,
      "loss": 0.3599,
      "step": 2460
    },
    {
      "epoch": 4.9399999999999995,
      "grad_norm": 0.8508066534996033,
      "learning_rate": 0.00015369696969696968,
      "loss": 0.3752,
      "step": 2470
    },
    {
      "epoch": 4.96,
      "grad_norm": 3.7609667778015137,
      "learning_rate": 0.00015309090909090906,
      "loss": 0.3394,
      "step": 2480
    },
    {
      "epoch": 4.98,
      "grad_norm": 2.4784371852874756,
      "learning_rate": 0.00015248484848484847,
      "loss": 0.3557,
      "step": 2490
    },
    {
      "epoch": 5.0,
      "grad_norm": 10.700453758239746,
      "learning_rate": 0.00015187878787878789,
      "loss": 0.3432,
      "step": 2500
    },
    {
      "epoch": 5.0,
      "eval_loss": 1.7439535856246948,
      "eval_runtime": 8.3859,
      "eval_samples_per_second": 23.85,
      "eval_steps_per_second": 23.85,
      "step": 2500
    },
    {
      "epoch": 5.02,
      "grad_norm": 4.773482322692871,
      "learning_rate": 0.00015127272727272727,
      "loss": 0.2303,
      "step": 2510
    },
    {
      "epoch": 5.04,
      "grad_norm": 1.3470046520233154,
      "learning_rate": 0.00015066666666666665,
      "loss": 0.1869,
      "step": 2520
    },
    {
      "epoch": 5.06,
      "grad_norm": 1.1576956510543823,
      "learning_rate": 0.00015006060606060603,
      "loss": 0.2259,
      "step": 2530
    },
    {
      "epoch": 5.08,
      "grad_norm": 2.0810563564300537,
      "learning_rate": 0.00014945454545454545,
      "loss": 0.2217,
      "step": 2540
    },
    {
      "epoch": 5.1,
      "grad_norm": 6.154351234436035,
      "learning_rate": 0.00014884848484848483,
      "loss": 0.3183,
      "step": 2550
    },
    {
      "epoch": 5.12,
      "grad_norm": 1.388074278831482,
      "learning_rate": 0.00014824242424242424,
      "loss": 0.2461,
      "step": 2560
    },
    {
      "epoch": 5.14,
      "grad_norm": 1.3756141662597656,
      "learning_rate": 0.00014763636363636362,
      "loss": 0.2413,
      "step": 2570
    },
    {
      "epoch": 5.16,
      "grad_norm": 3.0197553634643555,
      "learning_rate": 0.000147030303030303,
      "loss": 0.3314,
      "step": 2580
    },
    {
      "epoch": 5.18,
      "grad_norm": 2.695723533630371,
      "learning_rate": 0.00014642424242424242,
      "loss": 0.312,
      "step": 2590
    },
    {
      "epoch": 5.2,
      "grad_norm": 4.056575298309326,
      "learning_rate": 0.0001458181818181818,
      "loss": 0.2148,
      "step": 2600
    },
    {
      "epoch": 5.2,
      "eval_loss": 1.8872402906417847,
      "eval_runtime": 8.3793,
      "eval_samples_per_second": 23.868,
      "eval_steps_per_second": 23.868,
      "step": 2600
    },
    {
      "epoch": 5.22,
      "grad_norm": 8.196367263793945,
      "learning_rate": 0.0001452121212121212,
      "loss": 0.2126,
      "step": 2610
    },
    {
      "epoch": 5.24,
      "grad_norm": 0.4665573835372925,
      "learning_rate": 0.0001446060606060606,
      "loss": 0.2396,
      "step": 2620
    },
    {
      "epoch": 5.26,
      "grad_norm": 2.6503236293792725,
      "learning_rate": 0.00014399999999999998,
      "loss": 0.2629,
      "step": 2630
    },
    {
      "epoch": 5.28,
      "grad_norm": 2.5396413803100586,
      "learning_rate": 0.0001433939393939394,
      "loss": 0.1903,
      "step": 2640
    },
    {
      "epoch": 5.3,
      "grad_norm": 3.5722227096557617,
      "learning_rate": 0.00014278787878787877,
      "loss": 0.2133,
      "step": 2650
    },
    {
      "epoch": 5.32,
      "grad_norm": 9.218652725219727,
      "learning_rate": 0.00014218181818181818,
      "loss": 0.2551,
      "step": 2660
    },
    {
      "epoch": 5.34,
      "grad_norm": 5.246298313140869,
      "learning_rate": 0.00014157575757575756,
      "loss": 0.3008,
      "step": 2670
    },
    {
      "epoch": 5.36,
      "grad_norm": 4.70271635055542,
      "learning_rate": 0.00014096969696969695,
      "loss": 0.2385,
      "step": 2680
    },
    {
      "epoch": 5.38,
      "grad_norm": 3.464804172515869,
      "learning_rate": 0.00014036363636363636,
      "loss": 0.2681,
      "step": 2690
    },
    {
      "epoch": 5.4,
      "grad_norm": 5.022521495819092,
      "learning_rate": 0.00013975757575757574,
      "loss": 0.1799,
      "step": 2700
    },
    {
      "epoch": 5.4,
      "eval_loss": 1.91896390914917,
      "eval_runtime": 8.3476,
      "eval_samples_per_second": 23.959,
      "eval_steps_per_second": 23.959,
      "step": 2700
    },
    {
      "epoch": 5.42,
      "grad_norm": 3.726210355758667,
      "learning_rate": 0.00013915151515151512,
      "loss": 0.2092,
      "step": 2710
    },
    {
      "epoch": 5.44,
      "grad_norm": 4.396193027496338,
      "learning_rate": 0.00013854545454545453,
      "loss": 0.27,
      "step": 2720
    },
    {
      "epoch": 5.46,
      "grad_norm": 4.54931116104126,
      "learning_rate": 0.00013793939393939395,
      "loss": 0.2752,
      "step": 2730
    },
    {
      "epoch": 5.48,
      "grad_norm": 3.5947818756103516,
      "learning_rate": 0.00013733333333333333,
      "loss": 0.237,
      "step": 2740
    },
    {
      "epoch": 5.5,
      "grad_norm": 2.753730297088623,
      "learning_rate": 0.0001367272727272727,
      "loss": 0.2434,
      "step": 2750
    },
    {
      "epoch": 5.52,
      "grad_norm": 4.032592296600342,
      "learning_rate": 0.0001361212121212121,
      "loss": 0.2098,
      "step": 2760
    },
    {
      "epoch": 5.54,
      "grad_norm": 2.548103094100952,
      "learning_rate": 0.0001355151515151515,
      "loss": 0.2118,
      "step": 2770
    },
    {
      "epoch": 5.5600000000000005,
      "grad_norm": 3.156501293182373,
      "learning_rate": 0.0001349090909090909,
      "loss": 0.2241,
      "step": 2780
    },
    {
      "epoch": 5.58,
      "grad_norm": 4.963234901428223,
      "learning_rate": 0.0001343030303030303,
      "loss": 0.2248,
      "step": 2790
    },
    {
      "epoch": 5.6,
      "grad_norm": 7.803716659545898,
      "learning_rate": 0.00013369696969696968,
      "loss": 0.3604,
      "step": 2800
    },
    {
      "epoch": 5.6,
      "eval_loss": 1.9195691347122192,
      "eval_runtime": 8.4272,
      "eval_samples_per_second": 23.733,
      "eval_steps_per_second": 23.733,
      "step": 2800
    },
    {
      "epoch": 5.62,
      "grad_norm": 4.376856327056885,
      "learning_rate": 0.0001330909090909091,
      "loss": 0.2422,
      "step": 2810
    },
    {
      "epoch": 5.64,
      "grad_norm": 5.7848734855651855,
      "learning_rate": 0.00013248484848484848,
      "loss": 0.3053,
      "step": 2820
    },
    {
      "epoch": 5.66,
      "grad_norm": 4.972110748291016,
      "learning_rate": 0.00013187878787878786,
      "loss": 0.26,
      "step": 2830
    },
    {
      "epoch": 5.68,
      "grad_norm": 4.697103023529053,
      "learning_rate": 0.00013127272727272727,
      "loss": 0.2213,
      "step": 2840
    },
    {
      "epoch": 5.7,
      "grad_norm": 2.589846134185791,
      "learning_rate": 0.00013066666666666665,
      "loss": 0.2224,
      "step": 2850
    },
    {
      "epoch": 5.72,
      "grad_norm": 1.86372709274292,
      "learning_rate": 0.00013006060606060606,
      "loss": 0.1897,
      "step": 2860
    },
    {
      "epoch": 5.74,
      "grad_norm": 2.992584705352783,
      "learning_rate": 0.00012945454545454545,
      "loss": 0.2062,
      "step": 2870
    },
    {
      "epoch": 5.76,
      "grad_norm": 1.34650456905365,
      "learning_rate": 0.00012884848484848483,
      "loss": 0.2874,
      "step": 2880
    },
    {
      "epoch": 5.78,
      "grad_norm": 2.6700849533081055,
      "learning_rate": 0.00012824242424242421,
      "loss": 0.2026,
      "step": 2890
    },
    {
      "epoch": 5.8,
      "grad_norm": 1.7936142683029175,
      "learning_rate": 0.00012763636363636362,
      "loss": 0.2404,
      "step": 2900
    },
    {
      "epoch": 5.8,
      "eval_loss": 1.8887825012207031,
      "eval_runtime": 8.3638,
      "eval_samples_per_second": 23.912,
      "eval_steps_per_second": 23.912,
      "step": 2900
    },
    {
      "epoch": 5.82,
      "grad_norm": 4.9484639167785645,
      "learning_rate": 0.00012703030303030303,
      "loss": 0.2717,
      "step": 2910
    },
    {
      "epoch": 5.84,
      "grad_norm": 1.417857050895691,
      "learning_rate": 0.00012642424242424242,
      "loss": 0.2747,
      "step": 2920
    },
    {
      "epoch": 5.86,
      "grad_norm": 2.227557897567749,
      "learning_rate": 0.0001258181818181818,
      "loss": 0.2549,
      "step": 2930
    },
    {
      "epoch": 5.88,
      "grad_norm": 1.000319242477417,
      "learning_rate": 0.0001252121212121212,
      "loss": 0.2062,
      "step": 2940
    },
    {
      "epoch": 5.9,
      "grad_norm": 3.3003828525543213,
      "learning_rate": 0.0001246060606060606,
      "loss": 0.3107,
      "step": 2950
    },
    {
      "epoch": 5.92,
      "grad_norm": 4.015034198760986,
      "learning_rate": 0.00012399999999999998,
      "loss": 0.4159,
      "step": 2960
    },
    {
      "epoch": 5.9399999999999995,
      "grad_norm": 3.7783312797546387,
      "learning_rate": 0.0001233939393939394,
      "loss": 0.2458,
      "step": 2970
    },
    {
      "epoch": 5.96,
      "grad_norm": 3.657855749130249,
      "learning_rate": 0.00012278787878787877,
      "loss": 0.2675,
      "step": 2980
    },
    {
      "epoch": 5.98,
      "grad_norm": 3.0649075508117676,
      "learning_rate": 0.00012218181818181818,
      "loss": 0.2742,
      "step": 2990
    },
    {
      "epoch": 6.0,
      "grad_norm": 5.879024982452393,
      "learning_rate": 0.00012157575757575757,
      "loss": 0.2527,
      "step": 3000
    },
    {
      "epoch": 6.0,
      "eval_loss": 1.9171513319015503,
      "eval_runtime": 8.3359,
      "eval_samples_per_second": 23.993,
      "eval_steps_per_second": 23.993,
      "step": 3000
    },
    {
      "epoch": 6.02,
      "grad_norm": 0.7637460231781006,
      "learning_rate": 0.00012096969696969695,
      "loss": 0.1383,
      "step": 3010
    },
    {
      "epoch": 6.04,
      "grad_norm": 1.2360153198242188,
      "learning_rate": 0.00012036363636363635,
      "loss": 0.1567,
      "step": 3020
    },
    {
      "epoch": 6.06,
      "grad_norm": 6.269498825073242,
      "learning_rate": 0.00011975757575757576,
      "loss": 0.1975,
      "step": 3030
    },
    {
      "epoch": 6.08,
      "grad_norm": 6.906530380249023,
      "learning_rate": 0.00011915151515151514,
      "loss": 0.2029,
      "step": 3040
    },
    {
      "epoch": 6.1,
      "grad_norm": 3.8356611728668213,
      "learning_rate": 0.00011854545454545454,
      "loss": 0.1368,
      "step": 3050
    },
    {
      "epoch": 6.12,
      "grad_norm": 2.0321617126464844,
      "learning_rate": 0.00011793939393939392,
      "loss": 0.1717,
      "step": 3060
    },
    {
      "epoch": 6.14,
      "grad_norm": 2.2249457836151123,
      "learning_rate": 0.00011733333333333333,
      "loss": 0.2052,
      "step": 3070
    },
    {
      "epoch": 6.16,
      "grad_norm": 1.8086713552474976,
      "learning_rate": 0.00011672727272727271,
      "loss": 0.2085,
      "step": 3080
    },
    {
      "epoch": 6.18,
      "grad_norm": 7.906174182891846,
      "learning_rate": 0.00011612121212121211,
      "loss": 0.1846,
      "step": 3090
    },
    {
      "epoch": 6.2,
      "grad_norm": 6.668639659881592,
      "learning_rate": 0.0001155151515151515,
      "loss": 0.1766,
      "step": 3100
    },
    {
      "epoch": 6.2,
      "eval_loss": 2.006539821624756,
      "eval_runtime": 8.2867,
      "eval_samples_per_second": 24.135,
      "eval_steps_per_second": 24.135,
      "step": 3100
    },
    {
      "epoch": 6.22,
      "grad_norm": 3.2711799144744873,
      "learning_rate": 0.0001149090909090909,
      "loss": 0.1944,
      "step": 3110
    },
    {
      "epoch": 6.24,
      "grad_norm": 1.4312727451324463,
      "learning_rate": 0.0001143030303030303,
      "loss": 0.1655,
      "step": 3120
    },
    {
      "epoch": 6.26,
      "grad_norm": 2.876854419708252,
      "learning_rate": 0.00011369696969696968,
      "loss": 0.1738,
      "step": 3130
    },
    {
      "epoch": 6.28,
      "grad_norm": 2.1016907691955566,
      "learning_rate": 0.00011309090909090908,
      "loss": 0.1721,
      "step": 3140
    },
    {
      "epoch": 6.3,
      "grad_norm": 9.298876762390137,
      "learning_rate": 0.00011248484848484848,
      "loss": 0.1805,
      "step": 3150
    },
    {
      "epoch": 6.32,
      "grad_norm": 1.484487533569336,
      "learning_rate": 0.00011187878787878787,
      "loss": 0.2063,
      "step": 3160
    },
    {
      "epoch": 6.34,
      "grad_norm": 3.917442560195923,
      "learning_rate": 0.00011127272727272726,
      "loss": 0.2305,
      "step": 3170
    },
    {
      "epoch": 6.36,
      "grad_norm": 1.3856931924819946,
      "learning_rate": 0.00011066666666666666,
      "loss": 0.183,
      "step": 3180
    },
    {
      "epoch": 6.38,
      "grad_norm": 3.8278231620788574,
      "learning_rate": 0.00011006060606060604,
      "loss": 0.1609,
      "step": 3190
    },
    {
      "epoch": 6.4,
      "grad_norm": 6.414953231811523,
      "learning_rate": 0.00010945454545454545,
      "loss": 0.1914,
      "step": 3200
    },
    {
      "epoch": 6.4,
      "eval_loss": 2.098956823348999,
      "eval_runtime": 8.3062,
      "eval_samples_per_second": 24.078,
      "eval_steps_per_second": 24.078,
      "step": 3200
    },
    {
      "epoch": 6.42,
      "grad_norm": 4.2560224533081055,
      "learning_rate": 0.00010884848484848485,
      "loss": 0.1392,
      "step": 3210
    },
    {
      "epoch": 6.44,
      "grad_norm": 4.016275405883789,
      "learning_rate": 0.00010824242424242423,
      "loss": 0.2364,
      "step": 3220
    },
    {
      "epoch": 6.46,
      "grad_norm": 2.188688039779663,
      "learning_rate": 0.00010763636363636363,
      "loss": 0.1723,
      "step": 3230
    },
    {
      "epoch": 6.48,
      "grad_norm": 4.352069854736328,
      "learning_rate": 0.00010703030303030302,
      "loss": 0.1754,
      "step": 3240
    },
    {
      "epoch": 6.5,
      "grad_norm": 5.697193622589111,
      "learning_rate": 0.00010642424242424242,
      "loss": 0.2321,
      "step": 3250
    },
    {
      "epoch": 6.52,
      "grad_norm": 2.1200520992279053,
      "learning_rate": 0.0001058181818181818,
      "loss": 0.2027,
      "step": 3260
    },
    {
      "epoch": 6.54,
      "grad_norm": 6.275257587432861,
      "learning_rate": 0.0001052121212121212,
      "loss": 0.1756,
      "step": 3270
    },
    {
      "epoch": 6.5600000000000005,
      "grad_norm": 4.3888840675354,
      "learning_rate": 0.00010460606060606061,
      "loss": 0.1687,
      "step": 3280
    },
    {
      "epoch": 6.58,
      "grad_norm": 1.0418548583984375,
      "learning_rate": 0.000104,
      "loss": 0.234,
      "step": 3290
    },
    {
      "epoch": 6.6,
      "grad_norm": 2.083061933517456,
      "learning_rate": 0.00010339393939393939,
      "loss": 0.1564,
      "step": 3300
    },
    {
      "epoch": 6.6,
      "eval_loss": 2.09810209274292,
      "eval_runtime": 8.3473,
      "eval_samples_per_second": 23.96,
      "eval_steps_per_second": 23.96,
      "step": 3300
    },
    {
      "epoch": 6.62,
      "grad_norm": 3.789644479751587,
      "learning_rate": 0.00010278787878787877,
      "loss": 0.2255,
      "step": 3310
    },
    {
      "epoch": 6.64,
      "grad_norm": 2.223116159439087,
      "learning_rate": 0.00010218181818181817,
      "loss": 0.1503,
      "step": 3320
    },
    {
      "epoch": 6.66,
      "grad_norm": 4.636918067932129,
      "learning_rate": 0.00010157575757575757,
      "loss": 0.1799,
      "step": 3330
    },
    {
      "epoch": 6.68,
      "grad_norm": 2.22503924369812,
      "learning_rate": 0.00010096969696969696,
      "loss": 0.1889,
      "step": 3340
    },
    {
      "epoch": 6.7,
      "grad_norm": 1.7863225936889648,
      "learning_rate": 0.00010036363636363635,
      "loss": 0.1567,
      "step": 3350
    },
    {
      "epoch": 6.72,
      "grad_norm": 1.8216782808303833,
      "learning_rate": 9.975757575757574e-05,
      "loss": 0.2044,
      "step": 3360
    },
    {
      "epoch": 6.74,
      "grad_norm": 1.3723225593566895,
      "learning_rate": 9.915151515151515e-05,
      "loss": 0.1944,
      "step": 3370
    },
    {
      "epoch": 6.76,
      "grad_norm": 1.7971456050872803,
      "learning_rate": 9.854545454545454e-05,
      "loss": 0.1911,
      "step": 3380
    },
    {
      "epoch": 6.78,
      "grad_norm": 1.4525907039642334,
      "learning_rate": 9.793939393939394e-05,
      "loss": 0.1856,
      "step": 3390
    },
    {
      "epoch": 6.8,
      "grad_norm": 0.8759751319885254,
      "learning_rate": 9.733333333333332e-05,
      "loss": 0.1583,
      "step": 3400
    },
    {
      "epoch": 6.8,
      "eval_loss": 2.0393075942993164,
      "eval_runtime": 8.3122,
      "eval_samples_per_second": 24.061,
      "eval_steps_per_second": 24.061,
      "step": 3400
    },
    {
      "epoch": 6.82,
      "grad_norm": 14.45158863067627,
      "learning_rate": 9.672727272727273e-05,
      "loss": 0.3369,
      "step": 3410
    },
    {
      "epoch": 6.84,
      "grad_norm": 3.60603666305542,
      "learning_rate": 9.612121212121211e-05,
      "loss": 0.2152,
      "step": 3420
    },
    {
      "epoch": 6.86,
      "grad_norm": 3.2959415912628174,
      "learning_rate": 9.551515151515151e-05,
      "loss": 0.1713,
      "step": 3430
    },
    {
      "epoch": 6.88,
      "grad_norm": 2.3864400386810303,
      "learning_rate": 9.490909090909089e-05,
      "loss": 0.1872,
      "step": 3440
    },
    {
      "epoch": 6.9,
      "grad_norm": 2.6784467697143555,
      "learning_rate": 9.43030303030303e-05,
      "loss": 0.2013,
      "step": 3450
    },
    {
      "epoch": 6.92,
      "grad_norm": 3.861084461212158,
      "learning_rate": 9.369696969696969e-05,
      "loss": 0.2027,
      "step": 3460
    },
    {
      "epoch": 6.9399999999999995,
      "grad_norm": 0.9787375926971436,
      "learning_rate": 9.309090909090908e-05,
      "loss": 0.2238,
      "step": 3470
    },
    {
      "epoch": 6.96,
      "grad_norm": 2.822434186935425,
      "learning_rate": 9.248484848484847e-05,
      "loss": 0.2039,
      "step": 3480
    },
    {
      "epoch": 6.98,
      "grad_norm": 1.7965145111083984,
      "learning_rate": 9.187878787878786e-05,
      "loss": 0.168,
      "step": 3490
    },
    {
      "epoch": 7.0,
      "grad_norm": 2.119190216064453,
      "learning_rate": 9.127272727272727e-05,
      "loss": 0.1753,
      "step": 3500
    },
    {
      "epoch": 7.0,
      "eval_loss": 2.017484664916992,
      "eval_runtime": 8.3259,
      "eval_samples_per_second": 24.022,
      "eval_steps_per_second": 24.022,
      "step": 3500
    },
    {
      "epoch": 7.02,
      "grad_norm": 1.4407050609588623,
      "learning_rate": 9.066666666666666e-05,
      "loss": 0.1467,
      "step": 3510
    },
    {
      "epoch": 7.04,
      "grad_norm": 2.122279644012451,
      "learning_rate": 9.006060606060605e-05,
      "loss": 0.1455,
      "step": 3520
    },
    {
      "epoch": 7.06,
      "grad_norm": 0.8184844851493835,
      "learning_rate": 8.945454545454544e-05,
      "loss": 0.1986,
      "step": 3530
    },
    {
      "epoch": 7.08,
      "grad_norm": 0.6230135560035706,
      "learning_rate": 8.884848484848485e-05,
      "loss": 0.1476,
      "step": 3540
    },
    {
      "epoch": 7.1,
      "grad_norm": 0.6207133531570435,
      "learning_rate": 8.824242424242423e-05,
      "loss": 0.1633,
      "step": 3550
    },
    {
      "epoch": 7.12,
      "grad_norm": 3.484734535217285,
      "learning_rate": 8.763636363636363e-05,
      "loss": 0.136,
      "step": 3560
    },
    {
      "epoch": 7.14,
      "grad_norm": 1.5392314195632935,
      "learning_rate": 8.703030303030301e-05,
      "loss": 0.1374,
      "step": 3570
    },
    {
      "epoch": 7.16,
      "grad_norm": 1.5709609985351562,
      "learning_rate": 8.642424242424242e-05,
      "loss": 0.1272,
      "step": 3580
    },
    {
      "epoch": 7.18,
      "grad_norm": 1.9344215393066406,
      "learning_rate": 8.581818181818182e-05,
      "loss": 0.1485,
      "step": 3590
    },
    {
      "epoch": 7.2,
      "grad_norm": 1.3260294198989868,
      "learning_rate": 8.52121212121212e-05,
      "loss": 0.1466,
      "step": 3600
    },
    {
      "epoch": 7.2,
      "eval_loss": 2.170623302459717,
      "eval_runtime": 8.3089,
      "eval_samples_per_second": 24.07,
      "eval_steps_per_second": 24.07,
      "step": 3600
    },
    {
      "epoch": 7.22,
      "grad_norm": 0.7782896161079407,
      "learning_rate": 8.46060606060606e-05,
      "loss": 0.1535,
      "step": 3610
    },
    {
      "epoch": 7.24,
      "grad_norm": 1.2580251693725586,
      "learning_rate": 8.4e-05,
      "loss": 0.182,
      "step": 3620
    },
    {
      "epoch": 7.26,
      "grad_norm": 1.2720444202423096,
      "learning_rate": 8.339393939393939e-05,
      "loss": 0.1279,
      "step": 3630
    },
    {
      "epoch": 7.28,
      "grad_norm": 0.8804038763046265,
      "learning_rate": 8.278787878787878e-05,
      "loss": 0.1224,
      "step": 3640
    },
    {
      "epoch": 7.3,
      "grad_norm": 1.2849749326705933,
      "learning_rate": 8.218181818181817e-05,
      "loss": 0.1458,
      "step": 3650
    },
    {
      "epoch": 7.32,
      "grad_norm": 1.4028499126434326,
      "learning_rate": 8.157575757575756e-05,
      "loss": 0.154,
      "step": 3660
    },
    {
      "epoch": 7.34,
      "grad_norm": 4.0326828956604,
      "learning_rate": 8.096969696969697e-05,
      "loss": 0.1648,
      "step": 3670
    },
    {
      "epoch": 7.36,
      "grad_norm": 2.7367825508117676,
      "learning_rate": 8.036363636363636e-05,
      "loss": 0.1556,
      "step": 3680
    },
    {
      "epoch": 7.38,
      "grad_norm": 1.2771904468536377,
      "learning_rate": 7.975757575757575e-05,
      "loss": 0.1485,
      "step": 3690
    },
    {
      "epoch": 7.4,
      "grad_norm": 1.1740891933441162,
      "learning_rate": 7.915151515151514e-05,
      "loss": 0.1372,
      "step": 3700
    },
    {
      "epoch": 7.4,
      "eval_loss": 2.2358896732330322,
      "eval_runtime": 8.3844,
      "eval_samples_per_second": 23.854,
      "eval_steps_per_second": 23.854,
      "step": 3700
    },
    {
      "epoch": 7.42,
      "grad_norm": 1.0006378889083862,
      "learning_rate": 7.854545454545454e-05,
      "loss": 0.1551,
      "step": 3710
    },
    {
      "epoch": 7.44,
      "grad_norm": 1.5537259578704834,
      "learning_rate": 7.793939393939394e-05,
      "loss": 0.1527,
      "step": 3720
    },
    {
      "epoch": 7.46,
      "grad_norm": 2.537116289138794,
      "learning_rate": 7.733333333333332e-05,
      "loss": 0.1372,
      "step": 3730
    },
    {
      "epoch": 7.48,
      "grad_norm": 7.523815155029297,
      "learning_rate": 7.672727272727272e-05,
      "loss": 0.1439,
      "step": 3740
    },
    {
      "epoch": 7.5,
      "grad_norm": 0.8186421394348145,
      "learning_rate": 7.612121212121213e-05,
      "loss": 0.1595,
      "step": 3750
    },
    {
      "epoch": 7.52,
      "grad_norm": 2.17948842048645,
      "learning_rate": 7.551515151515151e-05,
      "loss": 0.1518,
      "step": 3760
    },
    {
      "epoch": 7.54,
      "grad_norm": 3.4857230186462402,
      "learning_rate": 7.490909090909091e-05,
      "loss": 0.1712,
      "step": 3770
    },
    {
      "epoch": 7.5600000000000005,
      "grad_norm": 0.5907252430915833,
      "learning_rate": 7.43030303030303e-05,
      "loss": 0.1207,
      "step": 3780
    },
    {
      "epoch": 7.58,
      "grad_norm": 2.3993024826049805,
      "learning_rate": 7.369696969696969e-05,
      "loss": 0.1881,
      "step": 3790
    },
    {
      "epoch": 7.6,
      "grad_norm": 0.9393740892410278,
      "learning_rate": 7.309090909090908e-05,
      "loss": 0.136,
      "step": 3800
    },
    {
      "epoch": 7.6,
      "eval_loss": 2.1866235733032227,
      "eval_runtime": 8.3707,
      "eval_samples_per_second": 23.893,
      "eval_steps_per_second": 23.893,
      "step": 3800
    },
    {
      "epoch": 7.62,
      "grad_norm": 0.765025794506073,
      "learning_rate": 7.248484848484848e-05,
      "loss": 0.1534,
      "step": 3810
    },
    {
      "epoch": 7.64,
      "grad_norm": 7.033634662628174,
      "learning_rate": 7.187878787878786e-05,
      "loss": 0.1393,
      "step": 3820
    },
    {
      "epoch": 7.66,
      "grad_norm": 0.7442662119865417,
      "learning_rate": 7.127272727272726e-05,
      "loss": 0.1272,
      "step": 3830
    },
    {
      "epoch": 7.68,
      "grad_norm": 1.1034499406814575,
      "learning_rate": 7.066666666666666e-05,
      "loss": 0.1639,
      "step": 3840
    },
    {
      "epoch": 7.7,
      "grad_norm": 1.344477653503418,
      "learning_rate": 7.006060606060606e-05,
      "loss": 0.1617,
      "step": 3850
    },
    {
      "epoch": 7.72,
      "grad_norm": 3.740795850753784,
      "learning_rate": 6.945454545454545e-05,
      "loss": 0.1588,
      "step": 3860
    },
    {
      "epoch": 7.74,
      "grad_norm": 2.5955002307891846,
      "learning_rate": 6.884848484848485e-05,
      "loss": 0.1617,
      "step": 3870
    },
    {
      "epoch": 7.76,
      "grad_norm": 0.7907953858375549,
      "learning_rate": 6.824242424242423e-05,
      "loss": 0.1372,
      "step": 3880
    },
    {
      "epoch": 7.78,
      "grad_norm": 1.3214091062545776,
      "learning_rate": 6.763636363636363e-05,
      "loss": 0.1424,
      "step": 3890
    },
    {
      "epoch": 7.8,
      "grad_norm": 1.0429590940475464,
      "learning_rate": 6.703030303030303e-05,
      "loss": 0.1527,
      "step": 3900
    },
    {
      "epoch": 7.8,
      "eval_loss": 2.133718252182007,
      "eval_runtime": 8.3332,
      "eval_samples_per_second": 24.0,
      "eval_steps_per_second": 24.0,
      "step": 3900
    },
    {
      "epoch": 7.82,
      "grad_norm": 0.8164121508598328,
      "learning_rate": 6.642424242424242e-05,
      "loss": 0.1464,
      "step": 3910
    },
    {
      "epoch": 7.84,
      "grad_norm": 0.8840284943580627,
      "learning_rate": 6.58181818181818e-05,
      "loss": 0.171,
      "step": 3920
    },
    {
      "epoch": 7.86,
      "grad_norm": 2.8397815227508545,
      "learning_rate": 6.52121212121212e-05,
      "loss": 0.1685,
      "step": 3930
    },
    {
      "epoch": 7.88,
      "grad_norm": 7.160091400146484,
      "learning_rate": 6.46060606060606e-05,
      "loss": 0.1622,
      "step": 3940
    },
    {
      "epoch": 7.9,
      "grad_norm": 1.332266092300415,
      "learning_rate": 6.4e-05,
      "loss": 0.1416,
      "step": 3950
    },
    {
      "epoch": 7.92,
      "grad_norm": 1.4176545143127441,
      "learning_rate": 6.33939393939394e-05,
      "loss": 0.1773,
      "step": 3960
    },
    {
      "epoch": 7.9399999999999995,
      "grad_norm": 1.4311662912368774,
      "learning_rate": 6.278787878787878e-05,
      "loss": 0.1605,
      "step": 3970
    },
    {
      "epoch": 7.96,
      "grad_norm": 1.3712586164474487,
      "learning_rate": 6.218181818181817e-05,
      "loss": 0.1307,
      "step": 3980
    },
    {
      "epoch": 7.98,
      "grad_norm": 1.5995491743087769,
      "learning_rate": 6.157575757575757e-05,
      "loss": 0.1456,
      "step": 3990
    },
    {
      "epoch": 8.0,
      "grad_norm": 1.2908354997634888,
      "learning_rate": 6.096969696969697e-05,
      "loss": 0.1547,
      "step": 4000
    },
    {
      "epoch": 8.0,
      "eval_loss": 2.1539711952209473,
      "eval_runtime": 8.3525,
      "eval_samples_per_second": 23.945,
      "eval_steps_per_second": 23.945,
      "step": 4000
    },
    {
      "epoch": 8.02,
      "grad_norm": 0.9069127440452576,
      "learning_rate": 6.036363636363636e-05,
      "loss": 0.1149,
      "step": 4010
    },
    {
      "epoch": 8.04,
      "grad_norm": 1.683788776397705,
      "learning_rate": 5.9757575757575755e-05,
      "loss": 0.1176,
      "step": 4020
    },
    {
      "epoch": 8.06,
      "grad_norm": 1.1601463556289673,
      "learning_rate": 5.9151515151515145e-05,
      "loss": 0.1058,
      "step": 4030
    },
    {
      "epoch": 8.08,
      "grad_norm": 2.2765614986419678,
      "learning_rate": 5.854545454545454e-05,
      "loss": 0.1136,
      "step": 4040
    },
    {
      "epoch": 8.1,
      "grad_norm": 1.003087043762207,
      "learning_rate": 5.793939393939393e-05,
      "loss": 0.1271,
      "step": 4050
    },
    {
      "epoch": 8.12,
      "grad_norm": 1.154079556465149,
      "learning_rate": 5.733333333333333e-05,
      "loss": 0.1093,
      "step": 4060
    },
    {
      "epoch": 8.14,
      "grad_norm": 1.344069004058838,
      "learning_rate": 5.672727272727272e-05,
      "loss": 0.1703,
      "step": 4070
    },
    {
      "epoch": 8.16,
      "grad_norm": 8.300930976867676,
      "learning_rate": 5.612121212121212e-05,
      "loss": 0.1196,
      "step": 4080
    },
    {
      "epoch": 8.18,
      "grad_norm": 2.906099319458008,
      "learning_rate": 5.551515151515151e-05,
      "loss": 0.1065,
      "step": 4090
    },
    {
      "epoch": 8.2,
      "grad_norm": 0.7353864908218384,
      "learning_rate": 5.490909090909091e-05,
      "loss": 0.1089,
      "step": 4100
    },
    {
      "epoch": 8.2,
      "eval_loss": 2.332538366317749,
      "eval_runtime": 8.4157,
      "eval_samples_per_second": 23.765,
      "eval_steps_per_second": 23.765,
      "step": 4100
    },
    {
      "epoch": 8.22,
      "grad_norm": 2.632004976272583,
      "learning_rate": 5.43030303030303e-05,
      "loss": 0.1248,
      "step": 4110
    },
    {
      "epoch": 8.24,
      "grad_norm": 0.9110327959060669,
      "learning_rate": 5.369696969696969e-05,
      "loss": 0.132,
      "step": 4120
    },
    {
      "epoch": 8.26,
      "grad_norm": 2.805908203125,
      "learning_rate": 5.3090909090909087e-05,
      "loss": 0.1118,
      "step": 4130
    },
    {
      "epoch": 8.28,
      "grad_norm": 2.1057779788970947,
      "learning_rate": 5.2484848484848477e-05,
      "loss": 0.1247,
      "step": 4140
    },
    {
      "epoch": 8.3,
      "grad_norm": 3.940139055252075,
      "learning_rate": 5.1878787878787873e-05,
      "loss": 0.1487,
      "step": 4150
    },
    {
      "epoch": 8.32,
      "grad_norm": 4.136137962341309,
      "learning_rate": 5.1272727272727264e-05,
      "loss": 0.1253,
      "step": 4160
    },
    {
      "epoch": 8.34,
      "grad_norm": 3.0225677490234375,
      "learning_rate": 5.066666666666666e-05,
      "loss": 0.1389,
      "step": 4170
    },
    {
      "epoch": 8.36,
      "grad_norm": 1.1279953718185425,
      "learning_rate": 5.006060606060605e-05,
      "loss": 0.1252,
      "step": 4180
    },
    {
      "epoch": 8.38,
      "grad_norm": 4.340667247772217,
      "learning_rate": 4.9454545454545454e-05,
      "loss": 0.1402,
      "step": 4190
    },
    {
      "epoch": 8.4,
      "grad_norm": 1.1530883312225342,
      "learning_rate": 4.8848484848484844e-05,
      "loss": 0.1266,
      "step": 4200
    },
    {
      "epoch": 8.4,
      "eval_loss": 2.242238759994507,
      "eval_runtime": 8.395,
      "eval_samples_per_second": 23.824,
      "eval_steps_per_second": 23.824,
      "step": 4200
    },
    {
      "epoch": 8.42,
      "grad_norm": 0.6578046083450317,
      "learning_rate": 4.824242424242424e-05,
      "loss": 0.1302,
      "step": 4210
    },
    {
      "epoch": 8.44,
      "grad_norm": 0.6030781865119934,
      "learning_rate": 4.763636363636363e-05,
      "loss": 0.1345,
      "step": 4220
    },
    {
      "epoch": 8.46,
      "grad_norm": 0.9312596917152405,
      "learning_rate": 4.703030303030303e-05,
      "loss": 0.1253,
      "step": 4230
    },
    {
      "epoch": 8.48,
      "grad_norm": 1.9719610214233398,
      "learning_rate": 4.642424242424242e-05,
      "loss": 0.1197,
      "step": 4240
    },
    {
      "epoch": 8.5,
      "grad_norm": 4.914233684539795,
      "learning_rate": 4.5818181818181815e-05,
      "loss": 0.1405,
      "step": 4250
    },
    {
      "epoch": 8.52,
      "grad_norm": 0.7935662269592285,
      "learning_rate": 4.5212121212121205e-05,
      "loss": 0.1228,
      "step": 4260
    },
    {
      "epoch": 8.54,
      "grad_norm": 1.8226215839385986,
      "learning_rate": 4.460606060606061e-05,
      "loss": 0.1518,
      "step": 4270
    },
    {
      "epoch": 8.56,
      "grad_norm": 1.9397064447402954,
      "learning_rate": 4.4e-05,
      "loss": 0.1218,
      "step": 4280
    },
    {
      "epoch": 8.58,
      "grad_norm": 2.3194358348846436,
      "learning_rate": 4.339393939393939e-05,
      "loss": 0.1267,
      "step": 4290
    },
    {
      "epoch": 8.6,
      "grad_norm": 0.6734846234321594,
      "learning_rate": 4.2787878787878786e-05,
      "loss": 0.1148,
      "step": 4300
    },
    {
      "epoch": 8.6,
      "eval_loss": 2.2701125144958496,
      "eval_runtime": 8.3491,
      "eval_samples_per_second": 23.955,
      "eval_steps_per_second": 23.955,
      "step": 4300
    },
    {
      "epoch": 8.62,
      "grad_norm": 4.268064975738525,
      "learning_rate": 4.2181818181818176e-05,
      "loss": 0.1387,
      "step": 4310
    },
    {
      "epoch": 8.64,
      "grad_norm": 0.9926906824111938,
      "learning_rate": 4.157575757575757e-05,
      "loss": 0.134,
      "step": 4320
    },
    {
      "epoch": 8.66,
      "grad_norm": 1.8623493909835815,
      "learning_rate": 4.096969696969696e-05,
      "loss": 0.1259,
      "step": 4330
    },
    {
      "epoch": 8.68,
      "grad_norm": 1.3102995157241821,
      "learning_rate": 4.036363636363636e-05,
      "loss": 0.1153,
      "step": 4340
    },
    {
      "epoch": 8.7,
      "grad_norm": 0.7363973259925842,
      "learning_rate": 3.975757575757575e-05,
      "loss": 0.1434,
      "step": 4350
    },
    {
      "epoch": 8.72,
      "grad_norm": 1.8150554895401,
      "learning_rate": 3.9151515151515153e-05,
      "loss": 0.1319,
      "step": 4360
    },
    {
      "epoch": 8.74,
      "grad_norm": 1.8771672248840332,
      "learning_rate": 3.8545454545454544e-05,
      "loss": 0.1236,
      "step": 4370
    },
    {
      "epoch": 8.76,
      "grad_norm": 3.3735721111297607,
      "learning_rate": 3.793939393939394e-05,
      "loss": 0.1264,
      "step": 4380
    },
    {
      "epoch": 8.78,
      "grad_norm": 0.8260700106620789,
      "learning_rate": 3.733333333333333e-05,
      "loss": 0.146,
      "step": 4390
    },
    {
      "epoch": 8.8,
      "grad_norm": 16.77468490600586,
      "learning_rate": 3.672727272727272e-05,
      "loss": 0.1263,
      "step": 4400
    },
    {
      "epoch": 8.8,
      "eval_loss": 2.299602508544922,
      "eval_runtime": 8.3258,
      "eval_samples_per_second": 24.022,
      "eval_steps_per_second": 24.022,
      "step": 4400
    },
    {
      "epoch": 8.82,
      "grad_norm": 0.8239622116088867,
      "learning_rate": 3.612121212121212e-05,
      "loss": 0.1333,
      "step": 4410
    },
    {
      "epoch": 8.84,
      "grad_norm": 1.0313109159469604,
      "learning_rate": 3.5515151515151514e-05,
      "loss": 0.1351,
      "step": 4420
    },
    {
      "epoch": 8.86,
      "grad_norm": 1.6262106895446777,
      "learning_rate": 3.4909090909090904e-05,
      "loss": 0.13,
      "step": 4430
    },
    {
      "epoch": 8.88,
      "grad_norm": 0.539080798625946,
      "learning_rate": 3.43030303030303e-05,
      "loss": 0.1278,
      "step": 4440
    },
    {
      "epoch": 8.9,
      "grad_norm": 3.2214128971099854,
      "learning_rate": 3.369696969696969e-05,
      "loss": 0.124,
      "step": 4450
    },
    {
      "epoch": 8.92,
      "grad_norm": 1.3611174821853638,
      "learning_rate": 3.309090909090909e-05,
      "loss": 0.1213,
      "step": 4460
    },
    {
      "epoch": 8.94,
      "grad_norm": 1.873512864112854,
      "learning_rate": 3.2484848484848485e-05,
      "loss": 0.1304,
      "step": 4470
    },
    {
      "epoch": 8.96,
      "grad_norm": 1.1163207292556763,
      "learning_rate": 3.1878787878787875e-05,
      "loss": 0.1265,
      "step": 4480
    },
    {
      "epoch": 8.98,
      "grad_norm": 2.110534429550171,
      "learning_rate": 3.127272727272727e-05,
      "loss": 0.125,
      "step": 4490
    },
    {
      "epoch": 9.0,
      "grad_norm": 1.3713157176971436,
      "learning_rate": 3.066666666666667e-05,
      "loss": 0.1225,
      "step": 4500
    },
    {
      "epoch": 9.0,
      "eval_loss": 2.294174909591675,
      "eval_runtime": 8.414,
      "eval_samples_per_second": 23.77,
      "eval_steps_per_second": 23.77,
      "step": 4500
    },
    {
      "epoch": 9.02,
      "grad_norm": 1.1462863683700562,
      "learning_rate": 3.006060606060606e-05,
      "loss": 0.1191,
      "step": 4510
    },
    {
      "epoch": 9.04,
      "grad_norm": 0.8981087803840637,
      "learning_rate": 2.945454545454545e-05,
      "loss": 0.1076,
      "step": 4520
    },
    {
      "epoch": 9.06,
      "grad_norm": 1.654943585395813,
      "learning_rate": 2.8848484848484846e-05,
      "loss": 0.1166,
      "step": 4530
    },
    {
      "epoch": 9.08,
      "grad_norm": 0.5021364092826843,
      "learning_rate": 2.824242424242424e-05,
      "loss": 0.106,
      "step": 4540
    },
    {
      "epoch": 9.1,
      "grad_norm": 1.0764827728271484,
      "learning_rate": 2.7636363636363633e-05,
      "loss": 0.1163,
      "step": 4550
    },
    {
      "epoch": 9.12,
      "grad_norm": 0.6175435781478882,
      "learning_rate": 2.7030303030303026e-05,
      "loss": 0.1024,
      "step": 4560
    },
    {
      "epoch": 9.14,
      "grad_norm": 1.773941159248352,
      "learning_rate": 2.642424242424242e-05,
      "loss": 0.123,
      "step": 4570
    },
    {
      "epoch": 9.16,
      "grad_norm": 0.923073410987854,
      "learning_rate": 2.5818181818181817e-05,
      "loss": 0.1067,
      "step": 4580
    },
    {
      "epoch": 9.18,
      "grad_norm": 0.815702497959137,
      "learning_rate": 2.521212121212121e-05,
      "loss": 0.1031,
      "step": 4590
    },
    {
      "epoch": 9.2,
      "grad_norm": 0.6653199195861816,
      "learning_rate": 2.4606060606060604e-05,
      "loss": 0.1161,
      "step": 4600
    },
    {
      "epoch": 9.2,
      "eval_loss": 2.422408103942871,
      "eval_runtime": 8.3409,
      "eval_samples_per_second": 23.978,
      "eval_steps_per_second": 23.978,
      "step": 4600
    },
    {
      "epoch": 9.22,
      "grad_norm": 2.135214328765869,
      "learning_rate": 2.3999999999999997e-05,
      "loss": 0.1141,
      "step": 4610
    },
    {
      "epoch": 9.24,
      "grad_norm": 2.0416741371154785,
      "learning_rate": 2.3393939393939394e-05,
      "loss": 0.1157,
      "step": 4620
    },
    {
      "epoch": 9.26,
      "grad_norm": 1.5380804538726807,
      "learning_rate": 2.2787878787878788e-05,
      "loss": 0.1494,
      "step": 4630
    },
    {
      "epoch": 9.28,
      "grad_norm": 0.9661366939544678,
      "learning_rate": 2.218181818181818e-05,
      "loss": 0.1162,
      "step": 4640
    },
    {
      "epoch": 9.3,
      "grad_norm": 0.9745144844055176,
      "learning_rate": 2.1575757575757575e-05,
      "loss": 0.1193,
      "step": 4650
    },
    {
      "epoch": 9.32,
      "grad_norm": 2.114941120147705,
      "learning_rate": 2.0969696969696968e-05,
      "loss": 0.1078,
      "step": 4660
    },
    {
      "epoch": 9.34,
      "grad_norm": 2.4232420921325684,
      "learning_rate": 2.0363636363636365e-05,
      "loss": 0.1156,
      "step": 4670
    },
    {
      "epoch": 9.36,
      "grad_norm": 0.7641554474830627,
      "learning_rate": 1.9757575757575755e-05,
      "loss": 0.1042,
      "step": 4680
    },
    {
      "epoch": 9.38,
      "grad_norm": 1.242874264717102,
      "learning_rate": 1.915151515151515e-05,
      "loss": 0.1065,
      "step": 4690
    },
    {
      "epoch": 9.4,
      "grad_norm": 0.6047442555427551,
      "learning_rate": 1.8545454545454545e-05,
      "loss": 0.1141,
      "step": 4700
    },
    {
      "epoch": 9.4,
      "eval_loss": 2.411966323852539,
      "eval_runtime": 8.3915,
      "eval_samples_per_second": 23.834,
      "eval_steps_per_second": 23.834,
      "step": 4700
    },
    {
      "epoch": 9.42,
      "grad_norm": 1.1361521482467651,
      "learning_rate": 1.793939393939394e-05,
      "loss": 0.1105,
      "step": 4710
    },
    {
      "epoch": 9.44,
      "grad_norm": 0.9537219405174255,
      "learning_rate": 1.7333333333333332e-05,
      "loss": 0.1218,
      "step": 4720
    },
    {
      "epoch": 9.46,
      "grad_norm": 1.7590223550796509,
      "learning_rate": 1.6727272727272726e-05,
      "loss": 0.1092,
      "step": 4730
    },
    {
      "epoch": 9.48,
      "grad_norm": 1.1048344373703003,
      "learning_rate": 1.612121212121212e-05,
      "loss": 0.1065,
      "step": 4740
    },
    {
      "epoch": 9.5,
      "grad_norm": 1.1382333040237427,
      "learning_rate": 1.5515151515151513e-05,
      "loss": 0.1207,
      "step": 4750
    },
    {
      "epoch": 9.52,
      "grad_norm": 1.0555839538574219,
      "learning_rate": 1.4909090909090908e-05,
      "loss": 0.1011,
      "step": 4760
    },
    {
      "epoch": 9.54,
      "grad_norm": 0.988523006439209,
      "learning_rate": 1.4303030303030303e-05,
      "loss": 0.108,
      "step": 4770
    },
    {
      "epoch": 9.56,
      "grad_norm": 1.3466218709945679,
      "learning_rate": 1.3696969696969697e-05,
      "loss": 0.1152,
      "step": 4780
    },
    {
      "epoch": 9.58,
      "grad_norm": 1.3217039108276367,
      "learning_rate": 1.309090909090909e-05,
      "loss": 0.1018,
      "step": 4790
    },
    {
      "epoch": 9.6,
      "grad_norm": 1.7333111763000488,
      "learning_rate": 1.2484848484848483e-05,
      "loss": 0.1167,
      "step": 4800
    },
    {
      "epoch": 9.6,
      "eval_loss": 2.4003500938415527,
      "eval_runtime": 8.3445,
      "eval_samples_per_second": 23.968,
      "eval_steps_per_second": 23.968,
      "step": 4800
    },
    {
      "epoch": 9.62,
      "grad_norm": 1.7803468704223633,
      "learning_rate": 1.1878787878787877e-05,
      "loss": 0.1084,
      "step": 4810
    },
    {
      "epoch": 9.64,
      "grad_norm": 1.3324018716812134,
      "learning_rate": 1.1272727272727272e-05,
      "loss": 0.1076,
      "step": 4820
    },
    {
      "epoch": 9.66,
      "grad_norm": 0.8503245115280151,
      "learning_rate": 1.0666666666666666e-05,
      "loss": 0.1226,
      "step": 4830
    },
    {
      "epoch": 9.68,
      "grad_norm": 1.6170461177825928,
      "learning_rate": 1.006060606060606e-05,
      "loss": 0.1108,
      "step": 4840
    },
    {
      "epoch": 9.7,
      "grad_norm": 0.5847713351249695,
      "learning_rate": 9.454545454545454e-06,
      "loss": 0.1237,
      "step": 4850
    },
    {
      "epoch": 9.72,
      "grad_norm": 1.7748302221298218,
      "learning_rate": 8.848484848484848e-06,
      "loss": 0.1066,
      "step": 4860
    },
    {
      "epoch": 9.74,
      "grad_norm": 0.833016574382782,
      "learning_rate": 8.242424242424241e-06,
      "loss": 0.1197,
      "step": 4870
    },
    {
      "epoch": 9.76,
      "grad_norm": 1.4179149866104126,
      "learning_rate": 7.636363636363636e-06,
      "loss": 0.1,
      "step": 4880
    },
    {
      "epoch": 9.78,
      "grad_norm": 0.8852043747901917,
      "learning_rate": 7.03030303030303e-06,
      "loss": 0.1087,
      "step": 4890
    },
    {
      "epoch": 9.8,
      "grad_norm": 2.6731393337249756,
      "learning_rate": 6.424242424242423e-06,
      "loss": 0.1156,
      "step": 4900
    },
    {
      "epoch": 9.8,
      "eval_loss": 2.3814001083374023,
      "eval_runtime": 8.3104,
      "eval_samples_per_second": 24.066,
      "eval_steps_per_second": 24.066,
      "step": 4900
    },
    {
      "epoch": 9.82,
      "grad_norm": 0.8375221490859985,
      "learning_rate": 5.818181818181818e-06,
      "loss": 0.1043,
      "step": 4910
    },
    {
      "epoch": 9.84,
      "grad_norm": 0.9600119590759277,
      "learning_rate": 5.212121212121212e-06,
      "loss": 0.1082,
      "step": 4920
    },
    {
      "epoch": 9.86,
      "grad_norm": 0.5058053731918335,
      "learning_rate": 4.6060606060606055e-06,
      "loss": 0.1073,
      "step": 4930
    },
    {
      "epoch": 9.88,
      "grad_norm": 1.3137202262878418,
      "learning_rate": 4e-06,
      "loss": 0.1042,
      "step": 4940
    },
    {
      "epoch": 9.9,
      "grad_norm": 2.2903382778167725,
      "learning_rate": 3.3939393939393937e-06,
      "loss": 0.1307,
      "step": 4950
    },
    {
      "epoch": 9.92,
      "grad_norm": 0.5193279385566711,
      "learning_rate": 2.787878787878788e-06,
      "loss": 0.1146,
      "step": 4960
    },
    {
      "epoch": 9.94,
      "grad_norm": 0.47676318883895874,
      "learning_rate": 2.1818181818181815e-06,
      "loss": 0.1133,
      "step": 4970
    },
    {
      "epoch": 9.96,
      "grad_norm": 3.3035171031951904,
      "learning_rate": 1.5757575757575756e-06,
      "loss": 0.1072,
      "step": 4980
    },
    {
      "epoch": 9.98,
      "grad_norm": 2.1296937465667725,
      "learning_rate": 9.696969696969695e-07,
      "loss": 0.1137,
      "step": 4990
    },
    {
      "epoch": 10.0,
      "grad_norm": 1.2600370645523071,
      "learning_rate": 3.636363636363636e-07,
      "loss": 0.1099,
      "step": 5000
    },
    {
      "epoch": 10.0,
      "eval_loss": 2.3808581829071045,
      "eval_runtime": 8.4321,
      "eval_samples_per_second": 23.719,
      "eval_steps_per_second": 23.719,
      "step": 5000
    }
  ],
  "logging_steps": 10,
  "max_steps": 5000,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 10,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 1.496916688896e+16,
  "train_batch_size": 1,
  "trial_name": null,
  "trial_params": null
}

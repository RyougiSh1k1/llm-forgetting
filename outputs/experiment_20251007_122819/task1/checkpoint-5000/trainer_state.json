{
  "best_global_step": null,
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 10.0,
  "eval_steps": 100,
  "global_step": 5000,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.02,
      "grad_norm": 2.552588939666748,
      "learning_rate": 4.2e-05,
      "loss": 2.6039,
      "step": 10
    },
    {
      "epoch": 0.04,
      "grad_norm": 5.177523612976074,
      "learning_rate": 0.000102,
      "loss": 2.3963,
      "step": 20
    },
    {
      "epoch": 0.06,
      "grad_norm": 3.5246033668518066,
      "learning_rate": 0.000162,
      "loss": 1.8392,
      "step": 30
    },
    {
      "epoch": 0.08,
      "grad_norm": 3.855795383453369,
      "learning_rate": 0.00022199999999999998,
      "loss": 1.4579,
      "step": 40
    },
    {
      "epoch": 0.1,
      "grad_norm": 4.360617637634277,
      "learning_rate": 0.00028199999999999997,
      "loss": 1.4165,
      "step": 50
    },
    {
      "epoch": 0.12,
      "grad_norm": 7.275245189666748,
      "learning_rate": 0.00029957575757575756,
      "loss": 1.2205,
      "step": 60
    },
    {
      "epoch": 0.14,
      "grad_norm": 3.530540943145752,
      "learning_rate": 0.0002989696969696969,
      "loss": 1.2814,
      "step": 70
    },
    {
      "epoch": 0.16,
      "grad_norm": 9.55571174621582,
      "learning_rate": 0.0002983636363636363,
      "loss": 1.0517,
      "step": 80
    },
    {
      "epoch": 0.18,
      "grad_norm": 3.098482847213745,
      "learning_rate": 0.00029775757575757573,
      "loss": 1.174,
      "step": 90
    },
    {
      "epoch": 0.2,
      "grad_norm": 3.5745654106140137,
      "learning_rate": 0.00029715151515151514,
      "loss": 1.2695,
      "step": 100
    },
    {
      "epoch": 0.2,
      "eval_loss": 1.1434568166732788,
      "eval_runtime": 8.8299,
      "eval_samples_per_second": 22.65,
      "eval_steps_per_second": 22.65,
      "step": 100
    },
    {
      "epoch": 0.22,
      "grad_norm": 3.2430999279022217,
      "learning_rate": 0.00029654545454545455,
      "loss": 1.1264,
      "step": 110
    },
    {
      "epoch": 0.24,
      "grad_norm": 5.493202209472656,
      "learning_rate": 0.0002959393939393939,
      "loss": 0.9481,
      "step": 120
    },
    {
      "epoch": 0.26,
      "grad_norm": 3.3505873680114746,
      "learning_rate": 0.0002953333333333333,
      "loss": 1.3662,
      "step": 130
    },
    {
      "epoch": 0.28,
      "grad_norm": 2.826258659362793,
      "learning_rate": 0.0002947272727272727,
      "loss": 1.2685,
      "step": 140
    },
    {
      "epoch": 0.3,
      "grad_norm": 2.7151267528533936,
      "learning_rate": 0.0002941212121212121,
      "loss": 0.7756,
      "step": 150
    },
    {
      "epoch": 0.32,
      "grad_norm": 3.0434410572052,
      "learning_rate": 0.0002935151515151515,
      "loss": 0.8538,
      "step": 160
    },
    {
      "epoch": 0.34,
      "grad_norm": 7.739200592041016,
      "learning_rate": 0.00029290909090909085,
      "loss": 1.0637,
      "step": 170
    },
    {
      "epoch": 0.36,
      "grad_norm": 5.236054420471191,
      "learning_rate": 0.00029236363636363634,
      "loss": 1.2533,
      "step": 180
    },
    {
      "epoch": 0.38,
      "grad_norm": 1.8804144859313965,
      "learning_rate": 0.00029175757575757575,
      "loss": 1.1005,
      "step": 190
    },
    {
      "epoch": 0.4,
      "grad_norm": 4.36322021484375,
      "learning_rate": 0.00029115151515151516,
      "loss": 0.8653,
      "step": 200
    },
    {
      "epoch": 0.4,
      "eval_loss": 0.9382989406585693,
      "eval_runtime": 8.6547,
      "eval_samples_per_second": 23.109,
      "eval_steps_per_second": 23.109,
      "step": 200
    },
    {
      "epoch": 0.42,
      "grad_norm": 3.9669454097747803,
      "learning_rate": 0.0002905454545454545,
      "loss": 0.7422,
      "step": 210
    },
    {
      "epoch": 0.44,
      "grad_norm": 2.6371772289276123,
      "learning_rate": 0.0002899393939393939,
      "loss": 0.9826,
      "step": 220
    },
    {
      "epoch": 0.46,
      "grad_norm": 4.538693904876709,
      "learning_rate": 0.0002893333333333333,
      "loss": 0.8536,
      "step": 230
    },
    {
      "epoch": 0.48,
      "grad_norm": 2.381157636642456,
      "learning_rate": 0.0002887272727272727,
      "loss": 0.7727,
      "step": 240
    },
    {
      "epoch": 0.5,
      "grad_norm": 4.652095317840576,
      "learning_rate": 0.0002881212121212121,
      "loss": 0.91,
      "step": 250
    },
    {
      "epoch": 0.52,
      "grad_norm": 6.077571868896484,
      "learning_rate": 0.00028751515151515146,
      "loss": 0.883,
      "step": 260
    },
    {
      "epoch": 0.54,
      "grad_norm": 3.7622323036193848,
      "learning_rate": 0.0002869090909090909,
      "loss": 0.9736,
      "step": 270
    },
    {
      "epoch": 0.56,
      "grad_norm": 3.567901849746704,
      "learning_rate": 0.0002863030303030303,
      "loss": 1.0421,
      "step": 280
    },
    {
      "epoch": 0.58,
      "grad_norm": 6.364538669586182,
      "learning_rate": 0.0002856969696969697,
      "loss": 0.9049,
      "step": 290
    },
    {
      "epoch": 0.6,
      "grad_norm": 2.757753610610962,
      "learning_rate": 0.00028509090909090905,
      "loss": 0.7896,
      "step": 300
    },
    {
      "epoch": 0.6,
      "eval_loss": 0.8902467489242554,
      "eval_runtime": 8.2962,
      "eval_samples_per_second": 24.107,
      "eval_steps_per_second": 24.107,
      "step": 300
    },
    {
      "epoch": 0.62,
      "grad_norm": 3.8358123302459717,
      "learning_rate": 0.00028448484848484846,
      "loss": 1.0688,
      "step": 310
    },
    {
      "epoch": 0.64,
      "grad_norm": 6.662502288818359,
      "learning_rate": 0.00028387878787878787,
      "loss": 0.5881,
      "step": 320
    },
    {
      "epoch": 0.66,
      "grad_norm": 2.892827272415161,
      "learning_rate": 0.0002832727272727272,
      "loss": 0.6969,
      "step": 330
    },
    {
      "epoch": 0.68,
      "grad_norm": 1.9665758609771729,
      "learning_rate": 0.00028266666666666663,
      "loss": 1.0363,
      "step": 340
    },
    {
      "epoch": 0.7,
      "grad_norm": 1.760146975517273,
      "learning_rate": 0.00028206060606060605,
      "loss": 0.8651,
      "step": 350
    },
    {
      "epoch": 0.72,
      "grad_norm": 4.957758903503418,
      "learning_rate": 0.00028145454545454546,
      "loss": 0.8357,
      "step": 360
    },
    {
      "epoch": 0.74,
      "grad_norm": 2.7467546463012695,
      "learning_rate": 0.0002808484848484848,
      "loss": 0.8582,
      "step": 370
    },
    {
      "epoch": 0.76,
      "grad_norm": 3.361635446548462,
      "learning_rate": 0.0002802424242424242,
      "loss": 0.867,
      "step": 380
    },
    {
      "epoch": 0.78,
      "grad_norm": 2.7596116065979004,
      "learning_rate": 0.00027963636363636363,
      "loss": 0.6694,
      "step": 390
    },
    {
      "epoch": 0.8,
      "grad_norm": 11.626940727233887,
      "learning_rate": 0.000279030303030303,
      "loss": 0.7751,
      "step": 400
    },
    {
      "epoch": 0.8,
      "eval_loss": 0.8870335221290588,
      "eval_runtime": 8.6121,
      "eval_samples_per_second": 23.223,
      "eval_steps_per_second": 23.223,
      "step": 400
    },
    {
      "epoch": 0.82,
      "grad_norm": 3.004857063293457,
      "learning_rate": 0.0002784242424242424,
      "loss": 1.1272,
      "step": 410
    },
    {
      "epoch": 0.84,
      "grad_norm": 5.691037654876709,
      "learning_rate": 0.0002778181818181818,
      "loss": 0.802,
      "step": 420
    },
    {
      "epoch": 0.86,
      "grad_norm": 2.0191595554351807,
      "learning_rate": 0.00027721212121212117,
      "loss": 0.6967,
      "step": 430
    },
    {
      "epoch": 0.88,
      "grad_norm": 4.0683088302612305,
      "learning_rate": 0.0002766060606060606,
      "loss": 0.7017,
      "step": 440
    },
    {
      "epoch": 0.9,
      "grad_norm": 3.0711467266082764,
      "learning_rate": 0.000276,
      "loss": 0.7424,
      "step": 450
    },
    {
      "epoch": 0.92,
      "grad_norm": 3.1300764083862305,
      "learning_rate": 0.0002753939393939394,
      "loss": 1.0116,
      "step": 460
    },
    {
      "epoch": 0.94,
      "grad_norm": 2.910768747329712,
      "learning_rate": 0.00027478787878787875,
      "loss": 0.7073,
      "step": 470
    },
    {
      "epoch": 0.96,
      "grad_norm": 2.018134355545044,
      "learning_rate": 0.00027418181818181816,
      "loss": 0.8817,
      "step": 480
    },
    {
      "epoch": 0.98,
      "grad_norm": 1.6728620529174805,
      "learning_rate": 0.0002735757575757576,
      "loss": 0.9847,
      "step": 490
    },
    {
      "epoch": 1.0,
      "grad_norm": 6.5805253982543945,
      "learning_rate": 0.00027296969696969693,
      "loss": 0.7944,
      "step": 500
    },
    {
      "epoch": 1.0,
      "eval_loss": 0.8657165765762329,
      "eval_runtime": 8.8081,
      "eval_samples_per_second": 22.706,
      "eval_steps_per_second": 22.706,
      "step": 500
    },
    {
      "epoch": 1.02,
      "grad_norm": 5.448640823364258,
      "learning_rate": 0.00027236363636363634,
      "loss": 0.8046,
      "step": 510
    },
    {
      "epoch": 1.04,
      "grad_norm": 4.27337121963501,
      "learning_rate": 0.0002717575757575757,
      "loss": 0.7238,
      "step": 520
    },
    {
      "epoch": 1.06,
      "grad_norm": 2.0952017307281494,
      "learning_rate": 0.00027115151515151516,
      "loss": 0.5573,
      "step": 530
    },
    {
      "epoch": 1.08,
      "grad_norm": 3.1000328063964844,
      "learning_rate": 0.0002705454545454545,
      "loss": 0.7393,
      "step": 540
    },
    {
      "epoch": 1.1,
      "grad_norm": 2.1409971714019775,
      "learning_rate": 0.00026993939393939393,
      "loss": 0.5809,
      "step": 550
    },
    {
      "epoch": 1.12,
      "grad_norm": 2.800039291381836,
      "learning_rate": 0.00026933333333333334,
      "loss": 0.6879,
      "step": 560
    },
    {
      "epoch": 1.1400000000000001,
      "grad_norm": 6.544110298156738,
      "learning_rate": 0.0002687272727272727,
      "loss": 0.6101,
      "step": 570
    },
    {
      "epoch": 1.16,
      "grad_norm": 4.40684175491333,
      "learning_rate": 0.0002681212121212121,
      "loss": 0.8787,
      "step": 580
    },
    {
      "epoch": 1.18,
      "grad_norm": 2.1293253898620605,
      "learning_rate": 0.00026751515151515146,
      "loss": 0.6412,
      "step": 590
    },
    {
      "epoch": 1.2,
      "grad_norm": 1.8696141242980957,
      "learning_rate": 0.00026690909090909087,
      "loss": 0.5748,
      "step": 600
    },
    {
      "epoch": 1.2,
      "eval_loss": 0.8808581829071045,
      "eval_runtime": 8.5902,
      "eval_samples_per_second": 23.282,
      "eval_steps_per_second": 23.282,
      "step": 600
    },
    {
      "epoch": 1.22,
      "grad_norm": 5.0396294593811035,
      "learning_rate": 0.0002663030303030303,
      "loss": 0.6797,
      "step": 610
    },
    {
      "epoch": 1.24,
      "grad_norm": 3.081062078475952,
      "learning_rate": 0.0002656969696969697,
      "loss": 0.7754,
      "step": 620
    },
    {
      "epoch": 1.26,
      "grad_norm": 2.9601175785064697,
      "learning_rate": 0.00026509090909090905,
      "loss": 0.7161,
      "step": 630
    },
    {
      "epoch": 1.28,
      "grad_norm": 2.9587624073028564,
      "learning_rate": 0.00026448484848484846,
      "loss": 0.7105,
      "step": 640
    },
    {
      "epoch": 1.3,
      "grad_norm": 2.674834966659546,
      "learning_rate": 0.00026387878787878787,
      "loss": 0.7724,
      "step": 650
    },
    {
      "epoch": 1.32,
      "grad_norm": 2.7215211391448975,
      "learning_rate": 0.0002632727272727272,
      "loss": 0.5814,
      "step": 660
    },
    {
      "epoch": 1.34,
      "grad_norm": 1.7958061695098877,
      "learning_rate": 0.00026266666666666664,
      "loss": 0.7612,
      "step": 670
    },
    {
      "epoch": 1.3599999999999999,
      "grad_norm": 3.9028170108795166,
      "learning_rate": 0.00026206060606060605,
      "loss": 0.8738,
      "step": 680
    },
    {
      "epoch": 1.38,
      "grad_norm": 2.736260175704956,
      "learning_rate": 0.0002614545454545454,
      "loss": 0.5917,
      "step": 690
    },
    {
      "epoch": 1.4,
      "grad_norm": 3.2677841186523438,
      "learning_rate": 0.0002608484848484848,
      "loss": 0.6465,
      "step": 700
    },
    {
      "epoch": 1.4,
      "eval_loss": 0.8729231357574463,
      "eval_runtime": 8.3226,
      "eval_samples_per_second": 24.031,
      "eval_steps_per_second": 24.031,
      "step": 700
    },
    {
      "epoch": 1.42,
      "grad_norm": 2.1236064434051514,
      "learning_rate": 0.0002602424242424242,
      "loss": 0.7315,
      "step": 710
    },
    {
      "epoch": 1.44,
      "grad_norm": 3.0297391414642334,
      "learning_rate": 0.00025963636363636363,
      "loss": 0.5938,
      "step": 720
    },
    {
      "epoch": 1.46,
      "grad_norm": 3.6235523223876953,
      "learning_rate": 0.000259030303030303,
      "loss": 0.7878,
      "step": 730
    },
    {
      "epoch": 1.48,
      "grad_norm": 3.463885545730591,
      "learning_rate": 0.0002584242424242424,
      "loss": 0.7073,
      "step": 740
    },
    {
      "epoch": 1.5,
      "grad_norm": 5.238876819610596,
      "learning_rate": 0.0002578181818181818,
      "loss": 0.7411,
      "step": 750
    },
    {
      "epoch": 1.52,
      "grad_norm": 2.969597816467285,
      "learning_rate": 0.00025721212121212117,
      "loss": 0.8292,
      "step": 760
    },
    {
      "epoch": 1.54,
      "grad_norm": 1.6206566095352173,
      "learning_rate": 0.0002566060606060606,
      "loss": 0.7391,
      "step": 770
    },
    {
      "epoch": 1.56,
      "grad_norm": 1.313341736793518,
      "learning_rate": 0.000256,
      "loss": 0.5441,
      "step": 780
    },
    {
      "epoch": 1.58,
      "grad_norm": 5.154599189758301,
      "learning_rate": 0.0002553939393939394,
      "loss": 0.6492,
      "step": 790
    },
    {
      "epoch": 1.6,
      "grad_norm": 4.194591999053955,
      "learning_rate": 0.00025478787878787876,
      "loss": 0.7946,
      "step": 800
    },
    {
      "epoch": 1.6,
      "eval_loss": 0.8610199093818665,
      "eval_runtime": 8.3624,
      "eval_samples_per_second": 23.916,
      "eval_steps_per_second": 23.916,
      "step": 800
    },
    {
      "epoch": 1.62,
      "grad_norm": 3.350651741027832,
      "learning_rate": 0.00025418181818181817,
      "loss": 0.6832,
      "step": 810
    },
    {
      "epoch": 1.6400000000000001,
      "grad_norm": 2.836146593093872,
      "learning_rate": 0.0002535757575757576,
      "loss": 0.582,
      "step": 820
    },
    {
      "epoch": 1.6600000000000001,
      "grad_norm": 3.6138439178466797,
      "learning_rate": 0.00025296969696969693,
      "loss": 0.7352,
      "step": 830
    },
    {
      "epoch": 1.6800000000000002,
      "grad_norm": 4.386882305145264,
      "learning_rate": 0.00025236363636363634,
      "loss": 0.701,
      "step": 840
    },
    {
      "epoch": 1.7,
      "grad_norm": 3.7521772384643555,
      "learning_rate": 0.0002517575757575757,
      "loss": 0.7226,
      "step": 850
    },
    {
      "epoch": 1.72,
      "grad_norm": 4.426538467407227,
      "learning_rate": 0.0002511515151515151,
      "loss": 0.7279,
      "step": 860
    },
    {
      "epoch": 1.74,
      "grad_norm": 4.033475875854492,
      "learning_rate": 0.0002505454545454545,
      "loss": 0.6611,
      "step": 870
    },
    {
      "epoch": 1.76,
      "grad_norm": 4.524516582489014,
      "learning_rate": 0.00024993939393939393,
      "loss": 0.7485,
      "step": 880
    },
    {
      "epoch": 1.78,
      "grad_norm": 2.125028133392334,
      "learning_rate": 0.00024933333333333334,
      "loss": 0.566,
      "step": 890
    },
    {
      "epoch": 1.8,
      "grad_norm": 4.977164268493652,
      "learning_rate": 0.0002487272727272727,
      "loss": 0.6469,
      "step": 900
    },
    {
      "epoch": 1.8,
      "eval_loss": 0.8682401776313782,
      "eval_runtime": 8.7253,
      "eval_samples_per_second": 22.922,
      "eval_steps_per_second": 22.922,
      "step": 900
    },
    {
      "epoch": 1.8199999999999998,
      "grad_norm": 2.621786594390869,
      "learning_rate": 0.0002481212121212121,
      "loss": 0.636,
      "step": 910
    },
    {
      "epoch": 1.8399999999999999,
      "grad_norm": 4.089458465576172,
      "learning_rate": 0.00024751515151515146,
      "loss": 0.8309,
      "step": 920
    },
    {
      "epoch": 1.8599999999999999,
      "grad_norm": 2.801926851272583,
      "learning_rate": 0.0002469090909090909,
      "loss": 0.7726,
      "step": 930
    },
    {
      "epoch": 1.88,
      "grad_norm": 4.343912601470947,
      "learning_rate": 0.0002463030303030303,
      "loss": 0.5992,
      "step": 940
    },
    {
      "epoch": 1.9,
      "grad_norm": 2.4945626258850098,
      "learning_rate": 0.00024569696969696964,
      "loss": 0.7496,
      "step": 950
    },
    {
      "epoch": 1.92,
      "grad_norm": 2.087430715560913,
      "learning_rate": 0.0002450909090909091,
      "loss": 0.5926,
      "step": 960
    },
    {
      "epoch": 1.94,
      "grad_norm": 3.7543771266937256,
      "learning_rate": 0.00024448484848484846,
      "loss": 0.971,
      "step": 970
    },
    {
      "epoch": 1.96,
      "grad_norm": 4.8124213218688965,
      "learning_rate": 0.00024387878787878787,
      "loss": 0.8043,
      "step": 980
    },
    {
      "epoch": 1.98,
      "grad_norm": 4.580165386199951,
      "learning_rate": 0.00024327272727272725,
      "loss": 0.5908,
      "step": 990
    },
    {
      "epoch": 2.0,
      "grad_norm": 2.70241117477417,
      "learning_rate": 0.00024266666666666664,
      "loss": 0.8383,
      "step": 1000
    },
    {
      "epoch": 2.0,
      "eval_loss": 0.8533262014389038,
      "eval_runtime": 8.7974,
      "eval_samples_per_second": 22.734,
      "eval_steps_per_second": 22.734,
      "step": 1000
    },
    {
      "epoch": 2.02,
      "grad_norm": 3.9747354984283447,
      "learning_rate": 0.00024206060606060602,
      "loss": 0.4596,
      "step": 1010
    },
    {
      "epoch": 2.04,
      "grad_norm": 2.238459348678589,
      "learning_rate": 0.00024145454545454543,
      "loss": 0.5459,
      "step": 1020
    },
    {
      "epoch": 2.06,
      "grad_norm": 3.429398775100708,
      "learning_rate": 0.00024084848484848482,
      "loss": 0.6076,
      "step": 1030
    },
    {
      "epoch": 2.08,
      "grad_norm": 3.0319817066192627,
      "learning_rate": 0.00024024242424242423,
      "loss": 0.5376,
      "step": 1040
    },
    {
      "epoch": 2.1,
      "grad_norm": 3.057616710662842,
      "learning_rate": 0.00023963636363636364,
      "loss": 0.4721,
      "step": 1050
    },
    {
      "epoch": 2.12,
      "grad_norm": 3.1430211067199707,
      "learning_rate": 0.00023903030303030302,
      "loss": 0.5375,
      "step": 1060
    },
    {
      "epoch": 2.14,
      "grad_norm": 2.999356269836426,
      "learning_rate": 0.0002384242424242424,
      "loss": 0.4262,
      "step": 1070
    },
    {
      "epoch": 2.16,
      "grad_norm": 3.6842031478881836,
      "learning_rate": 0.00023781818181818179,
      "loss": 0.6291,
      "step": 1080
    },
    {
      "epoch": 2.18,
      "grad_norm": 2.440307855606079,
      "learning_rate": 0.0002372121212121212,
      "loss": 0.4586,
      "step": 1090
    },
    {
      "epoch": 2.2,
      "grad_norm": 2.2283735275268555,
      "learning_rate": 0.00023660606060606058,
      "loss": 0.3804,
      "step": 1100
    },
    {
      "epoch": 2.2,
      "eval_loss": 0.9553656578063965,
      "eval_runtime": 8.3083,
      "eval_samples_per_second": 24.072,
      "eval_steps_per_second": 24.072,
      "step": 1100
    },
    {
      "epoch": 2.22,
      "grad_norm": 2.6159279346466064,
      "learning_rate": 0.00023599999999999996,
      "loss": 0.4606,
      "step": 1110
    },
    {
      "epoch": 2.24,
      "grad_norm": 4.288969993591309,
      "learning_rate": 0.00023539393939393935,
      "loss": 0.5322,
      "step": 1120
    },
    {
      "epoch": 2.26,
      "grad_norm": 1.5970966815948486,
      "learning_rate": 0.00023478787878787878,
      "loss": 0.4745,
      "step": 1130
    },
    {
      "epoch": 2.2800000000000002,
      "grad_norm": 4.625598430633545,
      "learning_rate": 0.00023418181818181817,
      "loss": 0.5662,
      "step": 1140
    },
    {
      "epoch": 2.3,
      "grad_norm": 4.905804634094238,
      "learning_rate": 0.00023357575757575755,
      "loss": 0.4738,
      "step": 1150
    },
    {
      "epoch": 2.32,
      "grad_norm": 3.849210023880005,
      "learning_rate": 0.00023296969696969696,
      "loss": 0.4394,
      "step": 1160
    },
    {
      "epoch": 2.34,
      "grad_norm": 3.233506917953491,
      "learning_rate": 0.00023236363636363634,
      "loss": 0.5149,
      "step": 1170
    },
    {
      "epoch": 2.36,
      "grad_norm": 4.0389299392700195,
      "learning_rate": 0.00023175757575757573,
      "loss": 0.4601,
      "step": 1180
    },
    {
      "epoch": 2.38,
      "grad_norm": 2.252988576889038,
      "learning_rate": 0.0002311515151515151,
      "loss": 0.4903,
      "step": 1190
    },
    {
      "epoch": 2.4,
      "grad_norm": 3.0382041931152344,
      "learning_rate": 0.00023054545454545452,
      "loss": 0.4537,
      "step": 1200
    },
    {
      "epoch": 2.4,
      "eval_loss": 0.9000205993652344,
      "eval_runtime": 8.7537,
      "eval_samples_per_second": 22.847,
      "eval_steps_per_second": 22.847,
      "step": 1200
    },
    {
      "epoch": 2.42,
      "grad_norm": 2.681494951248169,
      "learning_rate": 0.00022993939393939393,
      "loss": 0.371,
      "step": 1210
    },
    {
      "epoch": 2.44,
      "grad_norm": 5.831950664520264,
      "learning_rate": 0.00022933333333333332,
      "loss": 0.6659,
      "step": 1220
    },
    {
      "epoch": 2.46,
      "grad_norm": 5.074825763702393,
      "learning_rate": 0.00022872727272727273,
      "loss": 0.5364,
      "step": 1230
    },
    {
      "epoch": 2.48,
      "grad_norm": 2.4539551734924316,
      "learning_rate": 0.0002281212121212121,
      "loss": 0.588,
      "step": 1240
    },
    {
      "epoch": 2.5,
      "grad_norm": 5.036037445068359,
      "learning_rate": 0.0002275151515151515,
      "loss": 0.5744,
      "step": 1250
    },
    {
      "epoch": 2.52,
      "grad_norm": 2.1266252994537354,
      "learning_rate": 0.00022690909090909088,
      "loss": 0.6146,
      "step": 1260
    },
    {
      "epoch": 2.54,
      "grad_norm": 4.26762580871582,
      "learning_rate": 0.00022630303030303029,
      "loss": 0.5565,
      "step": 1270
    },
    {
      "epoch": 2.56,
      "grad_norm": 1.543196678161621,
      "learning_rate": 0.00022569696969696967,
      "loss": 0.4135,
      "step": 1280
    },
    {
      "epoch": 2.58,
      "grad_norm": 3.4238290786743164,
      "learning_rate": 0.00022509090909090905,
      "loss": 0.4039,
      "step": 1290
    },
    {
      "epoch": 2.6,
      "grad_norm": 3.2038989067077637,
      "learning_rate": 0.0002244848484848485,
      "loss": 0.5905,
      "step": 1300
    },
    {
      "epoch": 2.6,
      "eval_loss": 0.9113476276397705,
      "eval_runtime": 8.4422,
      "eval_samples_per_second": 23.69,
      "eval_steps_per_second": 23.69,
      "step": 1300
    },
    {
      "epoch": 2.62,
      "grad_norm": 2.7139923572540283,
      "learning_rate": 0.00022387878787878787,
      "loss": 0.5918,
      "step": 1310
    },
    {
      "epoch": 2.64,
      "grad_norm": 2.110240936279297,
      "learning_rate": 0.00022327272727272726,
      "loss": 0.4675,
      "step": 1320
    },
    {
      "epoch": 2.66,
      "grad_norm": 4.4995317459106445,
      "learning_rate": 0.00022266666666666664,
      "loss": 0.5275,
      "step": 1330
    },
    {
      "epoch": 2.68,
      "grad_norm": 2.9616169929504395,
      "learning_rate": 0.00022206060606060605,
      "loss": 0.468,
      "step": 1340
    },
    {
      "epoch": 2.7,
      "grad_norm": 1.9719349145889282,
      "learning_rate": 0.00022145454545454543,
      "loss": 0.4542,
      "step": 1350
    },
    {
      "epoch": 2.7199999999999998,
      "grad_norm": 3.5198183059692383,
      "learning_rate": 0.00022084848484848482,
      "loss": 0.4908,
      "step": 1360
    },
    {
      "epoch": 2.74,
      "grad_norm": 3.451906681060791,
      "learning_rate": 0.0002202424242424242,
      "loss": 0.4979,
      "step": 1370
    },
    {
      "epoch": 2.76,
      "grad_norm": 6.610089302062988,
      "learning_rate": 0.00021963636363636364,
      "loss": 0.5288,
      "step": 1380
    },
    {
      "epoch": 2.7800000000000002,
      "grad_norm": 2.080651044845581,
      "learning_rate": 0.00021903030303030302,
      "loss": 0.6079,
      "step": 1390
    },
    {
      "epoch": 2.8,
      "grad_norm": 4.12012243270874,
      "learning_rate": 0.0002184242424242424,
      "loss": 0.5376,
      "step": 1400
    },
    {
      "epoch": 2.8,
      "eval_loss": 0.8908535838127136,
      "eval_runtime": 8.3939,
      "eval_samples_per_second": 23.827,
      "eval_steps_per_second": 23.827,
      "step": 1400
    },
    {
      "epoch": 2.82,
      "grad_norm": 2.862485647201538,
      "learning_rate": 0.00021781818181818181,
      "loss": 0.3929,
      "step": 1410
    },
    {
      "epoch": 2.84,
      "grad_norm": 3.4336321353912354,
      "learning_rate": 0.0002172121212121212,
      "loss": 0.418,
      "step": 1420
    },
    {
      "epoch": 2.86,
      "grad_norm": 3.457414150238037,
      "learning_rate": 0.00021660606060606058,
      "loss": 0.4892,
      "step": 1430
    },
    {
      "epoch": 2.88,
      "grad_norm": 3.080955743789673,
      "learning_rate": 0.00021599999999999996,
      "loss": 0.393,
      "step": 1440
    },
    {
      "epoch": 2.9,
      "grad_norm": 3.0150790214538574,
      "learning_rate": 0.00021539393939393938,
      "loss": 0.3655,
      "step": 1450
    },
    {
      "epoch": 2.92,
      "grad_norm": 2.495347738265991,
      "learning_rate": 0.00021478787878787876,
      "loss": 0.6034,
      "step": 1460
    },
    {
      "epoch": 2.94,
      "grad_norm": 2.289026975631714,
      "learning_rate": 0.00021418181818181817,
      "loss": 0.4502,
      "step": 1470
    },
    {
      "epoch": 2.96,
      "grad_norm": 4.053606033325195,
      "learning_rate": 0.00021357575757575758,
      "loss": 0.4519,
      "step": 1480
    },
    {
      "epoch": 2.98,
      "grad_norm": 2.443572521209717,
      "learning_rate": 0.00021296969696969696,
      "loss": 0.5166,
      "step": 1490
    },
    {
      "epoch": 3.0,
      "grad_norm": 4.871737480163574,
      "learning_rate": 0.00021236363636363635,
      "loss": 0.6372,
      "step": 1500
    },
    {
      "epoch": 3.0,
      "eval_loss": 0.8839948773384094,
      "eval_runtime": 8.3959,
      "eval_samples_per_second": 23.821,
      "eval_steps_per_second": 23.821,
      "step": 1500
    },
    {
      "epoch": 3.02,
      "grad_norm": 2.571981906890869,
      "learning_rate": 0.00021175757575757573,
      "loss": 0.3636,
      "step": 1510
    },
    {
      "epoch": 3.04,
      "grad_norm": 2.45817232131958,
      "learning_rate": 0.00021115151515151514,
      "loss": 0.3333,
      "step": 1520
    },
    {
      "epoch": 3.06,
      "grad_norm": 2.5296709537506104,
      "learning_rate": 0.00021054545454545452,
      "loss": 0.3511,
      "step": 1530
    },
    {
      "epoch": 3.08,
      "grad_norm": 3.376018524169922,
      "learning_rate": 0.0002099393939393939,
      "loss": 0.3396,
      "step": 1540
    },
    {
      "epoch": 3.1,
      "grad_norm": 3.372260808944702,
      "learning_rate": 0.00020933333333333334,
      "loss": 0.4362,
      "step": 1550
    },
    {
      "epoch": 3.12,
      "grad_norm": 4.328895568847656,
      "learning_rate": 0.00020872727272727273,
      "loss": 0.3132,
      "step": 1560
    },
    {
      "epoch": 3.14,
      "grad_norm": 2.059227228164673,
      "learning_rate": 0.0002081212121212121,
      "loss": 0.3885,
      "step": 1570
    },
    {
      "epoch": 3.16,
      "grad_norm": 1.8639894723892212,
      "learning_rate": 0.0002075151515151515,
      "loss": 0.3016,
      "step": 1580
    },
    {
      "epoch": 3.18,
      "grad_norm": 2.3412744998931885,
      "learning_rate": 0.0002069090909090909,
      "loss": 0.4046,
      "step": 1590
    },
    {
      "epoch": 3.2,
      "grad_norm": 2.8156445026397705,
      "learning_rate": 0.0002063030303030303,
      "loss": 0.4607,
      "step": 1600
    },
    {
      "epoch": 3.2,
      "eval_loss": 0.9544983506202698,
      "eval_runtime": 8.3657,
      "eval_samples_per_second": 23.907,
      "eval_steps_per_second": 23.907,
      "step": 1600
    },
    {
      "epoch": 3.22,
      "grad_norm": 2.079871892929077,
      "learning_rate": 0.00020569696969696967,
      "loss": 0.3524,
      "step": 1610
    },
    {
      "epoch": 3.24,
      "grad_norm": 2.4356536865234375,
      "learning_rate": 0.00020509090909090905,
      "loss": 0.2989,
      "step": 1620
    },
    {
      "epoch": 3.26,
      "grad_norm": 1.3709158897399902,
      "learning_rate": 0.00020448484848484846,
      "loss": 0.3226,
      "step": 1630
    },
    {
      "epoch": 3.2800000000000002,
      "grad_norm": 2.6052486896514893,
      "learning_rate": 0.00020387878787878788,
      "loss": 0.4735,
      "step": 1640
    },
    {
      "epoch": 3.3,
      "grad_norm": 2.9868457317352295,
      "learning_rate": 0.00020327272727272726,
      "loss": 0.371,
      "step": 1650
    },
    {
      "epoch": 3.32,
      "grad_norm": 1.850361704826355,
      "learning_rate": 0.00020266666666666664,
      "loss": 0.3681,
      "step": 1660
    },
    {
      "epoch": 3.34,
      "grad_norm": 1.5105646848678589,
      "learning_rate": 0.00020206060606060605,
      "loss": 0.2926,
      "step": 1670
    },
    {
      "epoch": 3.36,
      "grad_norm": 3.6634509563446045,
      "learning_rate": 0.00020145454545454544,
      "loss": 0.3685,
      "step": 1680
    },
    {
      "epoch": 3.38,
      "grad_norm": 2.2610201835632324,
      "learning_rate": 0.00020084848484848482,
      "loss": 0.4496,
      "step": 1690
    },
    {
      "epoch": 3.4,
      "grad_norm": 1.949282169342041,
      "learning_rate": 0.0002002424242424242,
      "loss": 0.3975,
      "step": 1700
    },
    {
      "epoch": 3.4,
      "eval_loss": 0.9942363500595093,
      "eval_runtime": 8.4266,
      "eval_samples_per_second": 23.734,
      "eval_steps_per_second": 23.734,
      "step": 1700
    },
    {
      "epoch": 3.42,
      "grad_norm": 2.7957301139831543,
      "learning_rate": 0.0001996363636363636,
      "loss": 0.4299,
      "step": 1710
    },
    {
      "epoch": 3.44,
      "grad_norm": 2.9906656742095947,
      "learning_rate": 0.00019903030303030302,
      "loss": 0.3077,
      "step": 1720
    },
    {
      "epoch": 3.46,
      "grad_norm": 2.415121078491211,
      "learning_rate": 0.0001984242424242424,
      "loss": 0.3792,
      "step": 1730
    },
    {
      "epoch": 3.48,
      "grad_norm": 0.8892455697059631,
      "learning_rate": 0.00019781818181818182,
      "loss": 0.3609,
      "step": 1740
    },
    {
      "epoch": 3.5,
      "grad_norm": 2.7538225650787354,
      "learning_rate": 0.0001972121212121212,
      "loss": 0.3879,
      "step": 1750
    },
    {
      "epoch": 3.52,
      "grad_norm": 4.156050682067871,
      "learning_rate": 0.00019660606060606058,
      "loss": 0.3964,
      "step": 1760
    },
    {
      "epoch": 3.54,
      "grad_norm": 2.9882867336273193,
      "learning_rate": 0.00019599999999999997,
      "loss": 0.2927,
      "step": 1770
    },
    {
      "epoch": 3.56,
      "grad_norm": 2.748136043548584,
      "learning_rate": 0.00019539393939393938,
      "loss": 0.3794,
      "step": 1780
    },
    {
      "epoch": 3.58,
      "grad_norm": 1.2515515089035034,
      "learning_rate": 0.00019478787878787876,
      "loss": 0.2955,
      "step": 1790
    },
    {
      "epoch": 3.6,
      "grad_norm": 3.1355185508728027,
      "learning_rate": 0.00019418181818181814,
      "loss": 0.4005,
      "step": 1800
    },
    {
      "epoch": 3.6,
      "eval_loss": 0.9569787383079529,
      "eval_runtime": 8.558,
      "eval_samples_per_second": 23.37,
      "eval_steps_per_second": 23.37,
      "step": 1800
    },
    {
      "epoch": 3.62,
      "grad_norm": 2.9475784301757812,
      "learning_rate": 0.00019357575757575758,
      "loss": 0.4213,
      "step": 1810
    },
    {
      "epoch": 3.64,
      "grad_norm": 3.4263596534729004,
      "learning_rate": 0.00019296969696969696,
      "loss": 0.445,
      "step": 1820
    },
    {
      "epoch": 3.66,
      "grad_norm": 2.7031266689300537,
      "learning_rate": 0.00019236363636363635,
      "loss": 0.3389,
      "step": 1830
    },
    {
      "epoch": 3.68,
      "grad_norm": 3.105167865753174,
      "learning_rate": 0.00019175757575757573,
      "loss": 0.3184,
      "step": 1840
    },
    {
      "epoch": 3.7,
      "grad_norm": 3.1054065227508545,
      "learning_rate": 0.00019115151515151514,
      "loss": 0.3303,
      "step": 1850
    },
    {
      "epoch": 3.7199999999999998,
      "grad_norm": 2.221020221710205,
      "learning_rate": 0.00019054545454545452,
      "loss": 0.3841,
      "step": 1860
    },
    {
      "epoch": 3.74,
      "grad_norm": 2.399097442626953,
      "learning_rate": 0.0001899393939393939,
      "loss": 0.4574,
      "step": 1870
    },
    {
      "epoch": 3.76,
      "grad_norm": 2.612697124481201,
      "learning_rate": 0.0001893333333333333,
      "loss": 0.3608,
      "step": 1880
    },
    {
      "epoch": 3.7800000000000002,
      "grad_norm": 2.860703468322754,
      "learning_rate": 0.00018872727272727273,
      "loss": 0.3658,
      "step": 1890
    },
    {
      "epoch": 3.8,
      "grad_norm": 2.214160203933716,
      "learning_rate": 0.0001881212121212121,
      "loss": 0.3894,
      "step": 1900
    },
    {
      "epoch": 3.8,
      "eval_loss": 0.9928626418113708,
      "eval_runtime": 8.3045,
      "eval_samples_per_second": 24.083,
      "eval_steps_per_second": 24.083,
      "step": 1900
    },
    {
      "epoch": 3.82,
      "grad_norm": 4.126676082611084,
      "learning_rate": 0.0001875151515151515,
      "loss": 0.4361,
      "step": 1910
    },
    {
      "epoch": 3.84,
      "grad_norm": 2.4535903930664062,
      "learning_rate": 0.0001869090909090909,
      "loss": 0.3332,
      "step": 1920
    },
    {
      "epoch": 3.86,
      "grad_norm": 4.378835201263428,
      "learning_rate": 0.0001863030303030303,
      "loss": 0.4041,
      "step": 1930
    },
    {
      "epoch": 3.88,
      "grad_norm": 4.234720706939697,
      "learning_rate": 0.00018569696969696967,
      "loss": 0.3677,
      "step": 1940
    },
    {
      "epoch": 3.9,
      "grad_norm": 2.68019437789917,
      "learning_rate": 0.00018509090909090906,
      "loss": 0.4055,
      "step": 1950
    },
    {
      "epoch": 3.92,
      "grad_norm": 3.324917793273926,
      "learning_rate": 0.00018448484848484847,
      "loss": 0.4195,
      "step": 1960
    },
    {
      "epoch": 3.94,
      "grad_norm": 3.089261054992676,
      "learning_rate": 0.00018387878787878785,
      "loss": 0.3827,
      "step": 1970
    },
    {
      "epoch": 3.96,
      "grad_norm": 2.211181879043579,
      "learning_rate": 0.00018327272727272726,
      "loss": 0.4235,
      "step": 1980
    },
    {
      "epoch": 3.98,
      "grad_norm": 2.1318068504333496,
      "learning_rate": 0.00018266666666666667,
      "loss": 0.3004,
      "step": 1990
    },
    {
      "epoch": 4.0,
      "grad_norm": 2.6332433223724365,
      "learning_rate": 0.00018206060606060605,
      "loss": 0.3487,
      "step": 2000
    },
    {
      "epoch": 4.0,
      "eval_loss": 0.9661723375320435,
      "eval_runtime": 8.435,
      "eval_samples_per_second": 23.711,
      "eval_steps_per_second": 23.711,
      "step": 2000
    },
    {
      "epoch": 4.02,
      "grad_norm": 1.508705496788025,
      "learning_rate": 0.00018145454545454544,
      "loss": 0.256,
      "step": 2010
    },
    {
      "epoch": 4.04,
      "grad_norm": 2.6120245456695557,
      "learning_rate": 0.00018084848484848482,
      "loss": 0.258,
      "step": 2020
    },
    {
      "epoch": 4.06,
      "grad_norm": 1.3171368837356567,
      "learning_rate": 0.00018024242424242423,
      "loss": 0.2357,
      "step": 2030
    },
    {
      "epoch": 4.08,
      "grad_norm": 2.800811529159546,
      "learning_rate": 0.00017963636363636361,
      "loss": 0.2646,
      "step": 2040
    },
    {
      "epoch": 4.1,
      "grad_norm": 4.03529691696167,
      "learning_rate": 0.000179030303030303,
      "loss": 0.2856,
      "step": 2050
    },
    {
      "epoch": 4.12,
      "grad_norm": 2.1835014820098877,
      "learning_rate": 0.00017842424242424244,
      "loss": 0.2097,
      "step": 2060
    },
    {
      "epoch": 4.14,
      "grad_norm": 2.9212050437927246,
      "learning_rate": 0.00017781818181818182,
      "loss": 0.3224,
      "step": 2070
    },
    {
      "epoch": 4.16,
      "grad_norm": 1.8830664157867432,
      "learning_rate": 0.0001772121212121212,
      "loss": 0.2296,
      "step": 2080
    },
    {
      "epoch": 4.18,
      "grad_norm": 2.2775793075561523,
      "learning_rate": 0.00017660606060606059,
      "loss": 0.2584,
      "step": 2090
    },
    {
      "epoch": 4.2,
      "grad_norm": 2.1545276641845703,
      "learning_rate": 0.000176,
      "loss": 0.3498,
      "step": 2100
    },
    {
      "epoch": 4.2,
      "eval_loss": 1.0124404430389404,
      "eval_runtime": 8.8353,
      "eval_samples_per_second": 22.637,
      "eval_steps_per_second": 22.637,
      "step": 2100
    },
    {
      "epoch": 4.22,
      "grad_norm": 3.0575733184814453,
      "learning_rate": 0.00017539393939393938,
      "loss": 0.2933,
      "step": 2110
    },
    {
      "epoch": 4.24,
      "grad_norm": 1.5668107271194458,
      "learning_rate": 0.00017478787878787876,
      "loss": 0.2337,
      "step": 2120
    },
    {
      "epoch": 4.26,
      "grad_norm": 4.025256633758545,
      "learning_rate": 0.00017418181818181815,
      "loss": 0.3221,
      "step": 2130
    },
    {
      "epoch": 4.28,
      "grad_norm": 1.7217909097671509,
      "learning_rate": 0.00017357575757575756,
      "loss": 0.2839,
      "step": 2140
    },
    {
      "epoch": 4.3,
      "grad_norm": 1.551192045211792,
      "learning_rate": 0.00017296969696969697,
      "loss": 0.2598,
      "step": 2150
    },
    {
      "epoch": 4.32,
      "grad_norm": 1.98665189743042,
      "learning_rate": 0.00017236363636363635,
      "loss": 0.2866,
      "step": 2160
    },
    {
      "epoch": 4.34,
      "grad_norm": 5.307729244232178,
      "learning_rate": 0.00017175757575757576,
      "loss": 0.2973,
      "step": 2170
    },
    {
      "epoch": 4.36,
      "grad_norm": 2.186950206756592,
      "learning_rate": 0.00017115151515151514,
      "loss": 0.3167,
      "step": 2180
    },
    {
      "epoch": 4.38,
      "grad_norm": 1.675806999206543,
      "learning_rate": 0.00017054545454545453,
      "loss": 0.3022,
      "step": 2190
    },
    {
      "epoch": 4.4,
      "grad_norm": 4.907446384429932,
      "learning_rate": 0.0001699393939393939,
      "loss": 0.3709,
      "step": 2200
    },
    {
      "epoch": 4.4,
      "eval_loss": 1.0353151559829712,
      "eval_runtime": 8.79,
      "eval_samples_per_second": 22.753,
      "eval_steps_per_second": 22.753,
      "step": 2200
    },
    {
      "epoch": 4.42,
      "grad_norm": 2.682190418243408,
      "learning_rate": 0.00016933333333333332,
      "loss": 0.3336,
      "step": 2210
    },
    {
      "epoch": 4.44,
      "grad_norm": 1.483954668045044,
      "learning_rate": 0.0001687272727272727,
      "loss": 0.2763,
      "step": 2220
    },
    {
      "epoch": 4.46,
      "grad_norm": 2.6727726459503174,
      "learning_rate": 0.0001681212121212121,
      "loss": 0.2976,
      "step": 2230
    },
    {
      "epoch": 4.48,
      "grad_norm": 1.555213451385498,
      "learning_rate": 0.00016751515151515152,
      "loss": 0.2973,
      "step": 2240
    },
    {
      "epoch": 4.5,
      "grad_norm": 4.578246593475342,
      "learning_rate": 0.0001669090909090909,
      "loss": 0.279,
      "step": 2250
    },
    {
      "epoch": 4.52,
      "grad_norm": 1.6385471820831299,
      "learning_rate": 0.0001663030303030303,
      "loss": 0.2935,
      "step": 2260
    },
    {
      "epoch": 4.54,
      "grad_norm": 2.2191452980041504,
      "learning_rate": 0.00016569696969696967,
      "loss": 0.2893,
      "step": 2270
    },
    {
      "epoch": 4.5600000000000005,
      "grad_norm": 1.53611421585083,
      "learning_rate": 0.00016509090909090908,
      "loss": 0.2728,
      "step": 2280
    },
    {
      "epoch": 4.58,
      "grad_norm": 2.760319948196411,
      "learning_rate": 0.00016448484848484847,
      "loss": 0.351,
      "step": 2290
    },
    {
      "epoch": 4.6,
      "grad_norm": 2.631459951400757,
      "learning_rate": 0.00016387878787878785,
      "loss": 0.2789,
      "step": 2300
    },
    {
      "epoch": 4.6,
      "eval_loss": 1.0350830554962158,
      "eval_runtime": 8.3124,
      "eval_samples_per_second": 24.06,
      "eval_steps_per_second": 24.06,
      "step": 2300
    },
    {
      "epoch": 4.62,
      "grad_norm": 2.822592258453369,
      "learning_rate": 0.00016327272727272723,
      "loss": 0.3306,
      "step": 2310
    },
    {
      "epoch": 4.64,
      "grad_norm": 2.2789254188537598,
      "learning_rate": 0.00016266666666666667,
      "loss": 0.2882,
      "step": 2320
    },
    {
      "epoch": 4.66,
      "grad_norm": 2.6659207344055176,
      "learning_rate": 0.00016206060606060606,
      "loss": 0.2994,
      "step": 2330
    },
    {
      "epoch": 4.68,
      "grad_norm": 4.865969657897949,
      "learning_rate": 0.00016145454545454544,
      "loss": 0.3445,
      "step": 2340
    },
    {
      "epoch": 4.7,
      "grad_norm": 3.531202554702759,
      "learning_rate": 0.00016084848484848485,
      "loss": 0.2497,
      "step": 2350
    },
    {
      "epoch": 4.72,
      "grad_norm": 2.8477020263671875,
      "learning_rate": 0.00016024242424242423,
      "loss": 0.2818,
      "step": 2360
    },
    {
      "epoch": 4.74,
      "grad_norm": 3.3114585876464844,
      "learning_rate": 0.00015963636363636362,
      "loss": 0.3647,
      "step": 2370
    },
    {
      "epoch": 4.76,
      "grad_norm": 6.407682418823242,
      "learning_rate": 0.000159030303030303,
      "loss": 0.3289,
      "step": 2380
    },
    {
      "epoch": 4.78,
      "grad_norm": 1.9264885187149048,
      "learning_rate": 0.0001584242424242424,
      "loss": 0.301,
      "step": 2390
    },
    {
      "epoch": 4.8,
      "grad_norm": 1.0352579355239868,
      "learning_rate": 0.0001578181818181818,
      "loss": 0.2248,
      "step": 2400
    },
    {
      "epoch": 4.8,
      "eval_loss": 1.0337016582489014,
      "eval_runtime": 8.3247,
      "eval_samples_per_second": 24.025,
      "eval_steps_per_second": 24.025,
      "step": 2400
    },
    {
      "epoch": 4.82,
      "grad_norm": 2.8255043029785156,
      "learning_rate": 0.0001572121212121212,
      "loss": 0.3019,
      "step": 2410
    },
    {
      "epoch": 4.84,
      "grad_norm": 1.6678459644317627,
      "learning_rate": 0.00015660606060606061,
      "loss": 0.3025,
      "step": 2420
    },
    {
      "epoch": 4.86,
      "grad_norm": 6.01357364654541,
      "learning_rate": 0.000156,
      "loss": 0.3651,
      "step": 2430
    },
    {
      "epoch": 4.88,
      "grad_norm": 3.4744675159454346,
      "learning_rate": 0.00015539393939393938,
      "loss": 0.2784,
      "step": 2440
    },
    {
      "epoch": 4.9,
      "grad_norm": 1.8098541498184204,
      "learning_rate": 0.00015478787878787876,
      "loss": 0.349,
      "step": 2450
    },
    {
      "epoch": 4.92,
      "grad_norm": 1.6330657005310059,
      "learning_rate": 0.00015418181818181817,
      "loss": 0.2662,
      "step": 2460
    },
    {
      "epoch": 4.9399999999999995,
      "grad_norm": 2.365457773208618,
      "learning_rate": 0.00015357575757575756,
      "loss": 0.338,
      "step": 2470
    },
    {
      "epoch": 4.96,
      "grad_norm": 1.5027261972427368,
      "learning_rate": 0.00015296969696969694,
      "loss": 0.2886,
      "step": 2480
    },
    {
      "epoch": 4.98,
      "grad_norm": 1.214308500289917,
      "learning_rate": 0.00015236363636363638,
      "loss": 0.3004,
      "step": 2490
    },
    {
      "epoch": 5.0,
      "grad_norm": 2.683161735534668,
      "learning_rate": 0.00015175757575757576,
      "loss": 0.2818,
      "step": 2500
    },
    {
      "epoch": 5.0,
      "eval_loss": 1.0577393770217896,
      "eval_runtime": 8.7045,
      "eval_samples_per_second": 22.977,
      "eval_steps_per_second": 22.977,
      "step": 2500
    },
    {
      "epoch": 5.02,
      "grad_norm": 1.6600358486175537,
      "learning_rate": 0.00015115151515151515,
      "loss": 0.2304,
      "step": 2510
    },
    {
      "epoch": 5.04,
      "grad_norm": 1.7318834066390991,
      "learning_rate": 0.00015054545454545453,
      "loss": 0.1977,
      "step": 2520
    },
    {
      "epoch": 5.06,
      "grad_norm": 1.5881913900375366,
      "learning_rate": 0.00014993939393939394,
      "loss": 0.1683,
      "step": 2530
    },
    {
      "epoch": 5.08,
      "grad_norm": 0.9534883499145508,
      "learning_rate": 0.00014933333333333332,
      "loss": 0.2476,
      "step": 2540
    },
    {
      "epoch": 5.1,
      "grad_norm": 1.2951186895370483,
      "learning_rate": 0.0001487272727272727,
      "loss": 0.1957,
      "step": 2550
    },
    {
      "epoch": 5.12,
      "grad_norm": 1.1293383836746216,
      "learning_rate": 0.00014812121212121212,
      "loss": 0.2576,
      "step": 2560
    },
    {
      "epoch": 5.14,
      "grad_norm": 1.9857592582702637,
      "learning_rate": 0.0001475151515151515,
      "loss": 0.243,
      "step": 2570
    },
    {
      "epoch": 5.16,
      "grad_norm": 1.7465285062789917,
      "learning_rate": 0.00014690909090909088,
      "loss": 0.2062,
      "step": 2580
    },
    {
      "epoch": 5.18,
      "grad_norm": 3.6523208618164062,
      "learning_rate": 0.0001463030303030303,
      "loss": 0.2111,
      "step": 2590
    },
    {
      "epoch": 5.2,
      "grad_norm": 1.0330233573913574,
      "learning_rate": 0.0001456969696969697,
      "loss": 0.2524,
      "step": 2600
    },
    {
      "epoch": 5.2,
      "eval_loss": 1.1167181730270386,
      "eval_runtime": 8.5963,
      "eval_samples_per_second": 23.266,
      "eval_steps_per_second": 23.266,
      "step": 2600
    },
    {
      "epoch": 5.22,
      "grad_norm": 2.2353334426879883,
      "learning_rate": 0.0001450909090909091,
      "loss": 0.2271,
      "step": 2610
    },
    {
      "epoch": 5.24,
      "grad_norm": 2.1594138145446777,
      "learning_rate": 0.00014448484848484847,
      "loss": 0.2707,
      "step": 2620
    },
    {
      "epoch": 5.26,
      "grad_norm": 1.6405811309814453,
      "learning_rate": 0.00014387878787878785,
      "loss": 0.2147,
      "step": 2630
    },
    {
      "epoch": 5.28,
      "grad_norm": 5.498475551605225,
      "learning_rate": 0.00014327272727272726,
      "loss": 0.2342,
      "step": 2640
    },
    {
      "epoch": 5.3,
      "grad_norm": 2.358522653579712,
      "learning_rate": 0.00014266666666666665,
      "loss": 0.2876,
      "step": 2650
    },
    {
      "epoch": 5.32,
      "grad_norm": 1.7730971574783325,
      "learning_rate": 0.00014206060606060606,
      "loss": 0.2261,
      "step": 2660
    },
    {
      "epoch": 5.34,
      "grad_norm": 2.1184847354888916,
      "learning_rate": 0.00014145454545454544,
      "loss": 0.2058,
      "step": 2670
    },
    {
      "epoch": 5.36,
      "grad_norm": 0.8000698685646057,
      "learning_rate": 0.00014084848484848485,
      "loss": 0.207,
      "step": 2680
    },
    {
      "epoch": 5.38,
      "grad_norm": 1.9869507551193237,
      "learning_rate": 0.00014024242424242423,
      "loss": 0.2478,
      "step": 2690
    },
    {
      "epoch": 5.4,
      "grad_norm": 1.0552560091018677,
      "learning_rate": 0.00013963636363636362,
      "loss": 0.2323,
      "step": 2700
    },
    {
      "epoch": 5.4,
      "eval_loss": 1.1012054681777954,
      "eval_runtime": 8.3112,
      "eval_samples_per_second": 24.064,
      "eval_steps_per_second": 24.064,
      "step": 2700
    },
    {
      "epoch": 5.42,
      "grad_norm": 1.950881004333496,
      "learning_rate": 0.000139030303030303,
      "loss": 0.239,
      "step": 2710
    },
    {
      "epoch": 5.44,
      "grad_norm": 1.969821810722351,
      "learning_rate": 0.0001384242424242424,
      "loss": 0.2658,
      "step": 2720
    },
    {
      "epoch": 5.46,
      "grad_norm": 2.796966552734375,
      "learning_rate": 0.00013781818181818182,
      "loss": 0.2099,
      "step": 2730
    },
    {
      "epoch": 5.48,
      "grad_norm": 2.0342814922332764,
      "learning_rate": 0.0001372121212121212,
      "loss": 0.2342,
      "step": 2740
    },
    {
      "epoch": 5.5,
      "grad_norm": 2.2430193424224854,
      "learning_rate": 0.0001366060606060606,
      "loss": 0.2175,
      "step": 2750
    },
    {
      "epoch": 5.52,
      "grad_norm": 1.0980159044265747,
      "learning_rate": 0.00013599999999999997,
      "loss": 0.2185,
      "step": 2760
    },
    {
      "epoch": 5.54,
      "grad_norm": 3.6368489265441895,
      "learning_rate": 0.00013539393939393938,
      "loss": 0.2425,
      "step": 2770
    },
    {
      "epoch": 5.5600000000000005,
      "grad_norm": 2.380826950073242,
      "learning_rate": 0.00013478787878787877,
      "loss": 0.2041,
      "step": 2780
    },
    {
      "epoch": 5.58,
      "grad_norm": 1.7712953090667725,
      "learning_rate": 0.00013418181818181818,
      "loss": 0.2584,
      "step": 2790
    },
    {
      "epoch": 5.6,
      "grad_norm": 1.144835352897644,
      "learning_rate": 0.00013357575757575756,
      "loss": 0.2072,
      "step": 2800
    },
    {
      "epoch": 5.6,
      "eval_loss": 1.0877248048782349,
      "eval_runtime": 8.4071,
      "eval_samples_per_second": 23.789,
      "eval_steps_per_second": 23.789,
      "step": 2800
    },
    {
      "epoch": 5.62,
      "grad_norm": 1.8226008415222168,
      "learning_rate": 0.00013296969696969697,
      "loss": 0.2235,
      "step": 2810
    },
    {
      "epoch": 5.64,
      "grad_norm": 3.0503556728363037,
      "learning_rate": 0.00013236363636363635,
      "loss": 0.243,
      "step": 2820
    },
    {
      "epoch": 5.66,
      "grad_norm": 2.912658929824829,
      "learning_rate": 0.00013175757575757574,
      "loss": 0.2538,
      "step": 2830
    },
    {
      "epoch": 5.68,
      "grad_norm": 3.404512405395508,
      "learning_rate": 0.00013115151515151515,
      "loss": 0.2324,
      "step": 2840
    },
    {
      "epoch": 5.7,
      "grad_norm": 1.5709049701690674,
      "learning_rate": 0.00013054545454545453,
      "loss": 0.2252,
      "step": 2850
    },
    {
      "epoch": 5.72,
      "grad_norm": 1.0227470397949219,
      "learning_rate": 0.00012993939393939394,
      "loss": 0.2566,
      "step": 2860
    },
    {
      "epoch": 5.74,
      "grad_norm": 2.0576605796813965,
      "learning_rate": 0.00012933333333333332,
      "loss": 0.2796,
      "step": 2870
    },
    {
      "epoch": 5.76,
      "grad_norm": 3.591792583465576,
      "learning_rate": 0.0001287272727272727,
      "loss": 0.2267,
      "step": 2880
    },
    {
      "epoch": 5.78,
      "grad_norm": 1.2393066883087158,
      "learning_rate": 0.0001281212121212121,
      "loss": 0.2465,
      "step": 2890
    },
    {
      "epoch": 5.8,
      "grad_norm": 1.6387439966201782,
      "learning_rate": 0.0001275151515151515,
      "loss": 0.2371,
      "step": 2900
    },
    {
      "epoch": 5.8,
      "eval_loss": 1.1210849285125732,
      "eval_runtime": 8.356,
      "eval_samples_per_second": 23.935,
      "eval_steps_per_second": 23.935,
      "step": 2900
    },
    {
      "epoch": 5.82,
      "grad_norm": 0.992708683013916,
      "learning_rate": 0.0001269090909090909,
      "loss": 0.2427,
      "step": 2910
    },
    {
      "epoch": 5.84,
      "grad_norm": 2.4761605262756348,
      "learning_rate": 0.0001263030303030303,
      "loss": 0.297,
      "step": 2920
    },
    {
      "epoch": 5.86,
      "grad_norm": 1.1464908123016357,
      "learning_rate": 0.00012569696969696968,
      "loss": 0.2543,
      "step": 2930
    },
    {
      "epoch": 5.88,
      "grad_norm": 4.9875359535217285,
      "learning_rate": 0.0001250909090909091,
      "loss": 0.2516,
      "step": 2940
    },
    {
      "epoch": 5.9,
      "grad_norm": 1.531579852104187,
      "learning_rate": 0.00012448484848484847,
      "loss": 0.227,
      "step": 2950
    },
    {
      "epoch": 5.92,
      "grad_norm": 2.5240085124969482,
      "learning_rate": 0.00012387878787878785,
      "loss": 0.2819,
      "step": 2960
    },
    {
      "epoch": 5.9399999999999995,
      "grad_norm": 2.6313512325286865,
      "learning_rate": 0.00012327272727272727,
      "loss": 0.2623,
      "step": 2970
    },
    {
      "epoch": 5.96,
      "grad_norm": 9.166557312011719,
      "learning_rate": 0.00012266666666666668,
      "loss": 0.2817,
      "step": 2980
    },
    {
      "epoch": 5.98,
      "grad_norm": 3.2020556926727295,
      "learning_rate": 0.00012206060606060606,
      "loss": 0.2553,
      "step": 2990
    },
    {
      "epoch": 6.0,
      "grad_norm": 2.0457284450531006,
      "learning_rate": 0.00012145454545454544,
      "loss": 0.2829,
      "step": 3000
    },
    {
      "epoch": 6.0,
      "eval_loss": 1.0667662620544434,
      "eval_runtime": 8.3167,
      "eval_samples_per_second": 24.048,
      "eval_steps_per_second": 24.048,
      "step": 3000
    },
    {
      "epoch": 6.02,
      "grad_norm": 1.1001644134521484,
      "learning_rate": 0.00012084848484848484,
      "loss": 0.1717,
      "step": 3010
    },
    {
      "epoch": 6.04,
      "grad_norm": 1.8466147184371948,
      "learning_rate": 0.00012024242424242424,
      "loss": 0.1883,
      "step": 3020
    },
    {
      "epoch": 6.06,
      "grad_norm": 2.3226397037506104,
      "learning_rate": 0.00011963636363636363,
      "loss": 0.1665,
      "step": 3030
    },
    {
      "epoch": 6.08,
      "grad_norm": 2.037018060684204,
      "learning_rate": 0.00011903030303030302,
      "loss": 0.2089,
      "step": 3040
    },
    {
      "epoch": 6.1,
      "grad_norm": 2.923886299133301,
      "learning_rate": 0.00011842424242424241,
      "loss": 0.2173,
      "step": 3050
    },
    {
      "epoch": 6.12,
      "grad_norm": 1.6086608171463013,
      "learning_rate": 0.0001178181818181818,
      "loss": 0.1813,
      "step": 3060
    },
    {
      "epoch": 6.14,
      "grad_norm": 1.873669981956482,
      "learning_rate": 0.00011721212121212121,
      "loss": 0.1922,
      "step": 3070
    },
    {
      "epoch": 6.16,
      "grad_norm": 2.4432590007781982,
      "learning_rate": 0.0001166060606060606,
      "loss": 0.1442,
      "step": 3080
    },
    {
      "epoch": 6.18,
      "grad_norm": 3.1594982147216797,
      "learning_rate": 0.00011599999999999999,
      "loss": 0.2028,
      "step": 3090
    },
    {
      "epoch": 6.2,
      "grad_norm": 3.680111885070801,
      "learning_rate": 0.00011539393939393938,
      "loss": 0.2078,
      "step": 3100
    },
    {
      "epoch": 6.2,
      "eval_loss": 1.2084589004516602,
      "eval_runtime": 8.7344,
      "eval_samples_per_second": 22.898,
      "eval_steps_per_second": 22.898,
      "step": 3100
    },
    {
      "epoch": 6.22,
      "grad_norm": 6.052511215209961,
      "learning_rate": 0.00011478787878787878,
      "loss": 0.1879,
      "step": 3110
    },
    {
      "epoch": 6.24,
      "grad_norm": 0.891977846622467,
      "learning_rate": 0.00011418181818181818,
      "loss": 0.1884,
      "step": 3120
    },
    {
      "epoch": 6.26,
      "grad_norm": 4.387754917144775,
      "learning_rate": 0.00011357575757575756,
      "loss": 0.2371,
      "step": 3130
    },
    {
      "epoch": 6.28,
      "grad_norm": 1.8512041568756104,
      "learning_rate": 0.00011296969696969696,
      "loss": 0.2158,
      "step": 3140
    },
    {
      "epoch": 6.3,
      "grad_norm": 2.1305980682373047,
      "learning_rate": 0.00011236363636363635,
      "loss": 0.1882,
      "step": 3150
    },
    {
      "epoch": 6.32,
      "grad_norm": 1.660284161567688,
      "learning_rate": 0.00011175757575757575,
      "loss": 0.1824,
      "step": 3160
    },
    {
      "epoch": 6.34,
      "grad_norm": 1.7030245065689087,
      "learning_rate": 0.00011115151515151513,
      "loss": 0.1743,
      "step": 3170
    },
    {
      "epoch": 6.36,
      "grad_norm": 4.000105381011963,
      "learning_rate": 0.00011054545454545453,
      "loss": 0.2652,
      "step": 3180
    },
    {
      "epoch": 6.38,
      "grad_norm": 3.0310475826263428,
      "learning_rate": 0.00010993939393939392,
      "loss": 0.1965,
      "step": 3190
    },
    {
      "epoch": 6.4,
      "grad_norm": 1.6114912033081055,
      "learning_rate": 0.00010933333333333333,
      "loss": 0.2009,
      "step": 3200
    },
    {
      "epoch": 6.4,
      "eval_loss": 1.149889349937439,
      "eval_runtime": 8.5414,
      "eval_samples_per_second": 23.415,
      "eval_steps_per_second": 23.415,
      "step": 3200
    },
    {
      "epoch": 6.42,
      "grad_norm": 1.196460247039795,
      "learning_rate": 0.00010872727272727272,
      "loss": 0.1898,
      "step": 3210
    },
    {
      "epoch": 6.44,
      "grad_norm": 2.7158923149108887,
      "learning_rate": 0.0001081212121212121,
      "loss": 0.2208,
      "step": 3220
    },
    {
      "epoch": 6.46,
      "grad_norm": 3.040210247039795,
      "learning_rate": 0.0001075151515151515,
      "loss": 0.2227,
      "step": 3230
    },
    {
      "epoch": 6.48,
      "grad_norm": 2.295182228088379,
      "learning_rate": 0.0001069090909090909,
      "loss": 0.2756,
      "step": 3240
    },
    {
      "epoch": 6.5,
      "grad_norm": 5.961663246154785,
      "learning_rate": 0.0001063030303030303,
      "loss": 0.2276,
      "step": 3250
    },
    {
      "epoch": 6.52,
      "grad_norm": 0.7864390015602112,
      "learning_rate": 0.00010569696969696968,
      "loss": 0.1733,
      "step": 3260
    },
    {
      "epoch": 6.54,
      "grad_norm": 1.9691503047943115,
      "learning_rate": 0.00010509090909090908,
      "loss": 0.1792,
      "step": 3270
    },
    {
      "epoch": 6.5600000000000005,
      "grad_norm": 1.6088846921920776,
      "learning_rate": 0.00010448484848484849,
      "loss": 0.2032,
      "step": 3280
    },
    {
      "epoch": 6.58,
      "grad_norm": 2.253365993499756,
      "learning_rate": 0.00010387878787878787,
      "loss": 0.2144,
      "step": 3290
    },
    {
      "epoch": 6.6,
      "grad_norm": 2.2298343181610107,
      "learning_rate": 0.00010327272727272727,
      "loss": 0.2108,
      "step": 3300
    },
    {
      "epoch": 6.6,
      "eval_loss": 1.2220146656036377,
      "eval_runtime": 8.7457,
      "eval_samples_per_second": 22.868,
      "eval_steps_per_second": 22.868,
      "step": 3300
    },
    {
      "epoch": 6.62,
      "grad_norm": 2.6907153129577637,
      "learning_rate": 0.00010266666666666665,
      "loss": 0.2133,
      "step": 3310
    },
    {
      "epoch": 6.64,
      "grad_norm": 1.9254789352416992,
      "learning_rate": 0.00010206060606060606,
      "loss": 0.1954,
      "step": 3320
    },
    {
      "epoch": 6.66,
      "grad_norm": 1.7116773128509521,
      "learning_rate": 0.00010145454545454544,
      "loss": 0.197,
      "step": 3330
    },
    {
      "epoch": 6.68,
      "grad_norm": 1.5666072368621826,
      "learning_rate": 0.00010084848484848484,
      "loss": 0.2167,
      "step": 3340
    },
    {
      "epoch": 6.7,
      "grad_norm": 0.886454164981842,
      "learning_rate": 0.00010024242424242422,
      "loss": 0.2063,
      "step": 3350
    },
    {
      "epoch": 6.72,
      "grad_norm": 2.466883659362793,
      "learning_rate": 9.963636363636362e-05,
      "loss": 0.1957,
      "step": 3360
    },
    {
      "epoch": 6.74,
      "grad_norm": 2.0141284465789795,
      "learning_rate": 9.903030303030303e-05,
      "loss": 0.2039,
      "step": 3370
    },
    {
      "epoch": 6.76,
      "grad_norm": 2.822864055633545,
      "learning_rate": 9.842424242424241e-05,
      "loss": 0.2306,
      "step": 3380
    },
    {
      "epoch": 6.78,
      "grad_norm": 1.7785605192184448,
      "learning_rate": 9.781818181818181e-05,
      "loss": 0.1981,
      "step": 3390
    },
    {
      "epoch": 6.8,
      "grad_norm": 2.9854257106781006,
      "learning_rate": 9.72121212121212e-05,
      "loss": 0.235,
      "step": 3400
    },
    {
      "epoch": 6.8,
      "eval_loss": 1.1844404935836792,
      "eval_runtime": 8.5547,
      "eval_samples_per_second": 23.379,
      "eval_steps_per_second": 23.379,
      "step": 3400
    },
    {
      "epoch": 6.82,
      "grad_norm": 1.6093189716339111,
      "learning_rate": 9.66060606060606e-05,
      "loss": 0.1805,
      "step": 3410
    },
    {
      "epoch": 6.84,
      "grad_norm": 2.591984748840332,
      "learning_rate": 9.599999999999999e-05,
      "loss": 0.2087,
      "step": 3420
    },
    {
      "epoch": 6.86,
      "grad_norm": 1.9033244848251343,
      "learning_rate": 9.539393939393939e-05,
      "loss": 0.2507,
      "step": 3430
    },
    {
      "epoch": 6.88,
      "grad_norm": 1.0513311624526978,
      "learning_rate": 9.478787878787877e-05,
      "loss": 0.198,
      "step": 3440
    },
    {
      "epoch": 6.9,
      "grad_norm": 3.9038612842559814,
      "learning_rate": 9.418181818181818e-05,
      "loss": 0.2481,
      "step": 3450
    },
    {
      "epoch": 6.92,
      "grad_norm": 3.008490562438965,
      "learning_rate": 9.357575757575758e-05,
      "loss": 0.2108,
      "step": 3460
    },
    {
      "epoch": 6.9399999999999995,
      "grad_norm": 1.2714940309524536,
      "learning_rate": 9.296969696969696e-05,
      "loss": 0.2192,
      "step": 3470
    },
    {
      "epoch": 6.96,
      "grad_norm": 1.5957434177398682,
      "learning_rate": 9.236363636363636e-05,
      "loss": 0.2061,
      "step": 3480
    },
    {
      "epoch": 6.98,
      "grad_norm": 1.6172913312911987,
      "learning_rate": 9.175757575757575e-05,
      "loss": 0.2148,
      "step": 3490
    },
    {
      "epoch": 7.0,
      "grad_norm": 1.5747004747390747,
      "learning_rate": 9.115151515151515e-05,
      "loss": 0.1814,
      "step": 3500
    },
    {
      "epoch": 7.0,
      "eval_loss": 1.1779993772506714,
      "eval_runtime": 8.5381,
      "eval_samples_per_second": 23.425,
      "eval_steps_per_second": 23.425,
      "step": 3500
    },
    {
      "epoch": 7.02,
      "grad_norm": 1.5724023580551147,
      "learning_rate": 9.054545454545453e-05,
      "loss": 0.1492,
      "step": 3510
    },
    {
      "epoch": 7.04,
      "grad_norm": 1.6722066402435303,
      "learning_rate": 8.993939393939393e-05,
      "loss": 0.1575,
      "step": 3520
    },
    {
      "epoch": 7.06,
      "grad_norm": 1.0114400386810303,
      "learning_rate": 8.933333333333331e-05,
      "loss": 0.1533,
      "step": 3530
    },
    {
      "epoch": 7.08,
      "grad_norm": 2.3397884368896484,
      "learning_rate": 8.872727272727272e-05,
      "loss": 0.17,
      "step": 3540
    },
    {
      "epoch": 7.1,
      "grad_norm": 1.4098100662231445,
      "learning_rate": 8.812121212121212e-05,
      "loss": 0.168,
      "step": 3550
    },
    {
      "epoch": 7.12,
      "grad_norm": 1.7472506761550903,
      "learning_rate": 8.75151515151515e-05,
      "loss": 0.1601,
      "step": 3560
    },
    {
      "epoch": 7.14,
      "grad_norm": 2.854965925216675,
      "learning_rate": 8.69090909090909e-05,
      "loss": 0.1648,
      "step": 3570
    },
    {
      "epoch": 7.16,
      "grad_norm": 2.0604984760284424,
      "learning_rate": 8.63030303030303e-05,
      "loss": 0.1787,
      "step": 3580
    },
    {
      "epoch": 7.18,
      "grad_norm": 1.0301936864852905,
      "learning_rate": 8.56969696969697e-05,
      "loss": 0.1587,
      "step": 3590
    },
    {
      "epoch": 7.2,
      "grad_norm": 6.231661796569824,
      "learning_rate": 8.509090909090908e-05,
      "loss": 0.1755,
      "step": 3600
    },
    {
      "epoch": 7.2,
      "eval_loss": 1.2342162132263184,
      "eval_runtime": 8.8381,
      "eval_samples_per_second": 22.629,
      "eval_steps_per_second": 22.629,
      "step": 3600
    },
    {
      "epoch": 7.22,
      "grad_norm": 1.1150256395339966,
      "learning_rate": 8.448484848484848e-05,
      "loss": 0.2021,
      "step": 3610
    },
    {
      "epoch": 7.24,
      "grad_norm": 4.204712390899658,
      "learning_rate": 8.387878787878787e-05,
      "loss": 0.1748,
      "step": 3620
    },
    {
      "epoch": 7.26,
      "grad_norm": 1.8126171827316284,
      "learning_rate": 8.327272727272727e-05,
      "loss": 0.184,
      "step": 3630
    },
    {
      "epoch": 7.28,
      "grad_norm": 1.1408870220184326,
      "learning_rate": 8.266666666666665e-05,
      "loss": 0.1931,
      "step": 3640
    },
    {
      "epoch": 7.3,
      "grad_norm": 1.0623048543930054,
      "learning_rate": 8.206060606060605e-05,
      "loss": 0.165,
      "step": 3650
    },
    {
      "epoch": 7.32,
      "grad_norm": 1.4637213945388794,
      "learning_rate": 8.145454545454546e-05,
      "loss": 0.1684,
      "step": 3660
    },
    {
      "epoch": 7.34,
      "grad_norm": 1.6934136152267456,
      "learning_rate": 8.084848484848484e-05,
      "loss": 0.1629,
      "step": 3670
    },
    {
      "epoch": 7.36,
      "grad_norm": 1.0065399408340454,
      "learning_rate": 8.024242424242424e-05,
      "loss": 0.1766,
      "step": 3680
    },
    {
      "epoch": 7.38,
      "grad_norm": 3.034982442855835,
      "learning_rate": 7.963636363636362e-05,
      "loss": 0.1601,
      "step": 3690
    },
    {
      "epoch": 7.4,
      "grad_norm": 1.4292336702346802,
      "learning_rate": 7.903030303030302e-05,
      "loss": 0.1458,
      "step": 3700
    },
    {
      "epoch": 7.4,
      "eval_loss": 1.2458974123001099,
      "eval_runtime": 8.3523,
      "eval_samples_per_second": 23.946,
      "eval_steps_per_second": 23.946,
      "step": 3700
    },
    {
      "epoch": 7.42,
      "grad_norm": 3.573908567428589,
      "learning_rate": 7.842424242424242e-05,
      "loss": 0.2092,
      "step": 3710
    },
    {
      "epoch": 7.44,
      "grad_norm": 1.3846371173858643,
      "learning_rate": 7.781818181818181e-05,
      "loss": 0.1553,
      "step": 3720
    },
    {
      "epoch": 7.46,
      "grad_norm": 1.4401779174804688,
      "learning_rate": 7.72121212121212e-05,
      "loss": 0.1805,
      "step": 3730
    },
    {
      "epoch": 7.48,
      "grad_norm": 1.265376329421997,
      "learning_rate": 7.66060606060606e-05,
      "loss": 0.179,
      "step": 3740
    },
    {
      "epoch": 7.5,
      "grad_norm": 1.0249226093292236,
      "learning_rate": 7.6e-05,
      "loss": 0.2029,
      "step": 3750
    },
    {
      "epoch": 7.52,
      "grad_norm": 1.681100606918335,
      "learning_rate": 7.539393939393939e-05,
      "loss": 0.161,
      "step": 3760
    },
    {
      "epoch": 7.54,
      "grad_norm": 2.3327486515045166,
      "learning_rate": 7.478787878787878e-05,
      "loss": 0.1975,
      "step": 3770
    },
    {
      "epoch": 7.5600000000000005,
      "grad_norm": 2.559138536453247,
      "learning_rate": 7.418181818181818e-05,
      "loss": 0.1791,
      "step": 3780
    },
    {
      "epoch": 7.58,
      "grad_norm": 1.3079277276992798,
      "learning_rate": 7.357575757575756e-05,
      "loss": 0.1852,
      "step": 3790
    },
    {
      "epoch": 7.6,
      "grad_norm": 1.189188838005066,
      "learning_rate": 7.296969696969696e-05,
      "loss": 0.1934,
      "step": 3800
    },
    {
      "epoch": 7.6,
      "eval_loss": 1.209778904914856,
      "eval_runtime": 8.3366,
      "eval_samples_per_second": 23.99,
      "eval_steps_per_second": 23.99,
      "step": 3800
    },
    {
      "epoch": 7.62,
      "grad_norm": 1.2734471559524536,
      "learning_rate": 7.242424242424242e-05,
      "loss": 0.1994,
      "step": 3810
    },
    {
      "epoch": 7.64,
      "grad_norm": 2.9684977531433105,
      "learning_rate": 7.18181818181818e-05,
      "loss": 0.1834,
      "step": 3820
    },
    {
      "epoch": 7.66,
      "grad_norm": 2.327559471130371,
      "learning_rate": 7.12121212121212e-05,
      "loss": 0.1976,
      "step": 3830
    },
    {
      "epoch": 7.68,
      "grad_norm": 2.2927639484405518,
      "learning_rate": 7.06060606060606e-05,
      "loss": 0.1902,
      "step": 3840
    },
    {
      "epoch": 7.7,
      "grad_norm": 4.257630825042725,
      "learning_rate": 7e-05,
      "loss": 0.1842,
      "step": 3850
    },
    {
      "epoch": 7.72,
      "grad_norm": 1.410580039024353,
      "learning_rate": 6.939393939393939e-05,
      "loss": 0.1814,
      "step": 3860
    },
    {
      "epoch": 7.74,
      "grad_norm": 1.3680634498596191,
      "learning_rate": 6.878787878787879e-05,
      "loss": 0.175,
      "step": 3870
    },
    {
      "epoch": 7.76,
      "grad_norm": 1.1114221811294556,
      "learning_rate": 6.818181818181817e-05,
      "loss": 0.1904,
      "step": 3880
    },
    {
      "epoch": 7.78,
      "grad_norm": 2.0709657669067383,
      "learning_rate": 6.757575757575757e-05,
      "loss": 0.17,
      "step": 3890
    },
    {
      "epoch": 7.8,
      "grad_norm": 4.488206386566162,
      "learning_rate": 6.696969696969696e-05,
      "loss": 0.195,
      "step": 3900
    },
    {
      "epoch": 7.8,
      "eval_loss": 1.2163841724395752,
      "eval_runtime": 8.35,
      "eval_samples_per_second": 23.952,
      "eval_steps_per_second": 23.952,
      "step": 3900
    },
    {
      "epoch": 7.82,
      "grad_norm": 2.149081230163574,
      "learning_rate": 6.636363636363636e-05,
      "loss": 0.1904,
      "step": 3910
    },
    {
      "epoch": 7.84,
      "grad_norm": 1.5127201080322266,
      "learning_rate": 6.575757575757574e-05,
      "loss": 0.1884,
      "step": 3920
    },
    {
      "epoch": 7.86,
      "grad_norm": 1.3140100240707397,
      "learning_rate": 6.515151515151516e-05,
      "loss": 0.157,
      "step": 3930
    },
    {
      "epoch": 7.88,
      "grad_norm": 1.3690639734268188,
      "learning_rate": 6.454545454545454e-05,
      "loss": 0.1752,
      "step": 3940
    },
    {
      "epoch": 7.9,
      "grad_norm": 0.5195441246032715,
      "learning_rate": 6.393939393939394e-05,
      "loss": 0.1612,
      "step": 3950
    },
    {
      "epoch": 7.92,
      "grad_norm": 0.8128679394721985,
      "learning_rate": 6.333333333333333e-05,
      "loss": 0.1676,
      "step": 3960
    },
    {
      "epoch": 7.9399999999999995,
      "grad_norm": 2.3766729831695557,
      "learning_rate": 6.272727272727272e-05,
      "loss": 0.1793,
      "step": 3970
    },
    {
      "epoch": 7.96,
      "grad_norm": 1.8514270782470703,
      "learning_rate": 6.212121212121211e-05,
      "loss": 0.1844,
      "step": 3980
    },
    {
      "epoch": 7.98,
      "grad_norm": 1.4630035161972046,
      "learning_rate": 6.151515151515151e-05,
      "loss": 0.1848,
      "step": 3990
    },
    {
      "epoch": 8.0,
      "grad_norm": 2.2121057510375977,
      "learning_rate": 6.0909090909090906e-05,
      "loss": 0.2156,
      "step": 4000
    },
    {
      "epoch": 8.0,
      "eval_loss": 1.197739601135254,
      "eval_runtime": 8.4714,
      "eval_samples_per_second": 23.609,
      "eval_steps_per_second": 23.609,
      "step": 4000
    },
    {
      "epoch": 8.02,
      "grad_norm": 1.78961181640625,
      "learning_rate": 6.0303030303030296e-05,
      "loss": 0.1412,
      "step": 4010
    },
    {
      "epoch": 8.04,
      "grad_norm": 1.2655717134475708,
      "learning_rate": 5.969696969696969e-05,
      "loss": 0.151,
      "step": 4020
    },
    {
      "epoch": 8.06,
      "grad_norm": 0.8994134068489075,
      "learning_rate": 5.909090909090908e-05,
      "loss": 0.1448,
      "step": 4030
    },
    {
      "epoch": 8.08,
      "grad_norm": 1.6473915576934814,
      "learning_rate": 5.848484848484848e-05,
      "loss": 0.142,
      "step": 4040
    },
    {
      "epoch": 8.1,
      "grad_norm": 0.7907373905181885,
      "learning_rate": 5.787878787878787e-05,
      "loss": 0.1406,
      "step": 4050
    },
    {
      "epoch": 8.12,
      "grad_norm": 1.195477843284607,
      "learning_rate": 5.727272727272727e-05,
      "loss": 0.1452,
      "step": 4060
    },
    {
      "epoch": 8.14,
      "grad_norm": 2.66565203666687,
      "learning_rate": 5.666666666666666e-05,
      "loss": 0.1254,
      "step": 4070
    },
    {
      "epoch": 8.16,
      "grad_norm": 1.8617907762527466,
      "learning_rate": 5.606060606060606e-05,
      "loss": 0.1774,
      "step": 4080
    },
    {
      "epoch": 8.18,
      "grad_norm": 1.9838576316833496,
      "learning_rate": 5.545454545454545e-05,
      "loss": 0.1551,
      "step": 4090
    },
    {
      "epoch": 8.2,
      "grad_norm": 3.163904905319214,
      "learning_rate": 5.484848484848485e-05,
      "loss": 0.1473,
      "step": 4100
    },
    {
      "epoch": 8.2,
      "eval_loss": 1.2791882753372192,
      "eval_runtime": 8.3547,
      "eval_samples_per_second": 23.939,
      "eval_steps_per_second": 23.939,
      "step": 4100
    },
    {
      "epoch": 8.22,
      "grad_norm": 1.0661362409591675,
      "learning_rate": 5.424242424242424e-05,
      "loss": 0.143,
      "step": 4110
    },
    {
      "epoch": 8.24,
      "grad_norm": 1.5117703676223755,
      "learning_rate": 5.3636363636363635e-05,
      "loss": 0.155,
      "step": 4120
    },
    {
      "epoch": 8.26,
      "grad_norm": 1.654228687286377,
      "learning_rate": 5.3030303030303025e-05,
      "loss": 0.1753,
      "step": 4130
    },
    {
      "epoch": 8.28,
      "grad_norm": 0.9144983291625977,
      "learning_rate": 5.2424242424242415e-05,
      "loss": 0.1786,
      "step": 4140
    },
    {
      "epoch": 8.3,
      "grad_norm": 3.2644643783569336,
      "learning_rate": 5.181818181818181e-05,
      "loss": 0.1461,
      "step": 4150
    },
    {
      "epoch": 8.32,
      "grad_norm": 1.4185622930526733,
      "learning_rate": 5.12121212121212e-05,
      "loss": 0.161,
      "step": 4160
    },
    {
      "epoch": 8.34,
      "grad_norm": 2.9687142372131348,
      "learning_rate": 5.0606060606060606e-05,
      "loss": 0.1751,
      "step": 4170
    },
    {
      "epoch": 8.36,
      "grad_norm": 1.3932509422302246,
      "learning_rate": 4.9999999999999996e-05,
      "loss": 0.1587,
      "step": 4180
    },
    {
      "epoch": 8.38,
      "grad_norm": 3.651714324951172,
      "learning_rate": 4.939393939393939e-05,
      "loss": 0.1558,
      "step": 4190
    },
    {
      "epoch": 8.4,
      "grad_norm": 1.4918848276138306,
      "learning_rate": 4.878787878787878e-05,
      "loss": 0.1444,
      "step": 4200
    },
    {
      "epoch": 8.4,
      "eval_loss": 1.2744556665420532,
      "eval_runtime": 8.3288,
      "eval_samples_per_second": 24.013,
      "eval_steps_per_second": 24.013,
      "step": 4200
    },
    {
      "epoch": 8.42,
      "grad_norm": 1.548941969871521,
      "learning_rate": 4.818181818181818e-05,
      "loss": 0.1434,
      "step": 4210
    },
    {
      "epoch": 8.44,
      "grad_norm": 1.4439880847930908,
      "learning_rate": 4.757575757575757e-05,
      "loss": 0.1789,
      "step": 4220
    },
    {
      "epoch": 8.46,
      "grad_norm": 1.4062331914901733,
      "learning_rate": 4.6969696969696966e-05,
      "loss": 0.1485,
      "step": 4230
    },
    {
      "epoch": 8.48,
      "grad_norm": 2.5316710472106934,
      "learning_rate": 4.6363636363636356e-05,
      "loss": 0.1618,
      "step": 4240
    },
    {
      "epoch": 8.5,
      "grad_norm": 1.6750627756118774,
      "learning_rate": 4.575757575757576e-05,
      "loss": 0.1503,
      "step": 4250
    },
    {
      "epoch": 8.52,
      "grad_norm": 1.6302313804626465,
      "learning_rate": 4.515151515151515e-05,
      "loss": 0.1429,
      "step": 4260
    },
    {
      "epoch": 8.54,
      "grad_norm": 1.6112533807754517,
      "learning_rate": 4.454545454545455e-05,
      "loss": 0.143,
      "step": 4270
    },
    {
      "epoch": 8.56,
      "grad_norm": 2.401688814163208,
      "learning_rate": 4.393939393939394e-05,
      "loss": 0.1633,
      "step": 4280
    },
    {
      "epoch": 8.58,
      "grad_norm": 1.0935494899749756,
      "learning_rate": 4.333333333333333e-05,
      "loss": 0.1587,
      "step": 4290
    },
    {
      "epoch": 8.6,
      "grad_norm": 1.0928561687469482,
      "learning_rate": 4.2727272727272724e-05,
      "loss": 0.149,
      "step": 4300
    },
    {
      "epoch": 8.6,
      "eval_loss": 1.2918552160263062,
      "eval_runtime": 8.4288,
      "eval_samples_per_second": 23.728,
      "eval_steps_per_second": 23.728,
      "step": 4300
    },
    {
      "epoch": 8.62,
      "grad_norm": 1.1460291147232056,
      "learning_rate": 4.2121212121212114e-05,
      "loss": 0.1546,
      "step": 4310
    },
    {
      "epoch": 8.64,
      "grad_norm": 3.131298065185547,
      "learning_rate": 4.151515151515151e-05,
      "loss": 0.1837,
      "step": 4320
    },
    {
      "epoch": 8.66,
      "grad_norm": 2.7698137760162354,
      "learning_rate": 4.09090909090909e-05,
      "loss": 0.1637,
      "step": 4330
    },
    {
      "epoch": 8.68,
      "grad_norm": 1.1760238409042358,
      "learning_rate": 4.03030303030303e-05,
      "loss": 0.1401,
      "step": 4340
    },
    {
      "epoch": 8.7,
      "grad_norm": 1.2933660745620728,
      "learning_rate": 3.969696969696969e-05,
      "loss": 0.1442,
      "step": 4350
    },
    {
      "epoch": 8.72,
      "grad_norm": 1.4329572916030884,
      "learning_rate": 3.909090909090909e-05,
      "loss": 0.167,
      "step": 4360
    },
    {
      "epoch": 8.74,
      "grad_norm": 1.3266475200653076,
      "learning_rate": 3.848484848484848e-05,
      "loss": 0.1513,
      "step": 4370
    },
    {
      "epoch": 8.76,
      "grad_norm": 2.094454765319824,
      "learning_rate": 3.787878787878788e-05,
      "loss": 0.1294,
      "step": 4380
    },
    {
      "epoch": 8.78,
      "grad_norm": 2.2751851081848145,
      "learning_rate": 3.727272727272727e-05,
      "loss": 0.1892,
      "step": 4390
    },
    {
      "epoch": 8.8,
      "grad_norm": 1.4255130290985107,
      "learning_rate": 3.666666666666666e-05,
      "loss": 0.1604,
      "step": 4400
    },
    {
      "epoch": 8.8,
      "eval_loss": 1.2819890975952148,
      "eval_runtime": 8.5446,
      "eval_samples_per_second": 23.406,
      "eval_steps_per_second": 23.406,
      "step": 4400
    },
    {
      "epoch": 8.82,
      "grad_norm": 3.425629138946533,
      "learning_rate": 3.6060606060606056e-05,
      "loss": 0.1864,
      "step": 4410
    },
    {
      "epoch": 8.84,
      "grad_norm": 1.470218300819397,
      "learning_rate": 3.545454545454545e-05,
      "loss": 0.1645,
      "step": 4420
    },
    {
      "epoch": 8.86,
      "grad_norm": 0.8820680379867554,
      "learning_rate": 3.484848484848484e-05,
      "loss": 0.1787,
      "step": 4430
    },
    {
      "epoch": 8.88,
      "grad_norm": 1.4931776523590088,
      "learning_rate": 3.424242424242424e-05,
      "loss": 0.1522,
      "step": 4440
    },
    {
      "epoch": 8.9,
      "grad_norm": 3.5585012435913086,
      "learning_rate": 3.3636363636363636e-05,
      "loss": 0.1607,
      "step": 4450
    },
    {
      "epoch": 8.92,
      "grad_norm": 1.3078765869140625,
      "learning_rate": 3.3030303030303027e-05,
      "loss": 0.154,
      "step": 4460
    },
    {
      "epoch": 8.94,
      "grad_norm": 1.2815148830413818,
      "learning_rate": 3.2424242424242423e-05,
      "loss": 0.1499,
      "step": 4470
    },
    {
      "epoch": 8.96,
      "grad_norm": 1.394088864326477,
      "learning_rate": 3.1818181818181814e-05,
      "loss": 0.181,
      "step": 4480
    },
    {
      "epoch": 8.98,
      "grad_norm": 1.3279714584350586,
      "learning_rate": 3.121212121212121e-05,
      "loss": 0.1443,
      "step": 4490
    },
    {
      "epoch": 9.0,
      "grad_norm": 2.9104878902435303,
      "learning_rate": 3.060606060606061e-05,
      "loss": 0.159,
      "step": 4500
    },
    {
      "epoch": 9.0,
      "eval_loss": 1.2664813995361328,
      "eval_runtime": 8.5926,
      "eval_samples_per_second": 23.276,
      "eval_steps_per_second": 23.276,
      "step": 4500
    },
    {
      "epoch": 9.02,
      "grad_norm": 0.8381604552268982,
      "learning_rate": 2.9999999999999997e-05,
      "loss": 0.1432,
      "step": 4510
    },
    {
      "epoch": 9.04,
      "grad_norm": 0.9395617842674255,
      "learning_rate": 2.9393939393939394e-05,
      "loss": 0.1298,
      "step": 4520
    },
    {
      "epoch": 9.06,
      "grad_norm": 1.0816400051116943,
      "learning_rate": 2.8787878787878784e-05,
      "loss": 0.1401,
      "step": 4530
    },
    {
      "epoch": 9.08,
      "grad_norm": 1.1854408979415894,
      "learning_rate": 2.8181818181818178e-05,
      "loss": 0.1272,
      "step": 4540
    },
    {
      "epoch": 9.1,
      "grad_norm": 1.3741042613983154,
      "learning_rate": 2.757575757575757e-05,
      "loss": 0.1474,
      "step": 4550
    },
    {
      "epoch": 9.12,
      "grad_norm": 2.06180739402771,
      "learning_rate": 2.6969696969696965e-05,
      "loss": 0.1487,
      "step": 4560
    },
    {
      "epoch": 9.14,
      "grad_norm": 1.311124563217163,
      "learning_rate": 2.636363636363636e-05,
      "loss": 0.1415,
      "step": 4570
    },
    {
      "epoch": 9.16,
      "grad_norm": 0.9483580589294434,
      "learning_rate": 2.5757575757575755e-05,
      "loss": 0.1356,
      "step": 4580
    },
    {
      "epoch": 9.18,
      "grad_norm": 1.549460768699646,
      "learning_rate": 2.515151515151515e-05,
      "loss": 0.136,
      "step": 4590
    },
    {
      "epoch": 9.2,
      "grad_norm": 0.7605770230293274,
      "learning_rate": 2.4545454545454542e-05,
      "loss": 0.1431,
      "step": 4600
    },
    {
      "epoch": 9.2,
      "eval_loss": 1.3399699926376343,
      "eval_runtime": 8.3495,
      "eval_samples_per_second": 23.954,
      "eval_steps_per_second": 23.954,
      "step": 4600
    },
    {
      "epoch": 9.22,
      "grad_norm": 1.3566571474075317,
      "learning_rate": 2.393939393939394e-05,
      "loss": 0.1426,
      "step": 4610
    },
    {
      "epoch": 9.24,
      "grad_norm": 1.498453974723816,
      "learning_rate": 2.3333333333333332e-05,
      "loss": 0.1403,
      "step": 4620
    },
    {
      "epoch": 9.26,
      "grad_norm": 2.8915421962738037,
      "learning_rate": 2.2727272727272726e-05,
      "loss": 0.132,
      "step": 4630
    },
    {
      "epoch": 9.28,
      "grad_norm": 1.5373866558074951,
      "learning_rate": 2.212121212121212e-05,
      "loss": 0.1273,
      "step": 4640
    },
    {
      "epoch": 9.3,
      "grad_norm": 1.7324986457824707,
      "learning_rate": 2.1515151515151513e-05,
      "loss": 0.1297,
      "step": 4650
    },
    {
      "epoch": 9.32,
      "grad_norm": 1.008670449256897,
      "learning_rate": 2.090909090909091e-05,
      "loss": 0.1344,
      "step": 4660
    },
    {
      "epoch": 9.34,
      "grad_norm": 1.3019064664840698,
      "learning_rate": 2.0303030303030303e-05,
      "loss": 0.1477,
      "step": 4670
    },
    {
      "epoch": 9.36,
      "grad_norm": 1.5280804634094238,
      "learning_rate": 1.9696969696969697e-05,
      "loss": 0.1377,
      "step": 4680
    },
    {
      "epoch": 9.38,
      "grad_norm": 1.371066927909851,
      "learning_rate": 1.9090909090909087e-05,
      "loss": 0.1408,
      "step": 4690
    },
    {
      "epoch": 9.4,
      "grad_norm": 2.0949184894561768,
      "learning_rate": 1.8484848484848484e-05,
      "loss": 0.1492,
      "step": 4700
    },
    {
      "epoch": 9.4,
      "eval_loss": 1.3554004430770874,
      "eval_runtime": 8.3337,
      "eval_samples_per_second": 23.999,
      "eval_steps_per_second": 23.999,
      "step": 4700
    },
    {
      "epoch": 9.42,
      "grad_norm": 1.8658121824264526,
      "learning_rate": 1.7878787878787877e-05,
      "loss": 0.1269,
      "step": 4710
    },
    {
      "epoch": 9.44,
      "grad_norm": 1.421907663345337,
      "learning_rate": 1.727272727272727e-05,
      "loss": 0.1591,
      "step": 4720
    },
    {
      "epoch": 9.46,
      "grad_norm": 0.6949044466018677,
      "learning_rate": 1.6666666666666664e-05,
      "loss": 0.1426,
      "step": 4730
    },
    {
      "epoch": 9.48,
      "grad_norm": 1.6241072416305542,
      "learning_rate": 1.6060606060606058e-05,
      "loss": 0.1458,
      "step": 4740
    },
    {
      "epoch": 9.5,
      "grad_norm": 1.9259300231933594,
      "learning_rate": 1.5454545454545454e-05,
      "loss": 0.1472,
      "step": 4750
    },
    {
      "epoch": 9.52,
      "grad_norm": 1.4483253955841064,
      "learning_rate": 1.4848484848484846e-05,
      "loss": 0.1377,
      "step": 4760
    },
    {
      "epoch": 9.54,
      "grad_norm": 1.7222025394439697,
      "learning_rate": 1.4242424242424241e-05,
      "loss": 0.1482,
      "step": 4770
    },
    {
      "epoch": 9.56,
      "grad_norm": 0.9668673872947693,
      "learning_rate": 1.3636363636363635e-05,
      "loss": 0.1411,
      "step": 4780
    },
    {
      "epoch": 9.58,
      "grad_norm": 1.5485191345214844,
      "learning_rate": 1.303030303030303e-05,
      "loss": 0.13,
      "step": 4790
    },
    {
      "epoch": 9.6,
      "grad_norm": 0.7883654832839966,
      "learning_rate": 1.2424242424242424e-05,
      "loss": 0.1362,
      "step": 4800
    },
    {
      "epoch": 9.6,
      "eval_loss": 1.3444796800613403,
      "eval_runtime": 8.7526,
      "eval_samples_per_second": 22.85,
      "eval_steps_per_second": 22.85,
      "step": 4800
    },
    {
      "epoch": 9.62,
      "grad_norm": 1.4055347442626953,
      "learning_rate": 1.1818181818181817e-05,
      "loss": 0.1496,
      "step": 4810
    },
    {
      "epoch": 9.64,
      "grad_norm": 1.3225412368774414,
      "learning_rate": 1.121212121212121e-05,
      "loss": 0.1465,
      "step": 4820
    },
    {
      "epoch": 9.66,
      "grad_norm": 1.3449029922485352,
      "learning_rate": 1.0606060606060604e-05,
      "loss": 0.1446,
      "step": 4830
    },
    {
      "epoch": 9.68,
      "grad_norm": 1.8200325965881348,
      "learning_rate": 9.999999999999999e-06,
      "loss": 0.1379,
      "step": 4840
    },
    {
      "epoch": 9.7,
      "grad_norm": 1.1093462705612183,
      "learning_rate": 9.393939393939393e-06,
      "loss": 0.132,
      "step": 4850
    },
    {
      "epoch": 9.72,
      "grad_norm": 1.725128173828125,
      "learning_rate": 8.787878787878788e-06,
      "loss": 0.1395,
      "step": 4860
    },
    {
      "epoch": 9.74,
      "grad_norm": 1.6892436742782593,
      "learning_rate": 8.181818181818181e-06,
      "loss": 0.184,
      "step": 4870
    },
    {
      "epoch": 9.76,
      "grad_norm": 1.6302423477172852,
      "learning_rate": 7.575757575757575e-06,
      "loss": 0.1382,
      "step": 4880
    },
    {
      "epoch": 9.78,
      "grad_norm": 1.5419827699661255,
      "learning_rate": 6.969696969696969e-06,
      "loss": 0.1355,
      "step": 4890
    },
    {
      "epoch": 9.8,
      "grad_norm": 1.6584222316741943,
      "learning_rate": 6.363636363636363e-06,
      "loss": 0.1283,
      "step": 4900
    },
    {
      "epoch": 9.8,
      "eval_loss": 1.341982126235962,
      "eval_runtime": 8.4402,
      "eval_samples_per_second": 23.696,
      "eval_steps_per_second": 23.696,
      "step": 4900
    },
    {
      "epoch": 9.82,
      "grad_norm": 1.5543631315231323,
      "learning_rate": 5.757575757575757e-06,
      "loss": 0.14,
      "step": 4910
    },
    {
      "epoch": 9.84,
      "grad_norm": 2.331653356552124,
      "learning_rate": 5.151515151515151e-06,
      "loss": 0.1378,
      "step": 4920
    },
    {
      "epoch": 9.86,
      "grad_norm": 1.229234218597412,
      "learning_rate": 4.5454545454545455e-06,
      "loss": 0.1275,
      "step": 4930
    },
    {
      "epoch": 9.88,
      "grad_norm": 3.225890636444092,
      "learning_rate": 3.939393939393939e-06,
      "loss": 0.1562,
      "step": 4940
    },
    {
      "epoch": 9.9,
      "grad_norm": 1.5185033082962036,
      "learning_rate": 3.3333333333333333e-06,
      "loss": 0.1544,
      "step": 4950
    },
    {
      "epoch": 9.92,
      "grad_norm": 1.61740243434906,
      "learning_rate": 2.727272727272727e-06,
      "loss": 0.1486,
      "step": 4960
    },
    {
      "epoch": 9.94,
      "grad_norm": 1.0317449569702148,
      "learning_rate": 2.121212121212121e-06,
      "loss": 0.116,
      "step": 4970
    },
    {
      "epoch": 9.96,
      "grad_norm": 1.8700026273727417,
      "learning_rate": 1.5151515151515152e-06,
      "loss": 0.1499,
      "step": 4980
    },
    {
      "epoch": 9.98,
      "grad_norm": 1.6406947374343872,
      "learning_rate": 9.09090909090909e-07,
      "loss": 0.1315,
      "step": 4990
    },
    {
      "epoch": 10.0,
      "grad_norm": 1.6273119449615479,
      "learning_rate": 3.03030303030303e-07,
      "loss": 0.1407,
      "step": 5000
    },
    {
      "epoch": 10.0,
      "eval_loss": 1.3432421684265137,
      "eval_runtime": 8.4911,
      "eval_samples_per_second": 23.554,
      "eval_steps_per_second": 23.554,
      "step": 5000
    }
  ],
  "logging_steps": 10,
  "max_steps": 5000,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 10,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 1.496916688896e+16,
  "train_batch_size": 1,
  "trial_name": null,
  "trial_params": null
}

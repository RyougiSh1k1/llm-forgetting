{
  "best_global_step": null,
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 9.0,
  "eval_steps": 100,
  "global_step": 4500,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.02,
      "grad_norm": 32.02870559692383,
      "learning_rate": 2.9999999999999997e-05,
      "loss": 5.2725,
      "step": 10
    },
    {
      "epoch": 0.04,
      "grad_norm": 10.145462989807129,
      "learning_rate": 8.999999999999999e-05,
      "loss": 4.042,
      "step": 20
    },
    {
      "epoch": 0.06,
      "grad_norm": 6.210398197174072,
      "learning_rate": 0.00015,
      "loss": 2.5659,
      "step": 30
    },
    {
      "epoch": 0.08,
      "grad_norm": 4.194079875946045,
      "learning_rate": 0.00020999999999999998,
      "loss": 1.7206,
      "step": 40
    },
    {
      "epoch": 0.1,
      "grad_norm": 2.9913997650146484,
      "learning_rate": 0.00027,
      "loss": 1.4575,
      "step": 50
    },
    {
      "epoch": 0.12,
      "grad_norm": 2.643197536468506,
      "learning_rate": 0.00029969696969696965,
      "loss": 1.4942,
      "step": 60
    },
    {
      "epoch": 0.14,
      "grad_norm": 2.1336703300476074,
      "learning_rate": 0.00029909090909090906,
      "loss": 1.4201,
      "step": 70
    },
    {
      "epoch": 0.16,
      "grad_norm": 2.5231645107269287,
      "learning_rate": 0.00029848484848484847,
      "loss": 1.3205,
      "step": 80
    },
    {
      "epoch": 0.18,
      "grad_norm": 2.210442066192627,
      "learning_rate": 0.00029787878787878783,
      "loss": 1.252,
      "step": 90
    },
    {
      "epoch": 0.2,
      "grad_norm": 3.1197147369384766,
      "learning_rate": 0.00029727272727272724,
      "loss": 1.0544,
      "step": 100
    },
    {
      "epoch": 0.2,
      "eval_loss": 1.3660175800323486,
      "eval_runtime": 8.3292,
      "eval_samples_per_second": 24.012,
      "eval_steps_per_second": 24.012,
      "step": 100
    },
    {
      "epoch": 0.22,
      "grad_norm": 3.2152767181396484,
      "learning_rate": 0.00029666666666666665,
      "loss": 1.1353,
      "step": 110
    },
    {
      "epoch": 0.24,
      "grad_norm": 2.7983715534210205,
      "learning_rate": 0.00029606060606060606,
      "loss": 1.3968,
      "step": 120
    },
    {
      "epoch": 0.26,
      "grad_norm": 2.870959520339966,
      "learning_rate": 0.0002954545454545454,
      "loss": 1.1186,
      "step": 130
    },
    {
      "epoch": 0.28,
      "grad_norm": 1.9130642414093018,
      "learning_rate": 0.0002948484848484848,
      "loss": 1.0588,
      "step": 140
    },
    {
      "epoch": 0.3,
      "grad_norm": 3.0966084003448486,
      "learning_rate": 0.00029424242424242424,
      "loss": 1.4192,
      "step": 150
    },
    {
      "epoch": 0.32,
      "grad_norm": 2.8281168937683105,
      "learning_rate": 0.0002936363636363636,
      "loss": 1.4458,
      "step": 160
    },
    {
      "epoch": 0.34,
      "grad_norm": 2.395942449569702,
      "learning_rate": 0.000293030303030303,
      "loss": 1.3854,
      "step": 170
    },
    {
      "epoch": 0.36,
      "grad_norm": 2.6172680854797363,
      "learning_rate": 0.00029242424242424236,
      "loss": 1.16,
      "step": 180
    },
    {
      "epoch": 0.38,
      "grad_norm": 2.201489210128784,
      "learning_rate": 0.0002918181818181818,
      "loss": 1.3443,
      "step": 190
    },
    {
      "epoch": 0.4,
      "grad_norm": 2.481471538543701,
      "learning_rate": 0.0002912121212121212,
      "loss": 1.1366,
      "step": 200
    },
    {
      "epoch": 0.4,
      "eval_loss": 1.2954025268554688,
      "eval_runtime": 8.2682,
      "eval_samples_per_second": 24.189,
      "eval_steps_per_second": 24.189,
      "step": 200
    },
    {
      "epoch": 0.42,
      "grad_norm": 1.8785288333892822,
      "learning_rate": 0.0002906060606060606,
      "loss": 1.3827,
      "step": 210
    },
    {
      "epoch": 0.44,
      "grad_norm": 1.5725271701812744,
      "learning_rate": 0.00029,
      "loss": 1.2076,
      "step": 220
    },
    {
      "epoch": 0.46,
      "grad_norm": 3.3210723400115967,
      "learning_rate": 0.00028939393939393936,
      "loss": 1.306,
      "step": 230
    },
    {
      "epoch": 0.48,
      "grad_norm": 1.8478087186813354,
      "learning_rate": 0.00028878787878787877,
      "loss": 1.2677,
      "step": 240
    },
    {
      "epoch": 0.5,
      "grad_norm": 2.554879903793335,
      "learning_rate": 0.0002881818181818181,
      "loss": 1.2409,
      "step": 250
    },
    {
      "epoch": 0.52,
      "grad_norm": 2.6163578033447266,
      "learning_rate": 0.00028757575757575753,
      "loss": 1.0882,
      "step": 260
    },
    {
      "epoch": 0.54,
      "grad_norm": 2.1531155109405518,
      "learning_rate": 0.00028696969696969695,
      "loss": 1.3768,
      "step": 270
    },
    {
      "epoch": 0.56,
      "grad_norm": 3.2901246547698975,
      "learning_rate": 0.00028636363636363636,
      "loss": 1.2196,
      "step": 280
    },
    {
      "epoch": 0.58,
      "grad_norm": 2.3378944396972656,
      "learning_rate": 0.00028575757575757577,
      "loss": 1.2505,
      "step": 290
    },
    {
      "epoch": 0.6,
      "grad_norm": 1.6698180437088013,
      "learning_rate": 0.0002851515151515151,
      "loss": 1.3925,
      "step": 300
    },
    {
      "epoch": 0.6,
      "eval_loss": 1.283450722694397,
      "eval_runtime": 8.3065,
      "eval_samples_per_second": 24.078,
      "eval_steps_per_second": 24.078,
      "step": 300
    },
    {
      "epoch": 0.62,
      "grad_norm": 2.315455913543701,
      "learning_rate": 0.00028454545454545453,
      "loss": 1.2047,
      "step": 310
    },
    {
      "epoch": 0.64,
      "grad_norm": 2.55448579788208,
      "learning_rate": 0.0002839393939393939,
      "loss": 1.0694,
      "step": 320
    },
    {
      "epoch": 0.66,
      "grad_norm": 1.8476028442382812,
      "learning_rate": 0.0002833333333333333,
      "loss": 1.2612,
      "step": 330
    },
    {
      "epoch": 0.68,
      "grad_norm": 2.171260118484497,
      "learning_rate": 0.0002827272727272727,
      "loss": 1.2861,
      "step": 340
    },
    {
      "epoch": 0.7,
      "grad_norm": 1.6289299726486206,
      "learning_rate": 0.00028212121212121207,
      "loss": 1.1251,
      "step": 350
    },
    {
      "epoch": 0.72,
      "grad_norm": 1.9088587760925293,
      "learning_rate": 0.00028151515151515153,
      "loss": 1.1057,
      "step": 360
    },
    {
      "epoch": 0.74,
      "grad_norm": 2.692324161529541,
      "learning_rate": 0.0002809090909090909,
      "loss": 1.3554,
      "step": 370
    },
    {
      "epoch": 0.76,
      "grad_norm": 2.9468917846679688,
      "learning_rate": 0.0002803030303030303,
      "loss": 1.3546,
      "step": 380
    },
    {
      "epoch": 0.78,
      "grad_norm": 2.7507822513580322,
      "learning_rate": 0.00027969696969696965,
      "loss": 1.4319,
      "step": 390
    },
    {
      "epoch": 0.8,
      "grad_norm": 1.9785808324813843,
      "learning_rate": 0.00027909090909090906,
      "loss": 1.185,
      "step": 400
    },
    {
      "epoch": 0.8,
      "eval_loss": 1.2734805345535278,
      "eval_runtime": 8.2388,
      "eval_samples_per_second": 24.275,
      "eval_steps_per_second": 24.275,
      "step": 400
    },
    {
      "epoch": 0.82,
      "grad_norm": 1.8422635793685913,
      "learning_rate": 0.0002784848484848485,
      "loss": 1.1266,
      "step": 410
    },
    {
      "epoch": 0.84,
      "grad_norm": 1.8456408977508545,
      "learning_rate": 0.00027787878787878783,
      "loss": 0.9997,
      "step": 420
    },
    {
      "epoch": 0.86,
      "grad_norm": 2.696457862854004,
      "learning_rate": 0.00027727272727272724,
      "loss": 1.4482,
      "step": 430
    },
    {
      "epoch": 0.88,
      "grad_norm": 2.0202760696411133,
      "learning_rate": 0.00027666666666666665,
      "loss": 1.2216,
      "step": 440
    },
    {
      "epoch": 0.9,
      "grad_norm": 2.1246447563171387,
      "learning_rate": 0.00027606060606060606,
      "loss": 1.2765,
      "step": 450
    },
    {
      "epoch": 0.92,
      "grad_norm": 3.494788408279419,
      "learning_rate": 0.0002754545454545454,
      "loss": 1.1684,
      "step": 460
    },
    {
      "epoch": 0.94,
      "grad_norm": 1.7071845531463623,
      "learning_rate": 0.00027484848484848483,
      "loss": 1.264,
      "step": 470
    },
    {
      "epoch": 0.96,
      "grad_norm": 1.9766799211502075,
      "learning_rate": 0.00027424242424242424,
      "loss": 1.333,
      "step": 480
    },
    {
      "epoch": 0.98,
      "grad_norm": 1.6463658809661865,
      "learning_rate": 0.0002736363636363636,
      "loss": 1.2499,
      "step": 490
    },
    {
      "epoch": 1.0,
      "grad_norm": 2.5879032611846924,
      "learning_rate": 0.000273030303030303,
      "loss": 1.4163,
      "step": 500
    },
    {
      "epoch": 1.0,
      "eval_loss": 1.262445330619812,
      "eval_runtime": 8.2485,
      "eval_samples_per_second": 24.247,
      "eval_steps_per_second": 24.247,
      "step": 500
    },
    {
      "epoch": 1.02,
      "grad_norm": 1.4777891635894775,
      "learning_rate": 0.0002724242424242424,
      "loss": 1.2179,
      "step": 510
    },
    {
      "epoch": 1.04,
      "grad_norm": 0.9841911792755127,
      "learning_rate": 0.00027181818181818177,
      "loss": 1.09,
      "step": 520
    },
    {
      "epoch": 1.06,
      "grad_norm": 2.3154807090759277,
      "learning_rate": 0.0002712121212121212,
      "loss": 0.8867,
      "step": 530
    },
    {
      "epoch": 1.08,
      "grad_norm": 4.706976413726807,
      "learning_rate": 0.0002706060606060606,
      "loss": 0.9486,
      "step": 540
    },
    {
      "epoch": 1.1,
      "grad_norm": 1.9752856492996216,
      "learning_rate": 0.00027,
      "loss": 0.9175,
      "step": 550
    },
    {
      "epoch": 1.12,
      "grad_norm": 1.949427604675293,
      "learning_rate": 0.00026939393939393936,
      "loss": 1.0235,
      "step": 560
    },
    {
      "epoch": 1.1400000000000001,
      "grad_norm": 3.2215139865875244,
      "learning_rate": 0.00026878787878787877,
      "loss": 0.9971,
      "step": 570
    },
    {
      "epoch": 1.16,
      "grad_norm": 2.081408977508545,
      "learning_rate": 0.0002681818181818181,
      "loss": 0.9583,
      "step": 580
    },
    {
      "epoch": 1.18,
      "grad_norm": 2.88950777053833,
      "learning_rate": 0.00026757575757575754,
      "loss": 1.1203,
      "step": 590
    },
    {
      "epoch": 1.2,
      "grad_norm": 2.4707090854644775,
      "learning_rate": 0.00026696969696969695,
      "loss": 1.0369,
      "step": 600
    },
    {
      "epoch": 1.2,
      "eval_loss": 1.2966678142547607,
      "eval_runtime": 8.2722,
      "eval_samples_per_second": 24.177,
      "eval_steps_per_second": 24.177,
      "step": 600
    },
    {
      "epoch": 1.22,
      "grad_norm": 2.133521556854248,
      "learning_rate": 0.00026636363636363636,
      "loss": 1.1845,
      "step": 610
    },
    {
      "epoch": 1.24,
      "grad_norm": 2.6044516563415527,
      "learning_rate": 0.00026575757575757577,
      "loss": 0.872,
      "step": 620
    },
    {
      "epoch": 1.26,
      "grad_norm": 3.150174140930176,
      "learning_rate": 0.0002651515151515151,
      "loss": 1.1765,
      "step": 630
    },
    {
      "epoch": 1.28,
      "grad_norm": 2.3491387367248535,
      "learning_rate": 0.00026454545454545453,
      "loss": 0.9493,
      "step": 640
    },
    {
      "epoch": 1.3,
      "grad_norm": 2.2699105739593506,
      "learning_rate": 0.0002639393939393939,
      "loss": 0.9001,
      "step": 650
    },
    {
      "epoch": 1.32,
      "grad_norm": 2.8257999420166016,
      "learning_rate": 0.0002633333333333333,
      "loss": 0.9945,
      "step": 660
    },
    {
      "epoch": 1.34,
      "grad_norm": 2.914652109146118,
      "learning_rate": 0.0002627272727272727,
      "loss": 1.0108,
      "step": 670
    },
    {
      "epoch": 1.3599999999999999,
      "grad_norm": 2.3415818214416504,
      "learning_rate": 0.00026212121212121207,
      "loss": 1.0989,
      "step": 680
    },
    {
      "epoch": 1.38,
      "grad_norm": 2.741408586502075,
      "learning_rate": 0.0002615151515151515,
      "loss": 1.0233,
      "step": 690
    },
    {
      "epoch": 1.4,
      "grad_norm": 2.7968640327453613,
      "learning_rate": 0.0002609090909090909,
      "loss": 1.2084,
      "step": 700
    },
    {
      "epoch": 1.4,
      "eval_loss": 1.2900768518447876,
      "eval_runtime": 8.2413,
      "eval_samples_per_second": 24.268,
      "eval_steps_per_second": 24.268,
      "step": 700
    },
    {
      "epoch": 1.42,
      "grad_norm": 2.1202824115753174,
      "learning_rate": 0.0002603030303030303,
      "loss": 1.082,
      "step": 710
    },
    {
      "epoch": 1.44,
      "grad_norm": 2.213059186935425,
      "learning_rate": 0.00025969696969696966,
      "loss": 1.04,
      "step": 720
    },
    {
      "epoch": 1.46,
      "grad_norm": 2.3688600063323975,
      "learning_rate": 0.00025909090909090907,
      "loss": 1.0787,
      "step": 730
    },
    {
      "epoch": 1.48,
      "grad_norm": 1.7648769617080688,
      "learning_rate": 0.0002584848484848485,
      "loss": 0.8886,
      "step": 740
    },
    {
      "epoch": 1.5,
      "grad_norm": 2.364196538925171,
      "learning_rate": 0.00025787878787878783,
      "loss": 0.9894,
      "step": 750
    },
    {
      "epoch": 1.52,
      "grad_norm": 2.5636391639709473,
      "learning_rate": 0.00025727272727272724,
      "loss": 0.9421,
      "step": 760
    },
    {
      "epoch": 1.54,
      "grad_norm": 2.694531202316284,
      "learning_rate": 0.00025666666666666665,
      "loss": 1.0747,
      "step": 770
    },
    {
      "epoch": 1.56,
      "grad_norm": 2.033560037612915,
      "learning_rate": 0.000256060606060606,
      "loss": 0.8927,
      "step": 780
    },
    {
      "epoch": 1.58,
      "grad_norm": 2.605903148651123,
      "learning_rate": 0.0002554545454545454,
      "loss": 1.0484,
      "step": 790
    },
    {
      "epoch": 1.6,
      "grad_norm": 2.612090587615967,
      "learning_rate": 0.00025484848484848483,
      "loss": 1.066,
      "step": 800
    },
    {
      "epoch": 1.6,
      "eval_loss": 1.29002046585083,
      "eval_runtime": 8.3414,
      "eval_samples_per_second": 23.977,
      "eval_steps_per_second": 23.977,
      "step": 800
    },
    {
      "epoch": 1.62,
      "grad_norm": 2.1888115406036377,
      "learning_rate": 0.00025424242424242424,
      "loss": 1.0727,
      "step": 810
    },
    {
      "epoch": 1.6400000000000001,
      "grad_norm": 2.9331812858581543,
      "learning_rate": 0.0002536363636363636,
      "loss": 1.0554,
      "step": 820
    },
    {
      "epoch": 1.6600000000000001,
      "grad_norm": 3.1528141498565674,
      "learning_rate": 0.000253030303030303,
      "loss": 1.1908,
      "step": 830
    },
    {
      "epoch": 1.6800000000000002,
      "grad_norm": 3.491569757461548,
      "learning_rate": 0.0002524242424242424,
      "loss": 1.2358,
      "step": 840
    },
    {
      "epoch": 1.7,
      "grad_norm": 2.7796850204467773,
      "learning_rate": 0.0002518181818181818,
      "loss": 0.8899,
      "step": 850
    },
    {
      "epoch": 1.72,
      "grad_norm": 2.571221351623535,
      "learning_rate": 0.0002512121212121212,
      "loss": 1.0602,
      "step": 860
    },
    {
      "epoch": 1.74,
      "grad_norm": 2.211547613143921,
      "learning_rate": 0.0002506060606060606,
      "loss": 0.9602,
      "step": 870
    },
    {
      "epoch": 1.76,
      "grad_norm": 2.949052095413208,
      "learning_rate": 0.00025,
      "loss": 1.1482,
      "step": 880
    },
    {
      "epoch": 1.78,
      "grad_norm": 2.4538369178771973,
      "learning_rate": 0.00024939393939393936,
      "loss": 1.0179,
      "step": 890
    },
    {
      "epoch": 1.8,
      "grad_norm": 2.3834073543548584,
      "learning_rate": 0.00024878787878787877,
      "loss": 0.959,
      "step": 900
    },
    {
      "epoch": 1.8,
      "eval_loss": 1.288864254951477,
      "eval_runtime": 8.3092,
      "eval_samples_per_second": 24.07,
      "eval_steps_per_second": 24.07,
      "step": 900
    },
    {
      "epoch": 1.8199999999999998,
      "grad_norm": 3.000385046005249,
      "learning_rate": 0.0002481818181818182,
      "loss": 0.9831,
      "step": 910
    },
    {
      "epoch": 1.8399999999999999,
      "grad_norm": 3.6233901977539062,
      "learning_rate": 0.00024757575757575754,
      "loss": 1.1991,
      "step": 920
    },
    {
      "epoch": 1.8599999999999999,
      "grad_norm": 2.485677719116211,
      "learning_rate": 0.00024696969696969695,
      "loss": 0.9371,
      "step": 930
    },
    {
      "epoch": 1.88,
      "grad_norm": 3.0964043140411377,
      "learning_rate": 0.0002463636363636363,
      "loss": 1.0437,
      "step": 940
    },
    {
      "epoch": 1.9,
      "grad_norm": 2.90208101272583,
      "learning_rate": 0.0002457575757575757,
      "loss": 0.9256,
      "step": 950
    },
    {
      "epoch": 1.92,
      "grad_norm": 2.6524245738983154,
      "learning_rate": 0.0002451515151515151,
      "loss": 0.9225,
      "step": 960
    },
    {
      "epoch": 1.94,
      "grad_norm": 3.500490188598633,
      "learning_rate": 0.00024454545454545454,
      "loss": 0.884,
      "step": 970
    },
    {
      "epoch": 1.96,
      "grad_norm": 3.3867812156677246,
      "learning_rate": 0.00024393939393939392,
      "loss": 1.2458,
      "step": 980
    },
    {
      "epoch": 1.98,
      "grad_norm": 3.885849714279175,
      "learning_rate": 0.0002433333333333333,
      "loss": 1.1831,
      "step": 990
    },
    {
      "epoch": 2.0,
      "grad_norm": 2.1688830852508545,
      "learning_rate": 0.0002427272727272727,
      "loss": 0.8041,
      "step": 1000
    },
    {
      "epoch": 2.0,
      "eval_loss": 1.2837220430374146,
      "eval_runtime": 8.3124,
      "eval_samples_per_second": 24.06,
      "eval_steps_per_second": 24.06,
      "step": 1000
    },
    {
      "epoch": 2.02,
      "grad_norm": 3.651637077331543,
      "learning_rate": 0.0002421212121212121,
      "loss": 0.6147,
      "step": 1010
    },
    {
      "epoch": 2.04,
      "grad_norm": 3.4891889095306396,
      "learning_rate": 0.00024151515151515148,
      "loss": 0.6481,
      "step": 1020
    },
    {
      "epoch": 2.06,
      "grad_norm": 3.2252304553985596,
      "learning_rate": 0.00024090909090909086,
      "loss": 0.8588,
      "step": 1030
    },
    {
      "epoch": 2.08,
      "grad_norm": 4.084847450256348,
      "learning_rate": 0.0002403030303030303,
      "loss": 0.7197,
      "step": 1040
    },
    {
      "epoch": 2.1,
      "grad_norm": 3.1168324947357178,
      "learning_rate": 0.00023969696969696968,
      "loss": 0.6316,
      "step": 1050
    },
    {
      "epoch": 2.12,
      "grad_norm": 0.3550378680229187,
      "learning_rate": 0.00023909090909090907,
      "loss": 0.9205,
      "step": 1060
    },
    {
      "epoch": 2.14,
      "grad_norm": 3.1786932945251465,
      "learning_rate": 0.00023848484848484848,
      "loss": 0.7811,
      "step": 1070
    },
    {
      "epoch": 2.16,
      "grad_norm": 2.8667116165161133,
      "learning_rate": 0.00023787878787878786,
      "loss": 0.853,
      "step": 1080
    },
    {
      "epoch": 2.18,
      "grad_norm": 2.5972487926483154,
      "learning_rate": 0.00023727272727272724,
      "loss": 0.7165,
      "step": 1090
    },
    {
      "epoch": 2.2,
      "grad_norm": 5.528200626373291,
      "learning_rate": 0.00023666666666666663,
      "loss": 0.6677,
      "step": 1100
    },
    {
      "epoch": 2.2,
      "eval_loss": 1.4045063257217407,
      "eval_runtime": 8.2349,
      "eval_samples_per_second": 24.287,
      "eval_steps_per_second": 24.287,
      "step": 1100
    },
    {
      "epoch": 2.22,
      "grad_norm": 3.380598783493042,
      "learning_rate": 0.00023606060606060604,
      "loss": 0.769,
      "step": 1110
    },
    {
      "epoch": 2.24,
      "grad_norm": 4.0323805809021,
      "learning_rate": 0.00023545454545454542,
      "loss": 0.7951,
      "step": 1120
    },
    {
      "epoch": 2.26,
      "grad_norm": 2.2024731636047363,
      "learning_rate": 0.00023484848484848483,
      "loss": 0.6518,
      "step": 1130
    },
    {
      "epoch": 2.2800000000000002,
      "grad_norm": 3.0161120891571045,
      "learning_rate": 0.00023424242424242424,
      "loss": 0.8424,
      "step": 1140
    },
    {
      "epoch": 2.3,
      "grad_norm": 3.992997884750366,
      "learning_rate": 0.00023363636363636363,
      "loss": 0.6852,
      "step": 1150
    },
    {
      "epoch": 2.32,
      "grad_norm": 3.6781113147735596,
      "learning_rate": 0.000233030303030303,
      "loss": 0.6815,
      "step": 1160
    },
    {
      "epoch": 2.34,
      "grad_norm": 1.9307647943496704,
      "learning_rate": 0.0002324242424242424,
      "loss": 0.7053,
      "step": 1170
    },
    {
      "epoch": 2.36,
      "grad_norm": 3.22884464263916,
      "learning_rate": 0.0002318181818181818,
      "loss": 0.8024,
      "step": 1180
    },
    {
      "epoch": 2.38,
      "grad_norm": 3.7474448680877686,
      "learning_rate": 0.00023121212121212119,
      "loss": 0.8304,
      "step": 1190
    },
    {
      "epoch": 2.4,
      "grad_norm": 3.2476541996002197,
      "learning_rate": 0.00023060606060606057,
      "loss": 0.7077,
      "step": 1200
    },
    {
      "epoch": 2.4,
      "eval_loss": 1.4181727170944214,
      "eval_runtime": 8.2219,
      "eval_samples_per_second": 24.325,
      "eval_steps_per_second": 24.325,
      "step": 1200
    },
    {
      "epoch": 2.42,
      "grad_norm": 3.509516954421997,
      "learning_rate": 0.00023,
      "loss": 0.7361,
      "step": 1210
    },
    {
      "epoch": 2.44,
      "grad_norm": 3.2190301418304443,
      "learning_rate": 0.0002293939393939394,
      "loss": 0.8102,
      "step": 1220
    },
    {
      "epoch": 2.46,
      "grad_norm": 3.054670572280884,
      "learning_rate": 0.00022878787878787877,
      "loss": 0.6564,
      "step": 1230
    },
    {
      "epoch": 2.48,
      "grad_norm": 1.834457516670227,
      "learning_rate": 0.00022818181818181816,
      "loss": 0.756,
      "step": 1240
    },
    {
      "epoch": 2.5,
      "grad_norm": 3.8381824493408203,
      "learning_rate": 0.00022757575757575757,
      "loss": 0.7439,
      "step": 1250
    },
    {
      "epoch": 2.52,
      "grad_norm": 2.667880058288574,
      "learning_rate": 0.00022696969696969695,
      "loss": 0.7426,
      "step": 1260
    },
    {
      "epoch": 2.54,
      "grad_norm": 2.9230704307556152,
      "learning_rate": 0.00022636363636363633,
      "loss": 0.8402,
      "step": 1270
    },
    {
      "epoch": 2.56,
      "grad_norm": 2.403378486633301,
      "learning_rate": 0.00022575757575757572,
      "loss": 0.7558,
      "step": 1280
    },
    {
      "epoch": 2.58,
      "grad_norm": 3.6861329078674316,
      "learning_rate": 0.00022515151515151513,
      "loss": 0.8997,
      "step": 1290
    },
    {
      "epoch": 2.6,
      "grad_norm": 4.080573558807373,
      "learning_rate": 0.00022454545454545454,
      "loss": 0.8379,
      "step": 1300
    },
    {
      "epoch": 2.6,
      "eval_loss": 1.384596586227417,
      "eval_runtime": 8.3359,
      "eval_samples_per_second": 23.993,
      "eval_steps_per_second": 23.993,
      "step": 1300
    },
    {
      "epoch": 2.62,
      "grad_norm": 4.392024517059326,
      "learning_rate": 0.00022393939393939392,
      "loss": 0.7262,
      "step": 1310
    },
    {
      "epoch": 2.64,
      "grad_norm": 3.788243055343628,
      "learning_rate": 0.00022333333333333333,
      "loss": 0.8344,
      "step": 1320
    },
    {
      "epoch": 2.66,
      "grad_norm": 2.546309471130371,
      "learning_rate": 0.00022272727272727272,
      "loss": 0.8917,
      "step": 1330
    },
    {
      "epoch": 2.68,
      "grad_norm": 3.0928139686584473,
      "learning_rate": 0.0002221212121212121,
      "loss": 0.7373,
      "step": 1340
    },
    {
      "epoch": 2.7,
      "grad_norm": 3.5262062549591064,
      "learning_rate": 0.00022151515151515148,
      "loss": 0.6459,
      "step": 1350
    },
    {
      "epoch": 2.7199999999999998,
      "grad_norm": 3.7494282722473145,
      "learning_rate": 0.0002209090909090909,
      "loss": 0.7424,
      "step": 1360
    },
    {
      "epoch": 2.74,
      "grad_norm": 3.889599084854126,
      "learning_rate": 0.00022030303030303028,
      "loss": 0.7611,
      "step": 1370
    },
    {
      "epoch": 2.76,
      "grad_norm": 4.515241622924805,
      "learning_rate": 0.00021969696969696969,
      "loss": 0.7509,
      "step": 1380
    },
    {
      "epoch": 2.7800000000000002,
      "grad_norm": 3.877457857131958,
      "learning_rate": 0.0002190909090909091,
      "loss": 0.7244,
      "step": 1390
    },
    {
      "epoch": 2.8,
      "grad_norm": 4.047255516052246,
      "learning_rate": 0.00021848484848484848,
      "loss": 0.6941,
      "step": 1400
    },
    {
      "epoch": 2.8,
      "eval_loss": 1.387237548828125,
      "eval_runtime": 8.3299,
      "eval_samples_per_second": 24.01,
      "eval_steps_per_second": 24.01,
      "step": 1400
    },
    {
      "epoch": 2.82,
      "grad_norm": 3.179429292678833,
      "learning_rate": 0.00021787878787878786,
      "loss": 0.7899,
      "step": 1410
    },
    {
      "epoch": 2.84,
      "grad_norm": 2.045783758163452,
      "learning_rate": 0.00021727272727272725,
      "loss": 0.8002,
      "step": 1420
    },
    {
      "epoch": 2.86,
      "grad_norm": 3.7849791049957275,
      "learning_rate": 0.00021666666666666666,
      "loss": 0.7242,
      "step": 1430
    },
    {
      "epoch": 2.88,
      "grad_norm": 4.110982418060303,
      "learning_rate": 0.00021606060606060604,
      "loss": 0.6603,
      "step": 1440
    },
    {
      "epoch": 2.9,
      "grad_norm": 2.9739160537719727,
      "learning_rate": 0.00021545454545454542,
      "loss": 0.7823,
      "step": 1450
    },
    {
      "epoch": 2.92,
      "grad_norm": 3.2334794998168945,
      "learning_rate": 0.0002148484848484848,
      "loss": 0.7041,
      "step": 1460
    },
    {
      "epoch": 2.94,
      "grad_norm": 2.48734712600708,
      "learning_rate": 0.00021424242424242424,
      "loss": 0.7655,
      "step": 1470
    },
    {
      "epoch": 2.96,
      "grad_norm": 4.056192398071289,
      "learning_rate": 0.00021363636363636363,
      "loss": 0.7672,
      "step": 1480
    },
    {
      "epoch": 2.98,
      "grad_norm": 4.775844097137451,
      "learning_rate": 0.000213030303030303,
      "loss": 0.8961,
      "step": 1490
    },
    {
      "epoch": 3.0,
      "grad_norm": 1.5941241979599,
      "learning_rate": 0.00021242424242424242,
      "loss": 0.7403,
      "step": 1500
    },
    {
      "epoch": 3.0,
      "eval_loss": 1.3619701862335205,
      "eval_runtime": 8.3182,
      "eval_samples_per_second": 24.044,
      "eval_steps_per_second": 24.044,
      "step": 1500
    },
    {
      "epoch": 3.02,
      "grad_norm": 2.5707502365112305,
      "learning_rate": 0.0002118181818181818,
      "loss": 0.5732,
      "step": 1510
    },
    {
      "epoch": 3.04,
      "grad_norm": 4.27816104888916,
      "learning_rate": 0.0002112121212121212,
      "loss": 0.5794,
      "step": 1520
    },
    {
      "epoch": 3.06,
      "grad_norm": 0.7271040678024292,
      "learning_rate": 0.00021060606060606057,
      "loss": 0.4149,
      "step": 1530
    },
    {
      "epoch": 3.08,
      "grad_norm": 3.4079267978668213,
      "learning_rate": 0.00020999999999999998,
      "loss": 0.5815,
      "step": 1540
    },
    {
      "epoch": 3.1,
      "grad_norm": 4.081483364105225,
      "learning_rate": 0.0002093939393939394,
      "loss": 0.4055,
      "step": 1550
    },
    {
      "epoch": 3.12,
      "grad_norm": 1.2498431205749512,
      "learning_rate": 0.00020878787878787878,
      "loss": 0.4288,
      "step": 1560
    },
    {
      "epoch": 3.14,
      "grad_norm": 5.491903305053711,
      "learning_rate": 0.00020818181818181816,
      "loss": 0.4012,
      "step": 1570
    },
    {
      "epoch": 3.16,
      "grad_norm": 2.306130886077881,
      "learning_rate": 0.00020757575757575757,
      "loss": 0.4816,
      "step": 1580
    },
    {
      "epoch": 3.18,
      "grad_norm": 3.437021017074585,
      "learning_rate": 0.00020696969696969695,
      "loss": 0.5375,
      "step": 1590
    },
    {
      "epoch": 3.2,
      "grad_norm": 3.4722001552581787,
      "learning_rate": 0.00020636363636363634,
      "loss": 0.6426,
      "step": 1600
    },
    {
      "epoch": 3.2,
      "eval_loss": 1.5466901063919067,
      "eval_runtime": 8.3151,
      "eval_samples_per_second": 24.053,
      "eval_steps_per_second": 24.053,
      "step": 1600
    },
    {
      "epoch": 3.22,
      "grad_norm": 4.120647430419922,
      "learning_rate": 0.00020575757575757572,
      "loss": 0.4154,
      "step": 1610
    },
    {
      "epoch": 3.24,
      "grad_norm": 3.1641790866851807,
      "learning_rate": 0.00020515151515151513,
      "loss": 0.5219,
      "step": 1620
    },
    {
      "epoch": 3.26,
      "grad_norm": 4.832020282745361,
      "learning_rate": 0.0002045454545454545,
      "loss": 0.4825,
      "step": 1630
    },
    {
      "epoch": 3.2800000000000002,
      "grad_norm": 5.349400997161865,
      "learning_rate": 0.00020393939393939392,
      "loss": 0.5421,
      "step": 1640
    },
    {
      "epoch": 3.3,
      "grad_norm": 4.52305793762207,
      "learning_rate": 0.00020333333333333333,
      "loss": 0.6629,
      "step": 1650
    },
    {
      "epoch": 3.32,
      "grad_norm": 5.061840057373047,
      "learning_rate": 0.00020272727272727272,
      "loss": 0.5481,
      "step": 1660
    },
    {
      "epoch": 3.34,
      "grad_norm": 4.0849833488464355,
      "learning_rate": 0.0002021212121212121,
      "loss": 0.521,
      "step": 1670
    },
    {
      "epoch": 3.36,
      "grad_norm": 6.471419811248779,
      "learning_rate": 0.00020151515151515148,
      "loss": 0.5067,
      "step": 1680
    },
    {
      "epoch": 3.38,
      "grad_norm": 4.614651203155518,
      "learning_rate": 0.0002009090909090909,
      "loss": 0.5445,
      "step": 1690
    },
    {
      "epoch": 3.4,
      "grad_norm": 1.4806171655654907,
      "learning_rate": 0.00020030303030303028,
      "loss": 0.4808,
      "step": 1700
    },
    {
      "epoch": 3.4,
      "eval_loss": 1.5282750129699707,
      "eval_runtime": 8.3493,
      "eval_samples_per_second": 23.954,
      "eval_steps_per_second": 23.954,
      "step": 1700
    },
    {
      "epoch": 3.42,
      "grad_norm": 0.5793550610542297,
      "learning_rate": 0.00019969696969696966,
      "loss": 0.5384,
      "step": 1710
    },
    {
      "epoch": 3.44,
      "grad_norm": 3.6086626052856445,
      "learning_rate": 0.0001990909090909091,
      "loss": 0.6274,
      "step": 1720
    },
    {
      "epoch": 3.46,
      "grad_norm": 2.635056495666504,
      "learning_rate": 0.00019848484848484848,
      "loss": 0.4702,
      "step": 1730
    },
    {
      "epoch": 3.48,
      "grad_norm": 3.331787109375,
      "learning_rate": 0.00019787878787878786,
      "loss": 0.4647,
      "step": 1740
    },
    {
      "epoch": 3.5,
      "grad_norm": 4.512632846832275,
      "learning_rate": 0.00019727272727272725,
      "loss": 0.5397,
      "step": 1750
    },
    {
      "epoch": 3.52,
      "grad_norm": 1.6637694835662842,
      "learning_rate": 0.00019666666666666666,
      "loss": 0.6128,
      "step": 1760
    },
    {
      "epoch": 3.54,
      "grad_norm": 4.553053379058838,
      "learning_rate": 0.00019606060606060604,
      "loss": 0.4602,
      "step": 1770
    },
    {
      "epoch": 3.56,
      "grad_norm": 5.373507499694824,
      "learning_rate": 0.00019545454545454543,
      "loss": 0.453,
      "step": 1780
    },
    {
      "epoch": 3.58,
      "grad_norm": 5.966502666473389,
      "learning_rate": 0.0001948484848484848,
      "loss": 0.5652,
      "step": 1790
    },
    {
      "epoch": 3.6,
      "grad_norm": 5.013939380645752,
      "learning_rate": 0.00019424242424242422,
      "loss": 0.3941,
      "step": 1800
    },
    {
      "epoch": 3.6,
      "eval_loss": 1.5630714893341064,
      "eval_runtime": 8.2359,
      "eval_samples_per_second": 24.284,
      "eval_steps_per_second": 24.284,
      "step": 1800
    },
    {
      "epoch": 3.62,
      "grad_norm": 6.575456142425537,
      "learning_rate": 0.00019363636363636363,
      "loss": 0.5343,
      "step": 1810
    },
    {
      "epoch": 3.64,
      "grad_norm": 2.9940309524536133,
      "learning_rate": 0.000193030303030303,
      "loss": 0.519,
      "step": 1820
    },
    {
      "epoch": 3.66,
      "grad_norm": 3.6993906497955322,
      "learning_rate": 0.00019242424242424242,
      "loss": 0.3786,
      "step": 1830
    },
    {
      "epoch": 3.68,
      "grad_norm": 1.1064848899841309,
      "learning_rate": 0.0001918181818181818,
      "loss": 0.5138,
      "step": 1840
    },
    {
      "epoch": 3.7,
      "grad_norm": 2.060715913772583,
      "learning_rate": 0.0001912121212121212,
      "loss": 0.4543,
      "step": 1850
    },
    {
      "epoch": 3.7199999999999998,
      "grad_norm": 5.485967636108398,
      "learning_rate": 0.00019060606060606057,
      "loss": 0.5995,
      "step": 1860
    },
    {
      "epoch": 3.74,
      "grad_norm": 5.785320281982422,
      "learning_rate": 0.00018999999999999998,
      "loss": 0.6425,
      "step": 1870
    },
    {
      "epoch": 3.76,
      "grad_norm": 5.234272480010986,
      "learning_rate": 0.00018939393939393937,
      "loss": 0.504,
      "step": 1880
    },
    {
      "epoch": 3.7800000000000002,
      "grad_norm": 2.497426986694336,
      "learning_rate": 0.00018878787878787878,
      "loss": 0.6175,
      "step": 1890
    },
    {
      "epoch": 3.8,
      "grad_norm": 4.775697231292725,
      "learning_rate": 0.0001881818181818182,
      "loss": 0.5522,
      "step": 1900
    },
    {
      "epoch": 3.8,
      "eval_loss": 1.5221221446990967,
      "eval_runtime": 8.2175,
      "eval_samples_per_second": 24.338,
      "eval_steps_per_second": 24.338,
      "step": 1900
    },
    {
      "epoch": 3.82,
      "grad_norm": 3.6990768909454346,
      "learning_rate": 0.00018757575757575757,
      "loss": 0.3955,
      "step": 1910
    },
    {
      "epoch": 3.84,
      "grad_norm": 5.750975608825684,
      "learning_rate": 0.00018696969696969695,
      "loss": 0.5577,
      "step": 1920
    },
    {
      "epoch": 3.86,
      "grad_norm": 3.3422224521636963,
      "learning_rate": 0.00018636363636363634,
      "loss": 0.5125,
      "step": 1930
    },
    {
      "epoch": 3.88,
      "grad_norm": 4.14088249206543,
      "learning_rate": 0.00018575757575757575,
      "loss": 0.5088,
      "step": 1940
    },
    {
      "epoch": 3.9,
      "grad_norm": 4.121521472930908,
      "learning_rate": 0.00018515151515151513,
      "loss": 0.6285,
      "step": 1950
    },
    {
      "epoch": 3.92,
      "grad_norm": 4.3906402587890625,
      "learning_rate": 0.00018454545454545451,
      "loss": 0.6121,
      "step": 1960
    },
    {
      "epoch": 3.94,
      "grad_norm": 2.74240779876709,
      "learning_rate": 0.0001839393939393939,
      "loss": 0.4965,
      "step": 1970
    },
    {
      "epoch": 3.96,
      "grad_norm": 3.3906240463256836,
      "learning_rate": 0.00018333333333333334,
      "loss": 0.6939,
      "step": 1980
    },
    {
      "epoch": 3.98,
      "grad_norm": 2.8770980834960938,
      "learning_rate": 0.00018272727272727272,
      "loss": 0.4048,
      "step": 1990
    },
    {
      "epoch": 4.0,
      "grad_norm": 3.5315067768096924,
      "learning_rate": 0.0001821212121212121,
      "loss": 0.4745,
      "step": 2000
    },
    {
      "epoch": 4.0,
      "eval_loss": 1.5719510316848755,
      "eval_runtime": 8.2422,
      "eval_samples_per_second": 24.265,
      "eval_steps_per_second": 24.265,
      "step": 2000
    },
    {
      "epoch": 4.02,
      "grad_norm": 4.903780937194824,
      "learning_rate": 0.0001815151515151515,
      "loss": 0.3893,
      "step": 2010
    },
    {
      "epoch": 4.04,
      "grad_norm": 2.421797037124634,
      "learning_rate": 0.0001809090909090909,
      "loss": 0.2693,
      "step": 2020
    },
    {
      "epoch": 4.06,
      "grad_norm": 4.209273338317871,
      "learning_rate": 0.00018030303030303028,
      "loss": 0.3378,
      "step": 2030
    },
    {
      "epoch": 4.08,
      "grad_norm": 4.04603910446167,
      "learning_rate": 0.00017969696969696966,
      "loss": 0.4105,
      "step": 2040
    },
    {
      "epoch": 4.1,
      "grad_norm": 5.588329315185547,
      "learning_rate": 0.00017909090909090907,
      "loss": 0.3023,
      "step": 2050
    },
    {
      "epoch": 4.12,
      "grad_norm": 1.6485629081726074,
      "learning_rate": 0.00017848484848484846,
      "loss": 0.2862,
      "step": 2060
    },
    {
      "epoch": 4.14,
      "grad_norm": 5.294388771057129,
      "learning_rate": 0.00017787878787878787,
      "loss": 0.2423,
      "step": 2070
    },
    {
      "epoch": 4.16,
      "grad_norm": 4.9173431396484375,
      "learning_rate": 0.00017727272727272728,
      "loss": 0.2372,
      "step": 2080
    },
    {
      "epoch": 4.18,
      "grad_norm": 4.762533664703369,
      "learning_rate": 0.00017666666666666666,
      "loss": 0.3795,
      "step": 2090
    },
    {
      "epoch": 4.2,
      "grad_norm": 1.5097863674163818,
      "learning_rate": 0.00017606060606060604,
      "loss": 0.2729,
      "step": 2100
    },
    {
      "epoch": 4.2,
      "eval_loss": 1.674826979637146,
      "eval_runtime": 8.3353,
      "eval_samples_per_second": 23.994,
      "eval_steps_per_second": 23.994,
      "step": 2100
    },
    {
      "epoch": 4.22,
      "grad_norm": 4.690376281738281,
      "learning_rate": 0.00017545454545454543,
      "loss": 0.2395,
      "step": 2110
    },
    {
      "epoch": 4.24,
      "grad_norm": 2.399904727935791,
      "learning_rate": 0.00017484848484848484,
      "loss": 0.2605,
      "step": 2120
    },
    {
      "epoch": 4.26,
      "grad_norm": 4.4073004722595215,
      "learning_rate": 0.00017424242424242422,
      "loss": 0.2347,
      "step": 2130
    },
    {
      "epoch": 4.28,
      "grad_norm": 5.5622639656066895,
      "learning_rate": 0.0001736363636363636,
      "loss": 0.3372,
      "step": 2140
    },
    {
      "epoch": 4.3,
      "grad_norm": 4.097209453582764,
      "learning_rate": 0.00017303030303030304,
      "loss": 0.3514,
      "step": 2150
    },
    {
      "epoch": 4.32,
      "grad_norm": 0.7115416526794434,
      "learning_rate": 0.00017242424242424242,
      "loss": 0.3845,
      "step": 2160
    },
    {
      "epoch": 4.34,
      "grad_norm": 5.946709156036377,
      "learning_rate": 0.0001718181818181818,
      "loss": 0.2851,
      "step": 2170
    },
    {
      "epoch": 4.36,
      "grad_norm": 2.581040620803833,
      "learning_rate": 0.0001712121212121212,
      "loss": 0.4095,
      "step": 2180
    },
    {
      "epoch": 4.38,
      "grad_norm": 2.4214115142822266,
      "learning_rate": 0.0001706060606060606,
      "loss": 0.3027,
      "step": 2190
    },
    {
      "epoch": 4.4,
      "grad_norm": 4.548612594604492,
      "learning_rate": 0.00016999999999999999,
      "loss": 0.3891,
      "step": 2200
    },
    {
      "epoch": 4.4,
      "eval_loss": 1.7162590026855469,
      "eval_runtime": 8.3428,
      "eval_samples_per_second": 23.973,
      "eval_steps_per_second": 23.973,
      "step": 2200
    },
    {
      "epoch": 4.42,
      "grad_norm": 3.3720059394836426,
      "learning_rate": 0.00016939393939393937,
      "loss": 0.3753,
      "step": 2210
    },
    {
      "epoch": 4.44,
      "grad_norm": 4.159976482391357,
      "learning_rate": 0.00016878787878787875,
      "loss": 0.3822,
      "step": 2220
    },
    {
      "epoch": 4.46,
      "grad_norm": 3.9824059009552,
      "learning_rate": 0.00016818181818181816,
      "loss": 0.2584,
      "step": 2230
    },
    {
      "epoch": 4.48,
      "grad_norm": 4.6532769203186035,
      "learning_rate": 0.00016757575757575757,
      "loss": 0.3506,
      "step": 2240
    },
    {
      "epoch": 4.5,
      "grad_norm": 4.986306667327881,
      "learning_rate": 0.00016696969696969696,
      "loss": 0.3704,
      "step": 2250
    },
    {
      "epoch": 4.52,
      "grad_norm": 5.57359504699707,
      "learning_rate": 0.00016636363636363637,
      "loss": 0.3007,
      "step": 2260
    },
    {
      "epoch": 4.54,
      "grad_norm": 2.4103212356567383,
      "learning_rate": 0.00016575757575757575,
      "loss": 0.3139,
      "step": 2270
    },
    {
      "epoch": 4.5600000000000005,
      "grad_norm": 5.209704875946045,
      "learning_rate": 0.00016515151515151513,
      "loss": 0.6325,
      "step": 2280
    },
    {
      "epoch": 4.58,
      "grad_norm": 1.3484309911727905,
      "learning_rate": 0.00016454545454545452,
      "loss": 0.3225,
      "step": 2290
    },
    {
      "epoch": 4.6,
      "grad_norm": 10.479171752929688,
      "learning_rate": 0.00016393939393939393,
      "loss": 0.3613,
      "step": 2300
    },
    {
      "epoch": 4.6,
      "eval_loss": 1.6602606773376465,
      "eval_runtime": 8.3196,
      "eval_samples_per_second": 24.04,
      "eval_steps_per_second": 24.04,
      "step": 2300
    },
    {
      "epoch": 4.62,
      "grad_norm": 3.3547983169555664,
      "learning_rate": 0.0001633333333333333,
      "loss": 0.2505,
      "step": 2310
    },
    {
      "epoch": 4.64,
      "grad_norm": 3.784263849258423,
      "learning_rate": 0.00016272727272727272,
      "loss": 0.5224,
      "step": 2320
    },
    {
      "epoch": 4.66,
      "grad_norm": 2.143306255340576,
      "learning_rate": 0.00016212121212121213,
      "loss": 0.3971,
      "step": 2330
    },
    {
      "epoch": 4.68,
      "grad_norm": 6.772907257080078,
      "learning_rate": 0.00016151515151515151,
      "loss": 0.3226,
      "step": 2340
    },
    {
      "epoch": 4.7,
      "grad_norm": 3.5673720836639404,
      "learning_rate": 0.0001609090909090909,
      "loss": 0.4284,
      "step": 2350
    },
    {
      "epoch": 4.72,
      "grad_norm": 4.351171970367432,
      "learning_rate": 0.00016030303030303028,
      "loss": 0.3611,
      "step": 2360
    },
    {
      "epoch": 4.74,
      "grad_norm": 5.337055206298828,
      "learning_rate": 0.0001596969696969697,
      "loss": 0.5468,
      "step": 2370
    },
    {
      "epoch": 4.76,
      "grad_norm": 1.9212242364883423,
      "learning_rate": 0.00015909090909090907,
      "loss": 0.3274,
      "step": 2380
    },
    {
      "epoch": 4.78,
      "grad_norm": 2.9319825172424316,
      "learning_rate": 0.00015848484848484846,
      "loss": 0.3492,
      "step": 2390
    },
    {
      "epoch": 4.8,
      "grad_norm": 5.1534576416015625,
      "learning_rate": 0.00015787878787878784,
      "loss": 0.4428,
      "step": 2400
    },
    {
      "epoch": 4.8,
      "eval_loss": 1.7169071435928345,
      "eval_runtime": 8.3171,
      "eval_samples_per_second": 24.047,
      "eval_steps_per_second": 24.047,
      "step": 2400
    },
    {
      "epoch": 4.82,
      "grad_norm": 4.450857162475586,
      "learning_rate": 0.00015727272727272728,
      "loss": 0.3837,
      "step": 2410
    },
    {
      "epoch": 4.84,
      "grad_norm": 5.598669052124023,
      "learning_rate": 0.00015666666666666666,
      "loss": 0.4543,
      "step": 2420
    },
    {
      "epoch": 4.86,
      "grad_norm": 4.750267505645752,
      "learning_rate": 0.00015606060606060605,
      "loss": 0.3917,
      "step": 2430
    },
    {
      "epoch": 4.88,
      "grad_norm": 3.9535655975341797,
      "learning_rate": 0.00015545454545454546,
      "loss": 0.3374,
      "step": 2440
    },
    {
      "epoch": 4.9,
      "grad_norm": 4.493166923522949,
      "learning_rate": 0.00015484848484848484,
      "loss": 0.3423,
      "step": 2450
    },
    {
      "epoch": 4.92,
      "grad_norm": 2.940704822540283,
      "learning_rate": 0.00015424242424242422,
      "loss": 0.3779,
      "step": 2460
    },
    {
      "epoch": 4.9399999999999995,
      "grad_norm": 1.0761830806732178,
      "learning_rate": 0.0001536363636363636,
      "loss": 0.3489,
      "step": 2470
    },
    {
      "epoch": 4.96,
      "grad_norm": 4.16510009765625,
      "learning_rate": 0.00015303030303030302,
      "loss": 0.3415,
      "step": 2480
    },
    {
      "epoch": 4.98,
      "grad_norm": 7.022369384765625,
      "learning_rate": 0.00015242424242424243,
      "loss": 0.3468,
      "step": 2490
    },
    {
      "epoch": 5.0,
      "grad_norm": 4.3351569175720215,
      "learning_rate": 0.0001518181818181818,
      "loss": 0.3256,
      "step": 2500
    },
    {
      "epoch": 5.0,
      "eval_loss": 1.689801812171936,
      "eval_runtime": 8.2851,
      "eval_samples_per_second": 24.14,
      "eval_steps_per_second": 24.14,
      "step": 2500
    },
    {
      "epoch": 5.02,
      "grad_norm": 8.606159210205078,
      "learning_rate": 0.00015121212121212122,
      "loss": 0.2647,
      "step": 2510
    },
    {
      "epoch": 5.04,
      "grad_norm": 1.3361890316009521,
      "learning_rate": 0.0001506060606060606,
      "loss": 0.227,
      "step": 2520
    },
    {
      "epoch": 5.06,
      "grad_norm": 2.4199202060699463,
      "learning_rate": 0.00015,
      "loss": 0.2328,
      "step": 2530
    },
    {
      "epoch": 5.08,
      "grad_norm": 2.3975417613983154,
      "learning_rate": 0.00014939393939393937,
      "loss": 0.2173,
      "step": 2540
    },
    {
      "epoch": 5.1,
      "grad_norm": 5.18161678314209,
      "learning_rate": 0.00014878787878787875,
      "loss": 0.2863,
      "step": 2550
    },
    {
      "epoch": 5.12,
      "grad_norm": 0.9499752521514893,
      "learning_rate": 0.00014818181818181816,
      "loss": 0.1995,
      "step": 2560
    },
    {
      "epoch": 5.14,
      "grad_norm": 1.6032984256744385,
      "learning_rate": 0.00014757575757575757,
      "loss": 0.2611,
      "step": 2570
    },
    {
      "epoch": 5.16,
      "grad_norm": 2.5202391147613525,
      "learning_rate": 0.00014696969696969696,
      "loss": 0.3539,
      "step": 2580
    },
    {
      "epoch": 5.18,
      "grad_norm": 1.7121713161468506,
      "learning_rate": 0.00014636363636363634,
      "loss": 0.3197,
      "step": 2590
    },
    {
      "epoch": 5.2,
      "grad_norm": 3.3209879398345947,
      "learning_rate": 0.00014575757575757575,
      "loss": 0.2125,
      "step": 2600
    },
    {
      "epoch": 5.2,
      "eval_loss": 1.843842625617981,
      "eval_runtime": 8.341,
      "eval_samples_per_second": 23.978,
      "eval_steps_per_second": 23.978,
      "step": 2600
    },
    {
      "epoch": 5.22,
      "grad_norm": 4.9994378089904785,
      "learning_rate": 0.00014515151515151513,
      "loss": 0.2085,
      "step": 2610
    },
    {
      "epoch": 5.24,
      "grad_norm": 0.787366509437561,
      "learning_rate": 0.00014454545454545452,
      "loss": 0.2107,
      "step": 2620
    },
    {
      "epoch": 5.26,
      "grad_norm": 1.2013776302337646,
      "learning_rate": 0.00014393939393939393,
      "loss": 0.2355,
      "step": 2630
    },
    {
      "epoch": 5.28,
      "grad_norm": 5.339505672454834,
      "learning_rate": 0.00014333333333333334,
      "loss": 0.1873,
      "step": 2640
    },
    {
      "epoch": 5.3,
      "grad_norm": 4.128903865814209,
      "learning_rate": 0.00014272727272727272,
      "loss": 0.2208,
      "step": 2650
    },
    {
      "epoch": 5.32,
      "grad_norm": 2.703300952911377,
      "learning_rate": 0.0001421212121212121,
      "loss": 0.2514,
      "step": 2660
    },
    {
      "epoch": 5.34,
      "grad_norm": 3.7197210788726807,
      "learning_rate": 0.0001415151515151515,
      "loss": 0.2727,
      "step": 2670
    },
    {
      "epoch": 5.36,
      "grad_norm": 5.681389808654785,
      "learning_rate": 0.0001409090909090909,
      "loss": 0.2478,
      "step": 2680
    },
    {
      "epoch": 5.38,
      "grad_norm": 3.5001795291900635,
      "learning_rate": 0.00014030303030303028,
      "loss": 0.247,
      "step": 2690
    },
    {
      "epoch": 5.4,
      "grad_norm": 6.389021873474121,
      "learning_rate": 0.0001396969696969697,
      "loss": 0.198,
      "step": 2700
    },
    {
      "epoch": 5.4,
      "eval_loss": 1.8904500007629395,
      "eval_runtime": 8.292,
      "eval_samples_per_second": 24.12,
      "eval_steps_per_second": 24.12,
      "step": 2700
    },
    {
      "epoch": 5.42,
      "grad_norm": 2.1633546352386475,
      "learning_rate": 0.00013909090909090908,
      "loss": 0.2078,
      "step": 2710
    },
    {
      "epoch": 5.44,
      "grad_norm": 5.764666557312012,
      "learning_rate": 0.00013848484848484846,
      "loss": 0.2192,
      "step": 2720
    },
    {
      "epoch": 5.46,
      "grad_norm": 2.467573642730713,
      "learning_rate": 0.00013787878787878787,
      "loss": 0.266,
      "step": 2730
    },
    {
      "epoch": 5.48,
      "grad_norm": 3.797478675842285,
      "learning_rate": 0.00013727272727272725,
      "loss": 0.2103,
      "step": 2740
    },
    {
      "epoch": 5.5,
      "grad_norm": 2.620788812637329,
      "learning_rate": 0.00013666666666666666,
      "loss": 0.2548,
      "step": 2750
    },
    {
      "epoch": 5.52,
      "grad_norm": 5.13503360748291,
      "learning_rate": 0.00013606060606060605,
      "loss": 0.2358,
      "step": 2760
    },
    {
      "epoch": 5.54,
      "grad_norm": 4.798820495605469,
      "learning_rate": 0.00013545454545454546,
      "loss": 0.2113,
      "step": 2770
    },
    {
      "epoch": 5.5600000000000005,
      "grad_norm": 2.7508702278137207,
      "learning_rate": 0.00013484848484848484,
      "loss": 0.2258,
      "step": 2780
    },
    {
      "epoch": 5.58,
      "grad_norm": 4.2274017333984375,
      "learning_rate": 0.00013424242424242422,
      "loss": 0.2337,
      "step": 2790
    },
    {
      "epoch": 5.6,
      "grad_norm": 6.69598913192749,
      "learning_rate": 0.0001336363636363636,
      "loss": 0.3774,
      "step": 2800
    },
    {
      "epoch": 5.6,
      "eval_loss": 1.8181172609329224,
      "eval_runtime": 8.3189,
      "eval_samples_per_second": 24.042,
      "eval_steps_per_second": 24.042,
      "step": 2800
    },
    {
      "epoch": 5.62,
      "grad_norm": 3.2097694873809814,
      "learning_rate": 0.00013303030303030302,
      "loss": 0.2653,
      "step": 2810
    },
    {
      "epoch": 5.64,
      "grad_norm": 5.2912516593933105,
      "learning_rate": 0.00013242424242424243,
      "loss": 0.2744,
      "step": 2820
    },
    {
      "epoch": 5.66,
      "grad_norm": 5.7086405754089355,
      "learning_rate": 0.0001318181818181818,
      "loss": 0.2719,
      "step": 2830
    },
    {
      "epoch": 5.68,
      "grad_norm": 3.569978952407837,
      "learning_rate": 0.0001312121212121212,
      "loss": 0.2083,
      "step": 2840
    },
    {
      "epoch": 5.7,
      "grad_norm": 1.504376769065857,
      "learning_rate": 0.00013060606060606058,
      "loss": 0.2287,
      "step": 2850
    },
    {
      "epoch": 5.72,
      "grad_norm": 1.5570921897888184,
      "learning_rate": 0.00013,
      "loss": 0.1982,
      "step": 2860
    },
    {
      "epoch": 5.74,
      "grad_norm": 2.092280626296997,
      "learning_rate": 0.00012939393939393937,
      "loss": 0.1865,
      "step": 2870
    },
    {
      "epoch": 5.76,
      "grad_norm": 0.7117984890937805,
      "learning_rate": 0.00012878787878787878,
      "loss": 0.2596,
      "step": 2880
    },
    {
      "epoch": 5.78,
      "grad_norm": 4.805862903594971,
      "learning_rate": 0.00012818181818181817,
      "loss": 0.1849,
      "step": 2890
    },
    {
      "epoch": 5.8,
      "grad_norm": 1.0906567573547363,
      "learning_rate": 0.00012757575757575758,
      "loss": 0.2039,
      "step": 2900
    },
    {
      "epoch": 5.8,
      "eval_loss": 1.9048593044281006,
      "eval_runtime": 8.338,
      "eval_samples_per_second": 23.986,
      "eval_steps_per_second": 23.986,
      "step": 2900
    },
    {
      "epoch": 5.82,
      "grad_norm": 3.9580726623535156,
      "learning_rate": 0.00012696969696969696,
      "loss": 0.2868,
      "step": 2910
    },
    {
      "epoch": 5.84,
      "grad_norm": 1.4556251764297485,
      "learning_rate": 0.00012636363636363634,
      "loss": 0.2919,
      "step": 2920
    },
    {
      "epoch": 5.86,
      "grad_norm": 3.6854984760284424,
      "learning_rate": 0.00012575757575757575,
      "loss": 0.2559,
      "step": 2930
    },
    {
      "epoch": 5.88,
      "grad_norm": 3.769350528717041,
      "learning_rate": 0.00012515151515151514,
      "loss": 0.2085,
      "step": 2940
    },
    {
      "epoch": 5.9,
      "grad_norm": 5.3778157234191895,
      "learning_rate": 0.00012454545454545455,
      "loss": 0.2762,
      "step": 2950
    },
    {
      "epoch": 5.92,
      "grad_norm": 6.189671516418457,
      "learning_rate": 0.00012393939393939393,
      "loss": 0.4164,
      "step": 2960
    },
    {
      "epoch": 5.9399999999999995,
      "grad_norm": 2.3428051471710205,
      "learning_rate": 0.0001233333333333333,
      "loss": 0.2484,
      "step": 2970
    },
    {
      "epoch": 5.96,
      "grad_norm": 4.757964611053467,
      "learning_rate": 0.00012272727272727272,
      "loss": 0.2473,
      "step": 2980
    },
    {
      "epoch": 5.98,
      "grad_norm": 3.5423600673675537,
      "learning_rate": 0.0001221212121212121,
      "loss": 0.3193,
      "step": 2990
    },
    {
      "epoch": 6.0,
      "grad_norm": 5.506838798522949,
      "learning_rate": 0.0001215151515151515,
      "loss": 0.2496,
      "step": 3000
    },
    {
      "epoch": 6.0,
      "eval_loss": 1.8852635622024536,
      "eval_runtime": 8.3206,
      "eval_samples_per_second": 24.037,
      "eval_steps_per_second": 24.037,
      "step": 3000
    },
    {
      "epoch": 6.02,
      "grad_norm": 0.8361535668373108,
      "learning_rate": 0.0001209090909090909,
      "loss": 0.1461,
      "step": 3010
    },
    {
      "epoch": 6.04,
      "grad_norm": 1.3948630094528198,
      "learning_rate": 0.00012030303030303028,
      "loss": 0.1523,
      "step": 3020
    },
    {
      "epoch": 6.06,
      "grad_norm": 3.4246301651000977,
      "learning_rate": 0.0001196969696969697,
      "loss": 0.1848,
      "step": 3030
    },
    {
      "epoch": 6.08,
      "grad_norm": 5.764403820037842,
      "learning_rate": 0.00011909090909090908,
      "loss": 0.2042,
      "step": 3040
    },
    {
      "epoch": 6.1,
      "grad_norm": 2.633141040802002,
      "learning_rate": 0.00011848484848484847,
      "loss": 0.1531,
      "step": 3050
    },
    {
      "epoch": 6.12,
      "grad_norm": 2.0677695274353027,
      "learning_rate": 0.00011787878787878786,
      "loss": 0.1677,
      "step": 3060
    },
    {
      "epoch": 6.14,
      "grad_norm": 0.8098371624946594,
      "learning_rate": 0.00011727272727272727,
      "loss": 0.1977,
      "step": 3070
    },
    {
      "epoch": 6.16,
      "grad_norm": 2.111524820327759,
      "learning_rate": 0.00011666666666666665,
      "loss": 0.212,
      "step": 3080
    },
    {
      "epoch": 6.18,
      "grad_norm": 7.130035400390625,
      "learning_rate": 0.00011606060606060605,
      "loss": 0.1744,
      "step": 3090
    },
    {
      "epoch": 6.2,
      "grad_norm": 2.644379138946533,
      "learning_rate": 0.00011545454545454543,
      "loss": 0.1408,
      "step": 3100
    },
    {
      "epoch": 6.2,
      "eval_loss": 2.092188835144043,
      "eval_runtime": 8.214,
      "eval_samples_per_second": 24.349,
      "eval_steps_per_second": 24.349,
      "step": 3100
    },
    {
      "epoch": 6.22,
      "grad_norm": 2.3364877700805664,
      "learning_rate": 0.00011484848484848484,
      "loss": 0.1842,
      "step": 3110
    },
    {
      "epoch": 6.24,
      "grad_norm": 2.5301895141601562,
      "learning_rate": 0.00011424242424242424,
      "loss": 0.183,
      "step": 3120
    },
    {
      "epoch": 6.26,
      "grad_norm": 1.6087886095046997,
      "learning_rate": 0.00011363636363636362,
      "loss": 0.1845,
      "step": 3130
    },
    {
      "epoch": 6.28,
      "grad_norm": 3.2097764015197754,
      "learning_rate": 0.00011303030303030302,
      "loss": 0.1723,
      "step": 3140
    },
    {
      "epoch": 6.3,
      "grad_norm": 3.8137474060058594,
      "learning_rate": 0.00011242424242424242,
      "loss": 0.1753,
      "step": 3150
    },
    {
      "epoch": 6.32,
      "grad_norm": 1.025673508644104,
      "learning_rate": 0.00011181818181818181,
      "loss": 0.2242,
      "step": 3160
    },
    {
      "epoch": 6.34,
      "grad_norm": 2.0824835300445557,
      "learning_rate": 0.0001112121212121212,
      "loss": 0.1994,
      "step": 3170
    },
    {
      "epoch": 6.36,
      "grad_norm": 3.781259298324585,
      "learning_rate": 0.0001106060606060606,
      "loss": 0.1825,
      "step": 3180
    },
    {
      "epoch": 6.38,
      "grad_norm": 9.076025009155273,
      "learning_rate": 0.00010999999999999998,
      "loss": 0.1878,
      "step": 3190
    },
    {
      "epoch": 6.4,
      "grad_norm": 1.4512730836868286,
      "learning_rate": 0.00010939393939393939,
      "loss": 0.2123,
      "step": 3200
    },
    {
      "epoch": 6.4,
      "eval_loss": 1.964113473892212,
      "eval_runtime": 8.1891,
      "eval_samples_per_second": 24.423,
      "eval_steps_per_second": 24.423,
      "step": 3200
    },
    {
      "epoch": 6.42,
      "grad_norm": 1.1874847412109375,
      "learning_rate": 0.00010878787878787878,
      "loss": 0.1448,
      "step": 3210
    },
    {
      "epoch": 6.44,
      "grad_norm": 1.9310752153396606,
      "learning_rate": 0.00010818181818181817,
      "loss": 0.2437,
      "step": 3220
    },
    {
      "epoch": 6.46,
      "grad_norm": 1.678608775138855,
      "learning_rate": 0.00010757575757575756,
      "loss": 0.1741,
      "step": 3230
    },
    {
      "epoch": 6.48,
      "grad_norm": 2.083911418914795,
      "learning_rate": 0.00010696969696969696,
      "loss": 0.1948,
      "step": 3240
    },
    {
      "epoch": 6.5,
      "grad_norm": 2.3343863487243652,
      "learning_rate": 0.00010636363636363636,
      "loss": 0.2121,
      "step": 3250
    },
    {
      "epoch": 6.52,
      "grad_norm": 3.0670461654663086,
      "learning_rate": 0.00010575757575757574,
      "loss": 0.1736,
      "step": 3260
    },
    {
      "epoch": 6.54,
      "grad_norm": 1.8857301473617554,
      "learning_rate": 0.00010515151515151514,
      "loss": 0.147,
      "step": 3270
    },
    {
      "epoch": 6.5600000000000005,
      "grad_norm": 1.28678560256958,
      "learning_rate": 0.00010454545454545455,
      "loss": 0.1664,
      "step": 3280
    },
    {
      "epoch": 6.58,
      "grad_norm": 4.611325740814209,
      "learning_rate": 0.00010393939393939393,
      "loss": 0.272,
      "step": 3290
    },
    {
      "epoch": 6.6,
      "grad_norm": 1.7134389877319336,
      "learning_rate": 0.00010333333333333333,
      "loss": 0.1694,
      "step": 3300
    },
    {
      "epoch": 6.6,
      "eval_loss": 1.9933620691299438,
      "eval_runtime": 8.1847,
      "eval_samples_per_second": 24.436,
      "eval_steps_per_second": 24.436,
      "step": 3300
    },
    {
      "epoch": 6.62,
      "grad_norm": 1.4859619140625,
      "learning_rate": 0.00010272727272727271,
      "loss": 0.2177,
      "step": 3310
    },
    {
      "epoch": 6.64,
      "grad_norm": 5.178668975830078,
      "learning_rate": 0.00010212121212121212,
      "loss": 0.1307,
      "step": 3320
    },
    {
      "epoch": 6.66,
      "grad_norm": 1.6992425918579102,
      "learning_rate": 0.0001015151515151515,
      "loss": 0.1901,
      "step": 3330
    },
    {
      "epoch": 6.68,
      "grad_norm": 2.600160598754883,
      "learning_rate": 0.0001009090909090909,
      "loss": 0.1906,
      "step": 3340
    },
    {
      "epoch": 6.7,
      "grad_norm": 2.2915964126586914,
      "learning_rate": 0.00010030303030303029,
      "loss": 0.1447,
      "step": 3350
    },
    {
      "epoch": 6.72,
      "grad_norm": 2.6431257724761963,
      "learning_rate": 9.969696969696968e-05,
      "loss": 0.1807,
      "step": 3360
    },
    {
      "epoch": 6.74,
      "grad_norm": 4.562329292297363,
      "learning_rate": 9.90909090909091e-05,
      "loss": 0.202,
      "step": 3370
    },
    {
      "epoch": 6.76,
      "grad_norm": 4.013442516326904,
      "learning_rate": 9.848484848484848e-05,
      "loss": 0.2011,
      "step": 3380
    },
    {
      "epoch": 6.78,
      "grad_norm": 2.7629027366638184,
      "learning_rate": 9.787878787878787e-05,
      "loss": 0.1964,
      "step": 3390
    },
    {
      "epoch": 6.8,
      "grad_norm": 1.810715675354004,
      "learning_rate": 9.727272727272726e-05,
      "loss": 0.1663,
      "step": 3400
    },
    {
      "epoch": 6.8,
      "eval_loss": 2.019414186477661,
      "eval_runtime": 8.1541,
      "eval_samples_per_second": 24.527,
      "eval_steps_per_second": 24.527,
      "step": 3400
    },
    {
      "epoch": 6.82,
      "grad_norm": 1.66086745262146,
      "learning_rate": 9.666666666666667e-05,
      "loss": 0.2996,
      "step": 3410
    },
    {
      "epoch": 6.84,
      "grad_norm": 2.777531147003174,
      "learning_rate": 9.606060606060605e-05,
      "loss": 0.2241,
      "step": 3420
    },
    {
      "epoch": 6.86,
      "grad_norm": 2.0146896839141846,
      "learning_rate": 9.545454545454545e-05,
      "loss": 0.1699,
      "step": 3430
    },
    {
      "epoch": 6.88,
      "grad_norm": 1.8148337602615356,
      "learning_rate": 9.484848484848483e-05,
      "loss": 0.1789,
      "step": 3440
    },
    {
      "epoch": 6.9,
      "grad_norm": 3.3557939529418945,
      "learning_rate": 9.424242424242424e-05,
      "loss": 0.2057,
      "step": 3450
    },
    {
      "epoch": 6.92,
      "grad_norm": 4.8320536613464355,
      "learning_rate": 9.363636363636364e-05,
      "loss": 0.2009,
      "step": 3460
    },
    {
      "epoch": 6.9399999999999995,
      "grad_norm": 1.0158812999725342,
      "learning_rate": 9.303030303030302e-05,
      "loss": 0.2055,
      "step": 3470
    },
    {
      "epoch": 6.96,
      "grad_norm": 2.7078158855438232,
      "learning_rate": 9.242424242424242e-05,
      "loss": 0.1931,
      "step": 3480
    },
    {
      "epoch": 6.98,
      "grad_norm": 1.8418301343917847,
      "learning_rate": 9.18181818181818e-05,
      "loss": 0.1836,
      "step": 3490
    },
    {
      "epoch": 7.0,
      "grad_norm": 6.890593528747559,
      "learning_rate": 9.121212121212121e-05,
      "loss": 0.1639,
      "step": 3500
    },
    {
      "epoch": 7.0,
      "eval_loss": 2.024702310562134,
      "eval_runtime": 8.2032,
      "eval_samples_per_second": 24.381,
      "eval_steps_per_second": 24.381,
      "step": 3500
    },
    {
      "epoch": 7.02,
      "grad_norm": 1.0216397047042847,
      "learning_rate": 9.06060606060606e-05,
      "loss": 0.147,
      "step": 3510
    },
    {
      "epoch": 7.04,
      "grad_norm": 2.234367609024048,
      "learning_rate": 8.999999999999999e-05,
      "loss": 0.1223,
      "step": 3520
    },
    {
      "epoch": 7.06,
      "grad_norm": 0.7792496085166931,
      "learning_rate": 8.939393939393938e-05,
      "loss": 0.1853,
      "step": 3530
    },
    {
      "epoch": 7.08,
      "grad_norm": 2.0717389583587646,
      "learning_rate": 8.878787878787879e-05,
      "loss": 0.1462,
      "step": 3540
    },
    {
      "epoch": 7.1,
      "grad_norm": 1.8696368932724,
      "learning_rate": 8.818181818181817e-05,
      "loss": 0.1454,
      "step": 3550
    },
    {
      "epoch": 7.12,
      "grad_norm": 3.6444125175476074,
      "learning_rate": 8.757575757575757e-05,
      "loss": 0.142,
      "step": 3560
    },
    {
      "epoch": 7.14,
      "grad_norm": 4.935952186584473,
      "learning_rate": 8.696969696969695e-05,
      "loss": 0.1409,
      "step": 3570
    },
    {
      "epoch": 7.16,
      "grad_norm": 3.8376336097717285,
      "learning_rate": 8.636363636363636e-05,
      "loss": 0.1266,
      "step": 3580
    },
    {
      "epoch": 7.18,
      "grad_norm": 3.2733843326568604,
      "learning_rate": 8.575757575757576e-05,
      "loss": 0.163,
      "step": 3590
    },
    {
      "epoch": 7.2,
      "grad_norm": 1.1149851083755493,
      "learning_rate": 8.515151515151514e-05,
      "loss": 0.1284,
      "step": 3600
    },
    {
      "epoch": 7.2,
      "eval_loss": 2.1891555786132812,
      "eval_runtime": 8.2449,
      "eval_samples_per_second": 24.257,
      "eval_steps_per_second": 24.257,
      "step": 3600
    },
    {
      "epoch": 7.22,
      "grad_norm": 0.8022818565368652,
      "learning_rate": 8.454545454545454e-05,
      "loss": 0.1711,
      "step": 3610
    },
    {
      "epoch": 7.24,
      "grad_norm": 0.953373372554779,
      "learning_rate": 8.393939393939393e-05,
      "loss": 0.1785,
      "step": 3620
    },
    {
      "epoch": 7.26,
      "grad_norm": 1.526854395866394,
      "learning_rate": 8.333333333333333e-05,
      "loss": 0.1249,
      "step": 3630
    },
    {
      "epoch": 7.28,
      "grad_norm": 2.3945651054382324,
      "learning_rate": 8.272727272727271e-05,
      "loss": 0.1302,
      "step": 3640
    },
    {
      "epoch": 7.3,
      "grad_norm": 4.049917221069336,
      "learning_rate": 8.212121212121211e-05,
      "loss": 0.1637,
      "step": 3650
    },
    {
      "epoch": 7.32,
      "grad_norm": 1.4794472455978394,
      "learning_rate": 8.15151515151515e-05,
      "loss": 0.1712,
      "step": 3660
    },
    {
      "epoch": 7.34,
      "grad_norm": 2.1503865718841553,
      "learning_rate": 8.09090909090909e-05,
      "loss": 0.1497,
      "step": 3670
    },
    {
      "epoch": 7.36,
      "grad_norm": 1.1445361375808716,
      "learning_rate": 8.03030303030303e-05,
      "loss": 0.1396,
      "step": 3680
    },
    {
      "epoch": 7.38,
      "grad_norm": 1.3103454113006592,
      "learning_rate": 7.969696969696968e-05,
      "loss": 0.1468,
      "step": 3690
    },
    {
      "epoch": 7.4,
      "grad_norm": 1.2794445753097534,
      "learning_rate": 7.909090909090908e-05,
      "loss": 0.1395,
      "step": 3700
    },
    {
      "epoch": 7.4,
      "eval_loss": 2.1705238819122314,
      "eval_runtime": 8.2614,
      "eval_samples_per_second": 24.209,
      "eval_steps_per_second": 24.209,
      "step": 3700
    },
    {
      "epoch": 7.42,
      "grad_norm": 0.5821869373321533,
      "learning_rate": 7.848484848484848e-05,
      "loss": 0.1499,
      "step": 3710
    },
    {
      "epoch": 7.44,
      "grad_norm": 2.959044933319092,
      "learning_rate": 7.787878787878788e-05,
      "loss": 0.182,
      "step": 3720
    },
    {
      "epoch": 7.46,
      "grad_norm": 3.6610074043273926,
      "learning_rate": 7.727272727272726e-05,
      "loss": 0.1352,
      "step": 3730
    },
    {
      "epoch": 7.48,
      "grad_norm": 6.678468227386475,
      "learning_rate": 7.666666666666666e-05,
      "loss": 0.1564,
      "step": 3740
    },
    {
      "epoch": 7.5,
      "grad_norm": 0.6322497129440308,
      "learning_rate": 7.606060606060607e-05,
      "loss": 0.1479,
      "step": 3750
    },
    {
      "epoch": 7.52,
      "grad_norm": 1.3593276739120483,
      "learning_rate": 7.545454545454545e-05,
      "loss": 0.1382,
      "step": 3760
    },
    {
      "epoch": 7.54,
      "grad_norm": 2.458402633666992,
      "learning_rate": 7.484848484848485e-05,
      "loss": 0.1563,
      "step": 3770
    },
    {
      "epoch": 7.5600000000000005,
      "grad_norm": 0.8688251972198486,
      "learning_rate": 7.424242424242424e-05,
      "loss": 0.1277,
      "step": 3780
    },
    {
      "epoch": 7.58,
      "grad_norm": 1.180662989616394,
      "learning_rate": 7.363636363636363e-05,
      "loss": 0.1817,
      "step": 3790
    },
    {
      "epoch": 7.6,
      "grad_norm": 0.5522838234901428,
      "learning_rate": 7.303030303030302e-05,
      "loss": 0.1323,
      "step": 3800
    },
    {
      "epoch": 7.6,
      "eval_loss": 2.225022554397583,
      "eval_runtime": 8.2784,
      "eval_samples_per_second": 24.159,
      "eval_steps_per_second": 24.159,
      "step": 3800
    },
    {
      "epoch": 7.62,
      "grad_norm": 0.8552913069725037,
      "learning_rate": 7.242424242424242e-05,
      "loss": 0.1711,
      "step": 3810
    },
    {
      "epoch": 7.64,
      "grad_norm": 1.0474528074264526,
      "learning_rate": 7.18181818181818e-05,
      "loss": 0.1468,
      "step": 3820
    },
    {
      "epoch": 7.66,
      "grad_norm": 0.5383652448654175,
      "learning_rate": 7.12121212121212e-05,
      "loss": 0.1343,
      "step": 3830
    },
    {
      "epoch": 7.68,
      "grad_norm": 0.7480127215385437,
      "learning_rate": 7.06060606060606e-05,
      "loss": 0.1701,
      "step": 3840
    },
    {
      "epoch": 7.7,
      "grad_norm": 2.7470693588256836,
      "learning_rate": 7e-05,
      "loss": 0.1543,
      "step": 3850
    },
    {
      "epoch": 7.72,
      "grad_norm": 2.730005979537964,
      "learning_rate": 6.939393939393939e-05,
      "loss": 0.1381,
      "step": 3860
    },
    {
      "epoch": 7.74,
      "grad_norm": 1.08186936378479,
      "learning_rate": 6.878787878787879e-05,
      "loss": 0.1466,
      "step": 3870
    },
    {
      "epoch": 7.76,
      "grad_norm": 1.8507094383239746,
      "learning_rate": 6.818181818181817e-05,
      "loss": 0.1399,
      "step": 3880
    },
    {
      "epoch": 7.78,
      "grad_norm": 2.194869041442871,
      "learning_rate": 6.757575757575757e-05,
      "loss": 0.1362,
      "step": 3890
    },
    {
      "epoch": 7.8,
      "grad_norm": 1.2467769384384155,
      "learning_rate": 6.696969696969696e-05,
      "loss": 0.1407,
      "step": 3900
    },
    {
      "epoch": 7.8,
      "eval_loss": 2.1339972019195557,
      "eval_runtime": 8.2854,
      "eval_samples_per_second": 24.139,
      "eval_steps_per_second": 24.139,
      "step": 3900
    },
    {
      "epoch": 7.82,
      "grad_norm": 1.1913502216339111,
      "learning_rate": 6.636363636363636e-05,
      "loss": 0.1595,
      "step": 3910
    },
    {
      "epoch": 7.84,
      "grad_norm": 0.9297650456428528,
      "learning_rate": 6.575757575757574e-05,
      "loss": 0.1646,
      "step": 3920
    },
    {
      "epoch": 7.86,
      "grad_norm": 2.4415528774261475,
      "learning_rate": 6.515151515151516e-05,
      "loss": 0.1545,
      "step": 3930
    },
    {
      "epoch": 7.88,
      "grad_norm": 6.0333170890808105,
      "learning_rate": 6.454545454545454e-05,
      "loss": 0.1364,
      "step": 3940
    },
    {
      "epoch": 7.9,
      "grad_norm": 1.3511830568313599,
      "learning_rate": 6.393939393939394e-05,
      "loss": 0.1354,
      "step": 3950
    },
    {
      "epoch": 7.92,
      "grad_norm": 3.2282164096832275,
      "learning_rate": 6.333333333333333e-05,
      "loss": 0.169,
      "step": 3960
    },
    {
      "epoch": 7.9399999999999995,
      "grad_norm": 6.122347354888916,
      "learning_rate": 6.272727272727272e-05,
      "loss": 0.1675,
      "step": 3970
    },
    {
      "epoch": 7.96,
      "grad_norm": 1.1622090339660645,
      "learning_rate": 6.212121212121211e-05,
      "loss": 0.1348,
      "step": 3980
    },
    {
      "epoch": 7.98,
      "grad_norm": 1.3391526937484741,
      "learning_rate": 6.151515151515151e-05,
      "loss": 0.1443,
      "step": 3990
    },
    {
      "epoch": 8.0,
      "grad_norm": 4.412323951721191,
      "learning_rate": 6.0909090909090906e-05,
      "loss": 0.1635,
      "step": 4000
    },
    {
      "epoch": 8.0,
      "eval_loss": 2.2181143760681152,
      "eval_runtime": 8.2276,
      "eval_samples_per_second": 24.308,
      "eval_steps_per_second": 24.308,
      "step": 4000
    },
    {
      "epoch": 8.02,
      "grad_norm": 1.0355887413024902,
      "learning_rate": 6.0303030303030296e-05,
      "loss": 0.1212,
      "step": 4010
    },
    {
      "epoch": 8.04,
      "grad_norm": 2.8004391193389893,
      "learning_rate": 5.969696969696969e-05,
      "loss": 0.1144,
      "step": 4020
    },
    {
      "epoch": 8.06,
      "grad_norm": 1.2013682126998901,
      "learning_rate": 5.909090909090908e-05,
      "loss": 0.1014,
      "step": 4030
    },
    {
      "epoch": 8.08,
      "grad_norm": 1.317516565322876,
      "learning_rate": 5.848484848484848e-05,
      "loss": 0.1118,
      "step": 4040
    },
    {
      "epoch": 8.1,
      "grad_norm": 0.5260334014892578,
      "learning_rate": 5.787878787878787e-05,
      "loss": 0.1304,
      "step": 4050
    },
    {
      "epoch": 8.12,
      "grad_norm": 1.0028164386749268,
      "learning_rate": 5.727272727272727e-05,
      "loss": 0.103,
      "step": 4060
    },
    {
      "epoch": 8.14,
      "grad_norm": 1.991310477256775,
      "learning_rate": 5.666666666666666e-05,
      "loss": 0.1671,
      "step": 4070
    },
    {
      "epoch": 8.16,
      "grad_norm": 1.4493738412857056,
      "learning_rate": 5.606060606060606e-05,
      "loss": 0.1216,
      "step": 4080
    },
    {
      "epoch": 8.18,
      "grad_norm": 2.082364082336426,
      "learning_rate": 5.545454545454545e-05,
      "loss": 0.1088,
      "step": 4090
    },
    {
      "epoch": 8.2,
      "grad_norm": 0.8325381278991699,
      "learning_rate": 5.484848484848485e-05,
      "loss": 0.1086,
      "step": 4100
    },
    {
      "epoch": 8.2,
      "eval_loss": 2.3665502071380615,
      "eval_runtime": 8.2932,
      "eval_samples_per_second": 24.116,
      "eval_steps_per_second": 24.116,
      "step": 4100
    },
    {
      "epoch": 8.22,
      "grad_norm": 1.3591917753219604,
      "learning_rate": 5.424242424242424e-05,
      "loss": 0.1317,
      "step": 4110
    },
    {
      "epoch": 8.24,
      "grad_norm": 1.7315335273742676,
      "learning_rate": 5.3636363636363635e-05,
      "loss": 0.135,
      "step": 4120
    },
    {
      "epoch": 8.26,
      "grad_norm": 1.0110046863555908,
      "learning_rate": 5.3030303030303025e-05,
      "loss": 0.1162,
      "step": 4130
    },
    {
      "epoch": 8.28,
      "grad_norm": 2.6165611743927,
      "learning_rate": 5.2424242424242415e-05,
      "loss": 0.1285,
      "step": 4140
    },
    {
      "epoch": 8.3,
      "grad_norm": 1.2915655374526978,
      "learning_rate": 5.181818181818181e-05,
      "loss": 0.141,
      "step": 4150
    },
    {
      "epoch": 8.32,
      "grad_norm": 14.986353874206543,
      "learning_rate": 5.12121212121212e-05,
      "loss": 0.123,
      "step": 4160
    },
    {
      "epoch": 8.34,
      "grad_norm": 6.082688331604004,
      "learning_rate": 5.0606060606060606e-05,
      "loss": 0.1362,
      "step": 4170
    },
    {
      "epoch": 8.36,
      "grad_norm": 1.147938847541809,
      "learning_rate": 4.9999999999999996e-05,
      "loss": 0.1299,
      "step": 4180
    },
    {
      "epoch": 8.38,
      "grad_norm": 3.295071601867676,
      "learning_rate": 4.939393939393939e-05,
      "loss": 0.1387,
      "step": 4190
    },
    {
      "epoch": 8.4,
      "grad_norm": 0.9013842940330505,
      "learning_rate": 4.878787878787878e-05,
      "loss": 0.1274,
      "step": 4200
    },
    {
      "epoch": 8.4,
      "eval_loss": 2.2837462425231934,
      "eval_runtime": 8.2916,
      "eval_samples_per_second": 24.121,
      "eval_steps_per_second": 24.121,
      "step": 4200
    },
    {
      "epoch": 8.42,
      "grad_norm": 0.7547112703323364,
      "learning_rate": 4.818181818181818e-05,
      "loss": 0.1292,
      "step": 4210
    },
    {
      "epoch": 8.44,
      "grad_norm": 0.4906081259250641,
      "learning_rate": 4.757575757575757e-05,
      "loss": 0.1318,
      "step": 4220
    },
    {
      "epoch": 8.46,
      "grad_norm": 0.8030958771705627,
      "learning_rate": 4.6969696969696966e-05,
      "loss": 0.1174,
      "step": 4230
    },
    {
      "epoch": 8.48,
      "grad_norm": 1.8381434679031372,
      "learning_rate": 4.6363636363636356e-05,
      "loss": 0.1136,
      "step": 4240
    },
    {
      "epoch": 8.5,
      "grad_norm": 4.311324119567871,
      "learning_rate": 4.575757575757576e-05,
      "loss": 0.1455,
      "step": 4250
    },
    {
      "epoch": 8.52,
      "grad_norm": 0.8271865248680115,
      "learning_rate": 4.515151515151515e-05,
      "loss": 0.1234,
      "step": 4260
    },
    {
      "epoch": 8.54,
      "grad_norm": 1.7356926202774048,
      "learning_rate": 4.454545454545455e-05,
      "loss": 0.1387,
      "step": 4270
    },
    {
      "epoch": 8.56,
      "grad_norm": 1.9165256023406982,
      "learning_rate": 4.393939393939394e-05,
      "loss": 0.1216,
      "step": 4280
    },
    {
      "epoch": 8.58,
      "grad_norm": 0.7882190942764282,
      "learning_rate": 4.333333333333333e-05,
      "loss": 0.1271,
      "step": 4290
    },
    {
      "epoch": 8.6,
      "grad_norm": 1.709191918373108,
      "learning_rate": 4.2727272727272724e-05,
      "loss": 0.1129,
      "step": 4300
    },
    {
      "epoch": 8.6,
      "eval_loss": 2.2767832279205322,
      "eval_runtime": 8.2626,
      "eval_samples_per_second": 24.205,
      "eval_steps_per_second": 24.205,
      "step": 4300
    },
    {
      "epoch": 8.62,
      "grad_norm": 2.649200916290283,
      "learning_rate": 4.2121212121212114e-05,
      "loss": 0.1422,
      "step": 4310
    },
    {
      "epoch": 8.64,
      "grad_norm": 0.9128920435905457,
      "learning_rate": 4.151515151515151e-05,
      "loss": 0.1294,
      "step": 4320
    },
    {
      "epoch": 8.66,
      "grad_norm": 6.983687877655029,
      "learning_rate": 4.09090909090909e-05,
      "loss": 0.1456,
      "step": 4330
    },
    {
      "epoch": 8.68,
      "grad_norm": 1.648065447807312,
      "learning_rate": 4.03030303030303e-05,
      "loss": 0.1197,
      "step": 4340
    },
    {
      "epoch": 8.7,
      "grad_norm": 0.7564874291419983,
      "learning_rate": 3.969696969696969e-05,
      "loss": 0.128,
      "step": 4350
    },
    {
      "epoch": 8.72,
      "grad_norm": 1.8456004858016968,
      "learning_rate": 3.909090909090909e-05,
      "loss": 0.127,
      "step": 4360
    },
    {
      "epoch": 8.74,
      "grad_norm": 1.920303225517273,
      "learning_rate": 3.848484848484848e-05,
      "loss": 0.1292,
      "step": 4370
    },
    {
      "epoch": 8.76,
      "grad_norm": 2.1589412689208984,
      "learning_rate": 3.787878787878788e-05,
      "loss": 0.1143,
      "step": 4380
    },
    {
      "epoch": 8.78,
      "grad_norm": 0.9080641865730286,
      "learning_rate": 3.727272727272727e-05,
      "loss": 0.1431,
      "step": 4390
    },
    {
      "epoch": 8.8,
      "grad_norm": 1.656468152999878,
      "learning_rate": 3.666666666666666e-05,
      "loss": 0.117,
      "step": 4400
    },
    {
      "epoch": 8.8,
      "eval_loss": 2.2894763946533203,
      "eval_runtime": 8.3207,
      "eval_samples_per_second": 24.036,
      "eval_steps_per_second": 24.036,
      "step": 4400
    },
    {
      "epoch": 8.82,
      "grad_norm": 0.7906970977783203,
      "learning_rate": 3.6060606060606056e-05,
      "loss": 0.1375,
      "step": 4410
    },
    {
      "epoch": 8.84,
      "grad_norm": 1.219292402267456,
      "learning_rate": 3.545454545454545e-05,
      "loss": 0.1391,
      "step": 4420
    },
    {
      "epoch": 8.86,
      "grad_norm": 3.1305410861968994,
      "learning_rate": 3.484848484848484e-05,
      "loss": 0.1224,
      "step": 4430
    },
    {
      "epoch": 8.88,
      "grad_norm": 0.6384252309799194,
      "learning_rate": 3.424242424242424e-05,
      "loss": 0.1163,
      "step": 4440
    },
    {
      "epoch": 8.9,
      "grad_norm": 0.8254655003547668,
      "learning_rate": 3.3636363636363636e-05,
      "loss": 0.1249,
      "step": 4450
    },
    {
      "epoch": 8.92,
      "grad_norm": 3.0142834186553955,
      "learning_rate": 3.3030303030303027e-05,
      "loss": 0.1268,
      "step": 4460
    },
    {
      "epoch": 8.94,
      "grad_norm": 1.47151780128479,
      "learning_rate": 3.2424242424242423e-05,
      "loss": 0.1089,
      "step": 4470
    },
    {
      "epoch": 8.96,
      "grad_norm": 2.0658326148986816,
      "learning_rate": 3.1818181818181814e-05,
      "loss": 0.1246,
      "step": 4480
    },
    {
      "epoch": 8.98,
      "grad_norm": 2.0742690563201904,
      "learning_rate": 3.121212121212121e-05,
      "loss": 0.1289,
      "step": 4490
    },
    {
      "epoch": 9.0,
      "grad_norm": 1.518100380897522,
      "learning_rate": 3.060606060606061e-05,
      "loss": 0.122,
      "step": 4500
    },
    {
      "epoch": 9.0,
      "eval_loss": 2.288153886795044,
      "eval_runtime": 8.3048,
      "eval_samples_per_second": 24.083,
      "eval_steps_per_second": 24.083,
      "step": 4500
    }
  ],
  "logging_steps": 10,
  "max_steps": 5000,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 10,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 1.3472250200064e+16,
  "train_batch_size": 1,
  "trial_name": null,
  "trial_params": null
}

{
  "best_global_step": null,
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 9.0,
  "eval_steps": 100,
  "global_step": 4500,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.02,
      "grad_norm": 31.28758430480957,
      "learning_rate": 2.9999999999999997e-05,
      "loss": 5.2126,
      "step": 10
    },
    {
      "epoch": 0.04,
      "grad_norm": 8.872700691223145,
      "learning_rate": 8.999999999999999e-05,
      "loss": 3.9439,
      "step": 20
    },
    {
      "epoch": 0.06,
      "grad_norm": 7.80799674987793,
      "learning_rate": 0.00015,
      "loss": 2.5169,
      "step": 30
    },
    {
      "epoch": 0.08,
      "grad_norm": 4.180459022521973,
      "learning_rate": 0.00020999999999999998,
      "loss": 1.6772,
      "step": 40
    },
    {
      "epoch": 0.1,
      "grad_norm": 3.0585086345672607,
      "learning_rate": 0.00027,
      "loss": 1.4457,
      "step": 50
    },
    {
      "epoch": 0.12,
      "grad_norm": 3.5747177600860596,
      "learning_rate": 0.00029969696969696965,
      "loss": 1.4978,
      "step": 60
    },
    {
      "epoch": 0.14,
      "grad_norm": 2.162794589996338,
      "learning_rate": 0.00029909090909090906,
      "loss": 1.3961,
      "step": 70
    },
    {
      "epoch": 0.16,
      "grad_norm": 2.6843740940093994,
      "learning_rate": 0.00029848484848484847,
      "loss": 1.3182,
      "step": 80
    },
    {
      "epoch": 0.18,
      "grad_norm": 2.1938672065734863,
      "learning_rate": 0.00029787878787878783,
      "loss": 1.2587,
      "step": 90
    },
    {
      "epoch": 0.2,
      "grad_norm": 2.7818312644958496,
      "learning_rate": 0.00029727272727272724,
      "loss": 1.0574,
      "step": 100
    },
    {
      "epoch": 0.2,
      "eval_loss": 1.345418095588684,
      "eval_runtime": 8.4143,
      "eval_samples_per_second": 23.769,
      "eval_steps_per_second": 23.769,
      "step": 100
    },
    {
      "epoch": 0.22,
      "grad_norm": 3.2977216243743896,
      "learning_rate": 0.00029666666666666665,
      "loss": 1.0952,
      "step": 110
    },
    {
      "epoch": 0.24,
      "grad_norm": 2.541250467300415,
      "learning_rate": 0.00029606060606060606,
      "loss": 1.3984,
      "step": 120
    },
    {
      "epoch": 0.26,
      "grad_norm": 2.1734254360198975,
      "learning_rate": 0.0002954545454545454,
      "loss": 1.1099,
      "step": 130
    },
    {
      "epoch": 0.28,
      "grad_norm": 1.897099494934082,
      "learning_rate": 0.0002948484848484848,
      "loss": 1.0713,
      "step": 140
    },
    {
      "epoch": 0.3,
      "grad_norm": 3.0821828842163086,
      "learning_rate": 0.00029424242424242424,
      "loss": 1.4138,
      "step": 150
    },
    {
      "epoch": 0.32,
      "grad_norm": 2.373305082321167,
      "learning_rate": 0.0002936363636363636,
      "loss": 1.4566,
      "step": 160
    },
    {
      "epoch": 0.34,
      "grad_norm": 2.2257637977600098,
      "learning_rate": 0.000293030303030303,
      "loss": 1.3922,
      "step": 170
    },
    {
      "epoch": 0.36,
      "grad_norm": 2.7492926120758057,
      "learning_rate": 0.00029242424242424236,
      "loss": 1.1437,
      "step": 180
    },
    {
      "epoch": 0.38,
      "grad_norm": 2.3630120754241943,
      "learning_rate": 0.0002918181818181818,
      "loss": 1.3496,
      "step": 190
    },
    {
      "epoch": 0.4,
      "grad_norm": 2.9528963565826416,
      "learning_rate": 0.0002912121212121212,
      "loss": 1.1444,
      "step": 200
    },
    {
      "epoch": 0.4,
      "eval_loss": 1.2929012775421143,
      "eval_runtime": 8.4131,
      "eval_samples_per_second": 23.773,
      "eval_steps_per_second": 23.773,
      "step": 200
    },
    {
      "epoch": 0.42,
      "grad_norm": 1.9404034614562988,
      "learning_rate": 0.0002906060606060606,
      "loss": 1.3763,
      "step": 210
    },
    {
      "epoch": 0.44,
      "grad_norm": 1.9674240350723267,
      "learning_rate": 0.00029,
      "loss": 1.2012,
      "step": 220
    },
    {
      "epoch": 0.46,
      "grad_norm": 7.533624172210693,
      "learning_rate": 0.00028939393939393936,
      "loss": 1.3082,
      "step": 230
    },
    {
      "epoch": 0.48,
      "grad_norm": 2.04516863822937,
      "learning_rate": 0.00028878787878787877,
      "loss": 1.2799,
      "step": 240
    },
    {
      "epoch": 0.5,
      "grad_norm": 2.699460506439209,
      "learning_rate": 0.0002881818181818181,
      "loss": 1.2507,
      "step": 250
    },
    {
      "epoch": 0.52,
      "grad_norm": 2.4898202419281006,
      "learning_rate": 0.00028757575757575753,
      "loss": 1.1052,
      "step": 260
    },
    {
      "epoch": 0.54,
      "grad_norm": 2.209700584411621,
      "learning_rate": 0.00028696969696969695,
      "loss": 1.3935,
      "step": 270
    },
    {
      "epoch": 0.56,
      "grad_norm": 2.6665263175964355,
      "learning_rate": 0.00028636363636363636,
      "loss": 1.1974,
      "step": 280
    },
    {
      "epoch": 0.58,
      "grad_norm": 2.4106969833374023,
      "learning_rate": 0.00028575757575757577,
      "loss": 1.2567,
      "step": 290
    },
    {
      "epoch": 0.6,
      "grad_norm": 1.5377525091171265,
      "learning_rate": 0.0002851515151515151,
      "loss": 1.3866,
      "step": 300
    },
    {
      "epoch": 0.6,
      "eval_loss": 1.279677391052246,
      "eval_runtime": 8.33,
      "eval_samples_per_second": 24.01,
      "eval_steps_per_second": 24.01,
      "step": 300
    },
    {
      "epoch": 0.62,
      "grad_norm": 2.4338154792785645,
      "learning_rate": 0.00028454545454545453,
      "loss": 1.2154,
      "step": 310
    },
    {
      "epoch": 0.64,
      "grad_norm": 2.2161858081817627,
      "learning_rate": 0.0002839393939393939,
      "loss": 1.0712,
      "step": 320
    },
    {
      "epoch": 0.66,
      "grad_norm": 1.9274519681930542,
      "learning_rate": 0.0002833333333333333,
      "loss": 1.258,
      "step": 330
    },
    {
      "epoch": 0.68,
      "grad_norm": 2.521975517272949,
      "learning_rate": 0.0002827272727272727,
      "loss": 1.3017,
      "step": 340
    },
    {
      "epoch": 0.7,
      "grad_norm": 1.5649762153625488,
      "learning_rate": 0.00028212121212121207,
      "loss": 1.15,
      "step": 350
    },
    {
      "epoch": 0.72,
      "grad_norm": 1.7940312623977661,
      "learning_rate": 0.00028151515151515153,
      "loss": 1.1301,
      "step": 360
    },
    {
      "epoch": 0.74,
      "grad_norm": 3.1420931816101074,
      "learning_rate": 0.0002809090909090909,
      "loss": 1.372,
      "step": 370
    },
    {
      "epoch": 0.76,
      "grad_norm": 2.94646954536438,
      "learning_rate": 0.0002803030303030303,
      "loss": 1.3405,
      "step": 380
    },
    {
      "epoch": 0.78,
      "grad_norm": 2.2631325721740723,
      "learning_rate": 0.00027969696969696965,
      "loss": 1.4165,
      "step": 390
    },
    {
      "epoch": 0.8,
      "grad_norm": 2.2290663719177246,
      "learning_rate": 0.00027909090909090906,
      "loss": 1.1911,
      "step": 400
    },
    {
      "epoch": 0.8,
      "eval_loss": 1.2705235481262207,
      "eval_runtime": 8.45,
      "eval_samples_per_second": 23.669,
      "eval_steps_per_second": 23.669,
      "step": 400
    },
    {
      "epoch": 0.82,
      "grad_norm": 1.8649888038635254,
      "learning_rate": 0.0002784848484848485,
      "loss": 1.1048,
      "step": 410
    },
    {
      "epoch": 0.84,
      "grad_norm": 1.6562010049819946,
      "learning_rate": 0.00027787878787878783,
      "loss": 1.011,
      "step": 420
    },
    {
      "epoch": 0.86,
      "grad_norm": 3.32995343208313,
      "learning_rate": 0.00027727272727272724,
      "loss": 1.4297,
      "step": 430
    },
    {
      "epoch": 0.88,
      "grad_norm": 2.2059483528137207,
      "learning_rate": 0.00027666666666666665,
      "loss": 1.2186,
      "step": 440
    },
    {
      "epoch": 0.9,
      "grad_norm": 1.9255695343017578,
      "learning_rate": 0.00027606060606060606,
      "loss": 1.2843,
      "step": 450
    },
    {
      "epoch": 0.92,
      "grad_norm": 3.469024419784546,
      "learning_rate": 0.0002754545454545454,
      "loss": 1.1675,
      "step": 460
    },
    {
      "epoch": 0.94,
      "grad_norm": 1.6896859407424927,
      "learning_rate": 0.00027484848484848483,
      "loss": 1.2575,
      "step": 470
    },
    {
      "epoch": 0.96,
      "grad_norm": 2.0773396492004395,
      "learning_rate": 0.00027424242424242424,
      "loss": 1.3417,
      "step": 480
    },
    {
      "epoch": 0.98,
      "grad_norm": 1.5614120960235596,
      "learning_rate": 0.0002736363636363636,
      "loss": 1.2342,
      "step": 490
    },
    {
      "epoch": 1.0,
      "grad_norm": 2.458909511566162,
      "learning_rate": 0.000273030303030303,
      "loss": 1.4332,
      "step": 500
    },
    {
      "epoch": 1.0,
      "eval_loss": 1.2636210918426514,
      "eval_runtime": 8.4488,
      "eval_samples_per_second": 23.672,
      "eval_steps_per_second": 23.672,
      "step": 500
    },
    {
      "epoch": 1.02,
      "grad_norm": 1.507619857788086,
      "learning_rate": 0.0002724242424242424,
      "loss": 1.2102,
      "step": 510
    },
    {
      "epoch": 1.04,
      "grad_norm": 1.0146986246109009,
      "learning_rate": 0.00027181818181818177,
      "loss": 1.0799,
      "step": 520
    },
    {
      "epoch": 1.06,
      "grad_norm": 2.1653151512145996,
      "learning_rate": 0.0002712121212121212,
      "loss": 0.8925,
      "step": 530
    },
    {
      "epoch": 1.08,
      "grad_norm": 4.892096042633057,
      "learning_rate": 0.0002706060606060606,
      "loss": 0.949,
      "step": 540
    },
    {
      "epoch": 1.1,
      "grad_norm": 2.1448516845703125,
      "learning_rate": 0.00027,
      "loss": 0.9386,
      "step": 550
    },
    {
      "epoch": 1.12,
      "grad_norm": 2.0050041675567627,
      "learning_rate": 0.00026939393939393936,
      "loss": 1.0416,
      "step": 560
    },
    {
      "epoch": 1.1400000000000001,
      "grad_norm": 3.0642876625061035,
      "learning_rate": 0.00026878787878787877,
      "loss": 0.9821,
      "step": 570
    },
    {
      "epoch": 1.16,
      "grad_norm": 2.3770854473114014,
      "learning_rate": 0.0002681818181818181,
      "loss": 0.9527,
      "step": 580
    },
    {
      "epoch": 1.18,
      "grad_norm": 3.2442405223846436,
      "learning_rate": 0.00026757575757575754,
      "loss": 1.1105,
      "step": 590
    },
    {
      "epoch": 1.2,
      "grad_norm": 2.6729302406311035,
      "learning_rate": 0.00026696969696969695,
      "loss": 1.0313,
      "step": 600
    },
    {
      "epoch": 1.2,
      "eval_loss": 1.29315185546875,
      "eval_runtime": 8.4387,
      "eval_samples_per_second": 23.7,
      "eval_steps_per_second": 23.7,
      "step": 600
    },
    {
      "epoch": 1.22,
      "grad_norm": 2.192847728729248,
      "learning_rate": 0.00026636363636363636,
      "loss": 1.1687,
      "step": 610
    },
    {
      "epoch": 1.24,
      "grad_norm": 3.313755512237549,
      "learning_rate": 0.00026575757575757577,
      "loss": 0.8997,
      "step": 620
    },
    {
      "epoch": 1.26,
      "grad_norm": 3.1656494140625,
      "learning_rate": 0.0002651515151515151,
      "loss": 1.1836,
      "step": 630
    },
    {
      "epoch": 1.28,
      "grad_norm": 2.4735798835754395,
      "learning_rate": 0.00026454545454545453,
      "loss": 0.9515,
      "step": 640
    },
    {
      "epoch": 1.3,
      "grad_norm": 2.3156914710998535,
      "learning_rate": 0.0002639393939393939,
      "loss": 0.906,
      "step": 650
    },
    {
      "epoch": 1.32,
      "grad_norm": 3.140326499938965,
      "learning_rate": 0.0002633333333333333,
      "loss": 0.9968,
      "step": 660
    },
    {
      "epoch": 1.34,
      "grad_norm": 3.1560232639312744,
      "learning_rate": 0.0002627272727272727,
      "loss": 1.0053,
      "step": 670
    },
    {
      "epoch": 1.3599999999999999,
      "grad_norm": 2.230013608932495,
      "learning_rate": 0.00026212121212121207,
      "loss": 1.0634,
      "step": 680
    },
    {
      "epoch": 1.38,
      "grad_norm": 2.5431995391845703,
      "learning_rate": 0.0002615151515151515,
      "loss": 1.0347,
      "step": 690
    },
    {
      "epoch": 1.4,
      "grad_norm": 2.775595188140869,
      "learning_rate": 0.0002609090909090909,
      "loss": 1.1888,
      "step": 700
    },
    {
      "epoch": 1.4,
      "eval_loss": 1.2974121570587158,
      "eval_runtime": 8.4058,
      "eval_samples_per_second": 23.793,
      "eval_steps_per_second": 23.793,
      "step": 700
    },
    {
      "epoch": 1.42,
      "grad_norm": 2.21598482131958,
      "learning_rate": 0.0002603030303030303,
      "loss": 1.0761,
      "step": 710
    },
    {
      "epoch": 1.44,
      "grad_norm": 2.4721784591674805,
      "learning_rate": 0.00025969696969696966,
      "loss": 1.0224,
      "step": 720
    },
    {
      "epoch": 1.46,
      "grad_norm": 2.3651437759399414,
      "learning_rate": 0.00025909090909090907,
      "loss": 1.1186,
      "step": 730
    },
    {
      "epoch": 1.48,
      "grad_norm": 1.4931007623672485,
      "learning_rate": 0.0002584848484848485,
      "loss": 0.8966,
      "step": 740
    },
    {
      "epoch": 1.5,
      "grad_norm": 2.1837875843048096,
      "learning_rate": 0.00025787878787878783,
      "loss": 0.9867,
      "step": 750
    },
    {
      "epoch": 1.52,
      "grad_norm": 2.406663179397583,
      "learning_rate": 0.00025727272727272724,
      "loss": 0.9277,
      "step": 760
    },
    {
      "epoch": 1.54,
      "grad_norm": 1.8659473657608032,
      "learning_rate": 0.00025666666666666665,
      "loss": 1.0516,
      "step": 770
    },
    {
      "epoch": 1.56,
      "grad_norm": 1.982875108718872,
      "learning_rate": 0.000256060606060606,
      "loss": 0.8783,
      "step": 780
    },
    {
      "epoch": 1.58,
      "grad_norm": 2.5591049194335938,
      "learning_rate": 0.0002554545454545454,
      "loss": 1.0551,
      "step": 790
    },
    {
      "epoch": 1.6,
      "grad_norm": 2.6420507431030273,
      "learning_rate": 0.00025484848484848483,
      "loss": 1.0779,
      "step": 800
    },
    {
      "epoch": 1.6,
      "eval_loss": 1.3002063035964966,
      "eval_runtime": 8.3522,
      "eval_samples_per_second": 23.946,
      "eval_steps_per_second": 23.946,
      "step": 800
    },
    {
      "epoch": 1.62,
      "grad_norm": 2.342548370361328,
      "learning_rate": 0.00025424242424242424,
      "loss": 1.0693,
      "step": 810
    },
    {
      "epoch": 1.6400000000000001,
      "grad_norm": 2.709005117416382,
      "learning_rate": 0.0002536363636363636,
      "loss": 1.0926,
      "step": 820
    },
    {
      "epoch": 1.6600000000000001,
      "grad_norm": 3.18961501121521,
      "learning_rate": 0.000253030303030303,
      "loss": 1.194,
      "step": 830
    },
    {
      "epoch": 1.6800000000000002,
      "grad_norm": 3.7010622024536133,
      "learning_rate": 0.0002524242424242424,
      "loss": 1.2072,
      "step": 840
    },
    {
      "epoch": 1.7,
      "grad_norm": 2.7811715602874756,
      "learning_rate": 0.0002518181818181818,
      "loss": 0.9063,
      "step": 850
    },
    {
      "epoch": 1.72,
      "grad_norm": 2.39392352104187,
      "learning_rate": 0.0002512121212121212,
      "loss": 1.0687,
      "step": 860
    },
    {
      "epoch": 1.74,
      "grad_norm": 2.6478989124298096,
      "learning_rate": 0.0002506060606060606,
      "loss": 0.9336,
      "step": 870
    },
    {
      "epoch": 1.76,
      "grad_norm": 2.926833152770996,
      "learning_rate": 0.00025,
      "loss": 1.1466,
      "step": 880
    },
    {
      "epoch": 1.78,
      "grad_norm": 2.5758094787597656,
      "learning_rate": 0.00024939393939393936,
      "loss": 1.0177,
      "step": 890
    },
    {
      "epoch": 1.8,
      "grad_norm": 2.6753220558166504,
      "learning_rate": 0.00024878787878787877,
      "loss": 0.9758,
      "step": 900
    },
    {
      "epoch": 1.8,
      "eval_loss": 1.2878390550613403,
      "eval_runtime": 8.4473,
      "eval_samples_per_second": 23.676,
      "eval_steps_per_second": 23.676,
      "step": 900
    },
    {
      "epoch": 1.8199999999999998,
      "grad_norm": 2.9981536865234375,
      "learning_rate": 0.0002481818181818182,
      "loss": 0.9781,
      "step": 910
    },
    {
      "epoch": 1.8399999999999999,
      "grad_norm": 3.903458833694458,
      "learning_rate": 0.00024757575757575754,
      "loss": 1.1783,
      "step": 920
    },
    {
      "epoch": 1.8599999999999999,
      "grad_norm": 2.22409725189209,
      "learning_rate": 0.00024696969696969695,
      "loss": 0.9248,
      "step": 930
    },
    {
      "epoch": 1.88,
      "grad_norm": 2.5056941509246826,
      "learning_rate": 0.0002463636363636363,
      "loss": 1.0497,
      "step": 940
    },
    {
      "epoch": 1.9,
      "grad_norm": 3.3671326637268066,
      "learning_rate": 0.0002457575757575757,
      "loss": 0.9187,
      "step": 950
    },
    {
      "epoch": 1.92,
      "grad_norm": 2.6355795860290527,
      "learning_rate": 0.0002451515151515151,
      "loss": 0.9211,
      "step": 960
    },
    {
      "epoch": 1.94,
      "grad_norm": 3.4127159118652344,
      "learning_rate": 0.00024454545454545454,
      "loss": 0.8722,
      "step": 970
    },
    {
      "epoch": 1.96,
      "grad_norm": 2.9481287002563477,
      "learning_rate": 0.00024393939393939392,
      "loss": 1.2426,
      "step": 980
    },
    {
      "epoch": 1.98,
      "grad_norm": 3.3082568645477295,
      "learning_rate": 0.0002433333333333333,
      "loss": 1.1669,
      "step": 990
    },
    {
      "epoch": 2.0,
      "grad_norm": 2.0977213382720947,
      "learning_rate": 0.0002427272727272727,
      "loss": 0.7776,
      "step": 1000
    },
    {
      "epoch": 2.0,
      "eval_loss": 1.287873387336731,
      "eval_runtime": 8.3659,
      "eval_samples_per_second": 23.906,
      "eval_steps_per_second": 23.906,
      "step": 1000
    },
    {
      "epoch": 2.02,
      "grad_norm": 2.830925226211548,
      "learning_rate": 0.0002421212121212121,
      "loss": 0.6028,
      "step": 1010
    },
    {
      "epoch": 2.04,
      "grad_norm": 3.6646480560302734,
      "learning_rate": 0.00024151515151515148,
      "loss": 0.6435,
      "step": 1020
    },
    {
      "epoch": 2.06,
      "grad_norm": 3.257075786590576,
      "learning_rate": 0.00024090909090909086,
      "loss": 0.8612,
      "step": 1030
    },
    {
      "epoch": 2.08,
      "grad_norm": 4.689837455749512,
      "learning_rate": 0.0002403030303030303,
      "loss": 0.7401,
      "step": 1040
    },
    {
      "epoch": 2.1,
      "grad_norm": 3.7086219787597656,
      "learning_rate": 0.00023969696969696968,
      "loss": 0.6591,
      "step": 1050
    },
    {
      "epoch": 2.12,
      "grad_norm": 0.43487557768821716,
      "learning_rate": 0.00023909090909090907,
      "loss": 0.9586,
      "step": 1060
    },
    {
      "epoch": 2.14,
      "grad_norm": 3.4661383628845215,
      "learning_rate": 0.00023848484848484848,
      "loss": 0.7939,
      "step": 1070
    },
    {
      "epoch": 2.16,
      "grad_norm": 3.034625291824341,
      "learning_rate": 0.00023787878787878786,
      "loss": 0.827,
      "step": 1080
    },
    {
      "epoch": 2.18,
      "grad_norm": 3.5249736309051514,
      "learning_rate": 0.00023727272727272724,
      "loss": 0.7091,
      "step": 1090
    },
    {
      "epoch": 2.2,
      "grad_norm": 3.9045650959014893,
      "learning_rate": 0.00023666666666666663,
      "loss": 0.6507,
      "step": 1100
    },
    {
      "epoch": 2.2,
      "eval_loss": 1.4095735549926758,
      "eval_runtime": 8.4649,
      "eval_samples_per_second": 23.627,
      "eval_steps_per_second": 23.627,
      "step": 1100
    },
    {
      "epoch": 2.22,
      "grad_norm": 3.05527663230896,
      "learning_rate": 0.00023606060606060604,
      "loss": 0.7584,
      "step": 1110
    },
    {
      "epoch": 2.24,
      "grad_norm": 3.949531316757202,
      "learning_rate": 0.00023545454545454542,
      "loss": 0.7665,
      "step": 1120
    },
    {
      "epoch": 2.26,
      "grad_norm": 2.5591065883636475,
      "learning_rate": 0.00023484848484848483,
      "loss": 0.619,
      "step": 1130
    },
    {
      "epoch": 2.2800000000000002,
      "grad_norm": 3.358548402786255,
      "learning_rate": 0.00023424242424242424,
      "loss": 0.8593,
      "step": 1140
    },
    {
      "epoch": 2.3,
      "grad_norm": 3.781599998474121,
      "learning_rate": 0.00023363636363636363,
      "loss": 0.6537,
      "step": 1150
    },
    {
      "epoch": 2.32,
      "grad_norm": 2.873863935470581,
      "learning_rate": 0.000233030303030303,
      "loss": 0.6514,
      "step": 1160
    },
    {
      "epoch": 2.34,
      "grad_norm": 2.117013931274414,
      "learning_rate": 0.0002324242424242424,
      "loss": 0.6736,
      "step": 1170
    },
    {
      "epoch": 2.36,
      "grad_norm": 3.375669240951538,
      "learning_rate": 0.0002318181818181818,
      "loss": 0.7942,
      "step": 1180
    },
    {
      "epoch": 2.38,
      "grad_norm": 3.498569965362549,
      "learning_rate": 0.00023121212121212119,
      "loss": 0.8367,
      "step": 1190
    },
    {
      "epoch": 2.4,
      "grad_norm": 2.917729139328003,
      "learning_rate": 0.00023060606060606057,
      "loss": 0.6847,
      "step": 1200
    },
    {
      "epoch": 2.4,
      "eval_loss": 1.4188705682754517,
      "eval_runtime": 8.4538,
      "eval_samples_per_second": 23.658,
      "eval_steps_per_second": 23.658,
      "step": 1200
    },
    {
      "epoch": 2.42,
      "grad_norm": 4.737537384033203,
      "learning_rate": 0.00023,
      "loss": 0.7333,
      "step": 1210
    },
    {
      "epoch": 2.44,
      "grad_norm": 2.888686180114746,
      "learning_rate": 0.0002293939393939394,
      "loss": 0.8,
      "step": 1220
    },
    {
      "epoch": 2.46,
      "grad_norm": 2.709480047225952,
      "learning_rate": 0.00022878787878787877,
      "loss": 0.6888,
      "step": 1230
    },
    {
      "epoch": 2.48,
      "grad_norm": 1.9516761302947998,
      "learning_rate": 0.00022818181818181816,
      "loss": 0.7567,
      "step": 1240
    },
    {
      "epoch": 2.5,
      "grad_norm": 4.597064971923828,
      "learning_rate": 0.00022757575757575757,
      "loss": 0.7176,
      "step": 1250
    },
    {
      "epoch": 2.52,
      "grad_norm": 2.5586791038513184,
      "learning_rate": 0.00022696969696969695,
      "loss": 0.7242,
      "step": 1260
    },
    {
      "epoch": 2.54,
      "grad_norm": 2.6998090744018555,
      "learning_rate": 0.00022636363636363633,
      "loss": 0.8131,
      "step": 1270
    },
    {
      "epoch": 2.56,
      "grad_norm": 2.5726683139801025,
      "learning_rate": 0.00022575757575757572,
      "loss": 0.7251,
      "step": 1280
    },
    {
      "epoch": 2.58,
      "grad_norm": 3.7838127613067627,
      "learning_rate": 0.00022515151515151513,
      "loss": 0.8981,
      "step": 1290
    },
    {
      "epoch": 2.6,
      "grad_norm": 4.051110744476318,
      "learning_rate": 0.00022454545454545454,
      "loss": 0.8313,
      "step": 1300
    },
    {
      "epoch": 2.6,
      "eval_loss": 1.4123733043670654,
      "eval_runtime": 8.5514,
      "eval_samples_per_second": 23.388,
      "eval_steps_per_second": 23.388,
      "step": 1300
    },
    {
      "epoch": 2.62,
      "grad_norm": 4.277744293212891,
      "learning_rate": 0.00022393939393939392,
      "loss": 0.72,
      "step": 1310
    },
    {
      "epoch": 2.64,
      "grad_norm": 3.544724464416504,
      "learning_rate": 0.00022333333333333333,
      "loss": 0.8318,
      "step": 1320
    },
    {
      "epoch": 2.66,
      "grad_norm": 3.004434823989868,
      "learning_rate": 0.00022272727272727272,
      "loss": 0.856,
      "step": 1330
    },
    {
      "epoch": 2.68,
      "grad_norm": 4.060131549835205,
      "learning_rate": 0.0002221212121212121,
      "loss": 0.7595,
      "step": 1340
    },
    {
      "epoch": 2.7,
      "grad_norm": 3.5267271995544434,
      "learning_rate": 0.00022151515151515148,
      "loss": 0.6397,
      "step": 1350
    },
    {
      "epoch": 2.7199999999999998,
      "grad_norm": 4.2736101150512695,
      "learning_rate": 0.0002209090909090909,
      "loss": 0.7167,
      "step": 1360
    },
    {
      "epoch": 2.74,
      "grad_norm": 2.8161885738372803,
      "learning_rate": 0.00022030303030303028,
      "loss": 0.7693,
      "step": 1370
    },
    {
      "epoch": 2.76,
      "grad_norm": 4.460194110870361,
      "learning_rate": 0.00021969696969696969,
      "loss": 0.7529,
      "step": 1380
    },
    {
      "epoch": 2.7800000000000002,
      "grad_norm": 4.553228855133057,
      "learning_rate": 0.0002190909090909091,
      "loss": 0.6939,
      "step": 1390
    },
    {
      "epoch": 2.8,
      "grad_norm": 3.917261838912964,
      "learning_rate": 0.00021848484848484848,
      "loss": 0.7071,
      "step": 1400
    },
    {
      "epoch": 2.8,
      "eval_loss": 1.4015107154846191,
      "eval_runtime": 8.4211,
      "eval_samples_per_second": 23.75,
      "eval_steps_per_second": 23.75,
      "step": 1400
    },
    {
      "epoch": 2.82,
      "grad_norm": 4.08258056640625,
      "learning_rate": 0.00021787878787878786,
      "loss": 0.7547,
      "step": 1410
    },
    {
      "epoch": 2.84,
      "grad_norm": 2.3247952461242676,
      "learning_rate": 0.00021727272727272725,
      "loss": 0.7846,
      "step": 1420
    },
    {
      "epoch": 2.86,
      "grad_norm": 3.3210012912750244,
      "learning_rate": 0.00021666666666666666,
      "loss": 0.7177,
      "step": 1430
    },
    {
      "epoch": 2.88,
      "grad_norm": 3.6215100288391113,
      "learning_rate": 0.00021606060606060604,
      "loss": 0.6515,
      "step": 1440
    },
    {
      "epoch": 2.9,
      "grad_norm": 3.117866039276123,
      "learning_rate": 0.00021545454545454542,
      "loss": 0.7691,
      "step": 1450
    },
    {
      "epoch": 2.92,
      "grad_norm": 3.634805917739868,
      "learning_rate": 0.0002148484848484848,
      "loss": 0.6877,
      "step": 1460
    },
    {
      "epoch": 2.94,
      "grad_norm": 2.8989503383636475,
      "learning_rate": 0.00021424242424242424,
      "loss": 0.7483,
      "step": 1470
    },
    {
      "epoch": 2.96,
      "grad_norm": 3.320434808731079,
      "learning_rate": 0.00021363636363636363,
      "loss": 0.7508,
      "step": 1480
    },
    {
      "epoch": 2.98,
      "grad_norm": 4.0481157302856445,
      "learning_rate": 0.000213030303030303,
      "loss": 0.8401,
      "step": 1490
    },
    {
      "epoch": 3.0,
      "grad_norm": 2.257594108581543,
      "learning_rate": 0.00021242424242424242,
      "loss": 0.7239,
      "step": 1500
    },
    {
      "epoch": 3.0,
      "eval_loss": 1.3880186080932617,
      "eval_runtime": 8.4372,
      "eval_samples_per_second": 23.705,
      "eval_steps_per_second": 23.705,
      "step": 1500
    },
    {
      "epoch": 3.02,
      "grad_norm": 2.6824707984924316,
      "learning_rate": 0.0002118181818181818,
      "loss": 0.5924,
      "step": 1510
    },
    {
      "epoch": 3.04,
      "grad_norm": 4.588799953460693,
      "learning_rate": 0.0002112121212121212,
      "loss": 0.5708,
      "step": 1520
    },
    {
      "epoch": 3.06,
      "grad_norm": 1.2742030620574951,
      "learning_rate": 0.00021060606060606057,
      "loss": 0.4293,
      "step": 1530
    },
    {
      "epoch": 3.08,
      "grad_norm": 4.705350875854492,
      "learning_rate": 0.00020999999999999998,
      "loss": 0.5316,
      "step": 1540
    },
    {
      "epoch": 3.1,
      "grad_norm": 4.749671936035156,
      "learning_rate": 0.0002093939393939394,
      "loss": 0.3959,
      "step": 1550
    },
    {
      "epoch": 3.12,
      "grad_norm": 1.3260949850082397,
      "learning_rate": 0.00020878787878787878,
      "loss": 0.4274,
      "step": 1560
    },
    {
      "epoch": 3.14,
      "grad_norm": 3.254258632659912,
      "learning_rate": 0.00020818181818181816,
      "loss": 0.3956,
      "step": 1570
    },
    {
      "epoch": 3.16,
      "grad_norm": 2.3264198303222656,
      "learning_rate": 0.00020757575757575757,
      "loss": 0.4841,
      "step": 1580
    },
    {
      "epoch": 3.18,
      "grad_norm": 4.070592880249023,
      "learning_rate": 0.00020696969696969695,
      "loss": 0.5106,
      "step": 1590
    },
    {
      "epoch": 3.2,
      "grad_norm": 3.055490016937256,
      "learning_rate": 0.00020636363636363634,
      "loss": 0.6309,
      "step": 1600
    },
    {
      "epoch": 3.2,
      "eval_loss": 1.5671463012695312,
      "eval_runtime": 8.3556,
      "eval_samples_per_second": 23.936,
      "eval_steps_per_second": 23.936,
      "step": 1600
    },
    {
      "epoch": 3.22,
      "grad_norm": 5.112276554107666,
      "learning_rate": 0.00020575757575757572,
      "loss": 0.4229,
      "step": 1610
    },
    {
      "epoch": 3.24,
      "grad_norm": 3.5973072052001953,
      "learning_rate": 0.00020515151515151513,
      "loss": 0.5425,
      "step": 1620
    },
    {
      "epoch": 3.26,
      "grad_norm": 4.560903072357178,
      "learning_rate": 0.0002045454545454545,
      "loss": 0.4993,
      "step": 1630
    },
    {
      "epoch": 3.2800000000000002,
      "grad_norm": 3.543632984161377,
      "learning_rate": 0.00020393939393939392,
      "loss": 0.5765,
      "step": 1640
    },
    {
      "epoch": 3.3,
      "grad_norm": 5.135825157165527,
      "learning_rate": 0.00020333333333333333,
      "loss": 0.6389,
      "step": 1650
    },
    {
      "epoch": 3.32,
      "grad_norm": 4.243987083435059,
      "learning_rate": 0.00020272727272727272,
      "loss": 0.5637,
      "step": 1660
    },
    {
      "epoch": 3.34,
      "grad_norm": 3.602782726287842,
      "learning_rate": 0.0002021212121212121,
      "loss": 0.5103,
      "step": 1670
    },
    {
      "epoch": 3.36,
      "grad_norm": 3.6816365718841553,
      "learning_rate": 0.00020151515151515148,
      "loss": 0.5202,
      "step": 1680
    },
    {
      "epoch": 3.38,
      "grad_norm": 6.046665668487549,
      "learning_rate": 0.0002009090909090909,
      "loss": 0.5307,
      "step": 1690
    },
    {
      "epoch": 3.4,
      "grad_norm": 1.9800333976745605,
      "learning_rate": 0.00020030303030303028,
      "loss": 0.4433,
      "step": 1700
    },
    {
      "epoch": 3.4,
      "eval_loss": 1.5456345081329346,
      "eval_runtime": 8.4655,
      "eval_samples_per_second": 23.625,
      "eval_steps_per_second": 23.625,
      "step": 1700
    },
    {
      "epoch": 3.42,
      "grad_norm": 0.3792451024055481,
      "learning_rate": 0.00019969696969696966,
      "loss": 0.5015,
      "step": 1710
    },
    {
      "epoch": 3.44,
      "grad_norm": 3.431313991546631,
      "learning_rate": 0.0001990909090909091,
      "loss": 0.5992,
      "step": 1720
    },
    {
      "epoch": 3.46,
      "grad_norm": 3.2754197120666504,
      "learning_rate": 0.00019848484848484848,
      "loss": 0.4157,
      "step": 1730
    },
    {
      "epoch": 3.48,
      "grad_norm": 3.715615749359131,
      "learning_rate": 0.00019787878787878786,
      "loss": 0.482,
      "step": 1740
    },
    {
      "epoch": 3.5,
      "grad_norm": 4.793345928192139,
      "learning_rate": 0.00019727272727272725,
      "loss": 0.5178,
      "step": 1750
    },
    {
      "epoch": 3.52,
      "grad_norm": 2.812443733215332,
      "learning_rate": 0.00019666666666666666,
      "loss": 0.5947,
      "step": 1760
    },
    {
      "epoch": 3.54,
      "grad_norm": 4.772388935089111,
      "learning_rate": 0.00019606060606060604,
      "loss": 0.4567,
      "step": 1770
    },
    {
      "epoch": 3.56,
      "grad_norm": 2.9931976795196533,
      "learning_rate": 0.00019545454545454543,
      "loss": 0.4469,
      "step": 1780
    },
    {
      "epoch": 3.58,
      "grad_norm": 6.77914571762085,
      "learning_rate": 0.0001948484848484848,
      "loss": 0.501,
      "step": 1790
    },
    {
      "epoch": 3.6,
      "grad_norm": 4.486056327819824,
      "learning_rate": 0.00019424242424242422,
      "loss": 0.4057,
      "step": 1800
    },
    {
      "epoch": 3.6,
      "eval_loss": 1.600733757019043,
      "eval_runtime": 8.4111,
      "eval_samples_per_second": 23.778,
      "eval_steps_per_second": 23.778,
      "step": 1800
    },
    {
      "epoch": 3.62,
      "grad_norm": 6.5992302894592285,
      "learning_rate": 0.00019363636363636363,
      "loss": 0.503,
      "step": 1810
    },
    {
      "epoch": 3.64,
      "grad_norm": 2.2570738792419434,
      "learning_rate": 0.000193030303030303,
      "loss": 0.4856,
      "step": 1820
    },
    {
      "epoch": 3.66,
      "grad_norm": 8.145820617675781,
      "learning_rate": 0.00019242424242424242,
      "loss": 0.3613,
      "step": 1830
    },
    {
      "epoch": 3.68,
      "grad_norm": 0.8093264102935791,
      "learning_rate": 0.0001918181818181818,
      "loss": 0.5405,
      "step": 1840
    },
    {
      "epoch": 3.7,
      "grad_norm": 2.4454216957092285,
      "learning_rate": 0.0001912121212121212,
      "loss": 0.4418,
      "step": 1850
    },
    {
      "epoch": 3.7199999999999998,
      "grad_norm": 5.083759784698486,
      "learning_rate": 0.00019060606060606057,
      "loss": 0.638,
      "step": 1860
    },
    {
      "epoch": 3.74,
      "grad_norm": 6.690917491912842,
      "learning_rate": 0.00018999999999999998,
      "loss": 0.6539,
      "step": 1870
    },
    {
      "epoch": 3.76,
      "grad_norm": 4.145776271820068,
      "learning_rate": 0.00018939393939393937,
      "loss": 0.4911,
      "step": 1880
    },
    {
      "epoch": 3.7800000000000002,
      "grad_norm": 2.3775269985198975,
      "learning_rate": 0.00018878787878787878,
      "loss": 0.6195,
      "step": 1890
    },
    {
      "epoch": 3.8,
      "grad_norm": 4.051588535308838,
      "learning_rate": 0.0001881818181818182,
      "loss": 0.5139,
      "step": 1900
    },
    {
      "epoch": 3.8,
      "eval_loss": 1.5681861639022827,
      "eval_runtime": 8.3696,
      "eval_samples_per_second": 23.896,
      "eval_steps_per_second": 23.896,
      "step": 1900
    },
    {
      "epoch": 3.82,
      "grad_norm": 3.649435520172119,
      "learning_rate": 0.00018757575757575757,
      "loss": 0.3806,
      "step": 1910
    },
    {
      "epoch": 3.84,
      "grad_norm": 4.324856281280518,
      "learning_rate": 0.00018696969696969695,
      "loss": 0.5366,
      "step": 1920
    },
    {
      "epoch": 3.86,
      "grad_norm": 2.5320358276367188,
      "learning_rate": 0.00018636363636363634,
      "loss": 0.5101,
      "step": 1930
    },
    {
      "epoch": 3.88,
      "grad_norm": 4.423282146453857,
      "learning_rate": 0.00018575757575757575,
      "loss": 0.4511,
      "step": 1940
    },
    {
      "epoch": 3.9,
      "grad_norm": 3.063751697540283,
      "learning_rate": 0.00018515151515151513,
      "loss": 0.6428,
      "step": 1950
    },
    {
      "epoch": 3.92,
      "grad_norm": 6.009853839874268,
      "learning_rate": 0.00018454545454545451,
      "loss": 0.6064,
      "step": 1960
    },
    {
      "epoch": 3.94,
      "grad_norm": 3.6759257316589355,
      "learning_rate": 0.0001839393939393939,
      "loss": 0.5157,
      "step": 1970
    },
    {
      "epoch": 3.96,
      "grad_norm": 7.06676721572876,
      "learning_rate": 0.00018333333333333334,
      "loss": 0.6761,
      "step": 1980
    },
    {
      "epoch": 3.98,
      "grad_norm": 2.5960536003112793,
      "learning_rate": 0.00018272727272727272,
      "loss": 0.4037,
      "step": 1990
    },
    {
      "epoch": 4.0,
      "grad_norm": 3.3609771728515625,
      "learning_rate": 0.0001821212121212121,
      "loss": 0.4791,
      "step": 2000
    },
    {
      "epoch": 4.0,
      "eval_loss": 1.5578558444976807,
      "eval_runtime": 8.4482,
      "eval_samples_per_second": 23.674,
      "eval_steps_per_second": 23.674,
      "step": 2000
    },
    {
      "epoch": 4.02,
      "grad_norm": 2.665661573410034,
      "learning_rate": 0.0001815151515151515,
      "loss": 0.3919,
      "step": 2010
    },
    {
      "epoch": 4.04,
      "grad_norm": 3.3170716762542725,
      "learning_rate": 0.0001809090909090909,
      "loss": 0.2875,
      "step": 2020
    },
    {
      "epoch": 4.06,
      "grad_norm": 4.358865737915039,
      "learning_rate": 0.00018030303030303028,
      "loss": 0.3529,
      "step": 2030
    },
    {
      "epoch": 4.08,
      "grad_norm": 3.819556951522827,
      "learning_rate": 0.00017969696969696966,
      "loss": 0.4188,
      "step": 2040
    },
    {
      "epoch": 4.1,
      "grad_norm": 8.150585174560547,
      "learning_rate": 0.00017909090909090907,
      "loss": 0.2967,
      "step": 2050
    },
    {
      "epoch": 4.12,
      "grad_norm": 1.2958017587661743,
      "learning_rate": 0.00017848484848484846,
      "loss": 0.2818,
      "step": 2060
    },
    {
      "epoch": 4.14,
      "grad_norm": 3.61509108543396,
      "learning_rate": 0.00017787878787878787,
      "loss": 0.2321,
      "step": 2070
    },
    {
      "epoch": 4.16,
      "grad_norm": 1.3745328187942505,
      "learning_rate": 0.00017727272727272728,
      "loss": 0.2464,
      "step": 2080
    },
    {
      "epoch": 4.18,
      "grad_norm": 6.740081787109375,
      "learning_rate": 0.00017666666666666666,
      "loss": 0.3951,
      "step": 2090
    },
    {
      "epoch": 4.2,
      "grad_norm": 2.2050058841705322,
      "learning_rate": 0.00017606060606060604,
      "loss": 0.2658,
      "step": 2100
    },
    {
      "epoch": 4.2,
      "eval_loss": 1.7361308336257935,
      "eval_runtime": 8.3616,
      "eval_samples_per_second": 23.919,
      "eval_steps_per_second": 23.919,
      "step": 2100
    },
    {
      "epoch": 4.22,
      "grad_norm": 7.3726806640625,
      "learning_rate": 0.00017545454545454543,
      "loss": 0.2505,
      "step": 2110
    },
    {
      "epoch": 4.24,
      "grad_norm": 1.4238688945770264,
      "learning_rate": 0.00017484848484848484,
      "loss": 0.2775,
      "step": 2120
    },
    {
      "epoch": 4.26,
      "grad_norm": 3.2047252655029297,
      "learning_rate": 0.00017424242424242422,
      "loss": 0.2663,
      "step": 2130
    },
    {
      "epoch": 4.28,
      "grad_norm": 3.3517274856567383,
      "learning_rate": 0.0001736363636363636,
      "loss": 0.3381,
      "step": 2140
    },
    {
      "epoch": 4.3,
      "grad_norm": 4.710339546203613,
      "learning_rate": 0.00017303030303030304,
      "loss": 0.3451,
      "step": 2150
    },
    {
      "epoch": 4.32,
      "grad_norm": 0.7602309584617615,
      "learning_rate": 0.00017242424242424242,
      "loss": 0.3827,
      "step": 2160
    },
    {
      "epoch": 4.34,
      "grad_norm": 4.451146125793457,
      "learning_rate": 0.0001718181818181818,
      "loss": 0.2724,
      "step": 2170
    },
    {
      "epoch": 4.36,
      "grad_norm": 3.045299768447876,
      "learning_rate": 0.0001712121212121212,
      "loss": 0.4467,
      "step": 2180
    },
    {
      "epoch": 4.38,
      "grad_norm": 2.359360933303833,
      "learning_rate": 0.0001706060606060606,
      "loss": 0.3202,
      "step": 2190
    },
    {
      "epoch": 4.4,
      "grad_norm": 4.178774833679199,
      "learning_rate": 0.00016999999999999999,
      "loss": 0.3426,
      "step": 2200
    },
    {
      "epoch": 4.4,
      "eval_loss": 1.7135589122772217,
      "eval_runtime": 8.3699,
      "eval_samples_per_second": 23.895,
      "eval_steps_per_second": 23.895,
      "step": 2200
    },
    {
      "epoch": 4.42,
      "grad_norm": 3.903071880340576,
      "learning_rate": 0.00016939393939393937,
      "loss": 0.4095,
      "step": 2210
    },
    {
      "epoch": 4.44,
      "grad_norm": 3.632858991622925,
      "learning_rate": 0.00016878787878787875,
      "loss": 0.3248,
      "step": 2220
    },
    {
      "epoch": 4.46,
      "grad_norm": 2.419828414916992,
      "learning_rate": 0.00016818181818181816,
      "loss": 0.2461,
      "step": 2230
    },
    {
      "epoch": 4.48,
      "grad_norm": 3.4455208778381348,
      "learning_rate": 0.00016757575757575757,
      "loss": 0.3481,
      "step": 2240
    },
    {
      "epoch": 4.5,
      "grad_norm": 3.408781051635742,
      "learning_rate": 0.00016696969696969696,
      "loss": 0.3678,
      "step": 2250
    },
    {
      "epoch": 4.52,
      "grad_norm": 6.3979034423828125,
      "learning_rate": 0.00016636363636363637,
      "loss": 0.2825,
      "step": 2260
    },
    {
      "epoch": 4.54,
      "grad_norm": 3.3604071140289307,
      "learning_rate": 0.00016575757575757575,
      "loss": 0.3492,
      "step": 2270
    },
    {
      "epoch": 4.5600000000000005,
      "grad_norm": 5.085422039031982,
      "learning_rate": 0.00016515151515151513,
      "loss": 0.6044,
      "step": 2280
    },
    {
      "epoch": 4.58,
      "grad_norm": 1.1912052631378174,
      "learning_rate": 0.00016454545454545452,
      "loss": 0.3062,
      "step": 2290
    },
    {
      "epoch": 4.6,
      "grad_norm": 5.825389385223389,
      "learning_rate": 0.00016393939393939393,
      "loss": 0.3257,
      "step": 2300
    },
    {
      "epoch": 4.6,
      "eval_loss": 1.7419800758361816,
      "eval_runtime": 8.3675,
      "eval_samples_per_second": 23.902,
      "eval_steps_per_second": 23.902,
      "step": 2300
    },
    {
      "epoch": 4.62,
      "grad_norm": 8.238669395446777,
      "learning_rate": 0.0001633333333333333,
      "loss": 0.2875,
      "step": 2310
    },
    {
      "epoch": 4.64,
      "grad_norm": 2.4934659004211426,
      "learning_rate": 0.00016272727272727272,
      "loss": 0.4964,
      "step": 2320
    },
    {
      "epoch": 4.66,
      "grad_norm": 2.0641050338745117,
      "learning_rate": 0.00016212121212121213,
      "loss": 0.32,
      "step": 2330
    },
    {
      "epoch": 4.68,
      "grad_norm": 7.096041202545166,
      "learning_rate": 0.00016151515151515151,
      "loss": 0.3105,
      "step": 2340
    },
    {
      "epoch": 4.7,
      "grad_norm": 4.377853870391846,
      "learning_rate": 0.0001609090909090909,
      "loss": 0.4071,
      "step": 2350
    },
    {
      "epoch": 4.72,
      "grad_norm": 4.392714500427246,
      "learning_rate": 0.00016030303030303028,
      "loss": 0.3424,
      "step": 2360
    },
    {
      "epoch": 4.74,
      "grad_norm": 3.216447353363037,
      "learning_rate": 0.0001596969696969697,
      "loss": 0.5617,
      "step": 2370
    },
    {
      "epoch": 4.76,
      "grad_norm": 1.7588672637939453,
      "learning_rate": 0.00015909090909090907,
      "loss": 0.3745,
      "step": 2380
    },
    {
      "epoch": 4.78,
      "grad_norm": 5.6163716316223145,
      "learning_rate": 0.00015848484848484846,
      "loss": 0.3825,
      "step": 2390
    },
    {
      "epoch": 4.8,
      "grad_norm": 4.46958065032959,
      "learning_rate": 0.00015787878787878784,
      "loss": 0.4531,
      "step": 2400
    },
    {
      "epoch": 4.8,
      "eval_loss": 1.6778002977371216,
      "eval_runtime": 8.4742,
      "eval_samples_per_second": 23.601,
      "eval_steps_per_second": 23.601,
      "step": 2400
    },
    {
      "epoch": 4.82,
      "grad_norm": 5.153345584869385,
      "learning_rate": 0.00015727272727272728,
      "loss": 0.3801,
      "step": 2410
    },
    {
      "epoch": 4.84,
      "grad_norm": 5.452594757080078,
      "learning_rate": 0.00015666666666666666,
      "loss": 0.4285,
      "step": 2420
    },
    {
      "epoch": 4.86,
      "grad_norm": 5.986551284790039,
      "learning_rate": 0.00015606060606060605,
      "loss": 0.3777,
      "step": 2430
    },
    {
      "epoch": 4.88,
      "grad_norm": 3.0313384532928467,
      "learning_rate": 0.00015545454545454546,
      "loss": 0.3272,
      "step": 2440
    },
    {
      "epoch": 4.9,
      "grad_norm": 3.611999034881592,
      "learning_rate": 0.00015484848484848484,
      "loss": 0.3182,
      "step": 2450
    },
    {
      "epoch": 4.92,
      "grad_norm": 3.098693609237671,
      "learning_rate": 0.00015424242424242422,
      "loss": 0.342,
      "step": 2460
    },
    {
      "epoch": 4.9399999999999995,
      "grad_norm": 0.8042653799057007,
      "learning_rate": 0.0001536363636363636,
      "loss": 0.3518,
      "step": 2470
    },
    {
      "epoch": 4.96,
      "grad_norm": 2.495593309402466,
      "learning_rate": 0.00015303030303030302,
      "loss": 0.3439,
      "step": 2480
    },
    {
      "epoch": 4.98,
      "grad_norm": 5.810417175292969,
      "learning_rate": 0.00015242424242424243,
      "loss": 0.3613,
      "step": 2490
    },
    {
      "epoch": 5.0,
      "grad_norm": 8.636038780212402,
      "learning_rate": 0.0001518181818181818,
      "loss": 0.3794,
      "step": 2500
    },
    {
      "epoch": 5.0,
      "eval_loss": 1.6946645975112915,
      "eval_runtime": 8.3354,
      "eval_samples_per_second": 23.994,
      "eval_steps_per_second": 23.994,
      "step": 2500
    },
    {
      "epoch": 5.02,
      "grad_norm": 5.099819660186768,
      "learning_rate": 0.00015121212121212122,
      "loss": 0.2514,
      "step": 2510
    },
    {
      "epoch": 5.04,
      "grad_norm": 1.4821889400482178,
      "learning_rate": 0.0001506060606060606,
      "loss": 0.2017,
      "step": 2520
    },
    {
      "epoch": 5.06,
      "grad_norm": 0.8699619174003601,
      "learning_rate": 0.00015,
      "loss": 0.2512,
      "step": 2530
    },
    {
      "epoch": 5.08,
      "grad_norm": 2.9397659301757812,
      "learning_rate": 0.00014939393939393937,
      "loss": 0.2199,
      "step": 2540
    },
    {
      "epoch": 5.1,
      "grad_norm": 6.761317729949951,
      "learning_rate": 0.00014878787878787875,
      "loss": 0.2897,
      "step": 2550
    },
    {
      "epoch": 5.12,
      "grad_norm": 1.1722605228424072,
      "learning_rate": 0.00014818181818181816,
      "loss": 0.2325,
      "step": 2560
    },
    {
      "epoch": 5.14,
      "grad_norm": 1.5147219896316528,
      "learning_rate": 0.00014757575757575757,
      "loss": 0.2547,
      "step": 2570
    },
    {
      "epoch": 5.16,
      "grad_norm": 3.960745334625244,
      "learning_rate": 0.00014696969696969696,
      "loss": 0.3238,
      "step": 2580
    },
    {
      "epoch": 5.18,
      "grad_norm": 2.855876922607422,
      "learning_rate": 0.00014636363636363634,
      "loss": 0.3034,
      "step": 2590
    },
    {
      "epoch": 5.2,
      "grad_norm": 3.6122610569000244,
      "learning_rate": 0.00014575757575757575,
      "loss": 0.2124,
      "step": 2600
    },
    {
      "epoch": 5.2,
      "eval_loss": 1.8295189142227173,
      "eval_runtime": 8.3488,
      "eval_samples_per_second": 23.955,
      "eval_steps_per_second": 23.955,
      "step": 2600
    },
    {
      "epoch": 5.22,
      "grad_norm": 2.6249122619628906,
      "learning_rate": 0.00014515151515151513,
      "loss": 0.2049,
      "step": 2610
    },
    {
      "epoch": 5.24,
      "grad_norm": 0.8576699495315552,
      "learning_rate": 0.00014454545454545452,
      "loss": 0.2301,
      "step": 2620
    },
    {
      "epoch": 5.26,
      "grad_norm": 4.3812994956970215,
      "learning_rate": 0.00014393939393939393,
      "loss": 0.2752,
      "step": 2630
    },
    {
      "epoch": 5.28,
      "grad_norm": 2.1442317962646484,
      "learning_rate": 0.00014333333333333334,
      "loss": 0.1785,
      "step": 2640
    },
    {
      "epoch": 5.3,
      "grad_norm": 3.4273626804351807,
      "learning_rate": 0.00014272727272727272,
      "loss": 0.2324,
      "step": 2650
    },
    {
      "epoch": 5.32,
      "grad_norm": 4.905290603637695,
      "learning_rate": 0.0001421212121212121,
      "loss": 0.2587,
      "step": 2660
    },
    {
      "epoch": 5.34,
      "grad_norm": 1.5224136114120483,
      "learning_rate": 0.0001415151515151515,
      "loss": 0.2832,
      "step": 2670
    },
    {
      "epoch": 5.36,
      "grad_norm": 9.100716590881348,
      "learning_rate": 0.0001409090909090909,
      "loss": 0.2433,
      "step": 2680
    },
    {
      "epoch": 5.38,
      "grad_norm": 2.621472120285034,
      "learning_rate": 0.00014030303030303028,
      "loss": 0.2532,
      "step": 2690
    },
    {
      "epoch": 5.4,
      "grad_norm": 1.1734211444854736,
      "learning_rate": 0.0001396969696969697,
      "loss": 0.1888,
      "step": 2700
    },
    {
      "epoch": 5.4,
      "eval_loss": 1.9339208602905273,
      "eval_runtime": 8.3654,
      "eval_samples_per_second": 23.908,
      "eval_steps_per_second": 23.908,
      "step": 2700
    },
    {
      "epoch": 5.42,
      "grad_norm": 3.3509981632232666,
      "learning_rate": 0.00013909090909090908,
      "loss": 0.2099,
      "step": 2710
    },
    {
      "epoch": 5.44,
      "grad_norm": 1.6470404863357544,
      "learning_rate": 0.00013848484848484846,
      "loss": 0.2229,
      "step": 2720
    },
    {
      "epoch": 5.46,
      "grad_norm": 0.917991042137146,
      "learning_rate": 0.00013787878787878787,
      "loss": 0.2686,
      "step": 2730
    },
    {
      "epoch": 5.48,
      "grad_norm": 4.158773422241211,
      "learning_rate": 0.00013727272727272725,
      "loss": 0.2328,
      "step": 2740
    },
    {
      "epoch": 5.5,
      "grad_norm": 3.7020249366760254,
      "learning_rate": 0.00013666666666666666,
      "loss": 0.257,
      "step": 2750
    },
    {
      "epoch": 5.52,
      "grad_norm": 4.2888054847717285,
      "learning_rate": 0.00013606060606060605,
      "loss": 0.2008,
      "step": 2760
    },
    {
      "epoch": 5.54,
      "grad_norm": 1.884477138519287,
      "learning_rate": 0.00013545454545454546,
      "loss": 0.218,
      "step": 2770
    },
    {
      "epoch": 5.5600000000000005,
      "grad_norm": 3.4627039432525635,
      "learning_rate": 0.00013484848484848484,
      "loss": 0.2193,
      "step": 2780
    },
    {
      "epoch": 5.58,
      "grad_norm": 5.2013092041015625,
      "learning_rate": 0.00013424242424242422,
      "loss": 0.2222,
      "step": 2790
    },
    {
      "epoch": 5.6,
      "grad_norm": 6.0401997566223145,
      "learning_rate": 0.0001336363636363636,
      "loss": 0.3778,
      "step": 2800
    },
    {
      "epoch": 5.6,
      "eval_loss": 1.852542757987976,
      "eval_runtime": 8.4257,
      "eval_samples_per_second": 23.737,
      "eval_steps_per_second": 23.737,
      "step": 2800
    },
    {
      "epoch": 5.62,
      "grad_norm": 3.2606492042541504,
      "learning_rate": 0.00013303030303030302,
      "loss": 0.2362,
      "step": 2810
    },
    {
      "epoch": 5.64,
      "grad_norm": 5.779614448547363,
      "learning_rate": 0.00013242424242424243,
      "loss": 0.2748,
      "step": 2820
    },
    {
      "epoch": 5.66,
      "grad_norm": 4.342981338500977,
      "learning_rate": 0.0001318181818181818,
      "loss": 0.2683,
      "step": 2830
    },
    {
      "epoch": 5.68,
      "grad_norm": 4.789221286773682,
      "learning_rate": 0.0001312121212121212,
      "loss": 0.2486,
      "step": 2840
    },
    {
      "epoch": 5.7,
      "grad_norm": 4.0357279777526855,
      "learning_rate": 0.00013060606060606058,
      "loss": 0.2472,
      "step": 2850
    },
    {
      "epoch": 5.72,
      "grad_norm": 2.6183438301086426,
      "learning_rate": 0.00013,
      "loss": 0.2439,
      "step": 2860
    },
    {
      "epoch": 5.74,
      "grad_norm": 3.6840827465057373,
      "learning_rate": 0.00012939393939393937,
      "loss": 0.2175,
      "step": 2870
    },
    {
      "epoch": 5.76,
      "grad_norm": 0.876437246799469,
      "learning_rate": 0.00012878787878787878,
      "loss": 0.263,
      "step": 2880
    },
    {
      "epoch": 5.78,
      "grad_norm": 2.3237550258636475,
      "learning_rate": 0.00012818181818181817,
      "loss": 0.2021,
      "step": 2890
    },
    {
      "epoch": 5.8,
      "grad_norm": 1.454313039779663,
      "learning_rate": 0.00012757575757575758,
      "loss": 0.2183,
      "step": 2900
    },
    {
      "epoch": 5.8,
      "eval_loss": 1.8825448751449585,
      "eval_runtime": 8.4212,
      "eval_samples_per_second": 23.749,
      "eval_steps_per_second": 23.749,
      "step": 2900
    },
    {
      "epoch": 5.82,
      "grad_norm": 4.822178363800049,
      "learning_rate": 0.00012696969696969696,
      "loss": 0.2716,
      "step": 2910
    },
    {
      "epoch": 5.84,
      "grad_norm": 1.5912015438079834,
      "learning_rate": 0.00012636363636363634,
      "loss": 0.2905,
      "step": 2920
    },
    {
      "epoch": 5.86,
      "grad_norm": 2.9546148777008057,
      "learning_rate": 0.00012575757575757575,
      "loss": 0.2764,
      "step": 2930
    },
    {
      "epoch": 5.88,
      "grad_norm": 1.0965344905853271,
      "learning_rate": 0.00012515151515151514,
      "loss": 0.2179,
      "step": 2940
    },
    {
      "epoch": 5.9,
      "grad_norm": 4.215549468994141,
      "learning_rate": 0.00012454545454545455,
      "loss": 0.2972,
      "step": 2950
    },
    {
      "epoch": 5.92,
      "grad_norm": 4.572079181671143,
      "learning_rate": 0.00012393939393939393,
      "loss": 0.4044,
      "step": 2960
    },
    {
      "epoch": 5.9399999999999995,
      "grad_norm": 1.8582183122634888,
      "learning_rate": 0.0001233333333333333,
      "loss": 0.2424,
      "step": 2970
    },
    {
      "epoch": 5.96,
      "grad_norm": 5.16299295425415,
      "learning_rate": 0.00012272727272727272,
      "loss": 0.2438,
      "step": 2980
    },
    {
      "epoch": 5.98,
      "grad_norm": 4.742432594299316,
      "learning_rate": 0.0001221212121212121,
      "loss": 0.2953,
      "step": 2990
    },
    {
      "epoch": 6.0,
      "grad_norm": 3.815173625946045,
      "learning_rate": 0.0001215151515151515,
      "loss": 0.2603,
      "step": 3000
    },
    {
      "epoch": 6.0,
      "eval_loss": 1.916953444480896,
      "eval_runtime": 8.3114,
      "eval_samples_per_second": 24.063,
      "eval_steps_per_second": 24.063,
      "step": 3000
    },
    {
      "epoch": 6.02,
      "grad_norm": 0.742137610912323,
      "learning_rate": 0.0001209090909090909,
      "loss": 0.1515,
      "step": 3010
    },
    {
      "epoch": 6.04,
      "grad_norm": 3.9801220893859863,
      "learning_rate": 0.00012030303030303028,
      "loss": 0.1322,
      "step": 3020
    },
    {
      "epoch": 6.06,
      "grad_norm": 8.068831443786621,
      "learning_rate": 0.0001196969696969697,
      "loss": 0.1972,
      "step": 3030
    },
    {
      "epoch": 6.08,
      "grad_norm": 11.174837112426758,
      "learning_rate": 0.00011909090909090908,
      "loss": 0.2199,
      "step": 3040
    },
    {
      "epoch": 6.1,
      "grad_norm": 3.276937484741211,
      "learning_rate": 0.00011848484848484847,
      "loss": 0.1409,
      "step": 3050
    },
    {
      "epoch": 6.12,
      "grad_norm": 1.6822776794433594,
      "learning_rate": 0.00011787878787878786,
      "loss": 0.1542,
      "step": 3060
    },
    {
      "epoch": 6.14,
      "grad_norm": 1.7630611658096313,
      "learning_rate": 0.00011727272727272727,
      "loss": 0.1921,
      "step": 3070
    },
    {
      "epoch": 6.16,
      "grad_norm": 1.8599581718444824,
      "learning_rate": 0.00011666666666666665,
      "loss": 0.1965,
      "step": 3080
    },
    {
      "epoch": 6.18,
      "grad_norm": 7.247847557067871,
      "learning_rate": 0.00011606060606060605,
      "loss": 0.1956,
      "step": 3090
    },
    {
      "epoch": 6.2,
      "grad_norm": 6.671987533569336,
      "learning_rate": 0.00011545454545454543,
      "loss": 0.1579,
      "step": 3100
    },
    {
      "epoch": 6.2,
      "eval_loss": 2.0961523056030273,
      "eval_runtime": 8.3913,
      "eval_samples_per_second": 23.834,
      "eval_steps_per_second": 23.834,
      "step": 3100
    },
    {
      "epoch": 6.22,
      "grad_norm": 5.7532877922058105,
      "learning_rate": 0.00011484848484848484,
      "loss": 0.1935,
      "step": 3110
    },
    {
      "epoch": 6.24,
      "grad_norm": 1.5480917692184448,
      "learning_rate": 0.00011424242424242424,
      "loss": 0.2085,
      "step": 3120
    },
    {
      "epoch": 6.26,
      "grad_norm": 1.7930879592895508,
      "learning_rate": 0.00011363636363636362,
      "loss": 0.1766,
      "step": 3130
    },
    {
      "epoch": 6.28,
      "grad_norm": 1.6223125457763672,
      "learning_rate": 0.00011303030303030302,
      "loss": 0.1872,
      "step": 3140
    },
    {
      "epoch": 6.3,
      "grad_norm": 2.5220248699188232,
      "learning_rate": 0.00011242424242424242,
      "loss": 0.1808,
      "step": 3150
    },
    {
      "epoch": 6.32,
      "grad_norm": 5.830231666564941,
      "learning_rate": 0.00011181818181818181,
      "loss": 0.2368,
      "step": 3160
    },
    {
      "epoch": 6.34,
      "grad_norm": 2.4459500312805176,
      "learning_rate": 0.0001112121212121212,
      "loss": 0.2003,
      "step": 3170
    },
    {
      "epoch": 6.36,
      "grad_norm": 3.256364107131958,
      "learning_rate": 0.0001106060606060606,
      "loss": 0.1708,
      "step": 3180
    },
    {
      "epoch": 6.38,
      "grad_norm": 1.6050941944122314,
      "learning_rate": 0.00010999999999999998,
      "loss": 0.1634,
      "step": 3190
    },
    {
      "epoch": 6.4,
      "grad_norm": 5.768906593322754,
      "learning_rate": 0.00010939393939393939,
      "loss": 0.1742,
      "step": 3200
    },
    {
      "epoch": 6.4,
      "eval_loss": 2.0495073795318604,
      "eval_runtime": 8.429,
      "eval_samples_per_second": 23.728,
      "eval_steps_per_second": 23.728,
      "step": 3200
    },
    {
      "epoch": 6.42,
      "grad_norm": 1.9737985134124756,
      "learning_rate": 0.00010878787878787878,
      "loss": 0.1647,
      "step": 3210
    },
    {
      "epoch": 6.44,
      "grad_norm": 5.949321746826172,
      "learning_rate": 0.00010818181818181817,
      "loss": 0.226,
      "step": 3220
    },
    {
      "epoch": 6.46,
      "grad_norm": 1.9436129331588745,
      "learning_rate": 0.00010757575757575756,
      "loss": 0.1903,
      "step": 3230
    },
    {
      "epoch": 6.48,
      "grad_norm": 2.9720375537872314,
      "learning_rate": 0.00010696969696969696,
      "loss": 0.1795,
      "step": 3240
    },
    {
      "epoch": 6.5,
      "grad_norm": 5.6233930587768555,
      "learning_rate": 0.00010636363636363636,
      "loss": 0.2005,
      "step": 3250
    },
    {
      "epoch": 6.52,
      "grad_norm": 3.37599515914917,
      "learning_rate": 0.00010575757575757574,
      "loss": 0.1796,
      "step": 3260
    },
    {
      "epoch": 6.54,
      "grad_norm": 3.339085578918457,
      "learning_rate": 0.00010515151515151514,
      "loss": 0.146,
      "step": 3270
    },
    {
      "epoch": 6.5600000000000005,
      "grad_norm": 1.8167848587036133,
      "learning_rate": 0.00010454545454545455,
      "loss": 0.1694,
      "step": 3280
    },
    {
      "epoch": 6.58,
      "grad_norm": 4.683482646942139,
      "learning_rate": 0.00010393939393939393,
      "loss": 0.2697,
      "step": 3290
    },
    {
      "epoch": 6.6,
      "grad_norm": 1.2420047521591187,
      "learning_rate": 0.00010333333333333333,
      "loss": 0.1613,
      "step": 3300
    },
    {
      "epoch": 6.6,
      "eval_loss": 2.0323009490966797,
      "eval_runtime": 8.3543,
      "eval_samples_per_second": 23.94,
      "eval_steps_per_second": 23.94,
      "step": 3300
    },
    {
      "epoch": 6.62,
      "grad_norm": 5.321410179138184,
      "learning_rate": 0.00010272727272727271,
      "loss": 0.2453,
      "step": 3310
    },
    {
      "epoch": 6.64,
      "grad_norm": 1.3860900402069092,
      "learning_rate": 0.00010212121212121212,
      "loss": 0.1289,
      "step": 3320
    },
    {
      "epoch": 6.66,
      "grad_norm": 1.4544702768325806,
      "learning_rate": 0.0001015151515151515,
      "loss": 0.189,
      "step": 3330
    },
    {
      "epoch": 6.68,
      "grad_norm": 2.0603749752044678,
      "learning_rate": 0.0001009090909090909,
      "loss": 0.2007,
      "step": 3340
    },
    {
      "epoch": 6.7,
      "grad_norm": 0.47979989647865295,
      "learning_rate": 0.00010030303030303029,
      "loss": 0.15,
      "step": 3350
    },
    {
      "epoch": 6.72,
      "grad_norm": 4.909175872802734,
      "learning_rate": 9.969696969696968e-05,
      "loss": 0.1912,
      "step": 3360
    },
    {
      "epoch": 6.74,
      "grad_norm": 3.431885242462158,
      "learning_rate": 9.90909090909091e-05,
      "loss": 0.1832,
      "step": 3370
    },
    {
      "epoch": 6.76,
      "grad_norm": 8.078734397888184,
      "learning_rate": 9.848484848484848e-05,
      "loss": 0.2021,
      "step": 3380
    },
    {
      "epoch": 6.78,
      "grad_norm": 0.8973594903945923,
      "learning_rate": 9.787878787878787e-05,
      "loss": 0.1791,
      "step": 3390
    },
    {
      "epoch": 6.8,
      "grad_norm": 1.2559733390808105,
      "learning_rate": 9.733333333333332e-05,
      "loss": 0.1815,
      "step": 3400
    },
    {
      "epoch": 6.8,
      "eval_loss": 2.0408623218536377,
      "eval_runtime": 8.4315,
      "eval_samples_per_second": 23.721,
      "eval_steps_per_second": 23.721,
      "step": 3400
    },
    {
      "epoch": 6.82,
      "grad_norm": 2.3896067142486572,
      "learning_rate": 9.672727272727273e-05,
      "loss": 0.3062,
      "step": 3410
    },
    {
      "epoch": 6.84,
      "grad_norm": 13.914735794067383,
      "learning_rate": 9.612121212121211e-05,
      "loss": 0.2175,
      "step": 3420
    },
    {
      "epoch": 6.86,
      "grad_norm": 4.098642349243164,
      "learning_rate": 9.551515151515151e-05,
      "loss": 0.1727,
      "step": 3430
    },
    {
      "epoch": 6.88,
      "grad_norm": 2.4009454250335693,
      "learning_rate": 9.490909090909089e-05,
      "loss": 0.1936,
      "step": 3440
    },
    {
      "epoch": 6.9,
      "grad_norm": 5.469816207885742,
      "learning_rate": 9.43030303030303e-05,
      "loss": 0.217,
      "step": 3450
    },
    {
      "epoch": 6.92,
      "grad_norm": 2.449035406112671,
      "learning_rate": 9.369696969696969e-05,
      "loss": 0.2025,
      "step": 3460
    },
    {
      "epoch": 6.9399999999999995,
      "grad_norm": 1.5952450037002563,
      "learning_rate": 9.309090909090908e-05,
      "loss": 0.2128,
      "step": 3470
    },
    {
      "epoch": 6.96,
      "grad_norm": 4.6535868644714355,
      "learning_rate": 9.248484848484847e-05,
      "loss": 0.2172,
      "step": 3480
    },
    {
      "epoch": 6.98,
      "grad_norm": 2.4868388175964355,
      "learning_rate": 9.187878787878786e-05,
      "loss": 0.1769,
      "step": 3490
    },
    {
      "epoch": 7.0,
      "grad_norm": 3.1803107261657715,
      "learning_rate": 9.127272727272727e-05,
      "loss": 0.1754,
      "step": 3500
    },
    {
      "epoch": 7.0,
      "eval_loss": 2.0034127235412598,
      "eval_runtime": 8.3149,
      "eval_samples_per_second": 24.053,
      "eval_steps_per_second": 24.053,
      "step": 3500
    },
    {
      "epoch": 7.02,
      "grad_norm": 3.792590379714966,
      "learning_rate": 9.066666666666666e-05,
      "loss": 0.1395,
      "step": 3510
    },
    {
      "epoch": 7.04,
      "grad_norm": 5.064057350158691,
      "learning_rate": 9.006060606060605e-05,
      "loss": 0.1639,
      "step": 3520
    },
    {
      "epoch": 7.06,
      "grad_norm": 1.4195282459259033,
      "learning_rate": 8.945454545454544e-05,
      "loss": 0.1845,
      "step": 3530
    },
    {
      "epoch": 7.08,
      "grad_norm": 5.668316841125488,
      "learning_rate": 8.884848484848485e-05,
      "loss": 0.1438,
      "step": 3540
    },
    {
      "epoch": 7.1,
      "grad_norm": 1.0866445302963257,
      "learning_rate": 8.824242424242423e-05,
      "loss": 0.136,
      "step": 3550
    },
    {
      "epoch": 7.12,
      "grad_norm": 1.3828660249710083,
      "learning_rate": 8.763636363636363e-05,
      "loss": 0.1302,
      "step": 3560
    },
    {
      "epoch": 7.14,
      "grad_norm": 1.0194694995880127,
      "learning_rate": 8.703030303030301e-05,
      "loss": 0.1346,
      "step": 3570
    },
    {
      "epoch": 7.16,
      "grad_norm": 3.1882970333099365,
      "learning_rate": 8.642424242424242e-05,
      "loss": 0.1336,
      "step": 3580
    },
    {
      "epoch": 7.18,
      "grad_norm": 1.038334846496582,
      "learning_rate": 8.581818181818182e-05,
      "loss": 0.1508,
      "step": 3590
    },
    {
      "epoch": 7.2,
      "grad_norm": 1.2625526189804077,
      "learning_rate": 8.52121212121212e-05,
      "loss": 0.1297,
      "step": 3600
    },
    {
      "epoch": 7.2,
      "eval_loss": 2.2040696144104004,
      "eval_runtime": 8.4433,
      "eval_samples_per_second": 23.687,
      "eval_steps_per_second": 23.687,
      "step": 3600
    },
    {
      "epoch": 7.22,
      "grad_norm": 0.7221952676773071,
      "learning_rate": 8.46060606060606e-05,
      "loss": 0.162,
      "step": 3610
    },
    {
      "epoch": 7.24,
      "grad_norm": 4.1197075843811035,
      "learning_rate": 8.4e-05,
      "loss": 0.177,
      "step": 3620
    },
    {
      "epoch": 7.26,
      "grad_norm": 1.2020198106765747,
      "learning_rate": 8.339393939393939e-05,
      "loss": 0.125,
      "step": 3630
    },
    {
      "epoch": 7.28,
      "grad_norm": 0.9516460299491882,
      "learning_rate": 8.278787878787878e-05,
      "loss": 0.1407,
      "step": 3640
    },
    {
      "epoch": 7.3,
      "grad_norm": 1.6984972953796387,
      "learning_rate": 8.218181818181817e-05,
      "loss": 0.1443,
      "step": 3650
    },
    {
      "epoch": 7.32,
      "grad_norm": 1.983641266822815,
      "learning_rate": 8.157575757575756e-05,
      "loss": 0.1752,
      "step": 3660
    },
    {
      "epoch": 7.34,
      "grad_norm": 1.7166376113891602,
      "learning_rate": 8.096969696969697e-05,
      "loss": 0.1556,
      "step": 3670
    },
    {
      "epoch": 7.36,
      "grad_norm": 2.5256242752075195,
      "learning_rate": 8.036363636363636e-05,
      "loss": 0.1549,
      "step": 3680
    },
    {
      "epoch": 7.38,
      "grad_norm": 2.37035870552063,
      "learning_rate": 7.975757575757575e-05,
      "loss": 0.1594,
      "step": 3690
    },
    {
      "epoch": 7.4,
      "grad_norm": 2.3183209896087646,
      "learning_rate": 7.915151515151514e-05,
      "loss": 0.1526,
      "step": 3700
    },
    {
      "epoch": 7.4,
      "eval_loss": 2.2028276920318604,
      "eval_runtime": 8.3549,
      "eval_samples_per_second": 23.938,
      "eval_steps_per_second": 23.938,
      "step": 3700
    },
    {
      "epoch": 7.42,
      "grad_norm": 0.7772328853607178,
      "learning_rate": 7.854545454545454e-05,
      "loss": 0.1601,
      "step": 3710
    },
    {
      "epoch": 7.44,
      "grad_norm": 15.148015022277832,
      "learning_rate": 7.793939393939394e-05,
      "loss": 0.183,
      "step": 3720
    },
    {
      "epoch": 7.46,
      "grad_norm": 8.372042655944824,
      "learning_rate": 7.733333333333332e-05,
      "loss": 0.1493,
      "step": 3730
    },
    {
      "epoch": 7.48,
      "grad_norm": 10.249011993408203,
      "learning_rate": 7.672727272727272e-05,
      "loss": 0.158,
      "step": 3740
    },
    {
      "epoch": 7.5,
      "grad_norm": 1.6077461242675781,
      "learning_rate": 7.612121212121213e-05,
      "loss": 0.1405,
      "step": 3750
    },
    {
      "epoch": 7.52,
      "grad_norm": 3.5866353511810303,
      "learning_rate": 7.551515151515151e-05,
      "loss": 0.1502,
      "step": 3760
    },
    {
      "epoch": 7.54,
      "grad_norm": 4.1336493492126465,
      "learning_rate": 7.490909090909091e-05,
      "loss": 0.1562,
      "step": 3770
    },
    {
      "epoch": 7.5600000000000005,
      "grad_norm": 0.7632027864456177,
      "learning_rate": 7.43030303030303e-05,
      "loss": 0.1389,
      "step": 3780
    },
    {
      "epoch": 7.58,
      "grad_norm": 1.202603816986084,
      "learning_rate": 7.369696969696969e-05,
      "loss": 0.1719,
      "step": 3790
    },
    {
      "epoch": 7.6,
      "grad_norm": 0.6249682903289795,
      "learning_rate": 7.309090909090908e-05,
      "loss": 0.1407,
      "step": 3800
    },
    {
      "epoch": 7.6,
      "eval_loss": 2.269979953765869,
      "eval_runtime": 8.335,
      "eval_samples_per_second": 23.995,
      "eval_steps_per_second": 23.995,
      "step": 3800
    },
    {
      "epoch": 7.62,
      "grad_norm": 0.778994619846344,
      "learning_rate": 7.248484848484848e-05,
      "loss": 0.1379,
      "step": 3810
    },
    {
      "epoch": 7.64,
      "grad_norm": 0.9339216947555542,
      "learning_rate": 7.187878787878786e-05,
      "loss": 0.1403,
      "step": 3820
    },
    {
      "epoch": 7.66,
      "grad_norm": 1.6224428415298462,
      "learning_rate": 7.127272727272726e-05,
      "loss": 0.1262,
      "step": 3830
    },
    {
      "epoch": 7.68,
      "grad_norm": 2.329989194869995,
      "learning_rate": 7.066666666666666e-05,
      "loss": 0.1671,
      "step": 3840
    },
    {
      "epoch": 7.7,
      "grad_norm": 1.4553167819976807,
      "learning_rate": 7.006060606060606e-05,
      "loss": 0.1761,
      "step": 3850
    },
    {
      "epoch": 7.72,
      "grad_norm": 2.412199020385742,
      "learning_rate": 6.945454545454545e-05,
      "loss": 0.1374,
      "step": 3860
    },
    {
      "epoch": 7.74,
      "grad_norm": 2.765947103500366,
      "learning_rate": 6.884848484848485e-05,
      "loss": 0.1499,
      "step": 3870
    },
    {
      "epoch": 7.76,
      "grad_norm": 1.4611968994140625,
      "learning_rate": 6.824242424242423e-05,
      "loss": 0.1457,
      "step": 3880
    },
    {
      "epoch": 7.78,
      "grad_norm": 0.807828426361084,
      "learning_rate": 6.763636363636363e-05,
      "loss": 0.1261,
      "step": 3890
    },
    {
      "epoch": 7.8,
      "grad_norm": 1.9216519594192505,
      "learning_rate": 6.703030303030303e-05,
      "loss": 0.1493,
      "step": 3900
    },
    {
      "epoch": 7.8,
      "eval_loss": 2.1818692684173584,
      "eval_runtime": 8.3377,
      "eval_samples_per_second": 23.988,
      "eval_steps_per_second": 23.988,
      "step": 3900
    },
    {
      "epoch": 7.82,
      "grad_norm": 2.0363590717315674,
      "learning_rate": 6.642424242424242e-05,
      "loss": 0.1614,
      "step": 3910
    },
    {
      "epoch": 7.84,
      "grad_norm": 1.145716905593872,
      "learning_rate": 6.58181818181818e-05,
      "loss": 0.1694,
      "step": 3920
    },
    {
      "epoch": 7.86,
      "grad_norm": 2.5021352767944336,
      "learning_rate": 6.52121212121212e-05,
      "loss": 0.1569,
      "step": 3930
    },
    {
      "epoch": 7.88,
      "grad_norm": 2.255699396133423,
      "learning_rate": 6.46060606060606e-05,
      "loss": 0.1452,
      "step": 3940
    },
    {
      "epoch": 7.9,
      "grad_norm": 1.2274688482284546,
      "learning_rate": 6.4e-05,
      "loss": 0.1361,
      "step": 3950
    },
    {
      "epoch": 7.92,
      "grad_norm": 0.8088545203208923,
      "learning_rate": 6.33939393939394e-05,
      "loss": 0.1725,
      "step": 3960
    },
    {
      "epoch": 7.9399999999999995,
      "grad_norm": 1.4477421045303345,
      "learning_rate": 6.278787878787878e-05,
      "loss": 0.1527,
      "step": 3970
    },
    {
      "epoch": 7.96,
      "grad_norm": 1.0566039085388184,
      "learning_rate": 6.218181818181817e-05,
      "loss": 0.1345,
      "step": 3980
    },
    {
      "epoch": 7.98,
      "grad_norm": 1.3348790407180786,
      "learning_rate": 6.157575757575757e-05,
      "loss": 0.1489,
      "step": 3990
    },
    {
      "epoch": 8.0,
      "grad_norm": 1.4267070293426514,
      "learning_rate": 6.096969696969697e-05,
      "loss": 0.1674,
      "step": 4000
    },
    {
      "epoch": 8.0,
      "eval_loss": 2.1679635047912598,
      "eval_runtime": 8.3084,
      "eval_samples_per_second": 24.072,
      "eval_steps_per_second": 24.072,
      "step": 4000
    },
    {
      "epoch": 8.02,
      "grad_norm": 0.8382382392883301,
      "learning_rate": 6.036363636363636e-05,
      "loss": 0.1272,
      "step": 4010
    },
    {
      "epoch": 8.04,
      "grad_norm": 1.1551201343536377,
      "learning_rate": 5.9757575757575755e-05,
      "loss": 0.123,
      "step": 4020
    },
    {
      "epoch": 8.06,
      "grad_norm": 1.1858150959014893,
      "learning_rate": 5.9151515151515145e-05,
      "loss": 0.1062,
      "step": 4030
    },
    {
      "epoch": 8.08,
      "grad_norm": 1.1805601119995117,
      "learning_rate": 5.854545454545454e-05,
      "loss": 0.1227,
      "step": 4040
    },
    {
      "epoch": 8.1,
      "grad_norm": 0.6928383708000183,
      "learning_rate": 5.793939393939393e-05,
      "loss": 0.1572,
      "step": 4050
    },
    {
      "epoch": 8.12,
      "grad_norm": 1.075461983680725,
      "learning_rate": 5.733333333333333e-05,
      "loss": 0.1255,
      "step": 4060
    },
    {
      "epoch": 8.14,
      "grad_norm": 1.623822569847107,
      "learning_rate": 5.672727272727272e-05,
      "loss": 0.1579,
      "step": 4070
    },
    {
      "epoch": 8.16,
      "grad_norm": 1.3995822668075562,
      "learning_rate": 5.612121212121212e-05,
      "loss": 0.1165,
      "step": 4080
    },
    {
      "epoch": 8.18,
      "grad_norm": 1.6069297790527344,
      "learning_rate": 5.551515151515151e-05,
      "loss": 0.1128,
      "step": 4090
    },
    {
      "epoch": 8.2,
      "grad_norm": 0.9072746634483337,
      "learning_rate": 5.490909090909091e-05,
      "loss": 0.1279,
      "step": 4100
    },
    {
      "epoch": 8.2,
      "eval_loss": 2.2975215911865234,
      "eval_runtime": 8.3877,
      "eval_samples_per_second": 23.845,
      "eval_steps_per_second": 23.845,
      "step": 4100
    },
    {
      "epoch": 8.22,
      "grad_norm": 1.752694845199585,
      "learning_rate": 5.43030303030303e-05,
      "loss": 0.1323,
      "step": 4110
    },
    {
      "epoch": 8.24,
      "grad_norm": 1.2475908994674683,
      "learning_rate": 5.369696969696969e-05,
      "loss": 0.1275,
      "step": 4120
    },
    {
      "epoch": 8.26,
      "grad_norm": 1.227030873298645,
      "learning_rate": 5.3090909090909087e-05,
      "loss": 0.1238,
      "step": 4130
    },
    {
      "epoch": 8.28,
      "grad_norm": 2.579362392425537,
      "learning_rate": 5.2484848484848477e-05,
      "loss": 0.1238,
      "step": 4140
    },
    {
      "epoch": 8.3,
      "grad_norm": 0.9999257326126099,
      "learning_rate": 5.1878787878787873e-05,
      "loss": 0.1341,
      "step": 4150
    },
    {
      "epoch": 8.32,
      "grad_norm": 4.450356483459473,
      "learning_rate": 5.1272727272727264e-05,
      "loss": 0.1183,
      "step": 4160
    },
    {
      "epoch": 8.34,
      "grad_norm": 3.3764126300811768,
      "learning_rate": 5.066666666666666e-05,
      "loss": 0.1485,
      "step": 4170
    },
    {
      "epoch": 8.36,
      "grad_norm": 0.5509064197540283,
      "learning_rate": 5.006060606060605e-05,
      "loss": 0.119,
      "step": 4180
    },
    {
      "epoch": 8.38,
      "grad_norm": 4.7639899253845215,
      "learning_rate": 4.9454545454545454e-05,
      "loss": 0.1317,
      "step": 4190
    },
    {
      "epoch": 8.4,
      "grad_norm": 1.1650407314300537,
      "learning_rate": 4.8848484848484844e-05,
      "loss": 0.1232,
      "step": 4200
    },
    {
      "epoch": 8.4,
      "eval_loss": 2.337158441543579,
      "eval_runtime": 8.3389,
      "eval_samples_per_second": 23.984,
      "eval_steps_per_second": 23.984,
      "step": 4200
    },
    {
      "epoch": 8.42,
      "grad_norm": 0.7234786152839661,
      "learning_rate": 4.824242424242424e-05,
      "loss": 0.1313,
      "step": 4210
    },
    {
      "epoch": 8.44,
      "grad_norm": 1.1945444345474243,
      "learning_rate": 4.763636363636363e-05,
      "loss": 0.135,
      "step": 4220
    },
    {
      "epoch": 8.46,
      "grad_norm": 0.859626054763794,
      "learning_rate": 4.703030303030303e-05,
      "loss": 0.125,
      "step": 4230
    },
    {
      "epoch": 8.48,
      "grad_norm": 2.0406320095062256,
      "learning_rate": 4.642424242424242e-05,
      "loss": 0.1222,
      "step": 4240
    },
    {
      "epoch": 8.5,
      "grad_norm": 6.2350921630859375,
      "learning_rate": 4.5818181818181815e-05,
      "loss": 0.1589,
      "step": 4250
    },
    {
      "epoch": 8.52,
      "grad_norm": 4.5924973487854,
      "learning_rate": 4.5212121212121205e-05,
      "loss": 0.1196,
      "step": 4260
    },
    {
      "epoch": 8.54,
      "grad_norm": 1.5795537233352661,
      "learning_rate": 4.460606060606061e-05,
      "loss": 0.1441,
      "step": 4270
    },
    {
      "epoch": 8.56,
      "grad_norm": 2.1370928287506104,
      "learning_rate": 4.4e-05,
      "loss": 0.1263,
      "step": 4280
    },
    {
      "epoch": 8.58,
      "grad_norm": 0.6741625666618347,
      "learning_rate": 4.339393939393939e-05,
      "loss": 0.1318,
      "step": 4290
    },
    {
      "epoch": 8.6,
      "grad_norm": 0.6166362166404724,
      "learning_rate": 4.2787878787878786e-05,
      "loss": 0.119,
      "step": 4300
    },
    {
      "epoch": 8.6,
      "eval_loss": 2.302257776260376,
      "eval_runtime": 8.3694,
      "eval_samples_per_second": 23.897,
      "eval_steps_per_second": 23.897,
      "step": 4300
    },
    {
      "epoch": 8.62,
      "grad_norm": 2.7796850204467773,
      "learning_rate": 4.2181818181818176e-05,
      "loss": 0.128,
      "step": 4310
    },
    {
      "epoch": 8.64,
      "grad_norm": 1.1914445161819458,
      "learning_rate": 4.157575757575757e-05,
      "loss": 0.1316,
      "step": 4320
    },
    {
      "epoch": 8.66,
      "grad_norm": 5.253080368041992,
      "learning_rate": 4.096969696969696e-05,
      "loss": 0.1251,
      "step": 4330
    },
    {
      "epoch": 8.68,
      "grad_norm": 1.7171603441238403,
      "learning_rate": 4.036363636363636e-05,
      "loss": 0.1269,
      "step": 4340
    },
    {
      "epoch": 8.7,
      "grad_norm": 0.7533727884292603,
      "learning_rate": 3.975757575757575e-05,
      "loss": 0.1263,
      "step": 4350
    },
    {
      "epoch": 8.72,
      "grad_norm": 2.5280635356903076,
      "learning_rate": 3.9151515151515153e-05,
      "loss": 0.1335,
      "step": 4360
    },
    {
      "epoch": 8.74,
      "grad_norm": 1.5270296335220337,
      "learning_rate": 3.8545454545454544e-05,
      "loss": 0.1235,
      "step": 4370
    },
    {
      "epoch": 8.76,
      "grad_norm": 2.058678150177002,
      "learning_rate": 3.793939393939394e-05,
      "loss": 0.116,
      "step": 4380
    },
    {
      "epoch": 8.78,
      "grad_norm": 7.660192012786865,
      "learning_rate": 3.733333333333333e-05,
      "loss": 0.1453,
      "step": 4390
    },
    {
      "epoch": 8.8,
      "grad_norm": 1.334085464477539,
      "learning_rate": 3.672727272727272e-05,
      "loss": 0.1225,
      "step": 4400
    },
    {
      "epoch": 8.8,
      "eval_loss": 2.298794984817505,
      "eval_runtime": 8.3258,
      "eval_samples_per_second": 24.022,
      "eval_steps_per_second": 24.022,
      "step": 4400
    },
    {
      "epoch": 8.82,
      "grad_norm": 1.1396725177764893,
      "learning_rate": 3.612121212121212e-05,
      "loss": 0.1273,
      "step": 4410
    },
    {
      "epoch": 8.84,
      "grad_norm": 0.9558030962944031,
      "learning_rate": 3.5515151515151514e-05,
      "loss": 0.1413,
      "step": 4420
    },
    {
      "epoch": 8.86,
      "grad_norm": 2.293168783187866,
      "learning_rate": 3.4909090909090904e-05,
      "loss": 0.1201,
      "step": 4430
    },
    {
      "epoch": 8.88,
      "grad_norm": 0.9326896071434021,
      "learning_rate": 3.43030303030303e-05,
      "loss": 0.1216,
      "step": 4440
    },
    {
      "epoch": 8.9,
      "grad_norm": 1.3537912368774414,
      "learning_rate": 3.369696969696969e-05,
      "loss": 0.129,
      "step": 4450
    },
    {
      "epoch": 8.92,
      "grad_norm": 1.0859888792037964,
      "learning_rate": 3.309090909090909e-05,
      "loss": 0.1291,
      "step": 4460
    },
    {
      "epoch": 8.94,
      "grad_norm": 1.0476161241531372,
      "learning_rate": 3.2484848484848485e-05,
      "loss": 0.1115,
      "step": 4470
    },
    {
      "epoch": 8.96,
      "grad_norm": 0.6087696552276611,
      "learning_rate": 3.1878787878787875e-05,
      "loss": 0.1182,
      "step": 4480
    },
    {
      "epoch": 8.98,
      "grad_norm": 2.6717514991760254,
      "learning_rate": 3.127272727272727e-05,
      "loss": 0.1287,
      "step": 4490
    },
    {
      "epoch": 9.0,
      "grad_norm": 1.084236979484558,
      "learning_rate": 3.066666666666667e-05,
      "loss": 0.1154,
      "step": 4500
    },
    {
      "epoch": 9.0,
      "eval_loss": 2.291710615158081,
      "eval_runtime": 8.3291,
      "eval_samples_per_second": 24.012,
      "eval_steps_per_second": 24.012,
      "step": 4500
    }
  ],
  "logging_steps": 10,
  "max_steps": 5000,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 10,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 1.3472250200064e+16,
  "train_batch_size": 1,
  "trial_name": null,
  "trial_params": null
}

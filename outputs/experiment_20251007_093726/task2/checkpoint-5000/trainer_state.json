{
  "best_global_step": null,
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 10.0,
  "eval_steps": 100,
  "global_step": 5000,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.02,
      "grad_norm": 33.629417419433594,
      "learning_rate": 2.9999999999999997e-05,
      "loss": 5.723,
      "step": 10
    },
    {
      "epoch": 0.04,
      "grad_norm": 9.752657890319824,
      "learning_rate": 8.999999999999999e-05,
      "loss": 4.2428,
      "step": 20
    },
    {
      "epoch": 0.06,
      "grad_norm": 6.154024124145508,
      "learning_rate": 0.00015,
      "loss": 2.5539,
      "step": 30
    },
    {
      "epoch": 0.08,
      "grad_norm": 4.167150020599365,
      "learning_rate": 0.00020999999999999998,
      "loss": 1.7232,
      "step": 40
    },
    {
      "epoch": 0.1,
      "grad_norm": 2.720163106918335,
      "learning_rate": 0.00027,
      "loss": 1.4376,
      "step": 50
    },
    {
      "epoch": 0.12,
      "grad_norm": 2.4879229068756104,
      "learning_rate": 0.00029969696969696965,
      "loss": 1.4875,
      "step": 60
    },
    {
      "epoch": 0.14,
      "grad_norm": 2.4538111686706543,
      "learning_rate": 0.00029909090909090906,
      "loss": 1.4149,
      "step": 70
    },
    {
      "epoch": 0.16,
      "grad_norm": 2.5301878452301025,
      "learning_rate": 0.00029848484848484847,
      "loss": 1.3077,
      "step": 80
    },
    {
      "epoch": 0.18,
      "grad_norm": 2.228843927383423,
      "learning_rate": 0.00029787878787878783,
      "loss": 1.2558,
      "step": 90
    },
    {
      "epoch": 0.2,
      "grad_norm": 2.6042659282684326,
      "learning_rate": 0.00029727272727272724,
      "loss": 1.03,
      "step": 100
    },
    {
      "epoch": 0.2,
      "eval_loss": 1.355014681816101,
      "eval_runtime": 8.474,
      "eval_samples_per_second": 23.602,
      "eval_steps_per_second": 23.602,
      "step": 100
    },
    {
      "epoch": 0.22,
      "grad_norm": 3.0775856971740723,
      "learning_rate": 0.00029666666666666665,
      "loss": 1.1153,
      "step": 110
    },
    {
      "epoch": 0.24,
      "grad_norm": 2.5659573078155518,
      "learning_rate": 0.00029606060606060606,
      "loss": 1.402,
      "step": 120
    },
    {
      "epoch": 0.26,
      "grad_norm": 2.480825662612915,
      "learning_rate": 0.0002954545454545454,
      "loss": 1.1114,
      "step": 130
    },
    {
      "epoch": 0.28,
      "grad_norm": 1.7537533044815063,
      "learning_rate": 0.0002948484848484848,
      "loss": 1.0576,
      "step": 140
    },
    {
      "epoch": 0.3,
      "grad_norm": 3.401437759399414,
      "learning_rate": 0.00029424242424242424,
      "loss": 1.426,
      "step": 150
    },
    {
      "epoch": 0.32,
      "grad_norm": 2.4115002155303955,
      "learning_rate": 0.0002936363636363636,
      "loss": 1.4561,
      "step": 160
    },
    {
      "epoch": 0.34,
      "grad_norm": 2.1533193588256836,
      "learning_rate": 0.000293030303030303,
      "loss": 1.3824,
      "step": 170
    },
    {
      "epoch": 0.36,
      "grad_norm": 3.1463375091552734,
      "learning_rate": 0.00029242424242424236,
      "loss": 1.1582,
      "step": 180
    },
    {
      "epoch": 0.38,
      "grad_norm": 2.908266067504883,
      "learning_rate": 0.0002918181818181818,
      "loss": 1.3528,
      "step": 190
    },
    {
      "epoch": 0.4,
      "grad_norm": 2.281741142272949,
      "learning_rate": 0.0002912121212121212,
      "loss": 1.126,
      "step": 200
    },
    {
      "epoch": 0.4,
      "eval_loss": 1.295249581336975,
      "eval_runtime": 8.6212,
      "eval_samples_per_second": 23.199,
      "eval_steps_per_second": 23.199,
      "step": 200
    },
    {
      "epoch": 0.42,
      "grad_norm": 1.5920047760009766,
      "learning_rate": 0.0002906060606060606,
      "loss": 1.3818,
      "step": 210
    },
    {
      "epoch": 0.44,
      "grad_norm": 1.6278905868530273,
      "learning_rate": 0.00029,
      "loss": 1.198,
      "step": 220
    },
    {
      "epoch": 0.46,
      "grad_norm": 5.805392742156982,
      "learning_rate": 0.00028939393939393936,
      "loss": 1.3112,
      "step": 230
    },
    {
      "epoch": 0.48,
      "grad_norm": 1.9832212924957275,
      "learning_rate": 0.00028878787878787877,
      "loss": 1.2702,
      "step": 240
    },
    {
      "epoch": 0.5,
      "grad_norm": 2.8486814498901367,
      "learning_rate": 0.0002881818181818181,
      "loss": 1.2575,
      "step": 250
    },
    {
      "epoch": 0.52,
      "grad_norm": 2.439958095550537,
      "learning_rate": 0.00028757575757575753,
      "loss": 1.1203,
      "step": 260
    },
    {
      "epoch": 0.54,
      "grad_norm": 2.006056785583496,
      "learning_rate": 0.00028696969696969695,
      "loss": 1.3762,
      "step": 270
    },
    {
      "epoch": 0.56,
      "grad_norm": 3.1827785968780518,
      "learning_rate": 0.00028636363636363636,
      "loss": 1.2089,
      "step": 280
    },
    {
      "epoch": 0.58,
      "grad_norm": 2.1348555088043213,
      "learning_rate": 0.00028575757575757577,
      "loss": 1.2385,
      "step": 290
    },
    {
      "epoch": 0.6,
      "grad_norm": 1.6285429000854492,
      "learning_rate": 0.0002851515151515151,
      "loss": 1.3933,
      "step": 300
    },
    {
      "epoch": 0.6,
      "eval_loss": 1.2787351608276367,
      "eval_runtime": 8.4318,
      "eval_samples_per_second": 23.72,
      "eval_steps_per_second": 23.72,
      "step": 300
    },
    {
      "epoch": 0.62,
      "grad_norm": 2.8176398277282715,
      "learning_rate": 0.00028454545454545453,
      "loss": 1.2077,
      "step": 310
    },
    {
      "epoch": 0.64,
      "grad_norm": 2.1461050510406494,
      "learning_rate": 0.0002839393939393939,
      "loss": 1.0678,
      "step": 320
    },
    {
      "epoch": 0.66,
      "grad_norm": 1.868735671043396,
      "learning_rate": 0.0002833333333333333,
      "loss": 1.2507,
      "step": 330
    },
    {
      "epoch": 0.68,
      "grad_norm": 2.174797296524048,
      "learning_rate": 0.0002827272727272727,
      "loss": 1.2965,
      "step": 340
    },
    {
      "epoch": 0.7,
      "grad_norm": 1.6318494081497192,
      "learning_rate": 0.00028212121212121207,
      "loss": 1.1364,
      "step": 350
    },
    {
      "epoch": 0.72,
      "grad_norm": 1.891925573348999,
      "learning_rate": 0.00028151515151515153,
      "loss": 1.1114,
      "step": 360
    },
    {
      "epoch": 0.74,
      "grad_norm": 2.287891149520874,
      "learning_rate": 0.0002809090909090909,
      "loss": 1.3647,
      "step": 370
    },
    {
      "epoch": 0.76,
      "grad_norm": 2.885627031326294,
      "learning_rate": 0.0002803030303030303,
      "loss": 1.3539,
      "step": 380
    },
    {
      "epoch": 0.78,
      "grad_norm": 2.5481741428375244,
      "learning_rate": 0.00027969696969696965,
      "loss": 1.4174,
      "step": 390
    },
    {
      "epoch": 0.8,
      "grad_norm": 2.0382938385009766,
      "learning_rate": 0.00027909090909090906,
      "loss": 1.1893,
      "step": 400
    },
    {
      "epoch": 0.8,
      "eval_loss": 1.270681619644165,
      "eval_runtime": 8.4324,
      "eval_samples_per_second": 23.718,
      "eval_steps_per_second": 23.718,
      "step": 400
    },
    {
      "epoch": 0.82,
      "grad_norm": 1.9594776630401611,
      "learning_rate": 0.0002784848484848485,
      "loss": 1.1113,
      "step": 410
    },
    {
      "epoch": 0.84,
      "grad_norm": 1.8153268098831177,
      "learning_rate": 0.00027787878787878783,
      "loss": 1.0091,
      "step": 420
    },
    {
      "epoch": 0.86,
      "grad_norm": 2.228222608566284,
      "learning_rate": 0.00027727272727272724,
      "loss": 1.416,
      "step": 430
    },
    {
      "epoch": 0.88,
      "grad_norm": 2.485320806503296,
      "learning_rate": 0.00027666666666666665,
      "loss": 1.2152,
      "step": 440
    },
    {
      "epoch": 0.9,
      "grad_norm": 2.0922698974609375,
      "learning_rate": 0.00027606060606060606,
      "loss": 1.275,
      "step": 450
    },
    {
      "epoch": 0.92,
      "grad_norm": 2.9456844329833984,
      "learning_rate": 0.0002754545454545454,
      "loss": 1.1728,
      "step": 460
    },
    {
      "epoch": 0.94,
      "grad_norm": 1.600268006324768,
      "learning_rate": 0.00027484848484848483,
      "loss": 1.2595,
      "step": 470
    },
    {
      "epoch": 0.96,
      "grad_norm": 1.9340260028839111,
      "learning_rate": 0.00027424242424242424,
      "loss": 1.3415,
      "step": 480
    },
    {
      "epoch": 0.98,
      "grad_norm": 1.7052018642425537,
      "learning_rate": 0.0002736363636363636,
      "loss": 1.2502,
      "step": 490
    },
    {
      "epoch": 1.0,
      "grad_norm": 2.4012794494628906,
      "learning_rate": 0.000273030303030303,
      "loss": 1.4292,
      "step": 500
    },
    {
      "epoch": 1.0,
      "eval_loss": 1.2585818767547607,
      "eval_runtime": 8.8074,
      "eval_samples_per_second": 22.708,
      "eval_steps_per_second": 22.708,
      "step": 500
    },
    {
      "epoch": 1.02,
      "grad_norm": 1.5978648662567139,
      "learning_rate": 0.0002724242424242424,
      "loss": 1.199,
      "step": 510
    },
    {
      "epoch": 1.04,
      "grad_norm": 0.9847096800804138,
      "learning_rate": 0.00027181818181818177,
      "loss": 1.0883,
      "step": 520
    },
    {
      "epoch": 1.06,
      "grad_norm": 2.410524845123291,
      "learning_rate": 0.0002712121212121212,
      "loss": 0.9013,
      "step": 530
    },
    {
      "epoch": 1.08,
      "grad_norm": 4.255842685699463,
      "learning_rate": 0.0002706060606060606,
      "loss": 0.9287,
      "step": 540
    },
    {
      "epoch": 1.1,
      "grad_norm": 2.0636839866638184,
      "learning_rate": 0.00027,
      "loss": 0.9237,
      "step": 550
    },
    {
      "epoch": 1.12,
      "grad_norm": 2.0298497676849365,
      "learning_rate": 0.00026939393939393936,
      "loss": 1.0256,
      "step": 560
    },
    {
      "epoch": 1.1400000000000001,
      "grad_norm": 3.1874730587005615,
      "learning_rate": 0.00026878787878787877,
      "loss": 0.989,
      "step": 570
    },
    {
      "epoch": 1.16,
      "grad_norm": 2.5261855125427246,
      "learning_rate": 0.0002681818181818181,
      "loss": 0.9677,
      "step": 580
    },
    {
      "epoch": 1.18,
      "grad_norm": 3.1696035861968994,
      "learning_rate": 0.00026757575757575754,
      "loss": 1.1144,
      "step": 590
    },
    {
      "epoch": 1.2,
      "grad_norm": 2.4855682849884033,
      "learning_rate": 0.00026696969696969695,
      "loss": 1.0365,
      "step": 600
    },
    {
      "epoch": 1.2,
      "eval_loss": 1.2911498546600342,
      "eval_runtime": 8.42,
      "eval_samples_per_second": 23.753,
      "eval_steps_per_second": 23.753,
      "step": 600
    },
    {
      "epoch": 1.22,
      "grad_norm": 2.2526118755340576,
      "learning_rate": 0.00026636363636363636,
      "loss": 1.1872,
      "step": 610
    },
    {
      "epoch": 1.24,
      "grad_norm": 2.6075234413146973,
      "learning_rate": 0.00026575757575757577,
      "loss": 0.8624,
      "step": 620
    },
    {
      "epoch": 1.26,
      "grad_norm": 2.913116693496704,
      "learning_rate": 0.0002651515151515151,
      "loss": 1.1585,
      "step": 630
    },
    {
      "epoch": 1.28,
      "grad_norm": 2.72367000579834,
      "learning_rate": 0.00026454545454545453,
      "loss": 0.951,
      "step": 640
    },
    {
      "epoch": 1.3,
      "grad_norm": 2.160315752029419,
      "learning_rate": 0.0002639393939393939,
      "loss": 0.8787,
      "step": 650
    },
    {
      "epoch": 1.32,
      "grad_norm": 3.24019193649292,
      "learning_rate": 0.0002633333333333333,
      "loss": 1.0054,
      "step": 660
    },
    {
      "epoch": 1.34,
      "grad_norm": 3.060971975326538,
      "learning_rate": 0.0002627272727272727,
      "loss": 0.986,
      "step": 670
    },
    {
      "epoch": 1.3599999999999999,
      "grad_norm": 2.7619950771331787,
      "learning_rate": 0.00026212121212121207,
      "loss": 1.0826,
      "step": 680
    },
    {
      "epoch": 1.38,
      "grad_norm": 2.7052619457244873,
      "learning_rate": 0.0002615151515151515,
      "loss": 1.0173,
      "step": 690
    },
    {
      "epoch": 1.4,
      "grad_norm": 3.158881664276123,
      "learning_rate": 0.0002609090909090909,
      "loss": 1.1964,
      "step": 700
    },
    {
      "epoch": 1.4,
      "eval_loss": 1.2882617712020874,
      "eval_runtime": 8.3365,
      "eval_samples_per_second": 23.991,
      "eval_steps_per_second": 23.991,
      "step": 700
    },
    {
      "epoch": 1.42,
      "grad_norm": 2.231612205505371,
      "learning_rate": 0.0002603030303030303,
      "loss": 1.077,
      "step": 710
    },
    {
      "epoch": 1.44,
      "grad_norm": 2.4076344966888428,
      "learning_rate": 0.00025969696969696966,
      "loss": 1.0442,
      "step": 720
    },
    {
      "epoch": 1.46,
      "grad_norm": 2.3276448249816895,
      "learning_rate": 0.00025909090909090907,
      "loss": 1.0943,
      "step": 730
    },
    {
      "epoch": 1.48,
      "grad_norm": 1.6331764459609985,
      "learning_rate": 0.0002584848484848485,
      "loss": 0.9053,
      "step": 740
    },
    {
      "epoch": 1.5,
      "grad_norm": 2.39428448677063,
      "learning_rate": 0.00025787878787878783,
      "loss": 0.9917,
      "step": 750
    },
    {
      "epoch": 1.52,
      "grad_norm": 2.713890314102173,
      "learning_rate": 0.00025727272727272724,
      "loss": 0.9324,
      "step": 760
    },
    {
      "epoch": 1.54,
      "grad_norm": 2.0202934741973877,
      "learning_rate": 0.00025666666666666665,
      "loss": 1.0679,
      "step": 770
    },
    {
      "epoch": 1.56,
      "grad_norm": 2.0959479808807373,
      "learning_rate": 0.000256060606060606,
      "loss": 0.8883,
      "step": 780
    },
    {
      "epoch": 1.58,
      "grad_norm": 2.716686725616455,
      "learning_rate": 0.0002554545454545454,
      "loss": 1.0707,
      "step": 790
    },
    {
      "epoch": 1.6,
      "grad_norm": 2.683284044265747,
      "learning_rate": 0.00025484848484848483,
      "loss": 1.0787,
      "step": 800
    },
    {
      "epoch": 1.6,
      "eval_loss": 1.2943191528320312,
      "eval_runtime": 8.3782,
      "eval_samples_per_second": 23.871,
      "eval_steps_per_second": 23.871,
      "step": 800
    },
    {
      "epoch": 1.62,
      "grad_norm": 1.7735633850097656,
      "learning_rate": 0.00025424242424242424,
      "loss": 1.0475,
      "step": 810
    },
    {
      "epoch": 1.6400000000000001,
      "grad_norm": 2.9451451301574707,
      "learning_rate": 0.0002536363636363636,
      "loss": 1.0791,
      "step": 820
    },
    {
      "epoch": 1.6600000000000001,
      "grad_norm": 2.8560006618499756,
      "learning_rate": 0.000253030303030303,
      "loss": 1.1968,
      "step": 830
    },
    {
      "epoch": 1.6800000000000002,
      "grad_norm": 3.6586883068084717,
      "learning_rate": 0.0002524242424242424,
      "loss": 1.222,
      "step": 840
    },
    {
      "epoch": 1.7,
      "grad_norm": 2.6683764457702637,
      "learning_rate": 0.0002518181818181818,
      "loss": 0.8991,
      "step": 850
    },
    {
      "epoch": 1.72,
      "grad_norm": 2.5743794441223145,
      "learning_rate": 0.0002512121212121212,
      "loss": 1.0674,
      "step": 860
    },
    {
      "epoch": 1.74,
      "grad_norm": 2.219989776611328,
      "learning_rate": 0.0002506060606060606,
      "loss": 0.943,
      "step": 870
    },
    {
      "epoch": 1.76,
      "grad_norm": 2.9837656021118164,
      "learning_rate": 0.00025,
      "loss": 1.1592,
      "step": 880
    },
    {
      "epoch": 1.78,
      "grad_norm": 2.4241783618927,
      "learning_rate": 0.00024939393939393936,
      "loss": 1.0251,
      "step": 890
    },
    {
      "epoch": 1.8,
      "grad_norm": 2.7631053924560547,
      "learning_rate": 0.00024878787878787877,
      "loss": 0.9216,
      "step": 900
    },
    {
      "epoch": 1.8,
      "eval_loss": 1.2992891073226929,
      "eval_runtime": 8.3378,
      "eval_samples_per_second": 23.987,
      "eval_steps_per_second": 23.987,
      "step": 900
    },
    {
      "epoch": 1.8199999999999998,
      "grad_norm": 2.8029625415802,
      "learning_rate": 0.0002481818181818182,
      "loss": 0.9921,
      "step": 910
    },
    {
      "epoch": 1.8399999999999999,
      "grad_norm": 4.040398120880127,
      "learning_rate": 0.00024757575757575754,
      "loss": 1.1964,
      "step": 920
    },
    {
      "epoch": 1.8599999999999999,
      "grad_norm": 2.6021695137023926,
      "learning_rate": 0.00024696969696969695,
      "loss": 0.9257,
      "step": 930
    },
    {
      "epoch": 1.88,
      "grad_norm": 2.7806859016418457,
      "learning_rate": 0.0002463636363636363,
      "loss": 1.0515,
      "step": 940
    },
    {
      "epoch": 1.9,
      "grad_norm": 2.9614317417144775,
      "learning_rate": 0.0002457575757575757,
      "loss": 0.9181,
      "step": 950
    },
    {
      "epoch": 1.92,
      "grad_norm": 2.689668893814087,
      "learning_rate": 0.0002451515151515151,
      "loss": 0.9289,
      "step": 960
    },
    {
      "epoch": 1.94,
      "grad_norm": 3.3760907649993896,
      "learning_rate": 0.00024454545454545454,
      "loss": 0.8834,
      "step": 970
    },
    {
      "epoch": 1.96,
      "grad_norm": 2.970425844192505,
      "learning_rate": 0.00024393939393939392,
      "loss": 1.2402,
      "step": 980
    },
    {
      "epoch": 1.98,
      "grad_norm": 3.031928062438965,
      "learning_rate": 0.0002433333333333333,
      "loss": 1.1854,
      "step": 990
    },
    {
      "epoch": 2.0,
      "grad_norm": 2.263988971710205,
      "learning_rate": 0.0002427272727272727,
      "loss": 0.8167,
      "step": 1000
    },
    {
      "epoch": 2.0,
      "eval_loss": 1.2840378284454346,
      "eval_runtime": 8.3077,
      "eval_samples_per_second": 24.074,
      "eval_steps_per_second": 24.074,
      "step": 1000
    },
    {
      "epoch": 2.02,
      "grad_norm": 3.1860926151275635,
      "learning_rate": 0.0002421212121212121,
      "loss": 0.6066,
      "step": 1010
    },
    {
      "epoch": 2.04,
      "grad_norm": 3.5222039222717285,
      "learning_rate": 0.00024151515151515148,
      "loss": 0.6483,
      "step": 1020
    },
    {
      "epoch": 2.06,
      "grad_norm": 6.0395379066467285,
      "learning_rate": 0.00024090909090909086,
      "loss": 0.8523,
      "step": 1030
    },
    {
      "epoch": 2.08,
      "grad_norm": 3.4689888954162598,
      "learning_rate": 0.0002403030303030303,
      "loss": 0.7511,
      "step": 1040
    },
    {
      "epoch": 2.1,
      "grad_norm": 3.353789806365967,
      "learning_rate": 0.00023969696969696968,
      "loss": 0.6116,
      "step": 1050
    },
    {
      "epoch": 2.12,
      "grad_norm": 0.5443699359893799,
      "learning_rate": 0.00023909090909090907,
      "loss": 0.9306,
      "step": 1060
    },
    {
      "epoch": 2.14,
      "grad_norm": 4.120171546936035,
      "learning_rate": 0.00023848484848484848,
      "loss": 0.7978,
      "step": 1070
    },
    {
      "epoch": 2.16,
      "grad_norm": 3.403811454772949,
      "learning_rate": 0.00023787878787878786,
      "loss": 0.8318,
      "step": 1080
    },
    {
      "epoch": 2.18,
      "grad_norm": 3.5260729789733887,
      "learning_rate": 0.00023727272727272724,
      "loss": 0.7093,
      "step": 1090
    },
    {
      "epoch": 2.2,
      "grad_norm": 3.143643617630005,
      "learning_rate": 0.00023666666666666663,
      "loss": 0.6637,
      "step": 1100
    },
    {
      "epoch": 2.2,
      "eval_loss": 1.3957589864730835,
      "eval_runtime": 8.4011,
      "eval_samples_per_second": 23.806,
      "eval_steps_per_second": 23.806,
      "step": 1100
    },
    {
      "epoch": 2.22,
      "grad_norm": 3.846147298812866,
      "learning_rate": 0.00023606060606060604,
      "loss": 0.7618,
      "step": 1110
    },
    {
      "epoch": 2.24,
      "grad_norm": 4.47155237197876,
      "learning_rate": 0.00023545454545454542,
      "loss": 0.7728,
      "step": 1120
    },
    {
      "epoch": 2.26,
      "grad_norm": 2.833091974258423,
      "learning_rate": 0.00023484848484848483,
      "loss": 0.619,
      "step": 1130
    },
    {
      "epoch": 2.2800000000000002,
      "grad_norm": 3.1264662742614746,
      "learning_rate": 0.00023424242424242424,
      "loss": 0.8079,
      "step": 1140
    },
    {
      "epoch": 2.3,
      "grad_norm": 4.148141860961914,
      "learning_rate": 0.00023363636363636363,
      "loss": 0.6877,
      "step": 1150
    },
    {
      "epoch": 2.32,
      "grad_norm": 2.2614855766296387,
      "learning_rate": 0.000233030303030303,
      "loss": 0.6619,
      "step": 1160
    },
    {
      "epoch": 2.34,
      "grad_norm": 2.268451690673828,
      "learning_rate": 0.0002324242424242424,
      "loss": 0.6964,
      "step": 1170
    },
    {
      "epoch": 2.36,
      "grad_norm": 3.4610681533813477,
      "learning_rate": 0.0002318181818181818,
      "loss": 0.798,
      "step": 1180
    },
    {
      "epoch": 2.38,
      "grad_norm": 3.61891508102417,
      "learning_rate": 0.00023121212121212119,
      "loss": 0.8786,
      "step": 1190
    },
    {
      "epoch": 2.4,
      "grad_norm": 3.5926384925842285,
      "learning_rate": 0.00023060606060606057,
      "loss": 0.6843,
      "step": 1200
    },
    {
      "epoch": 2.4,
      "eval_loss": 1.4208563566207886,
      "eval_runtime": 8.3406,
      "eval_samples_per_second": 23.979,
      "eval_steps_per_second": 23.979,
      "step": 1200
    },
    {
      "epoch": 2.42,
      "grad_norm": 3.782367467880249,
      "learning_rate": 0.00023,
      "loss": 0.7546,
      "step": 1210
    },
    {
      "epoch": 2.44,
      "grad_norm": 3.164734125137329,
      "learning_rate": 0.0002293939393939394,
      "loss": 0.8051,
      "step": 1220
    },
    {
      "epoch": 2.46,
      "grad_norm": 3.205404281616211,
      "learning_rate": 0.00022878787878787877,
      "loss": 0.6859,
      "step": 1230
    },
    {
      "epoch": 2.48,
      "grad_norm": 2.13216495513916,
      "learning_rate": 0.00022818181818181816,
      "loss": 0.7572,
      "step": 1240
    },
    {
      "epoch": 2.5,
      "grad_norm": 3.53143310546875,
      "learning_rate": 0.00022757575757575757,
      "loss": 0.7291,
      "step": 1250
    },
    {
      "epoch": 2.52,
      "grad_norm": 3.045048713684082,
      "learning_rate": 0.00022696969696969695,
      "loss": 0.7017,
      "step": 1260
    },
    {
      "epoch": 2.54,
      "grad_norm": 2.8228654861450195,
      "learning_rate": 0.00022636363636363633,
      "loss": 0.792,
      "step": 1270
    },
    {
      "epoch": 2.56,
      "grad_norm": 1.9401191473007202,
      "learning_rate": 0.00022575757575757572,
      "loss": 0.7306,
      "step": 1280
    },
    {
      "epoch": 2.58,
      "grad_norm": 4.236029148101807,
      "learning_rate": 0.00022515151515151513,
      "loss": 0.8649,
      "step": 1290
    },
    {
      "epoch": 2.6,
      "grad_norm": 4.212743759155273,
      "learning_rate": 0.00022454545454545454,
      "loss": 0.8419,
      "step": 1300
    },
    {
      "epoch": 2.6,
      "eval_loss": 1.389195442199707,
      "eval_runtime": 8.2946,
      "eval_samples_per_second": 24.112,
      "eval_steps_per_second": 24.112,
      "step": 1300
    },
    {
      "epoch": 2.62,
      "grad_norm": 4.070189952850342,
      "learning_rate": 0.00022393939393939392,
      "loss": 0.7305,
      "step": 1310
    },
    {
      "epoch": 2.64,
      "grad_norm": 4.124698162078857,
      "learning_rate": 0.00022333333333333333,
      "loss": 0.8178,
      "step": 1320
    },
    {
      "epoch": 2.66,
      "grad_norm": 2.7557737827301025,
      "learning_rate": 0.00022272727272727272,
      "loss": 0.8577,
      "step": 1330
    },
    {
      "epoch": 2.68,
      "grad_norm": 3.6216533184051514,
      "learning_rate": 0.0002221212121212121,
      "loss": 0.7489,
      "step": 1340
    },
    {
      "epoch": 2.7,
      "grad_norm": 4.3150553703308105,
      "learning_rate": 0.00022151515151515148,
      "loss": 0.649,
      "step": 1350
    },
    {
      "epoch": 2.7199999999999998,
      "grad_norm": 2.9080190658569336,
      "learning_rate": 0.0002209090909090909,
      "loss": 0.7186,
      "step": 1360
    },
    {
      "epoch": 2.74,
      "grad_norm": 2.6195318698883057,
      "learning_rate": 0.00022030303030303028,
      "loss": 0.7495,
      "step": 1370
    },
    {
      "epoch": 2.76,
      "grad_norm": 4.248599052429199,
      "learning_rate": 0.00021969696969696969,
      "loss": 0.7315,
      "step": 1380
    },
    {
      "epoch": 2.7800000000000002,
      "grad_norm": 4.680551052093506,
      "learning_rate": 0.0002190909090909091,
      "loss": 0.6902,
      "step": 1390
    },
    {
      "epoch": 2.8,
      "grad_norm": 2.883310079574585,
      "learning_rate": 0.00021848484848484848,
      "loss": 0.7105,
      "step": 1400
    },
    {
      "epoch": 2.8,
      "eval_loss": 1.3839035034179688,
      "eval_runtime": 8.3688,
      "eval_samples_per_second": 23.898,
      "eval_steps_per_second": 23.898,
      "step": 1400
    },
    {
      "epoch": 2.82,
      "grad_norm": 3.0462005138397217,
      "learning_rate": 0.00021787878787878786,
      "loss": 0.7966,
      "step": 1410
    },
    {
      "epoch": 2.84,
      "grad_norm": 2.248872995376587,
      "learning_rate": 0.00021727272727272725,
      "loss": 0.7985,
      "step": 1420
    },
    {
      "epoch": 2.86,
      "grad_norm": 3.8020195960998535,
      "learning_rate": 0.00021666666666666666,
      "loss": 0.768,
      "step": 1430
    },
    {
      "epoch": 2.88,
      "grad_norm": 3.267665386199951,
      "learning_rate": 0.00021606060606060604,
      "loss": 0.6478,
      "step": 1440
    },
    {
      "epoch": 2.9,
      "grad_norm": 2.756427764892578,
      "learning_rate": 0.00021545454545454542,
      "loss": 0.7661,
      "step": 1450
    },
    {
      "epoch": 2.92,
      "grad_norm": 2.3532841205596924,
      "learning_rate": 0.0002148484848484848,
      "loss": 0.6879,
      "step": 1460
    },
    {
      "epoch": 2.94,
      "grad_norm": 2.9246537685394287,
      "learning_rate": 0.00021424242424242424,
      "loss": 0.7516,
      "step": 1470
    },
    {
      "epoch": 2.96,
      "grad_norm": 2.470999240875244,
      "learning_rate": 0.00021363636363636363,
      "loss": 0.7627,
      "step": 1480
    },
    {
      "epoch": 2.98,
      "grad_norm": 3.8961474895477295,
      "learning_rate": 0.000213030303030303,
      "loss": 0.8725,
      "step": 1490
    },
    {
      "epoch": 3.0,
      "grad_norm": 1.8174386024475098,
      "learning_rate": 0.00021242424242424242,
      "loss": 0.7083,
      "step": 1500
    },
    {
      "epoch": 3.0,
      "eval_loss": 1.3690063953399658,
      "eval_runtime": 8.3863,
      "eval_samples_per_second": 23.848,
      "eval_steps_per_second": 23.848,
      "step": 1500
    },
    {
      "epoch": 3.02,
      "grad_norm": 2.559056282043457,
      "learning_rate": 0.0002118181818181818,
      "loss": 0.5617,
      "step": 1510
    },
    {
      "epoch": 3.04,
      "grad_norm": 3.7102155685424805,
      "learning_rate": 0.0002112121212121212,
      "loss": 0.5786,
      "step": 1520
    },
    {
      "epoch": 3.06,
      "grad_norm": 0.9230433702468872,
      "learning_rate": 0.00021060606060606057,
      "loss": 0.4407,
      "step": 1530
    },
    {
      "epoch": 3.08,
      "grad_norm": 3.199371576309204,
      "learning_rate": 0.00020999999999999998,
      "loss": 0.585,
      "step": 1540
    },
    {
      "epoch": 3.1,
      "grad_norm": 6.50702428817749,
      "learning_rate": 0.0002093939393939394,
      "loss": 0.4126,
      "step": 1550
    },
    {
      "epoch": 3.12,
      "grad_norm": 1.325773000717163,
      "learning_rate": 0.00020878787878787878,
      "loss": 0.4407,
      "step": 1560
    },
    {
      "epoch": 3.14,
      "grad_norm": 3.7027428150177,
      "learning_rate": 0.00020818181818181816,
      "loss": 0.3863,
      "step": 1570
    },
    {
      "epoch": 3.16,
      "grad_norm": 2.2701499462127686,
      "learning_rate": 0.00020757575757575757,
      "loss": 0.5162,
      "step": 1580
    },
    {
      "epoch": 3.18,
      "grad_norm": 4.286427021026611,
      "learning_rate": 0.00020696969696969695,
      "loss": 0.5329,
      "step": 1590
    },
    {
      "epoch": 3.2,
      "grad_norm": 2.2783029079437256,
      "learning_rate": 0.00020636363636363634,
      "loss": 0.611,
      "step": 1600
    },
    {
      "epoch": 3.2,
      "eval_loss": 1.5831185579299927,
      "eval_runtime": 8.3598,
      "eval_samples_per_second": 23.924,
      "eval_steps_per_second": 23.924,
      "step": 1600
    },
    {
      "epoch": 3.22,
      "grad_norm": 6.965603828430176,
      "learning_rate": 0.00020575757575757572,
      "loss": 0.4379,
      "step": 1610
    },
    {
      "epoch": 3.24,
      "grad_norm": 3.241940975189209,
      "learning_rate": 0.00020515151515151513,
      "loss": 0.4912,
      "step": 1620
    },
    {
      "epoch": 3.26,
      "grad_norm": 4.362778663635254,
      "learning_rate": 0.0002045454545454545,
      "loss": 0.4656,
      "step": 1630
    },
    {
      "epoch": 3.2800000000000002,
      "grad_norm": 2.6438798904418945,
      "learning_rate": 0.00020393939393939392,
      "loss": 0.583,
      "step": 1640
    },
    {
      "epoch": 3.3,
      "grad_norm": 4.949103832244873,
      "learning_rate": 0.00020333333333333333,
      "loss": 0.6213,
      "step": 1650
    },
    {
      "epoch": 3.32,
      "grad_norm": 5.068331718444824,
      "learning_rate": 0.00020272727272727272,
      "loss": 0.5762,
      "step": 1660
    },
    {
      "epoch": 3.34,
      "grad_norm": 3.99298357963562,
      "learning_rate": 0.0002021212121212121,
      "loss": 0.4959,
      "step": 1670
    },
    {
      "epoch": 3.36,
      "grad_norm": 5.732712268829346,
      "learning_rate": 0.00020151515151515148,
      "loss": 0.4679,
      "step": 1680
    },
    {
      "epoch": 3.38,
      "grad_norm": 5.031346797943115,
      "learning_rate": 0.0002009090909090909,
      "loss": 0.5333,
      "step": 1690
    },
    {
      "epoch": 3.4,
      "grad_norm": 1.6620811223983765,
      "learning_rate": 0.00020030303030303028,
      "loss": 0.4698,
      "step": 1700
    },
    {
      "epoch": 3.4,
      "eval_loss": 1.5535857677459717,
      "eval_runtime": 8.3739,
      "eval_samples_per_second": 23.884,
      "eval_steps_per_second": 23.884,
      "step": 1700
    },
    {
      "epoch": 3.42,
      "grad_norm": 14.12183666229248,
      "learning_rate": 0.00019969696969696966,
      "loss": 0.5057,
      "step": 1710
    },
    {
      "epoch": 3.44,
      "grad_norm": 4.235133171081543,
      "learning_rate": 0.0001990909090909091,
      "loss": 0.644,
      "step": 1720
    },
    {
      "epoch": 3.46,
      "grad_norm": 3.070622682571411,
      "learning_rate": 0.00019848484848484848,
      "loss": 0.4328,
      "step": 1730
    },
    {
      "epoch": 3.48,
      "grad_norm": 3.5885438919067383,
      "learning_rate": 0.00019787878787878786,
      "loss": 0.5047,
      "step": 1740
    },
    {
      "epoch": 3.5,
      "grad_norm": 5.048007488250732,
      "learning_rate": 0.00019727272727272725,
      "loss": 0.5759,
      "step": 1750
    },
    {
      "epoch": 3.52,
      "grad_norm": 1.5822149515151978,
      "learning_rate": 0.00019666666666666666,
      "loss": 0.5686,
      "step": 1760
    },
    {
      "epoch": 3.54,
      "grad_norm": 4.569571018218994,
      "learning_rate": 0.00019606060606060604,
      "loss": 0.4475,
      "step": 1770
    },
    {
      "epoch": 3.56,
      "grad_norm": 4.250733852386475,
      "learning_rate": 0.00019545454545454543,
      "loss": 0.4511,
      "step": 1780
    },
    {
      "epoch": 3.58,
      "grad_norm": 6.2464213371276855,
      "learning_rate": 0.0001948484848484848,
      "loss": 0.5632,
      "step": 1790
    },
    {
      "epoch": 3.6,
      "grad_norm": 5.053717613220215,
      "learning_rate": 0.00019424242424242422,
      "loss": 0.3861,
      "step": 1800
    },
    {
      "epoch": 3.6,
      "eval_loss": 1.5712876319885254,
      "eval_runtime": 8.3493,
      "eval_samples_per_second": 23.954,
      "eval_steps_per_second": 23.954,
      "step": 1800
    },
    {
      "epoch": 3.62,
      "grad_norm": 6.222312927246094,
      "learning_rate": 0.00019363636363636363,
      "loss": 0.5223,
      "step": 1810
    },
    {
      "epoch": 3.64,
      "grad_norm": 4.244654178619385,
      "learning_rate": 0.000193030303030303,
      "loss": 0.4766,
      "step": 1820
    },
    {
      "epoch": 3.66,
      "grad_norm": 6.645518779754639,
      "learning_rate": 0.00019242424242424242,
      "loss": 0.3605,
      "step": 1830
    },
    {
      "epoch": 3.68,
      "grad_norm": 0.5062503218650818,
      "learning_rate": 0.0001918181818181818,
      "loss": 0.5028,
      "step": 1840
    },
    {
      "epoch": 3.7,
      "grad_norm": 2.7801520824432373,
      "learning_rate": 0.0001912121212121212,
      "loss": 0.4929,
      "step": 1850
    },
    {
      "epoch": 3.7199999999999998,
      "grad_norm": 6.69301176071167,
      "learning_rate": 0.00019060606060606057,
      "loss": 0.6466,
      "step": 1860
    },
    {
      "epoch": 3.74,
      "grad_norm": 5.417182445526123,
      "learning_rate": 0.00018999999999999998,
      "loss": 0.666,
      "step": 1870
    },
    {
      "epoch": 3.76,
      "grad_norm": 4.151597499847412,
      "learning_rate": 0.00018939393939393937,
      "loss": 0.4805,
      "step": 1880
    },
    {
      "epoch": 3.7800000000000002,
      "grad_norm": 2.3855209350585938,
      "learning_rate": 0.00018878787878787878,
      "loss": 0.6104,
      "step": 1890
    },
    {
      "epoch": 3.8,
      "grad_norm": 4.5765380859375,
      "learning_rate": 0.0001881818181818182,
      "loss": 0.5384,
      "step": 1900
    },
    {
      "epoch": 3.8,
      "eval_loss": 1.5549110174179077,
      "eval_runtime": 8.3823,
      "eval_samples_per_second": 23.86,
      "eval_steps_per_second": 23.86,
      "step": 1900
    },
    {
      "epoch": 3.82,
      "grad_norm": 4.069054126739502,
      "learning_rate": 0.00018757575757575757,
      "loss": 0.387,
      "step": 1910
    },
    {
      "epoch": 3.84,
      "grad_norm": 5.721050262451172,
      "learning_rate": 0.00018696969696969695,
      "loss": 0.5518,
      "step": 1920
    },
    {
      "epoch": 3.86,
      "grad_norm": 1.865242838859558,
      "learning_rate": 0.00018636363636363634,
      "loss": 0.5238,
      "step": 1930
    },
    {
      "epoch": 3.88,
      "grad_norm": 3.9767918586730957,
      "learning_rate": 0.00018575757575757575,
      "loss": 0.5048,
      "step": 1940
    },
    {
      "epoch": 3.9,
      "grad_norm": 3.618985414505005,
      "learning_rate": 0.00018515151515151513,
      "loss": 0.6239,
      "step": 1950
    },
    {
      "epoch": 3.92,
      "grad_norm": 4.402286529541016,
      "learning_rate": 0.00018454545454545451,
      "loss": 0.5543,
      "step": 1960
    },
    {
      "epoch": 3.94,
      "grad_norm": 4.995577335357666,
      "learning_rate": 0.0001839393939393939,
      "loss": 0.5242,
      "step": 1970
    },
    {
      "epoch": 3.96,
      "grad_norm": 4.823939323425293,
      "learning_rate": 0.00018333333333333334,
      "loss": 0.655,
      "step": 1980
    },
    {
      "epoch": 3.98,
      "grad_norm": 3.2393321990966797,
      "learning_rate": 0.00018272727272727272,
      "loss": 0.4109,
      "step": 1990
    },
    {
      "epoch": 4.0,
      "grad_norm": 2.9264049530029297,
      "learning_rate": 0.0001821212121212121,
      "loss": 0.4652,
      "step": 2000
    },
    {
      "epoch": 4.0,
      "eval_loss": 1.5724115371704102,
      "eval_runtime": 8.2832,
      "eval_samples_per_second": 24.145,
      "eval_steps_per_second": 24.145,
      "step": 2000
    },
    {
      "epoch": 4.02,
      "grad_norm": 4.181143760681152,
      "learning_rate": 0.0001815151515151515,
      "loss": 0.3647,
      "step": 2010
    },
    {
      "epoch": 4.04,
      "grad_norm": 2.3416459560394287,
      "learning_rate": 0.0001809090909090909,
      "loss": 0.3056,
      "step": 2020
    },
    {
      "epoch": 4.06,
      "grad_norm": 5.513082027435303,
      "learning_rate": 0.00018030303030303028,
      "loss": 0.3581,
      "step": 2030
    },
    {
      "epoch": 4.08,
      "grad_norm": 3.8946897983551025,
      "learning_rate": 0.00017969696969696966,
      "loss": 0.3877,
      "step": 2040
    },
    {
      "epoch": 4.1,
      "grad_norm": 7.302180767059326,
      "learning_rate": 0.00017909090909090907,
      "loss": 0.3058,
      "step": 2050
    },
    {
      "epoch": 4.12,
      "grad_norm": 5.2619829177856445,
      "learning_rate": 0.00017848484848484846,
      "loss": 0.2827,
      "step": 2060
    },
    {
      "epoch": 4.14,
      "grad_norm": 6.004909038543701,
      "learning_rate": 0.00017787878787878787,
      "loss": 0.2587,
      "step": 2070
    },
    {
      "epoch": 4.16,
      "grad_norm": 1.2050436735153198,
      "learning_rate": 0.00017727272727272728,
      "loss": 0.2726,
      "step": 2080
    },
    {
      "epoch": 4.18,
      "grad_norm": 6.151947498321533,
      "learning_rate": 0.00017666666666666666,
      "loss": 0.3555,
      "step": 2090
    },
    {
      "epoch": 4.2,
      "grad_norm": 2.7127885818481445,
      "learning_rate": 0.00017606060606060604,
      "loss": 0.2635,
      "step": 2100
    },
    {
      "epoch": 4.2,
      "eval_loss": 1.7109386920928955,
      "eval_runtime": 8.3787,
      "eval_samples_per_second": 23.87,
      "eval_steps_per_second": 23.87,
      "step": 2100
    },
    {
      "epoch": 4.22,
      "grad_norm": 2.8644869327545166,
      "learning_rate": 0.00017545454545454543,
      "loss": 0.2468,
      "step": 2110
    },
    {
      "epoch": 4.24,
      "grad_norm": 1.7968928813934326,
      "learning_rate": 0.00017484848484848484,
      "loss": 0.2995,
      "step": 2120
    },
    {
      "epoch": 4.26,
      "grad_norm": 4.791069507598877,
      "learning_rate": 0.00017424242424242422,
      "loss": 0.2152,
      "step": 2130
    },
    {
      "epoch": 4.28,
      "grad_norm": 4.86476469039917,
      "learning_rate": 0.0001736363636363636,
      "loss": 0.3394,
      "step": 2140
    },
    {
      "epoch": 4.3,
      "grad_norm": 5.331603050231934,
      "learning_rate": 0.00017303030303030304,
      "loss": 0.373,
      "step": 2150
    },
    {
      "epoch": 4.32,
      "grad_norm": 1.1962729692459106,
      "learning_rate": 0.00017242424242424242,
      "loss": 0.4321,
      "step": 2160
    },
    {
      "epoch": 4.34,
      "grad_norm": 3.8027055263519287,
      "learning_rate": 0.0001718181818181818,
      "loss": 0.2942,
      "step": 2170
    },
    {
      "epoch": 4.36,
      "grad_norm": 2.6761391162872314,
      "learning_rate": 0.0001712121212121212,
      "loss": 0.4313,
      "step": 2180
    },
    {
      "epoch": 4.38,
      "grad_norm": 2.4942312240600586,
      "learning_rate": 0.0001706060606060606,
      "loss": 0.317,
      "step": 2190
    },
    {
      "epoch": 4.4,
      "grad_norm": 6.967769622802734,
      "learning_rate": 0.00016999999999999999,
      "loss": 0.365,
      "step": 2200
    },
    {
      "epoch": 4.4,
      "eval_loss": 1.7136310338974,
      "eval_runtime": 8.3832,
      "eval_samples_per_second": 23.857,
      "eval_steps_per_second": 23.857,
      "step": 2200
    },
    {
      "epoch": 4.42,
      "grad_norm": 4.266429901123047,
      "learning_rate": 0.00016939393939393937,
      "loss": 0.4035,
      "step": 2210
    },
    {
      "epoch": 4.44,
      "grad_norm": 3.543520212173462,
      "learning_rate": 0.00016878787878787875,
      "loss": 0.3507,
      "step": 2220
    },
    {
      "epoch": 4.46,
      "grad_norm": 4.102385520935059,
      "learning_rate": 0.00016818181818181816,
      "loss": 0.2794,
      "step": 2230
    },
    {
      "epoch": 4.48,
      "grad_norm": 4.61648416519165,
      "learning_rate": 0.00016757575757575757,
      "loss": 0.3774,
      "step": 2240
    },
    {
      "epoch": 4.5,
      "grad_norm": 2.002671241760254,
      "learning_rate": 0.00016696969696969696,
      "loss": 0.3454,
      "step": 2250
    },
    {
      "epoch": 4.52,
      "grad_norm": 4.620548725128174,
      "learning_rate": 0.00016636363636363637,
      "loss": 0.2893,
      "step": 2260
    },
    {
      "epoch": 4.54,
      "grad_norm": 3.094716787338257,
      "learning_rate": 0.00016575757575757575,
      "loss": 0.3669,
      "step": 2270
    },
    {
      "epoch": 4.5600000000000005,
      "grad_norm": 4.546056747436523,
      "learning_rate": 0.00016515151515151513,
      "loss": 0.6164,
      "step": 2280
    },
    {
      "epoch": 4.58,
      "grad_norm": 2.4719760417938232,
      "learning_rate": 0.00016454545454545452,
      "loss": 0.3679,
      "step": 2290
    },
    {
      "epoch": 4.6,
      "grad_norm": 6.276829242706299,
      "learning_rate": 0.00016393939393939393,
      "loss": 0.3336,
      "step": 2300
    },
    {
      "epoch": 4.6,
      "eval_loss": 1.692130446434021,
      "eval_runtime": 8.2796,
      "eval_samples_per_second": 24.156,
      "eval_steps_per_second": 24.156,
      "step": 2300
    },
    {
      "epoch": 4.62,
      "grad_norm": 3.9005227088928223,
      "learning_rate": 0.0001633333333333333,
      "loss": 0.2596,
      "step": 2310
    },
    {
      "epoch": 4.64,
      "grad_norm": 4.134552001953125,
      "learning_rate": 0.00016272727272727272,
      "loss": 0.4811,
      "step": 2320
    },
    {
      "epoch": 4.66,
      "grad_norm": 2.7157294750213623,
      "learning_rate": 0.00016212121212121213,
      "loss": 0.369,
      "step": 2330
    },
    {
      "epoch": 4.68,
      "grad_norm": 5.640425682067871,
      "learning_rate": 0.00016151515151515151,
      "loss": 0.3261,
      "step": 2340
    },
    {
      "epoch": 4.7,
      "grad_norm": 4.448179721832275,
      "learning_rate": 0.0001609090909090909,
      "loss": 0.4043,
      "step": 2350
    },
    {
      "epoch": 4.72,
      "grad_norm": 4.062061309814453,
      "learning_rate": 0.00016030303030303028,
      "loss": 0.3513,
      "step": 2360
    },
    {
      "epoch": 4.74,
      "grad_norm": 3.522590160369873,
      "learning_rate": 0.0001596969696969697,
      "loss": 0.5608,
      "step": 2370
    },
    {
      "epoch": 4.76,
      "grad_norm": 1.6488430500030518,
      "learning_rate": 0.00015909090909090907,
      "loss": 0.3869,
      "step": 2380
    },
    {
      "epoch": 4.78,
      "grad_norm": 2.586744546890259,
      "learning_rate": 0.00015848484848484846,
      "loss": 0.3668,
      "step": 2390
    },
    {
      "epoch": 4.8,
      "grad_norm": 4.943906307220459,
      "learning_rate": 0.00015787878787878784,
      "loss": 0.4909,
      "step": 2400
    },
    {
      "epoch": 4.8,
      "eval_loss": 1.690075397491455,
      "eval_runtime": 8.3956,
      "eval_samples_per_second": 23.822,
      "eval_steps_per_second": 23.822,
      "step": 2400
    },
    {
      "epoch": 4.82,
      "grad_norm": 4.943544864654541,
      "learning_rate": 0.00015727272727272728,
      "loss": 0.3726,
      "step": 2410
    },
    {
      "epoch": 4.84,
      "grad_norm": 4.767609119415283,
      "learning_rate": 0.00015666666666666666,
      "loss": 0.4032,
      "step": 2420
    },
    {
      "epoch": 4.86,
      "grad_norm": 5.242890357971191,
      "learning_rate": 0.00015606060606060605,
      "loss": 0.3913,
      "step": 2430
    },
    {
      "epoch": 4.88,
      "grad_norm": 2.926598072052002,
      "learning_rate": 0.00015545454545454546,
      "loss": 0.3383,
      "step": 2440
    },
    {
      "epoch": 4.9,
      "grad_norm": 2.9405007362365723,
      "learning_rate": 0.00015484848484848484,
      "loss": 0.3099,
      "step": 2450
    },
    {
      "epoch": 4.92,
      "grad_norm": 4.061038017272949,
      "learning_rate": 0.00015424242424242422,
      "loss": 0.3722,
      "step": 2460
    },
    {
      "epoch": 4.9399999999999995,
      "grad_norm": 0.715829610824585,
      "learning_rate": 0.0001536363636363636,
      "loss": 0.3737,
      "step": 2470
    },
    {
      "epoch": 4.96,
      "grad_norm": 3.489168882369995,
      "learning_rate": 0.00015303030303030302,
      "loss": 0.3566,
      "step": 2480
    },
    {
      "epoch": 4.98,
      "grad_norm": 2.44069766998291,
      "learning_rate": 0.00015242424242424243,
      "loss": 0.3273,
      "step": 2490
    },
    {
      "epoch": 5.0,
      "grad_norm": 7.726382255554199,
      "learning_rate": 0.0001518181818181818,
      "loss": 0.3288,
      "step": 2500
    },
    {
      "epoch": 5.0,
      "eval_loss": 1.7987926006317139,
      "eval_runtime": 8.3882,
      "eval_samples_per_second": 23.843,
      "eval_steps_per_second": 23.843,
      "step": 2500
    },
    {
      "epoch": 5.02,
      "grad_norm": 7.354400157928467,
      "learning_rate": 0.00015121212121212122,
      "loss": 0.2585,
      "step": 2510
    },
    {
      "epoch": 5.04,
      "grad_norm": 1.6410224437713623,
      "learning_rate": 0.0001506060606060606,
      "loss": 0.2287,
      "step": 2520
    },
    {
      "epoch": 5.06,
      "grad_norm": 1.1943944692611694,
      "learning_rate": 0.00015,
      "loss": 0.2015,
      "step": 2530
    },
    {
      "epoch": 5.08,
      "grad_norm": 1.9269447326660156,
      "learning_rate": 0.00014939393939393937,
      "loss": 0.2122,
      "step": 2540
    },
    {
      "epoch": 5.1,
      "grad_norm": 6.477923393249512,
      "learning_rate": 0.00014878787878787875,
      "loss": 0.3071,
      "step": 2550
    },
    {
      "epoch": 5.12,
      "grad_norm": 2.174898386001587,
      "learning_rate": 0.00014818181818181816,
      "loss": 0.2408,
      "step": 2560
    },
    {
      "epoch": 5.14,
      "grad_norm": 2.189291000366211,
      "learning_rate": 0.00014757575757575757,
      "loss": 0.2721,
      "step": 2570
    },
    {
      "epoch": 5.16,
      "grad_norm": 1.7102081775665283,
      "learning_rate": 0.00014696969696969696,
      "loss": 0.3433,
      "step": 2580
    },
    {
      "epoch": 5.18,
      "grad_norm": 2.9031906127929688,
      "learning_rate": 0.00014636363636363634,
      "loss": 0.3545,
      "step": 2590
    },
    {
      "epoch": 5.2,
      "grad_norm": 7.661604881286621,
      "learning_rate": 0.00014575757575757575,
      "loss": 0.2179,
      "step": 2600
    },
    {
      "epoch": 5.2,
      "eval_loss": 1.8260738849639893,
      "eval_runtime": 8.4159,
      "eval_samples_per_second": 23.764,
      "eval_steps_per_second": 23.764,
      "step": 2600
    },
    {
      "epoch": 5.22,
      "grad_norm": 4.117256164550781,
      "learning_rate": 0.00014515151515151513,
      "loss": 0.2464,
      "step": 2610
    },
    {
      "epoch": 5.24,
      "grad_norm": 0.4252321124076843,
      "learning_rate": 0.00014454545454545452,
      "loss": 0.2375,
      "step": 2620
    },
    {
      "epoch": 5.26,
      "grad_norm": 3.2553443908691406,
      "learning_rate": 0.00014393939393939393,
      "loss": 0.2484,
      "step": 2630
    },
    {
      "epoch": 5.28,
      "grad_norm": 3.5254993438720703,
      "learning_rate": 0.00014333333333333334,
      "loss": 0.1964,
      "step": 2640
    },
    {
      "epoch": 5.3,
      "grad_norm": 3.220517873764038,
      "learning_rate": 0.00014272727272727272,
      "loss": 0.2144,
      "step": 2650
    },
    {
      "epoch": 5.32,
      "grad_norm": 2.9870529174804688,
      "learning_rate": 0.0001421212121212121,
      "loss": 0.257,
      "step": 2660
    },
    {
      "epoch": 5.34,
      "grad_norm": 4.014398097991943,
      "learning_rate": 0.0001415151515151515,
      "loss": 0.2709,
      "step": 2670
    },
    {
      "epoch": 5.36,
      "grad_norm": 4.078643798828125,
      "learning_rate": 0.0001409090909090909,
      "loss": 0.2436,
      "step": 2680
    },
    {
      "epoch": 5.38,
      "grad_norm": 3.211777687072754,
      "learning_rate": 0.00014030303030303028,
      "loss": 0.2457,
      "step": 2690
    },
    {
      "epoch": 5.4,
      "grad_norm": 2.9926822185516357,
      "learning_rate": 0.0001396969696969697,
      "loss": 0.1958,
      "step": 2700
    },
    {
      "epoch": 5.4,
      "eval_loss": 1.9341630935668945,
      "eval_runtime": 8.3439,
      "eval_samples_per_second": 23.97,
      "eval_steps_per_second": 23.97,
      "step": 2700
    },
    {
      "epoch": 5.42,
      "grad_norm": 2.4919064044952393,
      "learning_rate": 0.00013909090909090908,
      "loss": 0.2124,
      "step": 2710
    },
    {
      "epoch": 5.44,
      "grad_norm": 6.144721508026123,
      "learning_rate": 0.00013848484848484846,
      "loss": 0.23,
      "step": 2720
    },
    {
      "epoch": 5.46,
      "grad_norm": 1.592446208000183,
      "learning_rate": 0.00013787878787878787,
      "loss": 0.2653,
      "step": 2730
    },
    {
      "epoch": 5.48,
      "grad_norm": 2.2382900714874268,
      "learning_rate": 0.00013727272727272725,
      "loss": 0.2214,
      "step": 2740
    },
    {
      "epoch": 5.5,
      "grad_norm": 5.538259029388428,
      "learning_rate": 0.00013666666666666666,
      "loss": 0.2611,
      "step": 2750
    },
    {
      "epoch": 5.52,
      "grad_norm": 4.225912094116211,
      "learning_rate": 0.00013606060606060605,
      "loss": 0.181,
      "step": 2760
    },
    {
      "epoch": 5.54,
      "grad_norm": 2.9072530269622803,
      "learning_rate": 0.00013545454545454546,
      "loss": 0.2007,
      "step": 2770
    },
    {
      "epoch": 5.5600000000000005,
      "grad_norm": 2.087653160095215,
      "learning_rate": 0.00013484848484848484,
      "loss": 0.2137,
      "step": 2780
    },
    {
      "epoch": 5.58,
      "grad_norm": 12.405137062072754,
      "learning_rate": 0.00013424242424242422,
      "loss": 0.2471,
      "step": 2790
    },
    {
      "epoch": 5.6,
      "grad_norm": 7.275853157043457,
      "learning_rate": 0.0001336363636363636,
      "loss": 0.3737,
      "step": 2800
    },
    {
      "epoch": 5.6,
      "eval_loss": 1.8255736827850342,
      "eval_runtime": 8.4128,
      "eval_samples_per_second": 23.773,
      "eval_steps_per_second": 23.773,
      "step": 2800
    },
    {
      "epoch": 5.62,
      "grad_norm": 5.30650520324707,
      "learning_rate": 0.00013303030303030302,
      "loss": 0.2686,
      "step": 2810
    },
    {
      "epoch": 5.64,
      "grad_norm": 4.457026958465576,
      "learning_rate": 0.00013242424242424243,
      "loss": 0.2611,
      "step": 2820
    },
    {
      "epoch": 5.66,
      "grad_norm": 6.334913730621338,
      "learning_rate": 0.0001318181818181818,
      "loss": 0.2709,
      "step": 2830
    },
    {
      "epoch": 5.68,
      "grad_norm": 2.8689537048339844,
      "learning_rate": 0.0001312121212121212,
      "loss": 0.2255,
      "step": 2840
    },
    {
      "epoch": 5.7,
      "grad_norm": 2.5113024711608887,
      "learning_rate": 0.00013060606060606058,
      "loss": 0.2404,
      "step": 2850
    },
    {
      "epoch": 5.72,
      "grad_norm": 1.4318674802780151,
      "learning_rate": 0.00013,
      "loss": 0.2011,
      "step": 2860
    },
    {
      "epoch": 5.74,
      "grad_norm": 2.3558542728424072,
      "learning_rate": 0.00012939393939393937,
      "loss": 0.1954,
      "step": 2870
    },
    {
      "epoch": 5.76,
      "grad_norm": 0.7512531876564026,
      "learning_rate": 0.00012878787878787878,
      "loss": 0.2894,
      "step": 2880
    },
    {
      "epoch": 5.78,
      "grad_norm": 2.0084853172302246,
      "learning_rate": 0.00012818181818181817,
      "loss": 0.1871,
      "step": 2890
    },
    {
      "epoch": 5.8,
      "grad_norm": 1.3986759185791016,
      "learning_rate": 0.00012757575757575758,
      "loss": 0.2544,
      "step": 2900
    },
    {
      "epoch": 5.8,
      "eval_loss": 1.8935126066207886,
      "eval_runtime": 8.4217,
      "eval_samples_per_second": 23.748,
      "eval_steps_per_second": 23.748,
      "step": 2900
    },
    {
      "epoch": 5.82,
      "grad_norm": 3.7115490436553955,
      "learning_rate": 0.00012696969696969696,
      "loss": 0.2637,
      "step": 2910
    },
    {
      "epoch": 5.84,
      "grad_norm": 1.4755938053131104,
      "learning_rate": 0.00012636363636363634,
      "loss": 0.2821,
      "step": 2920
    },
    {
      "epoch": 5.86,
      "grad_norm": 4.451046943664551,
      "learning_rate": 0.00012575757575757575,
      "loss": 0.246,
      "step": 2930
    },
    {
      "epoch": 5.88,
      "grad_norm": 0.9967950582504272,
      "learning_rate": 0.00012515151515151514,
      "loss": 0.2339,
      "step": 2940
    },
    {
      "epoch": 5.9,
      "grad_norm": 5.947153568267822,
      "learning_rate": 0.00012454545454545455,
      "loss": 0.2816,
      "step": 2950
    },
    {
      "epoch": 5.92,
      "grad_norm": 4.289927959442139,
      "learning_rate": 0.00012393939393939393,
      "loss": 0.3987,
      "step": 2960
    },
    {
      "epoch": 5.9399999999999995,
      "grad_norm": 1.5769470930099487,
      "learning_rate": 0.0001233333333333333,
      "loss": 0.2701,
      "step": 2970
    },
    {
      "epoch": 5.96,
      "grad_norm": 5.194871425628662,
      "learning_rate": 0.00012272727272727272,
      "loss": 0.241,
      "step": 2980
    },
    {
      "epoch": 5.98,
      "grad_norm": 3.7539238929748535,
      "learning_rate": 0.0001221212121212121,
      "loss": 0.3082,
      "step": 2990
    },
    {
      "epoch": 6.0,
      "grad_norm": 6.177037239074707,
      "learning_rate": 0.0001215151515151515,
      "loss": 0.2543,
      "step": 3000
    },
    {
      "epoch": 6.0,
      "eval_loss": 1.896538257598877,
      "eval_runtime": 8.3272,
      "eval_samples_per_second": 24.018,
      "eval_steps_per_second": 24.018,
      "step": 3000
    },
    {
      "epoch": 6.02,
      "grad_norm": 0.5664095878601074,
      "learning_rate": 0.0001209090909090909,
      "loss": 0.1638,
      "step": 3010
    },
    {
      "epoch": 6.04,
      "grad_norm": 1.4534616470336914,
      "learning_rate": 0.00012030303030303028,
      "loss": 0.1558,
      "step": 3020
    },
    {
      "epoch": 6.06,
      "grad_norm": 4.458374500274658,
      "learning_rate": 0.0001196969696969697,
      "loss": 0.1917,
      "step": 3030
    },
    {
      "epoch": 6.08,
      "grad_norm": 7.757816314697266,
      "learning_rate": 0.00011909090909090908,
      "loss": 0.1885,
      "step": 3040
    },
    {
      "epoch": 6.1,
      "grad_norm": 2.6760878562927246,
      "learning_rate": 0.00011848484848484847,
      "loss": 0.1462,
      "step": 3050
    },
    {
      "epoch": 6.12,
      "grad_norm": 3.2351267337799072,
      "learning_rate": 0.00011787878787878786,
      "loss": 0.1673,
      "step": 3060
    },
    {
      "epoch": 6.14,
      "grad_norm": 1.256703495979309,
      "learning_rate": 0.00011727272727272727,
      "loss": 0.1912,
      "step": 3070
    },
    {
      "epoch": 6.16,
      "grad_norm": 2.2887508869171143,
      "learning_rate": 0.00011666666666666665,
      "loss": 0.1986,
      "step": 3080
    },
    {
      "epoch": 6.18,
      "grad_norm": 6.404567718505859,
      "learning_rate": 0.00011606060606060605,
      "loss": 0.1828,
      "step": 3090
    },
    {
      "epoch": 6.2,
      "grad_norm": 2.0037286281585693,
      "learning_rate": 0.00011545454545454543,
      "loss": 0.1593,
      "step": 3100
    },
    {
      "epoch": 6.2,
      "eval_loss": 2.038989782333374,
      "eval_runtime": 8.4183,
      "eval_samples_per_second": 23.758,
      "eval_steps_per_second": 23.758,
      "step": 3100
    },
    {
      "epoch": 6.22,
      "grad_norm": 3.0737709999084473,
      "learning_rate": 0.00011484848484848484,
      "loss": 0.1952,
      "step": 3110
    },
    {
      "epoch": 6.24,
      "grad_norm": 1.3408161401748657,
      "learning_rate": 0.00011424242424242424,
      "loss": 0.1914,
      "step": 3120
    },
    {
      "epoch": 6.26,
      "grad_norm": 1.268082857131958,
      "learning_rate": 0.00011363636363636362,
      "loss": 0.1804,
      "step": 3130
    },
    {
      "epoch": 6.28,
      "grad_norm": 2.6654248237609863,
      "learning_rate": 0.00011303030303030302,
      "loss": 0.1532,
      "step": 3140
    },
    {
      "epoch": 6.3,
      "grad_norm": 4.469668865203857,
      "learning_rate": 0.00011242424242424242,
      "loss": 0.1715,
      "step": 3150
    },
    {
      "epoch": 6.32,
      "grad_norm": 1.9838653802871704,
      "learning_rate": 0.00011181818181818181,
      "loss": 0.2102,
      "step": 3160
    },
    {
      "epoch": 6.34,
      "grad_norm": 1.7370903491973877,
      "learning_rate": 0.0001112121212121212,
      "loss": 0.2299,
      "step": 3170
    },
    {
      "epoch": 6.36,
      "grad_norm": 2.7366747856140137,
      "learning_rate": 0.0001106060606060606,
      "loss": 0.1711,
      "step": 3180
    },
    {
      "epoch": 6.38,
      "grad_norm": 1.207750678062439,
      "learning_rate": 0.00010999999999999998,
      "loss": 0.1864,
      "step": 3190
    },
    {
      "epoch": 6.4,
      "grad_norm": 1.4551005363464355,
      "learning_rate": 0.00010939393939393939,
      "loss": 0.2078,
      "step": 3200
    },
    {
      "epoch": 6.4,
      "eval_loss": 2.027754545211792,
      "eval_runtime": 8.3889,
      "eval_samples_per_second": 23.841,
      "eval_steps_per_second": 23.841,
      "step": 3200
    },
    {
      "epoch": 6.42,
      "grad_norm": 3.8566954135894775,
      "learning_rate": 0.00010878787878787878,
      "loss": 0.1542,
      "step": 3210
    },
    {
      "epoch": 6.44,
      "grad_norm": 3.7426862716674805,
      "learning_rate": 0.00010818181818181817,
      "loss": 0.229,
      "step": 3220
    },
    {
      "epoch": 6.46,
      "grad_norm": 1.8360505104064941,
      "learning_rate": 0.00010757575757575756,
      "loss": 0.1869,
      "step": 3230
    },
    {
      "epoch": 6.48,
      "grad_norm": 1.181337594985962,
      "learning_rate": 0.00010696969696969696,
      "loss": 0.1707,
      "step": 3240
    },
    {
      "epoch": 6.5,
      "grad_norm": 3.076735496520996,
      "learning_rate": 0.00010636363636363636,
      "loss": 0.2352,
      "step": 3250
    },
    {
      "epoch": 6.52,
      "grad_norm": 2.546877145767212,
      "learning_rate": 0.00010575757575757574,
      "loss": 0.1836,
      "step": 3260
    },
    {
      "epoch": 6.54,
      "grad_norm": 4.172927379608154,
      "learning_rate": 0.00010515151515151514,
      "loss": 0.1481,
      "step": 3270
    },
    {
      "epoch": 6.5600000000000005,
      "grad_norm": 2.2106335163116455,
      "learning_rate": 0.00010454545454545455,
      "loss": 0.1807,
      "step": 3280
    },
    {
      "epoch": 6.58,
      "grad_norm": 1.7213551998138428,
      "learning_rate": 0.00010393939393939393,
      "loss": 0.2262,
      "step": 3290
    },
    {
      "epoch": 6.6,
      "grad_norm": 6.366570949554443,
      "learning_rate": 0.00010333333333333333,
      "loss": 0.1731,
      "step": 3300
    },
    {
      "epoch": 6.6,
      "eval_loss": 2.0194852352142334,
      "eval_runtime": 8.3856,
      "eval_samples_per_second": 23.85,
      "eval_steps_per_second": 23.85,
      "step": 3300
    },
    {
      "epoch": 6.62,
      "grad_norm": 8.620712280273438,
      "learning_rate": 0.00010272727272727271,
      "loss": 0.2255,
      "step": 3310
    },
    {
      "epoch": 6.64,
      "grad_norm": 1.1692862510681152,
      "learning_rate": 0.00010212121212121212,
      "loss": 0.1376,
      "step": 3320
    },
    {
      "epoch": 6.66,
      "grad_norm": 3.895657539367676,
      "learning_rate": 0.0001015151515151515,
      "loss": 0.1706,
      "step": 3330
    },
    {
      "epoch": 6.68,
      "grad_norm": 3.7017080783843994,
      "learning_rate": 0.0001009090909090909,
      "loss": 0.1956,
      "step": 3340
    },
    {
      "epoch": 6.7,
      "grad_norm": 2.6707801818847656,
      "learning_rate": 0.00010030303030303029,
      "loss": 0.1773,
      "step": 3350
    },
    {
      "epoch": 6.72,
      "grad_norm": 2.6554012298583984,
      "learning_rate": 9.969696969696968e-05,
      "loss": 0.18,
      "step": 3360
    },
    {
      "epoch": 6.74,
      "grad_norm": 0.7609615325927734,
      "learning_rate": 9.90909090909091e-05,
      "loss": 0.1839,
      "step": 3370
    },
    {
      "epoch": 6.76,
      "grad_norm": 1.9594521522521973,
      "learning_rate": 9.848484848484848e-05,
      "loss": 0.1941,
      "step": 3380
    },
    {
      "epoch": 6.78,
      "grad_norm": 9.8054780960083,
      "learning_rate": 9.787878787878787e-05,
      "loss": 0.2102,
      "step": 3390
    },
    {
      "epoch": 6.8,
      "grad_norm": 1.9461395740509033,
      "learning_rate": 9.727272727272726e-05,
      "loss": 0.1607,
      "step": 3400
    },
    {
      "epoch": 6.8,
      "eval_loss": 2.051917791366577,
      "eval_runtime": 8.4347,
      "eval_samples_per_second": 23.711,
      "eval_steps_per_second": 23.711,
      "step": 3400
    },
    {
      "epoch": 6.82,
      "grad_norm": 6.358090400695801,
      "learning_rate": 9.666666666666667e-05,
      "loss": 0.3109,
      "step": 3410
    },
    {
      "epoch": 6.84,
      "grad_norm": 3.914384365081787,
      "learning_rate": 9.606060606060605e-05,
      "loss": 0.2243,
      "step": 3420
    },
    {
      "epoch": 6.86,
      "grad_norm": 4.555246829986572,
      "learning_rate": 9.545454545454545e-05,
      "loss": 0.1835,
      "step": 3430
    },
    {
      "epoch": 6.88,
      "grad_norm": 2.337395668029785,
      "learning_rate": 9.484848484848483e-05,
      "loss": 0.1871,
      "step": 3440
    },
    {
      "epoch": 6.9,
      "grad_norm": 8.141631126403809,
      "learning_rate": 9.424242424242424e-05,
      "loss": 0.2015,
      "step": 3450
    },
    {
      "epoch": 6.92,
      "grad_norm": 2.6135528087615967,
      "learning_rate": 9.363636363636364e-05,
      "loss": 0.1948,
      "step": 3460
    },
    {
      "epoch": 6.9399999999999995,
      "grad_norm": 1.253052830696106,
      "learning_rate": 9.303030303030302e-05,
      "loss": 0.225,
      "step": 3470
    },
    {
      "epoch": 6.96,
      "grad_norm": 3.415184736251831,
      "learning_rate": 9.242424242424242e-05,
      "loss": 0.1972,
      "step": 3480
    },
    {
      "epoch": 6.98,
      "grad_norm": 2.7429864406585693,
      "learning_rate": 9.18181818181818e-05,
      "loss": 0.2009,
      "step": 3490
    },
    {
      "epoch": 7.0,
      "grad_norm": 1.7365903854370117,
      "learning_rate": 9.121212121212121e-05,
      "loss": 0.1748,
      "step": 3500
    },
    {
      "epoch": 7.0,
      "eval_loss": 1.9956908226013184,
      "eval_runtime": 8.4107,
      "eval_samples_per_second": 23.779,
      "eval_steps_per_second": 23.779,
      "step": 3500
    },
    {
      "epoch": 7.02,
      "grad_norm": 1.1712397336959839,
      "learning_rate": 9.06060606060606e-05,
      "loss": 0.1405,
      "step": 3510
    },
    {
      "epoch": 7.04,
      "grad_norm": 2.211824893951416,
      "learning_rate": 8.999999999999999e-05,
      "loss": 0.1394,
      "step": 3520
    },
    {
      "epoch": 7.06,
      "grad_norm": 1.3427658081054688,
      "learning_rate": 8.939393939393938e-05,
      "loss": 0.1898,
      "step": 3530
    },
    {
      "epoch": 7.08,
      "grad_norm": 1.5435075759887695,
      "learning_rate": 8.878787878787879e-05,
      "loss": 0.1452,
      "step": 3540
    },
    {
      "epoch": 7.1,
      "grad_norm": 1.4240984916687012,
      "learning_rate": 8.818181818181817e-05,
      "loss": 0.16,
      "step": 3550
    },
    {
      "epoch": 7.12,
      "grad_norm": 3.995514154434204,
      "learning_rate": 8.757575757575757e-05,
      "loss": 0.1255,
      "step": 3560
    },
    {
      "epoch": 7.14,
      "grad_norm": 3.214961290359497,
      "learning_rate": 8.696969696969695e-05,
      "loss": 0.1492,
      "step": 3570
    },
    {
      "epoch": 7.16,
      "grad_norm": 5.750002861022949,
      "learning_rate": 8.636363636363636e-05,
      "loss": 0.1172,
      "step": 3580
    },
    {
      "epoch": 7.18,
      "grad_norm": 2.9042186737060547,
      "learning_rate": 8.575757575757576e-05,
      "loss": 0.1586,
      "step": 3590
    },
    {
      "epoch": 7.2,
      "grad_norm": 1.1675801277160645,
      "learning_rate": 8.515151515151514e-05,
      "loss": 0.1437,
      "step": 3600
    },
    {
      "epoch": 7.2,
      "eval_loss": 2.17283034324646,
      "eval_runtime": 8.3388,
      "eval_samples_per_second": 23.984,
      "eval_steps_per_second": 23.984,
      "step": 3600
    },
    {
      "epoch": 7.22,
      "grad_norm": 0.746903121471405,
      "learning_rate": 8.454545454545454e-05,
      "loss": 0.1592,
      "step": 3610
    },
    {
      "epoch": 7.24,
      "grad_norm": 1.5880426168441772,
      "learning_rate": 8.393939393939393e-05,
      "loss": 0.1848,
      "step": 3620
    },
    {
      "epoch": 7.26,
      "grad_norm": 1.3744683265686035,
      "learning_rate": 8.333333333333333e-05,
      "loss": 0.1271,
      "step": 3630
    },
    {
      "epoch": 7.28,
      "grad_norm": 0.8164516091346741,
      "learning_rate": 8.272727272727271e-05,
      "loss": 0.1288,
      "step": 3640
    },
    {
      "epoch": 7.3,
      "grad_norm": 2.1812517642974854,
      "learning_rate": 8.212121212121211e-05,
      "loss": 0.1464,
      "step": 3650
    },
    {
      "epoch": 7.32,
      "grad_norm": 7.076591491699219,
      "learning_rate": 8.15151515151515e-05,
      "loss": 0.152,
      "step": 3660
    },
    {
      "epoch": 7.34,
      "grad_norm": 8.998759269714355,
      "learning_rate": 8.09090909090909e-05,
      "loss": 0.1529,
      "step": 3670
    },
    {
      "epoch": 7.36,
      "grad_norm": 2.3938028812408447,
      "learning_rate": 8.03030303030303e-05,
      "loss": 0.1476,
      "step": 3680
    },
    {
      "epoch": 7.38,
      "grad_norm": 1.4295423030853271,
      "learning_rate": 7.969696969696968e-05,
      "loss": 0.1494,
      "step": 3690
    },
    {
      "epoch": 7.4,
      "grad_norm": 1.0613133907318115,
      "learning_rate": 7.909090909090908e-05,
      "loss": 0.1364,
      "step": 3700
    },
    {
      "epoch": 7.4,
      "eval_loss": 2.1762149333953857,
      "eval_runtime": 8.3676,
      "eval_samples_per_second": 23.902,
      "eval_steps_per_second": 23.902,
      "step": 3700
    },
    {
      "epoch": 7.42,
      "grad_norm": 0.5291877388954163,
      "learning_rate": 7.848484848484848e-05,
      "loss": 0.1628,
      "step": 3710
    },
    {
      "epoch": 7.44,
      "grad_norm": 1.3636798858642578,
      "learning_rate": 7.787878787878788e-05,
      "loss": 0.1825,
      "step": 3720
    },
    {
      "epoch": 7.46,
      "grad_norm": 3.895495891571045,
      "learning_rate": 7.727272727272726e-05,
      "loss": 0.1382,
      "step": 3730
    },
    {
      "epoch": 7.48,
      "grad_norm": 3.7109880447387695,
      "learning_rate": 7.666666666666666e-05,
      "loss": 0.1586,
      "step": 3740
    },
    {
      "epoch": 7.5,
      "grad_norm": 1.8918246030807495,
      "learning_rate": 7.606060606060607e-05,
      "loss": 0.1559,
      "step": 3750
    },
    {
      "epoch": 7.52,
      "grad_norm": 4.307856559753418,
      "learning_rate": 7.545454545454545e-05,
      "loss": 0.1496,
      "step": 3760
    },
    {
      "epoch": 7.54,
      "grad_norm": 1.593826413154602,
      "learning_rate": 7.484848484848485e-05,
      "loss": 0.1544,
      "step": 3770
    },
    {
      "epoch": 7.5600000000000005,
      "grad_norm": 0.7844262719154358,
      "learning_rate": 7.424242424242424e-05,
      "loss": 0.1453,
      "step": 3780
    },
    {
      "epoch": 7.58,
      "grad_norm": 0.9887115955352783,
      "learning_rate": 7.363636363636363e-05,
      "loss": 0.1808,
      "step": 3790
    },
    {
      "epoch": 7.6,
      "grad_norm": 0.9158424139022827,
      "learning_rate": 7.303030303030302e-05,
      "loss": 0.1406,
      "step": 3800
    },
    {
      "epoch": 7.6,
      "eval_loss": 2.194671630859375,
      "eval_runtime": 8.4086,
      "eval_samples_per_second": 23.785,
      "eval_steps_per_second": 23.785,
      "step": 3800
    },
    {
      "epoch": 7.62,
      "grad_norm": 2.4267337322235107,
      "learning_rate": 7.242424242424242e-05,
      "loss": 0.144,
      "step": 3810
    },
    {
      "epoch": 7.64,
      "grad_norm": 1.0020431280136108,
      "learning_rate": 7.18181818181818e-05,
      "loss": 0.1293,
      "step": 3820
    },
    {
      "epoch": 7.66,
      "grad_norm": 1.5153776407241821,
      "learning_rate": 7.12121212121212e-05,
      "loss": 0.1378,
      "step": 3830
    },
    {
      "epoch": 7.68,
      "grad_norm": 0.8870676159858704,
      "learning_rate": 7.06060606060606e-05,
      "loss": 0.1761,
      "step": 3840
    },
    {
      "epoch": 7.7,
      "grad_norm": 1.0140098333358765,
      "learning_rate": 7e-05,
      "loss": 0.1631,
      "step": 3850
    },
    {
      "epoch": 7.72,
      "grad_norm": 5.020876884460449,
      "learning_rate": 6.939393939393939e-05,
      "loss": 0.1486,
      "step": 3860
    },
    {
      "epoch": 7.74,
      "grad_norm": 1.7951043844223022,
      "learning_rate": 6.878787878787879e-05,
      "loss": 0.1588,
      "step": 3870
    },
    {
      "epoch": 7.76,
      "grad_norm": 0.9461630582809448,
      "learning_rate": 6.818181818181817e-05,
      "loss": 0.146,
      "step": 3880
    },
    {
      "epoch": 7.78,
      "grad_norm": 1.620382308959961,
      "learning_rate": 6.757575757575757e-05,
      "loss": 0.1373,
      "step": 3890
    },
    {
      "epoch": 7.8,
      "grad_norm": 0.9577290415763855,
      "learning_rate": 6.696969696969696e-05,
      "loss": 0.1419,
      "step": 3900
    },
    {
      "epoch": 7.8,
      "eval_loss": 2.139521598815918,
      "eval_runtime": 8.4295,
      "eval_samples_per_second": 23.726,
      "eval_steps_per_second": 23.726,
      "step": 3900
    },
    {
      "epoch": 7.82,
      "grad_norm": 0.8784626722335815,
      "learning_rate": 6.636363636363636e-05,
      "loss": 0.1464,
      "step": 3910
    },
    {
      "epoch": 7.84,
      "grad_norm": 1.0974023342132568,
      "learning_rate": 6.575757575757574e-05,
      "loss": 0.1638,
      "step": 3920
    },
    {
      "epoch": 7.86,
      "grad_norm": 2.3608384132385254,
      "learning_rate": 6.515151515151516e-05,
      "loss": 0.1578,
      "step": 3930
    },
    {
      "epoch": 7.88,
      "grad_norm": 3.9995696544647217,
      "learning_rate": 6.454545454545454e-05,
      "loss": 0.1684,
      "step": 3940
    },
    {
      "epoch": 7.9,
      "grad_norm": 1.3242764472961426,
      "learning_rate": 6.393939393939394e-05,
      "loss": 0.1356,
      "step": 3950
    },
    {
      "epoch": 7.92,
      "grad_norm": 0.6546344757080078,
      "learning_rate": 6.333333333333333e-05,
      "loss": 0.1735,
      "step": 3960
    },
    {
      "epoch": 7.9399999999999995,
      "grad_norm": 1.24947190284729,
      "learning_rate": 6.272727272727272e-05,
      "loss": 0.1584,
      "step": 3970
    },
    {
      "epoch": 7.96,
      "grad_norm": 2.369365692138672,
      "learning_rate": 6.212121212121211e-05,
      "loss": 0.1443,
      "step": 3980
    },
    {
      "epoch": 7.98,
      "grad_norm": 1.4658641815185547,
      "learning_rate": 6.151515151515151e-05,
      "loss": 0.1485,
      "step": 3990
    },
    {
      "epoch": 8.0,
      "grad_norm": 1.0054517984390259,
      "learning_rate": 6.0909090909090906e-05,
      "loss": 0.1537,
      "step": 4000
    },
    {
      "epoch": 8.0,
      "eval_loss": 2.171074628829956,
      "eval_runtime": 8.6231,
      "eval_samples_per_second": 23.194,
      "eval_steps_per_second": 23.194,
      "step": 4000
    },
    {
      "epoch": 8.02,
      "grad_norm": 0.8430290818214417,
      "learning_rate": 6.0303030303030296e-05,
      "loss": 0.1297,
      "step": 4010
    },
    {
      "epoch": 8.04,
      "grad_norm": 1.6489664316177368,
      "learning_rate": 5.969696969696969e-05,
      "loss": 0.1127,
      "step": 4020
    },
    {
      "epoch": 8.06,
      "grad_norm": 0.997545599937439,
      "learning_rate": 5.909090909090908e-05,
      "loss": 0.1188,
      "step": 4030
    },
    {
      "epoch": 8.08,
      "grad_norm": 2.0912981033325195,
      "learning_rate": 5.848484848484848e-05,
      "loss": 0.1186,
      "step": 4040
    },
    {
      "epoch": 8.1,
      "grad_norm": 0.5397942066192627,
      "learning_rate": 5.787878787878787e-05,
      "loss": 0.1331,
      "step": 4050
    },
    {
      "epoch": 8.12,
      "grad_norm": 1.100218653678894,
      "learning_rate": 5.727272727272727e-05,
      "loss": 0.1092,
      "step": 4060
    },
    {
      "epoch": 8.14,
      "grad_norm": 1.1890023946762085,
      "learning_rate": 5.666666666666666e-05,
      "loss": 0.1616,
      "step": 4070
    },
    {
      "epoch": 8.16,
      "grad_norm": 0.9520226716995239,
      "learning_rate": 5.606060606060606e-05,
      "loss": 0.1097,
      "step": 4080
    },
    {
      "epoch": 8.18,
      "grad_norm": 1.3616594076156616,
      "learning_rate": 5.545454545454545e-05,
      "loss": 0.1073,
      "step": 4090
    },
    {
      "epoch": 8.2,
      "grad_norm": 0.7089632749557495,
      "learning_rate": 5.484848484848485e-05,
      "loss": 0.1148,
      "step": 4100
    },
    {
      "epoch": 8.2,
      "eval_loss": 2.349041223526001,
      "eval_runtime": 8.329,
      "eval_samples_per_second": 24.012,
      "eval_steps_per_second": 24.012,
      "step": 4100
    },
    {
      "epoch": 8.22,
      "grad_norm": 1.4731003046035767,
      "learning_rate": 5.424242424242424e-05,
      "loss": 0.1252,
      "step": 4110
    },
    {
      "epoch": 8.24,
      "grad_norm": 1.651597261428833,
      "learning_rate": 5.3636363636363635e-05,
      "loss": 0.1379,
      "step": 4120
    },
    {
      "epoch": 8.26,
      "grad_norm": 1.0607926845550537,
      "learning_rate": 5.3030303030303025e-05,
      "loss": 0.1169,
      "step": 4130
    },
    {
      "epoch": 8.28,
      "grad_norm": 0.9692249894142151,
      "learning_rate": 5.2424242424242415e-05,
      "loss": 0.1209,
      "step": 4140
    },
    {
      "epoch": 8.3,
      "grad_norm": 2.2719855308532715,
      "learning_rate": 5.181818181818181e-05,
      "loss": 0.1581,
      "step": 4150
    },
    {
      "epoch": 8.32,
      "grad_norm": 1.4834238290786743,
      "learning_rate": 5.12121212121212e-05,
      "loss": 0.1149,
      "step": 4160
    },
    {
      "epoch": 8.34,
      "grad_norm": 3.004453420639038,
      "learning_rate": 5.0606060606060606e-05,
      "loss": 0.1271,
      "step": 4170
    },
    {
      "epoch": 8.36,
      "grad_norm": 0.5632070302963257,
      "learning_rate": 5.006060606060605e-05,
      "loss": 0.1271,
      "step": 4180
    },
    {
      "epoch": 8.38,
      "grad_norm": 4.731890678405762,
      "learning_rate": 4.9454545454545454e-05,
      "loss": 0.1447,
      "step": 4190
    },
    {
      "epoch": 8.4,
      "grad_norm": 1.1844509840011597,
      "learning_rate": 4.8848484848484844e-05,
      "loss": 0.1225,
      "step": 4200
    },
    {
      "epoch": 8.4,
      "eval_loss": 2.283135414123535,
      "eval_runtime": 8.3766,
      "eval_samples_per_second": 23.876,
      "eval_steps_per_second": 23.876,
      "step": 4200
    },
    {
      "epoch": 8.42,
      "grad_norm": 0.6252098679542542,
      "learning_rate": 4.824242424242424e-05,
      "loss": 0.1393,
      "step": 4210
    },
    {
      "epoch": 8.44,
      "grad_norm": 0.6484094262123108,
      "learning_rate": 4.763636363636363e-05,
      "loss": 0.1265,
      "step": 4220
    },
    {
      "epoch": 8.46,
      "grad_norm": 0.8397106528282166,
      "learning_rate": 4.703030303030303e-05,
      "loss": 0.124,
      "step": 4230
    },
    {
      "epoch": 8.48,
      "grad_norm": 1.5241299867630005,
      "learning_rate": 4.642424242424242e-05,
      "loss": 0.1112,
      "step": 4240
    },
    {
      "epoch": 8.5,
      "grad_norm": 7.058493137359619,
      "learning_rate": 4.5818181818181815e-05,
      "loss": 0.1493,
      "step": 4250
    },
    {
      "epoch": 8.52,
      "grad_norm": 0.7281776666641235,
      "learning_rate": 4.5212121212121205e-05,
      "loss": 0.127,
      "step": 4260
    },
    {
      "epoch": 8.54,
      "grad_norm": 1.9095079898834229,
      "learning_rate": 4.460606060606061e-05,
      "loss": 0.1362,
      "step": 4270
    },
    {
      "epoch": 8.56,
      "grad_norm": 1.635792851448059,
      "learning_rate": 4.4e-05,
      "loss": 0.1197,
      "step": 4280
    },
    {
      "epoch": 8.58,
      "grad_norm": 1.1125048398971558,
      "learning_rate": 4.339393939393939e-05,
      "loss": 0.1326,
      "step": 4290
    },
    {
      "epoch": 8.6,
      "grad_norm": 1.0411245822906494,
      "learning_rate": 4.2787878787878786e-05,
      "loss": 0.1188,
      "step": 4300
    },
    {
      "epoch": 8.6,
      "eval_loss": 2.3035683631896973,
      "eval_runtime": 8.3269,
      "eval_samples_per_second": 24.019,
      "eval_steps_per_second": 24.019,
      "step": 4300
    },
    {
      "epoch": 8.62,
      "grad_norm": 2.8742167949676514,
      "learning_rate": 4.2181818181818176e-05,
      "loss": 0.1314,
      "step": 4310
    },
    {
      "epoch": 8.64,
      "grad_norm": 1.2601076364517212,
      "learning_rate": 4.157575757575757e-05,
      "loss": 0.1414,
      "step": 4320
    },
    {
      "epoch": 8.66,
      "grad_norm": 5.844449996948242,
      "learning_rate": 4.096969696969696e-05,
      "loss": 0.1305,
      "step": 4330
    },
    {
      "epoch": 8.68,
      "grad_norm": 1.4463658332824707,
      "learning_rate": 4.036363636363636e-05,
      "loss": 0.1177,
      "step": 4340
    },
    {
      "epoch": 8.7,
      "grad_norm": 0.6612874269485474,
      "learning_rate": 3.975757575757575e-05,
      "loss": 0.1376,
      "step": 4350
    },
    {
      "epoch": 8.72,
      "grad_norm": 2.218337059020996,
      "learning_rate": 3.9151515151515153e-05,
      "loss": 0.1264,
      "step": 4360
    },
    {
      "epoch": 8.74,
      "grad_norm": 2.0072081089019775,
      "learning_rate": 3.8545454545454544e-05,
      "loss": 0.1298,
      "step": 4370
    },
    {
      "epoch": 8.76,
      "grad_norm": 2.2230188846588135,
      "learning_rate": 3.793939393939394e-05,
      "loss": 0.1276,
      "step": 4380
    },
    {
      "epoch": 8.78,
      "grad_norm": 0.6935476660728455,
      "learning_rate": 3.733333333333333e-05,
      "loss": 0.1401,
      "step": 4390
    },
    {
      "epoch": 8.8,
      "grad_norm": 1.0277423858642578,
      "learning_rate": 3.672727272727272e-05,
      "loss": 0.1151,
      "step": 4400
    },
    {
      "epoch": 8.8,
      "eval_loss": 2.3340117931365967,
      "eval_runtime": 8.3784,
      "eval_samples_per_second": 23.871,
      "eval_steps_per_second": 23.871,
      "step": 4400
    },
    {
      "epoch": 8.82,
      "grad_norm": 1.598243236541748,
      "learning_rate": 3.612121212121212e-05,
      "loss": 0.1355,
      "step": 4410
    },
    {
      "epoch": 8.84,
      "grad_norm": 0.7861824035644531,
      "learning_rate": 3.5515151515151514e-05,
      "loss": 0.1392,
      "step": 4420
    },
    {
      "epoch": 8.86,
      "grad_norm": 1.9549797773361206,
      "learning_rate": 3.4909090909090904e-05,
      "loss": 0.1224,
      "step": 4430
    },
    {
      "epoch": 8.88,
      "grad_norm": 0.5861558318138123,
      "learning_rate": 3.43030303030303e-05,
      "loss": 0.1206,
      "step": 4440
    },
    {
      "epoch": 8.9,
      "grad_norm": 1.158347487449646,
      "learning_rate": 3.369696969696969e-05,
      "loss": 0.1286,
      "step": 4450
    },
    {
      "epoch": 8.92,
      "grad_norm": 1.1739062070846558,
      "learning_rate": 3.309090909090909e-05,
      "loss": 0.1243,
      "step": 4460
    },
    {
      "epoch": 8.94,
      "grad_norm": 4.6017680168151855,
      "learning_rate": 3.2484848484848485e-05,
      "loss": 0.1295,
      "step": 4470
    },
    {
      "epoch": 8.96,
      "grad_norm": 0.6745694875717163,
      "learning_rate": 3.1878787878787875e-05,
      "loss": 0.1209,
      "step": 4480
    },
    {
      "epoch": 8.98,
      "grad_norm": 2.0992488861083984,
      "learning_rate": 3.127272727272727e-05,
      "loss": 0.1286,
      "step": 4490
    },
    {
      "epoch": 9.0,
      "grad_norm": 1.0563335418701172,
      "learning_rate": 3.066666666666667e-05,
      "loss": 0.1185,
      "step": 4500
    },
    {
      "epoch": 9.0,
      "eval_loss": 2.3124947547912598,
      "eval_runtime": 8.4053,
      "eval_samples_per_second": 23.794,
      "eval_steps_per_second": 23.794,
      "step": 4500
    },
    {
      "epoch": 9.02,
      "grad_norm": 0.7424799799919128,
      "learning_rate": 3.006060606060606e-05,
      "loss": 0.1117,
      "step": 4510
    },
    {
      "epoch": 9.04,
      "grad_norm": 0.8352100253105164,
      "learning_rate": 2.945454545454545e-05,
      "loss": 0.1081,
      "step": 4520
    },
    {
      "epoch": 9.06,
      "grad_norm": 1.35098135471344,
      "learning_rate": 2.8848484848484846e-05,
      "loss": 0.1104,
      "step": 4530
    },
    {
      "epoch": 9.08,
      "grad_norm": 0.4882221519947052,
      "learning_rate": 2.824242424242424e-05,
      "loss": 0.1102,
      "step": 4540
    },
    {
      "epoch": 9.1,
      "grad_norm": 0.7885629534721375,
      "learning_rate": 2.7636363636363633e-05,
      "loss": 0.1163,
      "step": 4550
    },
    {
      "epoch": 9.12,
      "grad_norm": 1.282186508178711,
      "learning_rate": 2.7030303030303026e-05,
      "loss": 0.1087,
      "step": 4560
    },
    {
      "epoch": 9.14,
      "grad_norm": 2.3048558235168457,
      "learning_rate": 2.642424242424242e-05,
      "loss": 0.1257,
      "step": 4570
    },
    {
      "epoch": 9.16,
      "grad_norm": 1.1562237739562988,
      "learning_rate": 2.5818181818181817e-05,
      "loss": 0.1157,
      "step": 4580
    },
    {
      "epoch": 9.18,
      "grad_norm": 2.6882073879241943,
      "learning_rate": 2.521212121212121e-05,
      "loss": 0.1135,
      "step": 4590
    },
    {
      "epoch": 9.2,
      "grad_norm": 0.6248125433921814,
      "learning_rate": 2.4606060606060604e-05,
      "loss": 0.1338,
      "step": 4600
    },
    {
      "epoch": 9.2,
      "eval_loss": 2.399625778198242,
      "eval_runtime": 8.3781,
      "eval_samples_per_second": 23.872,
      "eval_steps_per_second": 23.872,
      "step": 4600
    },
    {
      "epoch": 9.22,
      "grad_norm": 2.5829291343688965,
      "learning_rate": 2.3999999999999997e-05,
      "loss": 0.1112,
      "step": 4610
    },
    {
      "epoch": 9.24,
      "grad_norm": 1.4382084608078003,
      "learning_rate": 2.3393939393939394e-05,
      "loss": 0.1153,
      "step": 4620
    },
    {
      "epoch": 9.26,
      "grad_norm": 1.558646321296692,
      "learning_rate": 2.2787878787878788e-05,
      "loss": 0.1412,
      "step": 4630
    },
    {
      "epoch": 9.28,
      "grad_norm": 1.1421502828598022,
      "learning_rate": 2.218181818181818e-05,
      "loss": 0.108,
      "step": 4640
    },
    {
      "epoch": 9.3,
      "grad_norm": 0.9972438812255859,
      "learning_rate": 2.1575757575757575e-05,
      "loss": 0.1159,
      "step": 4650
    },
    {
      "epoch": 9.32,
      "grad_norm": 1.4726715087890625,
      "learning_rate": 2.0969696969696968e-05,
      "loss": 0.0994,
      "step": 4660
    },
    {
      "epoch": 9.34,
      "grad_norm": 1.7414377927780151,
      "learning_rate": 2.0363636363636365e-05,
      "loss": 0.1065,
      "step": 4670
    },
    {
      "epoch": 9.36,
      "grad_norm": 0.7147479057312012,
      "learning_rate": 1.9757575757575755e-05,
      "loss": 0.1017,
      "step": 4680
    },
    {
      "epoch": 9.38,
      "grad_norm": 0.9090542197227478,
      "learning_rate": 1.915151515151515e-05,
      "loss": 0.113,
      "step": 4690
    },
    {
      "epoch": 9.4,
      "grad_norm": 1.1019572019577026,
      "learning_rate": 1.8545454545454545e-05,
      "loss": 0.1129,
      "step": 4700
    },
    {
      "epoch": 9.4,
      "eval_loss": 2.428297758102417,
      "eval_runtime": 8.391,
      "eval_samples_per_second": 23.835,
      "eval_steps_per_second": 23.835,
      "step": 4700
    },
    {
      "epoch": 9.42,
      "grad_norm": 1.2962768077850342,
      "learning_rate": 1.793939393939394e-05,
      "loss": 0.1009,
      "step": 4710
    },
    {
      "epoch": 9.44,
      "grad_norm": 0.9679306149482727,
      "learning_rate": 1.7333333333333332e-05,
      "loss": 0.1192,
      "step": 4720
    },
    {
      "epoch": 9.46,
      "grad_norm": 1.6756939888000488,
      "learning_rate": 1.6727272727272726e-05,
      "loss": 0.1163,
      "step": 4730
    },
    {
      "epoch": 9.48,
      "grad_norm": 1.178094506263733,
      "learning_rate": 1.612121212121212e-05,
      "loss": 0.1196,
      "step": 4740
    },
    {
      "epoch": 9.5,
      "grad_norm": 1.7656450271606445,
      "learning_rate": 1.5515151515151513e-05,
      "loss": 0.1191,
      "step": 4750
    },
    {
      "epoch": 9.52,
      "grad_norm": 0.935477614402771,
      "learning_rate": 1.4909090909090908e-05,
      "loss": 0.1035,
      "step": 4760
    },
    {
      "epoch": 9.54,
      "grad_norm": 1.6771281957626343,
      "learning_rate": 1.4303030303030303e-05,
      "loss": 0.1126,
      "step": 4770
    },
    {
      "epoch": 9.56,
      "grad_norm": 1.5407356023788452,
      "learning_rate": 1.3696969696969697e-05,
      "loss": 0.1114,
      "step": 4780
    },
    {
      "epoch": 9.58,
      "grad_norm": 1.5651525259017944,
      "learning_rate": 1.309090909090909e-05,
      "loss": 0.1013,
      "step": 4790
    },
    {
      "epoch": 9.6,
      "grad_norm": 2.180654525756836,
      "learning_rate": 1.2484848484848483e-05,
      "loss": 0.1124,
      "step": 4800
    },
    {
      "epoch": 9.6,
      "eval_loss": 2.4363584518432617,
      "eval_runtime": 8.4128,
      "eval_samples_per_second": 23.773,
      "eval_steps_per_second": 23.773,
      "step": 4800
    },
    {
      "epoch": 9.62,
      "grad_norm": 2.120354652404785,
      "learning_rate": 1.1878787878787877e-05,
      "loss": 0.1165,
      "step": 4810
    },
    {
      "epoch": 9.64,
      "grad_norm": 1.4898006916046143,
      "learning_rate": 1.1272727272727272e-05,
      "loss": 0.1241,
      "step": 4820
    },
    {
      "epoch": 9.66,
      "grad_norm": 0.6528483033180237,
      "learning_rate": 1.0666666666666666e-05,
      "loss": 0.118,
      "step": 4830
    },
    {
      "epoch": 9.68,
      "grad_norm": 1.8050787448883057,
      "learning_rate": 1.006060606060606e-05,
      "loss": 0.1112,
      "step": 4840
    },
    {
      "epoch": 9.7,
      "grad_norm": 0.9596809148788452,
      "learning_rate": 9.454545454545454e-06,
      "loss": 0.1177,
      "step": 4850
    },
    {
      "epoch": 9.72,
      "grad_norm": 2.123405933380127,
      "learning_rate": 8.848484848484848e-06,
      "loss": 0.1121,
      "step": 4860
    },
    {
      "epoch": 9.74,
      "grad_norm": 0.9560576677322388,
      "learning_rate": 8.242424242424241e-06,
      "loss": 0.1214,
      "step": 4870
    },
    {
      "epoch": 9.76,
      "grad_norm": 1.1377582550048828,
      "learning_rate": 7.636363636363636e-06,
      "loss": 0.0958,
      "step": 4880
    },
    {
      "epoch": 9.78,
      "grad_norm": 1.1671791076660156,
      "learning_rate": 7.03030303030303e-06,
      "loss": 0.1091,
      "step": 4890
    },
    {
      "epoch": 9.8,
      "grad_norm": 1.9359192848205566,
      "learning_rate": 6.424242424242423e-06,
      "loss": 0.112,
      "step": 4900
    },
    {
      "epoch": 9.8,
      "eval_loss": 2.413241386413574,
      "eval_runtime": 8.4558,
      "eval_samples_per_second": 23.652,
      "eval_steps_per_second": 23.652,
      "step": 4900
    },
    {
      "epoch": 9.82,
      "grad_norm": 0.8882389664649963,
      "learning_rate": 5.818181818181818e-06,
      "loss": 0.11,
      "step": 4910
    },
    {
      "epoch": 9.84,
      "grad_norm": 1.0400493144989014,
      "learning_rate": 5.212121212121212e-06,
      "loss": 0.1113,
      "step": 4920
    },
    {
      "epoch": 9.86,
      "grad_norm": 0.4378143846988678,
      "learning_rate": 4.6060606060606055e-06,
      "loss": 0.1042,
      "step": 4930
    },
    {
      "epoch": 9.88,
      "grad_norm": 0.6267286539077759,
      "learning_rate": 4e-06,
      "loss": 0.1038,
      "step": 4940
    },
    {
      "epoch": 9.9,
      "grad_norm": 1.412969708442688,
      "learning_rate": 3.3939393939393937e-06,
      "loss": 0.1168,
      "step": 4950
    },
    {
      "epoch": 9.92,
      "grad_norm": 1.490763783454895,
      "learning_rate": 2.787878787878788e-06,
      "loss": 0.1133,
      "step": 4960
    },
    {
      "epoch": 9.94,
      "grad_norm": 0.4233054220676422,
      "learning_rate": 2.1818181818181815e-06,
      "loss": 0.1128,
      "step": 4970
    },
    {
      "epoch": 9.96,
      "grad_norm": 1.6220110654830933,
      "learning_rate": 1.5757575757575756e-06,
      "loss": 0.1046,
      "step": 4980
    },
    {
      "epoch": 9.98,
      "grad_norm": 0.9771044850349426,
      "learning_rate": 9.696969696969695e-07,
      "loss": 0.1075,
      "step": 4990
    },
    {
      "epoch": 10.0,
      "grad_norm": 1.198035478591919,
      "learning_rate": 3.636363636363636e-07,
      "loss": 0.1029,
      "step": 5000
    },
    {
      "epoch": 10.0,
      "eval_loss": 2.412074089050293,
      "eval_runtime": 8.4306,
      "eval_samples_per_second": 23.723,
      "eval_steps_per_second": 23.723,
      "step": 5000
    }
  ],
  "logging_steps": 10,
  "max_steps": 5000,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 10,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 1.496916688896e+16,
  "train_batch_size": 1,
  "trial_name": null,
  "trial_params": null
}

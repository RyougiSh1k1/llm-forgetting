{
  "best_global_step": null,
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 9.0,
  "eval_steps": 100,
  "global_step": 4500,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.02,
      "grad_norm": 2.3382411003112793,
      "learning_rate": 4.2e-05,
      "loss": 2.6028,
      "step": 10
    },
    {
      "epoch": 0.04,
      "grad_norm": 5.057858467102051,
      "learning_rate": 0.000102,
      "loss": 2.3996,
      "step": 20
    },
    {
      "epoch": 0.06,
      "grad_norm": 3.5744218826293945,
      "learning_rate": 0.000162,
      "loss": 1.8481,
      "step": 30
    },
    {
      "epoch": 0.08,
      "grad_norm": 3.771421432495117,
      "learning_rate": 0.00022199999999999998,
      "loss": 1.4557,
      "step": 40
    },
    {
      "epoch": 0.1,
      "grad_norm": 3.856877088546753,
      "learning_rate": 0.00028199999999999997,
      "loss": 1.4101,
      "step": 50
    },
    {
      "epoch": 0.12,
      "grad_norm": 7.764348030090332,
      "learning_rate": 0.00029957575757575756,
      "loss": 1.2245,
      "step": 60
    },
    {
      "epoch": 0.14,
      "grad_norm": 3.5772836208343506,
      "learning_rate": 0.0002989696969696969,
      "loss": 1.2903,
      "step": 70
    },
    {
      "epoch": 0.16,
      "grad_norm": 8.813631057739258,
      "learning_rate": 0.0002983636363636363,
      "loss": 1.0709,
      "step": 80
    },
    {
      "epoch": 0.18,
      "grad_norm": 2.8988776206970215,
      "learning_rate": 0.00029775757575757573,
      "loss": 1.1642,
      "step": 90
    },
    {
      "epoch": 0.2,
      "grad_norm": 3.4935550689697266,
      "learning_rate": 0.00029715151515151514,
      "loss": 1.2634,
      "step": 100
    },
    {
      "epoch": 0.2,
      "eval_loss": 1.1196287870407104,
      "eval_runtime": 8.296,
      "eval_samples_per_second": 24.108,
      "eval_steps_per_second": 24.108,
      "step": 100
    },
    {
      "epoch": 0.22,
      "grad_norm": 2.666334390640259,
      "learning_rate": 0.00029654545454545455,
      "loss": 1.0836,
      "step": 110
    },
    {
      "epoch": 0.24,
      "grad_norm": 5.555864334106445,
      "learning_rate": 0.0002959393939393939,
      "loss": 0.9068,
      "step": 120
    },
    {
      "epoch": 0.26,
      "grad_norm": 3.60229229927063,
      "learning_rate": 0.0002953333333333333,
      "loss": 1.3216,
      "step": 130
    },
    {
      "epoch": 0.28,
      "grad_norm": 2.9093234539031982,
      "learning_rate": 0.0002947272727272727,
      "loss": 1.235,
      "step": 140
    },
    {
      "epoch": 0.3,
      "grad_norm": 2.278369665145874,
      "learning_rate": 0.0002941212121212121,
      "loss": 0.7488,
      "step": 150
    },
    {
      "epoch": 0.32,
      "grad_norm": 3.3587124347686768,
      "learning_rate": 0.0002935151515151515,
      "loss": 0.8381,
      "step": 160
    },
    {
      "epoch": 0.34,
      "grad_norm": 6.200328826904297,
      "learning_rate": 0.00029290909090909085,
      "loss": 1.0685,
      "step": 170
    },
    {
      "epoch": 0.36,
      "grad_norm": 2.7946488857269287,
      "learning_rate": 0.00029230303030303026,
      "loss": 1.229,
      "step": 180
    },
    {
      "epoch": 0.38,
      "grad_norm": 3.2368931770324707,
      "learning_rate": 0.0002916969696969697,
      "loss": 1.1025,
      "step": 190
    },
    {
      "epoch": 0.4,
      "grad_norm": 3.379099130630493,
      "learning_rate": 0.0002910909090909091,
      "loss": 0.8635,
      "step": 200
    },
    {
      "epoch": 0.4,
      "eval_loss": 0.9036555290222168,
      "eval_runtime": 8.3111,
      "eval_samples_per_second": 24.064,
      "eval_steps_per_second": 24.064,
      "step": 200
    },
    {
      "epoch": 0.42,
      "grad_norm": 3.6302638053894043,
      "learning_rate": 0.00029048484848484844,
      "loss": 0.7269,
      "step": 210
    },
    {
      "epoch": 0.44,
      "grad_norm": 3.1496171951293945,
      "learning_rate": 0.00028987878787878785,
      "loss": 0.9875,
      "step": 220
    },
    {
      "epoch": 0.46,
      "grad_norm": 3.619481325149536,
      "learning_rate": 0.00028927272727272726,
      "loss": 0.7678,
      "step": 230
    },
    {
      "epoch": 0.48,
      "grad_norm": 2.4067957401275635,
      "learning_rate": 0.0002886666666666666,
      "loss": 0.757,
      "step": 240
    },
    {
      "epoch": 0.5,
      "grad_norm": 3.8081443309783936,
      "learning_rate": 0.00028806060606060603,
      "loss": 0.92,
      "step": 250
    },
    {
      "epoch": 0.52,
      "grad_norm": 4.832754135131836,
      "learning_rate": 0.00028745454545454544,
      "loss": 0.8576,
      "step": 260
    },
    {
      "epoch": 0.54,
      "grad_norm": 4.112178325653076,
      "learning_rate": 0.00028684848484848485,
      "loss": 1.0155,
      "step": 270
    },
    {
      "epoch": 0.56,
      "grad_norm": 4.127808570861816,
      "learning_rate": 0.0002862424242424242,
      "loss": 1.08,
      "step": 280
    },
    {
      "epoch": 0.58,
      "grad_norm": 4.1790571212768555,
      "learning_rate": 0.0002856363636363636,
      "loss": 0.9297,
      "step": 290
    },
    {
      "epoch": 0.6,
      "grad_norm": 2.77850604057312,
      "learning_rate": 0.000285030303030303,
      "loss": 0.7498,
      "step": 300
    },
    {
      "epoch": 0.6,
      "eval_loss": 0.8964874148368835,
      "eval_runtime": 8.2895,
      "eval_samples_per_second": 24.127,
      "eval_steps_per_second": 24.127,
      "step": 300
    },
    {
      "epoch": 0.62,
      "grad_norm": 3.446934700012207,
      "learning_rate": 0.0002844242424242424,
      "loss": 1.0684,
      "step": 310
    },
    {
      "epoch": 0.64,
      "grad_norm": 3.317094087600708,
      "learning_rate": 0.0002838181818181818,
      "loss": 0.6053,
      "step": 320
    },
    {
      "epoch": 0.66,
      "grad_norm": 3.038219690322876,
      "learning_rate": 0.0002832121212121212,
      "loss": 0.6996,
      "step": 330
    },
    {
      "epoch": 0.68,
      "grad_norm": 1.767200231552124,
      "learning_rate": 0.00028260606060606056,
      "loss": 1.0349,
      "step": 340
    },
    {
      "epoch": 0.7,
      "grad_norm": 1.6309196949005127,
      "learning_rate": 0.00028199999999999997,
      "loss": 0.841,
      "step": 350
    },
    {
      "epoch": 0.72,
      "grad_norm": 4.533759117126465,
      "learning_rate": 0.0002813939393939394,
      "loss": 0.8471,
      "step": 360
    },
    {
      "epoch": 0.74,
      "grad_norm": 3.3562839031219482,
      "learning_rate": 0.0002807878787878788,
      "loss": 0.8356,
      "step": 370
    },
    {
      "epoch": 0.76,
      "grad_norm": 3.432953119277954,
      "learning_rate": 0.00028018181818181815,
      "loss": 0.8548,
      "step": 380
    },
    {
      "epoch": 0.78,
      "grad_norm": 2.947848320007324,
      "learning_rate": 0.00027957575757575756,
      "loss": 0.658,
      "step": 390
    },
    {
      "epoch": 0.8,
      "grad_norm": Infinity,
      "learning_rate": 0.00027896969696969697,
      "loss": 0.7747,
      "step": 400
    },
    {
      "epoch": 0.8,
      "eval_loss": 0.8954545855522156,
      "eval_runtime": 8.3707,
      "eval_samples_per_second": 23.893,
      "eval_steps_per_second": 23.893,
      "step": 400
    },
    {
      "epoch": 0.82,
      "grad_norm": 2.945387363433838,
      "learning_rate": 0.0002784242424242424,
      "loss": 1.1143,
      "step": 410
    },
    {
      "epoch": 0.84,
      "grad_norm": 3.7847321033477783,
      "learning_rate": 0.0002778181818181818,
      "loss": 0.8347,
      "step": 420
    },
    {
      "epoch": 0.86,
      "grad_norm": 2.2336690425872803,
      "learning_rate": 0.00027721212121212117,
      "loss": 0.7059,
      "step": 430
    },
    {
      "epoch": 0.88,
      "grad_norm": 3.9947447776794434,
      "learning_rate": 0.0002766060606060606,
      "loss": 0.7383,
      "step": 440
    },
    {
      "epoch": 0.9,
      "grad_norm": 2.6671195030212402,
      "learning_rate": 0.000276,
      "loss": 0.7383,
      "step": 450
    },
    {
      "epoch": 0.92,
      "grad_norm": 3.321829080581665,
      "learning_rate": 0.0002753939393939394,
      "loss": 0.9891,
      "step": 460
    },
    {
      "epoch": 0.94,
      "grad_norm": 2.538966655731201,
      "learning_rate": 0.00027478787878787875,
      "loss": 0.6956,
      "step": 470
    },
    {
      "epoch": 0.96,
      "grad_norm": 2.1863913536071777,
      "learning_rate": 0.00027418181818181816,
      "loss": 0.9033,
      "step": 480
    },
    {
      "epoch": 0.98,
      "grad_norm": 1.7029281854629517,
      "learning_rate": 0.0002735757575757576,
      "loss": 1.0037,
      "step": 490
    },
    {
      "epoch": 1.0,
      "grad_norm": 6.155425071716309,
      "learning_rate": 0.00027296969696969693,
      "loss": 0.7802,
      "step": 500
    },
    {
      "epoch": 1.0,
      "eval_loss": 0.8635212779045105,
      "eval_runtime": 8.3484,
      "eval_samples_per_second": 23.957,
      "eval_steps_per_second": 23.957,
      "step": 500
    },
    {
      "epoch": 1.02,
      "grad_norm": 4.138461589813232,
      "learning_rate": 0.00027236363636363634,
      "loss": 0.8354,
      "step": 510
    },
    {
      "epoch": 1.04,
      "grad_norm": 4.775811672210693,
      "learning_rate": 0.0002717575757575757,
      "loss": 0.7239,
      "step": 520
    },
    {
      "epoch": 1.06,
      "grad_norm": 1.9930126667022705,
      "learning_rate": 0.00027115151515151516,
      "loss": 0.5679,
      "step": 530
    },
    {
      "epoch": 1.08,
      "grad_norm": 3.436445713043213,
      "learning_rate": 0.0002705454545454545,
      "loss": 0.72,
      "step": 540
    },
    {
      "epoch": 1.1,
      "grad_norm": 2.435415029525757,
      "learning_rate": 0.00026993939393939393,
      "loss": 0.5938,
      "step": 550
    },
    {
      "epoch": 1.12,
      "grad_norm": 1.7967511415481567,
      "learning_rate": 0.00026933333333333334,
      "loss": 0.7092,
      "step": 560
    },
    {
      "epoch": 1.1400000000000001,
      "grad_norm": 2.892393112182617,
      "learning_rate": 0.0002687272727272727,
      "loss": 0.5937,
      "step": 570
    },
    {
      "epoch": 1.16,
      "grad_norm": 3.947781801223755,
      "learning_rate": 0.0002681212121212121,
      "loss": 0.8785,
      "step": 580
    },
    {
      "epoch": 1.18,
      "grad_norm": 2.6444694995880127,
      "learning_rate": 0.00026751515151515146,
      "loss": 0.6411,
      "step": 590
    },
    {
      "epoch": 1.2,
      "grad_norm": 1.6146166324615479,
      "learning_rate": 0.00026690909090909087,
      "loss": 0.5755,
      "step": 600
    },
    {
      "epoch": 1.2,
      "eval_loss": 0.8759171962738037,
      "eval_runtime": 8.3308,
      "eval_samples_per_second": 24.007,
      "eval_steps_per_second": 24.007,
      "step": 600
    },
    {
      "epoch": 1.22,
      "grad_norm": 5.328301429748535,
      "learning_rate": 0.0002663030303030303,
      "loss": 0.6946,
      "step": 610
    },
    {
      "epoch": 1.24,
      "grad_norm": 4.48146915435791,
      "learning_rate": 0.0002656969696969697,
      "loss": 0.7758,
      "step": 620
    },
    {
      "epoch": 1.26,
      "grad_norm": 2.8765413761138916,
      "learning_rate": 0.00026509090909090905,
      "loss": 0.7421,
      "step": 630
    },
    {
      "epoch": 1.28,
      "grad_norm": 3.433485507965088,
      "learning_rate": 0.00026448484848484846,
      "loss": 0.6928,
      "step": 640
    },
    {
      "epoch": 1.3,
      "grad_norm": 3.0906174182891846,
      "learning_rate": 0.00026387878787878787,
      "loss": 0.7624,
      "step": 650
    },
    {
      "epoch": 1.32,
      "grad_norm": 2.6538572311401367,
      "learning_rate": 0.0002632727272727272,
      "loss": 0.5707,
      "step": 660
    },
    {
      "epoch": 1.34,
      "grad_norm": 2.0208547115325928,
      "learning_rate": 0.00026266666666666664,
      "loss": 0.7577,
      "step": 670
    },
    {
      "epoch": 1.3599999999999999,
      "grad_norm": 4.822268962860107,
      "learning_rate": 0.00026206060606060605,
      "loss": 0.8927,
      "step": 680
    },
    {
      "epoch": 1.38,
      "grad_norm": 3.184541940689087,
      "learning_rate": 0.0002614545454545454,
      "loss": 0.5584,
      "step": 690
    },
    {
      "epoch": 1.4,
      "grad_norm": 3.7720940113067627,
      "learning_rate": 0.0002608484848484848,
      "loss": 0.6562,
      "step": 700
    },
    {
      "epoch": 1.4,
      "eval_loss": 0.8672248125076294,
      "eval_runtime": 8.3156,
      "eval_samples_per_second": 24.051,
      "eval_steps_per_second": 24.051,
      "step": 700
    },
    {
      "epoch": 1.42,
      "grad_norm": 1.9715526103973389,
      "learning_rate": 0.0002602424242424242,
      "loss": 0.7207,
      "step": 710
    },
    {
      "epoch": 1.44,
      "grad_norm": 3.426621675491333,
      "learning_rate": 0.00025963636363636363,
      "loss": 0.6179,
      "step": 720
    },
    {
      "epoch": 1.46,
      "grad_norm": 3.779542922973633,
      "learning_rate": 0.000259030303030303,
      "loss": 0.7704,
      "step": 730
    },
    {
      "epoch": 1.48,
      "grad_norm": 2.1214559078216553,
      "learning_rate": 0.0002584242424242424,
      "loss": 0.6809,
      "step": 740
    },
    {
      "epoch": 1.5,
      "grad_norm": 6.410375595092773,
      "learning_rate": 0.0002578181818181818,
      "loss": 0.7504,
      "step": 750
    },
    {
      "epoch": 1.52,
      "grad_norm": 2.99414324760437,
      "learning_rate": 0.00025721212121212117,
      "loss": 0.8378,
      "step": 760
    },
    {
      "epoch": 1.54,
      "grad_norm": 1.6506197452545166,
      "learning_rate": 0.0002566060606060606,
      "loss": 0.7137,
      "step": 770
    },
    {
      "epoch": 1.56,
      "grad_norm": 1.5625183582305908,
      "learning_rate": 0.000256,
      "loss": 0.5674,
      "step": 780
    },
    {
      "epoch": 1.58,
      "grad_norm": 5.064727306365967,
      "learning_rate": 0.0002553939393939394,
      "loss": 0.6452,
      "step": 790
    },
    {
      "epoch": 1.6,
      "grad_norm": 2.2459733486175537,
      "learning_rate": 0.00025478787878787876,
      "loss": 0.797,
      "step": 800
    },
    {
      "epoch": 1.6,
      "eval_loss": 0.86064612865448,
      "eval_runtime": 8.3059,
      "eval_samples_per_second": 24.079,
      "eval_steps_per_second": 24.079,
      "step": 800
    },
    {
      "epoch": 1.62,
      "grad_norm": 2.910245656967163,
      "learning_rate": 0.00025418181818181817,
      "loss": 0.6984,
      "step": 810
    },
    {
      "epoch": 1.6400000000000001,
      "grad_norm": 3.1609466075897217,
      "learning_rate": 0.0002535757575757576,
      "loss": 0.5905,
      "step": 820
    },
    {
      "epoch": 1.6600000000000001,
      "grad_norm": 3.6047232151031494,
      "learning_rate": 0.00025296969696969693,
      "loss": 0.7167,
      "step": 830
    },
    {
      "epoch": 1.6800000000000002,
      "grad_norm": 3.945023536682129,
      "learning_rate": 0.00025236363636363634,
      "loss": 0.717,
      "step": 840
    },
    {
      "epoch": 1.7,
      "grad_norm": 3.357691764831543,
      "learning_rate": 0.0002517575757575757,
      "loss": 0.7462,
      "step": 850
    },
    {
      "epoch": 1.72,
      "grad_norm": 4.624851703643799,
      "learning_rate": 0.0002511515151515151,
      "loss": 0.688,
      "step": 860
    },
    {
      "epoch": 1.74,
      "grad_norm": 4.450809955596924,
      "learning_rate": 0.0002505454545454545,
      "loss": 0.6509,
      "step": 870
    },
    {
      "epoch": 1.76,
      "grad_norm": 4.530634880065918,
      "learning_rate": 0.00024993939393939393,
      "loss": 0.7622,
      "step": 880
    },
    {
      "epoch": 1.78,
      "grad_norm": 2.387073040008545,
      "learning_rate": 0.00024933333333333334,
      "loss": 0.5383,
      "step": 890
    },
    {
      "epoch": 1.8,
      "grad_norm": 4.067559719085693,
      "learning_rate": 0.0002487272727272727,
      "loss": 0.6344,
      "step": 900
    },
    {
      "epoch": 1.8,
      "eval_loss": 0.8540768623352051,
      "eval_runtime": 8.299,
      "eval_samples_per_second": 24.099,
      "eval_steps_per_second": 24.099,
      "step": 900
    },
    {
      "epoch": 1.8199999999999998,
      "grad_norm": 1.9960765838623047,
      "learning_rate": 0.0002481212121212121,
      "loss": 0.673,
      "step": 910
    },
    {
      "epoch": 1.8399999999999999,
      "grad_norm": 3.731710910797119,
      "learning_rate": 0.00024751515151515146,
      "loss": 0.8113,
      "step": 920
    },
    {
      "epoch": 1.8599999999999999,
      "grad_norm": 2.709285020828247,
      "learning_rate": 0.0002469090909090909,
      "loss": 0.8038,
      "step": 930
    },
    {
      "epoch": 1.88,
      "grad_norm": 4.032413482666016,
      "learning_rate": 0.0002463030303030303,
      "loss": 0.579,
      "step": 940
    },
    {
      "epoch": 1.9,
      "grad_norm": 3.653299570083618,
      "learning_rate": 0.00024569696969696964,
      "loss": 0.736,
      "step": 950
    },
    {
      "epoch": 1.92,
      "grad_norm": 2.2394254207611084,
      "learning_rate": 0.0002450909090909091,
      "loss": 0.5886,
      "step": 960
    },
    {
      "epoch": 1.94,
      "grad_norm": 3.95078182220459,
      "learning_rate": 0.00024448484848484846,
      "loss": 0.9702,
      "step": 970
    },
    {
      "epoch": 1.96,
      "grad_norm": 4.638155937194824,
      "learning_rate": 0.00024387878787878787,
      "loss": 0.7993,
      "step": 980
    },
    {
      "epoch": 1.98,
      "grad_norm": 3.1152398586273193,
      "learning_rate": 0.00024327272727272725,
      "loss": 0.5951,
      "step": 990
    },
    {
      "epoch": 2.0,
      "grad_norm": 2.860375165939331,
      "learning_rate": 0.00024266666666666664,
      "loss": 0.8663,
      "step": 1000
    },
    {
      "epoch": 2.0,
      "eval_loss": 0.846017599105835,
      "eval_runtime": 8.3285,
      "eval_samples_per_second": 24.014,
      "eval_steps_per_second": 24.014,
      "step": 1000
    },
    {
      "epoch": 2.02,
      "grad_norm": 5.10117769241333,
      "learning_rate": 0.00024206060606060602,
      "loss": 0.439,
      "step": 1010
    },
    {
      "epoch": 2.04,
      "grad_norm": 4.2495808601379395,
      "learning_rate": 0.00024145454545454543,
      "loss": 0.5203,
      "step": 1020
    },
    {
      "epoch": 2.06,
      "grad_norm": 3.3760452270507812,
      "learning_rate": 0.00024084848484848482,
      "loss": 0.6013,
      "step": 1030
    },
    {
      "epoch": 2.08,
      "grad_norm": 2.9759280681610107,
      "learning_rate": 0.00024024242424242423,
      "loss": 0.5101,
      "step": 1040
    },
    {
      "epoch": 2.1,
      "grad_norm": 2.7538187503814697,
      "learning_rate": 0.00023963636363636364,
      "loss": 0.45,
      "step": 1050
    },
    {
      "epoch": 2.12,
      "grad_norm": 2.734312057495117,
      "learning_rate": 0.00023903030303030302,
      "loss": 0.5114,
      "step": 1060
    },
    {
      "epoch": 2.14,
      "grad_norm": 3.7720162868499756,
      "learning_rate": 0.0002384242424242424,
      "loss": 0.4293,
      "step": 1070
    },
    {
      "epoch": 2.16,
      "grad_norm": 5.500620365142822,
      "learning_rate": 0.00023781818181818179,
      "loss": 0.637,
      "step": 1080
    },
    {
      "epoch": 2.18,
      "grad_norm": 2.398308277130127,
      "learning_rate": 0.0002372121212121212,
      "loss": 0.4536,
      "step": 1090
    },
    {
      "epoch": 2.2,
      "grad_norm": 1.5095456838607788,
      "learning_rate": 0.00023660606060606058,
      "loss": 0.3817,
      "step": 1100
    },
    {
      "epoch": 2.2,
      "eval_loss": 0.9504778981208801,
      "eval_runtime": 8.3152,
      "eval_samples_per_second": 24.052,
      "eval_steps_per_second": 24.052,
      "step": 1100
    },
    {
      "epoch": 2.22,
      "grad_norm": 3.42844820022583,
      "learning_rate": 0.00023599999999999996,
      "loss": 0.4503,
      "step": 1110
    },
    {
      "epoch": 2.24,
      "grad_norm": 2.694570779800415,
      "learning_rate": 0.00023539393939393935,
      "loss": 0.5048,
      "step": 1120
    },
    {
      "epoch": 2.26,
      "grad_norm": 1.7489750385284424,
      "learning_rate": 0.00023478787878787878,
      "loss": 0.4765,
      "step": 1130
    },
    {
      "epoch": 2.2800000000000002,
      "grad_norm": 4.866194248199463,
      "learning_rate": 0.00023418181818181817,
      "loss": 0.5494,
      "step": 1140
    },
    {
      "epoch": 2.3,
      "grad_norm": 4.028097629547119,
      "learning_rate": 0.00023357575757575755,
      "loss": 0.4841,
      "step": 1150
    },
    {
      "epoch": 2.32,
      "grad_norm": 3.6016082763671875,
      "learning_rate": 0.00023296969696969696,
      "loss": 0.4318,
      "step": 1160
    },
    {
      "epoch": 2.34,
      "grad_norm": 3.381582021713257,
      "learning_rate": 0.00023236363636363634,
      "loss": 0.4905,
      "step": 1170
    },
    {
      "epoch": 2.36,
      "grad_norm": 5.223179817199707,
      "learning_rate": 0.00023175757575757573,
      "loss": 0.4573,
      "step": 1180
    },
    {
      "epoch": 2.38,
      "grad_norm": 2.985621213912964,
      "learning_rate": 0.0002311515151515151,
      "loss": 0.493,
      "step": 1190
    },
    {
      "epoch": 2.4,
      "grad_norm": 3.311054229736328,
      "learning_rate": 0.00023054545454545452,
      "loss": 0.4429,
      "step": 1200
    },
    {
      "epoch": 2.4,
      "eval_loss": 0.9051905274391174,
      "eval_runtime": 8.3071,
      "eval_samples_per_second": 24.076,
      "eval_steps_per_second": 24.076,
      "step": 1200
    },
    {
      "epoch": 2.42,
      "grad_norm": 2.0001332759857178,
      "learning_rate": 0.00022993939393939393,
      "loss": 0.3748,
      "step": 1210
    },
    {
      "epoch": 2.44,
      "grad_norm": 7.840647220611572,
      "learning_rate": 0.00022933333333333332,
      "loss": 0.6649,
      "step": 1220
    },
    {
      "epoch": 2.46,
      "grad_norm": 5.346685886383057,
      "learning_rate": 0.00022872727272727273,
      "loss": 0.5289,
      "step": 1230
    },
    {
      "epoch": 2.48,
      "grad_norm": 2.6436238288879395,
      "learning_rate": 0.0002281212121212121,
      "loss": 0.5722,
      "step": 1240
    },
    {
      "epoch": 2.5,
      "grad_norm": 4.341616630554199,
      "learning_rate": 0.0002275151515151515,
      "loss": 0.5767,
      "step": 1250
    },
    {
      "epoch": 2.52,
      "grad_norm": 1.9566513299942017,
      "learning_rate": 0.00022690909090909088,
      "loss": 0.6307,
      "step": 1260
    },
    {
      "epoch": 2.54,
      "grad_norm": 4.674917221069336,
      "learning_rate": 0.00022630303030303029,
      "loss": 0.5579,
      "step": 1270
    },
    {
      "epoch": 2.56,
      "grad_norm": 1.3990769386291504,
      "learning_rate": 0.00022569696969696967,
      "loss": 0.4281,
      "step": 1280
    },
    {
      "epoch": 2.58,
      "grad_norm": 3.0934536457061768,
      "learning_rate": 0.00022509090909090905,
      "loss": 0.4129,
      "step": 1290
    },
    {
      "epoch": 2.6,
      "grad_norm": 3.616969585418701,
      "learning_rate": 0.0002244848484848485,
      "loss": 0.5762,
      "step": 1300
    },
    {
      "epoch": 2.6,
      "eval_loss": 0.9173758029937744,
      "eval_runtime": 8.302,
      "eval_samples_per_second": 24.091,
      "eval_steps_per_second": 24.091,
      "step": 1300
    },
    {
      "epoch": 2.62,
      "grad_norm": 2.5137202739715576,
      "learning_rate": 0.00022387878787878787,
      "loss": 0.5826,
      "step": 1310
    },
    {
      "epoch": 2.64,
      "grad_norm": 2.5559775829315186,
      "learning_rate": 0.00022327272727272726,
      "loss": 0.4705,
      "step": 1320
    },
    {
      "epoch": 2.66,
      "grad_norm": 4.293034553527832,
      "learning_rate": 0.00022266666666666664,
      "loss": 0.5527,
      "step": 1330
    },
    {
      "epoch": 2.68,
      "grad_norm": 1.929250717163086,
      "learning_rate": 0.00022206060606060605,
      "loss": 0.4762,
      "step": 1340
    },
    {
      "epoch": 2.7,
      "grad_norm": 2.8381738662719727,
      "learning_rate": 0.00022145454545454543,
      "loss": 0.4682,
      "step": 1350
    },
    {
      "epoch": 2.7199999999999998,
      "grad_norm": 3.2738866806030273,
      "learning_rate": 0.00022084848484848482,
      "loss": 0.4682,
      "step": 1360
    },
    {
      "epoch": 2.74,
      "grad_norm": 3.449162721633911,
      "learning_rate": 0.0002202424242424242,
      "loss": 0.4774,
      "step": 1370
    },
    {
      "epoch": 2.76,
      "grad_norm": 4.939647674560547,
      "learning_rate": 0.00021963636363636364,
      "loss": 0.5891,
      "step": 1380
    },
    {
      "epoch": 2.7800000000000002,
      "grad_norm": 2.170347213745117,
      "learning_rate": 0.00021903030303030302,
      "loss": 0.6519,
      "step": 1390
    },
    {
      "epoch": 2.8,
      "grad_norm": 4.09350061416626,
      "learning_rate": 0.0002184242424242424,
      "loss": 0.5454,
      "step": 1400
    },
    {
      "epoch": 2.8,
      "eval_loss": 0.8864569067955017,
      "eval_runtime": 8.3003,
      "eval_samples_per_second": 24.096,
      "eval_steps_per_second": 24.096,
      "step": 1400
    },
    {
      "epoch": 2.82,
      "grad_norm": 1.9536678791046143,
      "learning_rate": 0.00021781818181818181,
      "loss": 0.3931,
      "step": 1410
    },
    {
      "epoch": 2.84,
      "grad_norm": 3.440305471420288,
      "learning_rate": 0.0002172121212121212,
      "loss": 0.4298,
      "step": 1420
    },
    {
      "epoch": 2.86,
      "grad_norm": 3.3600423336029053,
      "learning_rate": 0.00021660606060606058,
      "loss": 0.47,
      "step": 1430
    },
    {
      "epoch": 2.88,
      "grad_norm": 3.954071521759033,
      "learning_rate": 0.00021599999999999996,
      "loss": 0.4055,
      "step": 1440
    },
    {
      "epoch": 2.9,
      "grad_norm": 3.112100839614868,
      "learning_rate": 0.00021539393939393938,
      "loss": 0.3557,
      "step": 1450
    },
    {
      "epoch": 2.92,
      "grad_norm": 2.5311899185180664,
      "learning_rate": 0.00021478787878787876,
      "loss": 0.6138,
      "step": 1460
    },
    {
      "epoch": 2.94,
      "grad_norm": 2.0322117805480957,
      "learning_rate": 0.00021418181818181817,
      "loss": 0.4341,
      "step": 1470
    },
    {
      "epoch": 2.96,
      "grad_norm": 3.4899914264678955,
      "learning_rate": 0.00021357575757575758,
      "loss": 0.4525,
      "step": 1480
    },
    {
      "epoch": 2.98,
      "grad_norm": 2.7245116233825684,
      "learning_rate": 0.00021296969696969696,
      "loss": 0.5488,
      "step": 1490
    },
    {
      "epoch": 3.0,
      "grad_norm": 4.991137981414795,
      "learning_rate": 0.00021236363636363635,
      "loss": 0.6465,
      "step": 1500
    },
    {
      "epoch": 3.0,
      "eval_loss": 0.8836947679519653,
      "eval_runtime": 8.335,
      "eval_samples_per_second": 23.995,
      "eval_steps_per_second": 23.995,
      "step": 1500
    },
    {
      "epoch": 3.02,
      "grad_norm": 2.9515774250030518,
      "learning_rate": 0.00021175757575757573,
      "loss": 0.3662,
      "step": 1510
    },
    {
      "epoch": 3.04,
      "grad_norm": 2.507035970687866,
      "learning_rate": 0.00021115151515151514,
      "loss": 0.3091,
      "step": 1520
    },
    {
      "epoch": 3.06,
      "grad_norm": 3.65979266166687,
      "learning_rate": 0.00021054545454545452,
      "loss": 0.3169,
      "step": 1530
    },
    {
      "epoch": 3.08,
      "grad_norm": 2.387647867202759,
      "learning_rate": 0.0002099393939393939,
      "loss": 0.3393,
      "step": 1540
    },
    {
      "epoch": 3.1,
      "grad_norm": 3.4811489582061768,
      "learning_rate": 0.00020933333333333334,
      "loss": 0.4387,
      "step": 1550
    },
    {
      "epoch": 3.12,
      "grad_norm": 3.544610023498535,
      "learning_rate": 0.00020872727272727273,
      "loss": 0.3094,
      "step": 1560
    },
    {
      "epoch": 3.14,
      "grad_norm": 2.6739561557769775,
      "learning_rate": 0.0002081212121212121,
      "loss": 0.4062,
      "step": 1570
    },
    {
      "epoch": 3.16,
      "grad_norm": 1.8066452741622925,
      "learning_rate": 0.0002075151515151515,
      "loss": 0.3105,
      "step": 1580
    },
    {
      "epoch": 3.18,
      "grad_norm": 3.4542336463928223,
      "learning_rate": 0.0002069090909090909,
      "loss": 0.4083,
      "step": 1590
    },
    {
      "epoch": 3.2,
      "grad_norm": 3.1189920902252197,
      "learning_rate": 0.0002063030303030303,
      "loss": 0.4273,
      "step": 1600
    },
    {
      "epoch": 3.2,
      "eval_loss": 0.9614207744598389,
      "eval_runtime": 8.2977,
      "eval_samples_per_second": 24.103,
      "eval_steps_per_second": 24.103,
      "step": 1600
    },
    {
      "epoch": 3.22,
      "grad_norm": 1.6059356927871704,
      "learning_rate": 0.00020569696969696967,
      "loss": 0.3596,
      "step": 1610
    },
    {
      "epoch": 3.24,
      "grad_norm": 5.688713550567627,
      "learning_rate": 0.00020509090909090905,
      "loss": 0.2916,
      "step": 1620
    },
    {
      "epoch": 3.26,
      "grad_norm": 1.8617455959320068,
      "learning_rate": 0.00020448484848484846,
      "loss": 0.3177,
      "step": 1630
    },
    {
      "epoch": 3.2800000000000002,
      "grad_norm": 2.9159774780273438,
      "learning_rate": 0.00020387878787878788,
      "loss": 0.4907,
      "step": 1640
    },
    {
      "epoch": 3.3,
      "grad_norm": 1.5392087697982788,
      "learning_rate": 0.00020327272727272726,
      "loss": 0.3933,
      "step": 1650
    },
    {
      "epoch": 3.32,
      "grad_norm": 1.7442266941070557,
      "learning_rate": 0.00020266666666666664,
      "loss": 0.3705,
      "step": 1660
    },
    {
      "epoch": 3.34,
      "grad_norm": 1.6757160425186157,
      "learning_rate": 0.00020206060606060605,
      "loss": 0.2925,
      "step": 1670
    },
    {
      "epoch": 3.36,
      "grad_norm": 4.255112648010254,
      "learning_rate": 0.00020145454545454544,
      "loss": 0.3688,
      "step": 1680
    },
    {
      "epoch": 3.38,
      "grad_norm": 1.9908796548843384,
      "learning_rate": 0.00020084848484848482,
      "loss": 0.4345,
      "step": 1690
    },
    {
      "epoch": 3.4,
      "grad_norm": 2.0418035984039307,
      "learning_rate": 0.0002002424242424242,
      "loss": 0.4034,
      "step": 1700
    },
    {
      "epoch": 3.4,
      "eval_loss": 0.976621150970459,
      "eval_runtime": 8.3031,
      "eval_samples_per_second": 24.087,
      "eval_steps_per_second": 24.087,
      "step": 1700
    },
    {
      "epoch": 3.42,
      "grad_norm": 3.311453104019165,
      "learning_rate": 0.0001996363636363636,
      "loss": 0.4211,
      "step": 1710
    },
    {
      "epoch": 3.44,
      "grad_norm": 2.618415355682373,
      "learning_rate": 0.00019903030303030302,
      "loss": 0.3211,
      "step": 1720
    },
    {
      "epoch": 3.46,
      "grad_norm": 2.068063259124756,
      "learning_rate": 0.0001984242424242424,
      "loss": 0.3858,
      "step": 1730
    },
    {
      "epoch": 3.48,
      "grad_norm": 0.8544336557388306,
      "learning_rate": 0.00019781818181818182,
      "loss": 0.3653,
      "step": 1740
    },
    {
      "epoch": 3.5,
      "grad_norm": 2.3732028007507324,
      "learning_rate": 0.0001972121212121212,
      "loss": 0.3942,
      "step": 1750
    },
    {
      "epoch": 3.52,
      "grad_norm": 4.027651309967041,
      "learning_rate": 0.00019660606060606058,
      "loss": 0.3911,
      "step": 1760
    },
    {
      "epoch": 3.54,
      "grad_norm": 1.8607012033462524,
      "learning_rate": 0.00019599999999999997,
      "loss": 0.2887,
      "step": 1770
    },
    {
      "epoch": 3.56,
      "grad_norm": 1.6103065013885498,
      "learning_rate": 0.00019539393939393938,
      "loss": 0.365,
      "step": 1780
    },
    {
      "epoch": 3.58,
      "grad_norm": 1.9558367729187012,
      "learning_rate": 0.00019478787878787876,
      "loss": 0.2837,
      "step": 1790
    },
    {
      "epoch": 3.6,
      "grad_norm": 3.9317381381988525,
      "learning_rate": 0.00019418181818181814,
      "loss": 0.4122,
      "step": 1800
    },
    {
      "epoch": 3.6,
      "eval_loss": 0.9645704627037048,
      "eval_runtime": 8.2987,
      "eval_samples_per_second": 24.1,
      "eval_steps_per_second": 24.1,
      "step": 1800
    },
    {
      "epoch": 3.62,
      "grad_norm": 2.7209296226501465,
      "learning_rate": 0.00019357575757575758,
      "loss": 0.3945,
      "step": 1810
    },
    {
      "epoch": 3.64,
      "grad_norm": 4.611355781555176,
      "learning_rate": 0.00019296969696969696,
      "loss": 0.4252,
      "step": 1820
    },
    {
      "epoch": 3.66,
      "grad_norm": 2.301093101501465,
      "learning_rate": 0.00019236363636363635,
      "loss": 0.3364,
      "step": 1830
    },
    {
      "epoch": 3.68,
      "grad_norm": 3.734799385070801,
      "learning_rate": 0.00019175757575757573,
      "loss": 0.3429,
      "step": 1840
    },
    {
      "epoch": 3.7,
      "grad_norm": 3.0854833126068115,
      "learning_rate": 0.00019115151515151514,
      "loss": 0.3492,
      "step": 1850
    },
    {
      "epoch": 3.7199999999999998,
      "grad_norm": 1.909977674484253,
      "learning_rate": 0.00019054545454545452,
      "loss": 0.3768,
      "step": 1860
    },
    {
      "epoch": 3.74,
      "grad_norm": 2.3186845779418945,
      "learning_rate": 0.0001899393939393939,
      "loss": 0.4491,
      "step": 1870
    },
    {
      "epoch": 3.76,
      "grad_norm": 2.220297336578369,
      "learning_rate": 0.0001893333333333333,
      "loss": 0.3617,
      "step": 1880
    },
    {
      "epoch": 3.7800000000000002,
      "grad_norm": 2.756587028503418,
      "learning_rate": 0.00018872727272727273,
      "loss": 0.3907,
      "step": 1890
    },
    {
      "epoch": 3.8,
      "grad_norm": 2.1087450981140137,
      "learning_rate": 0.0001881212121212121,
      "loss": 0.439,
      "step": 1900
    },
    {
      "epoch": 3.8,
      "eval_loss": 0.9939900040626526,
      "eval_runtime": 8.3154,
      "eval_samples_per_second": 24.052,
      "eval_steps_per_second": 24.052,
      "step": 1900
    },
    {
      "epoch": 3.82,
      "grad_norm": 3.5514187812805176,
      "learning_rate": 0.0001875151515151515,
      "loss": 0.4321,
      "step": 1910
    },
    {
      "epoch": 3.84,
      "grad_norm": 2.5096099376678467,
      "learning_rate": 0.0001869090909090909,
      "loss": 0.3326,
      "step": 1920
    },
    {
      "epoch": 3.86,
      "grad_norm": 6.205289840698242,
      "learning_rate": 0.0001863030303030303,
      "loss": 0.4006,
      "step": 1930
    },
    {
      "epoch": 3.88,
      "grad_norm": 2.2949881553649902,
      "learning_rate": 0.00018569696969696967,
      "loss": 0.3927,
      "step": 1940
    },
    {
      "epoch": 3.9,
      "grad_norm": 3.014017343521118,
      "learning_rate": 0.00018509090909090906,
      "loss": 0.3899,
      "step": 1950
    },
    {
      "epoch": 3.92,
      "grad_norm": 3.3669703006744385,
      "learning_rate": 0.00018448484848484847,
      "loss": 0.3974,
      "step": 1960
    },
    {
      "epoch": 3.94,
      "grad_norm": 3.700472593307495,
      "learning_rate": 0.00018387878787878785,
      "loss": 0.3636,
      "step": 1970
    },
    {
      "epoch": 3.96,
      "grad_norm": 2.2830493450164795,
      "learning_rate": 0.00018327272727272726,
      "loss": 0.4167,
      "step": 1980
    },
    {
      "epoch": 3.98,
      "grad_norm": 2.4189727306365967,
      "learning_rate": 0.00018266666666666667,
      "loss": 0.321,
      "step": 1990
    },
    {
      "epoch": 4.0,
      "grad_norm": 2.9629228115081787,
      "learning_rate": 0.00018206060606060605,
      "loss": 0.3545,
      "step": 2000
    },
    {
      "epoch": 4.0,
      "eval_loss": 0.9463561773300171,
      "eval_runtime": 8.2891,
      "eval_samples_per_second": 24.128,
      "eval_steps_per_second": 24.128,
      "step": 2000
    },
    {
      "epoch": 4.02,
      "grad_norm": 1.6753743886947632,
      "learning_rate": 0.00018145454545454544,
      "loss": 0.2685,
      "step": 2010
    },
    {
      "epoch": 4.04,
      "grad_norm": 2.667018175125122,
      "learning_rate": 0.00018084848484848482,
      "loss": 0.2779,
      "step": 2020
    },
    {
      "epoch": 4.06,
      "grad_norm": 1.630929946899414,
      "learning_rate": 0.00018024242424242423,
      "loss": 0.2624,
      "step": 2030
    },
    {
      "epoch": 4.08,
      "grad_norm": 2.279188871383667,
      "learning_rate": 0.00017963636363636361,
      "loss": 0.223,
      "step": 2040
    },
    {
      "epoch": 4.1,
      "grad_norm": 3.8420252799987793,
      "learning_rate": 0.000179030303030303,
      "loss": 0.2966,
      "step": 2050
    },
    {
      "epoch": 4.12,
      "grad_norm": 1.9314334392547607,
      "learning_rate": 0.00017842424242424244,
      "loss": 0.2213,
      "step": 2060
    },
    {
      "epoch": 4.14,
      "grad_norm": 2.407994270324707,
      "learning_rate": 0.00017781818181818182,
      "loss": 0.3299,
      "step": 2070
    },
    {
      "epoch": 4.16,
      "grad_norm": 2.1928646564483643,
      "learning_rate": 0.0001772121212121212,
      "loss": 0.2301,
      "step": 2080
    },
    {
      "epoch": 4.18,
      "grad_norm": 2.910639524459839,
      "learning_rate": 0.00017660606060606059,
      "loss": 0.258,
      "step": 2090
    },
    {
      "epoch": 4.2,
      "grad_norm": 4.728976726531982,
      "learning_rate": 0.000176,
      "loss": 0.3598,
      "step": 2100
    },
    {
      "epoch": 4.2,
      "eval_loss": 1.0338951349258423,
      "eval_runtime": 8.3404,
      "eval_samples_per_second": 23.98,
      "eval_steps_per_second": 23.98,
      "step": 2100
    },
    {
      "epoch": 4.22,
      "grad_norm": 3.5330777168273926,
      "learning_rate": 0.00017539393939393938,
      "loss": 0.3171,
      "step": 2110
    },
    {
      "epoch": 4.24,
      "grad_norm": 1.7018871307373047,
      "learning_rate": 0.00017478787878787876,
      "loss": 0.2403,
      "step": 2120
    },
    {
      "epoch": 4.26,
      "grad_norm": 6.157635688781738,
      "learning_rate": 0.00017418181818181815,
      "loss": 0.3225,
      "step": 2130
    },
    {
      "epoch": 4.28,
      "grad_norm": 2.3852577209472656,
      "learning_rate": 0.00017357575757575756,
      "loss": 0.2816,
      "step": 2140
    },
    {
      "epoch": 4.3,
      "grad_norm": 1.5676207542419434,
      "learning_rate": 0.00017296969696969697,
      "loss": 0.2723,
      "step": 2150
    },
    {
      "epoch": 4.32,
      "grad_norm": 2.027982711791992,
      "learning_rate": 0.00017236363636363635,
      "loss": 0.2867,
      "step": 2160
    },
    {
      "epoch": 4.34,
      "grad_norm": 2.1666338443756104,
      "learning_rate": 0.00017175757575757576,
      "loss": 0.3133,
      "step": 2170
    },
    {
      "epoch": 4.36,
      "grad_norm": 1.915571689605713,
      "learning_rate": 0.00017115151515151514,
      "loss": 0.2985,
      "step": 2180
    },
    {
      "epoch": 4.38,
      "grad_norm": 1.980036973953247,
      "learning_rate": 0.00017054545454545453,
      "loss": 0.3039,
      "step": 2190
    },
    {
      "epoch": 4.4,
      "grad_norm": 2.072894811630249,
      "learning_rate": 0.0001699393939393939,
      "loss": 0.3468,
      "step": 2200
    },
    {
      "epoch": 4.4,
      "eval_loss": 1.0086053609848022,
      "eval_runtime": 8.3596,
      "eval_samples_per_second": 23.925,
      "eval_steps_per_second": 23.925,
      "step": 2200
    },
    {
      "epoch": 4.42,
      "grad_norm": 2.3886048793792725,
      "learning_rate": 0.00016933333333333332,
      "loss": 0.333,
      "step": 2210
    },
    {
      "epoch": 4.44,
      "grad_norm": 5.215615272521973,
      "learning_rate": 0.0001687272727272727,
      "loss": 0.2749,
      "step": 2220
    },
    {
      "epoch": 4.46,
      "grad_norm": 6.782882213592529,
      "learning_rate": 0.0001681212121212121,
      "loss": 0.2725,
      "step": 2230
    },
    {
      "epoch": 4.48,
      "grad_norm": 3.1977055072784424,
      "learning_rate": 0.00016751515151515152,
      "loss": 0.2911,
      "step": 2240
    },
    {
      "epoch": 4.5,
      "grad_norm": 6.099739074707031,
      "learning_rate": 0.0001669090909090909,
      "loss": 0.2756,
      "step": 2250
    },
    {
      "epoch": 4.52,
      "grad_norm": 1.3752182722091675,
      "learning_rate": 0.0001663030303030303,
      "loss": 0.3374,
      "step": 2260
    },
    {
      "epoch": 4.54,
      "grad_norm": 2.174396514892578,
      "learning_rate": 0.00016569696969696967,
      "loss": 0.2826,
      "step": 2270
    },
    {
      "epoch": 4.5600000000000005,
      "grad_norm": 1.5874853134155273,
      "learning_rate": 0.00016509090909090908,
      "loss": 0.2606,
      "step": 2280
    },
    {
      "epoch": 4.58,
      "grad_norm": 2.9032840728759766,
      "learning_rate": 0.00016448484848484847,
      "loss": 0.3373,
      "step": 2290
    },
    {
      "epoch": 4.6,
      "grad_norm": 3.1759753227233887,
      "learning_rate": 0.00016387878787878785,
      "loss": 0.2923,
      "step": 2300
    },
    {
      "epoch": 4.6,
      "eval_loss": 1.0317167043685913,
      "eval_runtime": 8.3807,
      "eval_samples_per_second": 23.864,
      "eval_steps_per_second": 23.864,
      "step": 2300
    },
    {
      "epoch": 4.62,
      "grad_norm": 4.0349860191345215,
      "learning_rate": 0.00016327272727272723,
      "loss": 0.3336,
      "step": 2310
    },
    {
      "epoch": 4.64,
      "grad_norm": 2.3992364406585693,
      "learning_rate": 0.00016266666666666667,
      "loss": 0.2945,
      "step": 2320
    },
    {
      "epoch": 4.66,
      "grad_norm": 1.9158473014831543,
      "learning_rate": 0.00016206060606060606,
      "loss": 0.2793,
      "step": 2330
    },
    {
      "epoch": 4.68,
      "grad_norm": 5.039926052093506,
      "learning_rate": 0.00016145454545454544,
      "loss": 0.3146,
      "step": 2340
    },
    {
      "epoch": 4.7,
      "grad_norm": 2.736388683319092,
      "learning_rate": 0.00016084848484848485,
      "loss": 0.2511,
      "step": 2350
    },
    {
      "epoch": 4.72,
      "grad_norm": 2.8868625164031982,
      "learning_rate": 0.00016024242424242423,
      "loss": 0.2847,
      "step": 2360
    },
    {
      "epoch": 4.74,
      "grad_norm": 2.141356945037842,
      "learning_rate": 0.00015963636363636362,
      "loss": 0.3649,
      "step": 2370
    },
    {
      "epoch": 4.76,
      "grad_norm": 4.458664417266846,
      "learning_rate": 0.000159030303030303,
      "loss": 0.3291,
      "step": 2380
    },
    {
      "epoch": 4.78,
      "grad_norm": 3.1775457859039307,
      "learning_rate": 0.0001584242424242424,
      "loss": 0.3087,
      "step": 2390
    },
    {
      "epoch": 4.8,
      "grad_norm": 0.7821369171142578,
      "learning_rate": 0.0001578181818181818,
      "loss": 0.2143,
      "step": 2400
    },
    {
      "epoch": 4.8,
      "eval_loss": 1.0130046606063843,
      "eval_runtime": 8.3847,
      "eval_samples_per_second": 23.853,
      "eval_steps_per_second": 23.853,
      "step": 2400
    },
    {
      "epoch": 4.82,
      "grad_norm": 2.616387128829956,
      "learning_rate": 0.0001572121212121212,
      "loss": 0.3274,
      "step": 2410
    },
    {
      "epoch": 4.84,
      "grad_norm": 2.228691577911377,
      "learning_rate": 0.00015660606060606061,
      "loss": 0.2954,
      "step": 2420
    },
    {
      "epoch": 4.86,
      "grad_norm": 4.789204120635986,
      "learning_rate": 0.000156,
      "loss": 0.333,
      "step": 2430
    },
    {
      "epoch": 4.88,
      "grad_norm": 3.515901565551758,
      "learning_rate": 0.00015539393939393938,
      "loss": 0.3013,
      "step": 2440
    },
    {
      "epoch": 4.9,
      "grad_norm": 2.4155495166778564,
      "learning_rate": 0.00015478787878787876,
      "loss": 0.3434,
      "step": 2450
    },
    {
      "epoch": 4.92,
      "grad_norm": 2.788285493850708,
      "learning_rate": 0.00015418181818181817,
      "loss": 0.2789,
      "step": 2460
    },
    {
      "epoch": 4.9399999999999995,
      "grad_norm": 2.1496262550354004,
      "learning_rate": 0.00015357575757575756,
      "loss": 0.3311,
      "step": 2470
    },
    {
      "epoch": 4.96,
      "grad_norm": 1.2214279174804688,
      "learning_rate": 0.00015296969696969694,
      "loss": 0.2903,
      "step": 2480
    },
    {
      "epoch": 4.98,
      "grad_norm": 1.1620092391967773,
      "learning_rate": 0.00015236363636363638,
      "loss": 0.2984,
      "step": 2490
    },
    {
      "epoch": 5.0,
      "grad_norm": 5.432713031768799,
      "learning_rate": 0.00015175757575757576,
      "loss": 0.281,
      "step": 2500
    },
    {
      "epoch": 5.0,
      "eval_loss": 1.0590144395828247,
      "eval_runtime": 8.3986,
      "eval_samples_per_second": 23.814,
      "eval_steps_per_second": 23.814,
      "step": 2500
    },
    {
      "epoch": 5.02,
      "grad_norm": 2.330104351043701,
      "learning_rate": 0.00015115151515151515,
      "loss": 0.256,
      "step": 2510
    },
    {
      "epoch": 5.04,
      "grad_norm": 2.4061403274536133,
      "learning_rate": 0.00015054545454545453,
      "loss": 0.2208,
      "step": 2520
    },
    {
      "epoch": 5.06,
      "grad_norm": 1.8475598096847534,
      "learning_rate": 0.00014993939393939394,
      "loss": 0.1669,
      "step": 2530
    },
    {
      "epoch": 5.08,
      "grad_norm": 0.9123973846435547,
      "learning_rate": 0.00014933333333333332,
      "loss": 0.2488,
      "step": 2540
    },
    {
      "epoch": 5.1,
      "grad_norm": 1.3702212572097778,
      "learning_rate": 0.0001487272727272727,
      "loss": 0.1998,
      "step": 2550
    },
    {
      "epoch": 5.12,
      "grad_norm": 1.3315858840942383,
      "learning_rate": 0.00014812121212121212,
      "loss": 0.2539,
      "step": 2560
    },
    {
      "epoch": 5.14,
      "grad_norm": 1.619918704032898,
      "learning_rate": 0.0001475151515151515,
      "loss": 0.2408,
      "step": 2570
    },
    {
      "epoch": 5.16,
      "grad_norm": 2.3862133026123047,
      "learning_rate": 0.00014690909090909088,
      "loss": 0.2071,
      "step": 2580
    },
    {
      "epoch": 5.18,
      "grad_norm": 3.9085869789123535,
      "learning_rate": 0.0001463030303030303,
      "loss": 0.2174,
      "step": 2590
    },
    {
      "epoch": 5.2,
      "grad_norm": 1.1890370845794678,
      "learning_rate": 0.0001456969696969697,
      "loss": 0.2558,
      "step": 2600
    },
    {
      "epoch": 5.2,
      "eval_loss": 1.146665334701538,
      "eval_runtime": 8.3957,
      "eval_samples_per_second": 23.822,
      "eval_steps_per_second": 23.822,
      "step": 2600
    },
    {
      "epoch": 5.22,
      "grad_norm": 5.432294845581055,
      "learning_rate": 0.0001450909090909091,
      "loss": 0.2161,
      "step": 2610
    },
    {
      "epoch": 5.24,
      "grad_norm": 2.647406816482544,
      "learning_rate": 0.00014448484848484847,
      "loss": 0.2796,
      "step": 2620
    },
    {
      "epoch": 5.26,
      "grad_norm": 2.0752336978912354,
      "learning_rate": 0.00014387878787878785,
      "loss": 0.2195,
      "step": 2630
    },
    {
      "epoch": 5.28,
      "grad_norm": 1.8608264923095703,
      "learning_rate": 0.00014327272727272726,
      "loss": 0.2491,
      "step": 2640
    },
    {
      "epoch": 5.3,
      "grad_norm": 2.379094362258911,
      "learning_rate": 0.00014266666666666665,
      "loss": 0.2738,
      "step": 2650
    },
    {
      "epoch": 5.32,
      "grad_norm": 1.8542771339416504,
      "learning_rate": 0.00014206060606060606,
      "loss": 0.2234,
      "step": 2660
    },
    {
      "epoch": 5.34,
      "grad_norm": 2.0296294689178467,
      "learning_rate": 0.00014145454545454544,
      "loss": 0.2154,
      "step": 2670
    },
    {
      "epoch": 5.36,
      "grad_norm": 6.162708759307861,
      "learning_rate": 0.00014084848484848485,
      "loss": 0.2267,
      "step": 2680
    },
    {
      "epoch": 5.38,
      "grad_norm": 2.2582929134368896,
      "learning_rate": 0.00014024242424242423,
      "loss": 0.2439,
      "step": 2690
    },
    {
      "epoch": 5.4,
      "grad_norm": 0.8291829228401184,
      "learning_rate": 0.00013963636363636362,
      "loss": 0.2279,
      "step": 2700
    },
    {
      "epoch": 5.4,
      "eval_loss": 1.0980550050735474,
      "eval_runtime": 8.3896,
      "eval_samples_per_second": 23.839,
      "eval_steps_per_second": 23.839,
      "step": 2700
    },
    {
      "epoch": 5.42,
      "grad_norm": 2.600799083709717,
      "learning_rate": 0.000139030303030303,
      "loss": 0.2593,
      "step": 2710
    },
    {
      "epoch": 5.44,
      "grad_norm": 1.252718210220337,
      "learning_rate": 0.0001384242424242424,
      "loss": 0.2457,
      "step": 2720
    },
    {
      "epoch": 5.46,
      "grad_norm": 6.238326549530029,
      "learning_rate": 0.00013781818181818182,
      "loss": 0.2157,
      "step": 2730
    },
    {
      "epoch": 5.48,
      "grad_norm": 2.096330165863037,
      "learning_rate": 0.0001372121212121212,
      "loss": 0.2588,
      "step": 2740
    },
    {
      "epoch": 5.5,
      "grad_norm": 2.6737191677093506,
      "learning_rate": 0.0001366060606060606,
      "loss": 0.2285,
      "step": 2750
    },
    {
      "epoch": 5.52,
      "grad_norm": 1.0459976196289062,
      "learning_rate": 0.00013599999999999997,
      "loss": 0.2165,
      "step": 2760
    },
    {
      "epoch": 5.54,
      "grad_norm": 4.279753684997559,
      "learning_rate": 0.00013539393939393938,
      "loss": 0.2487,
      "step": 2770
    },
    {
      "epoch": 5.5600000000000005,
      "grad_norm": 2.5004022121429443,
      "learning_rate": 0.00013478787878787877,
      "loss": 0.2117,
      "step": 2780
    },
    {
      "epoch": 5.58,
      "grad_norm": 2.07493257522583,
      "learning_rate": 0.00013418181818181818,
      "loss": 0.2722,
      "step": 2790
    },
    {
      "epoch": 5.6,
      "grad_norm": 1.9409266710281372,
      "learning_rate": 0.00013357575757575756,
      "loss": 0.2293,
      "step": 2800
    },
    {
      "epoch": 5.6,
      "eval_loss": 1.0476908683776855,
      "eval_runtime": 8.3712,
      "eval_samples_per_second": 23.891,
      "eval_steps_per_second": 23.891,
      "step": 2800
    },
    {
      "epoch": 5.62,
      "grad_norm": 2.3300154209136963,
      "learning_rate": 0.00013296969696969697,
      "loss": 0.2428,
      "step": 2810
    },
    {
      "epoch": 5.64,
      "grad_norm": 2.64188551902771,
      "learning_rate": 0.00013236363636363635,
      "loss": 0.2306,
      "step": 2820
    },
    {
      "epoch": 5.66,
      "grad_norm": 1.9876747131347656,
      "learning_rate": 0.00013175757575757574,
      "loss": 0.2257,
      "step": 2830
    },
    {
      "epoch": 5.68,
      "grad_norm": 4.4187164306640625,
      "learning_rate": 0.00013115151515151515,
      "loss": 0.2385,
      "step": 2840
    },
    {
      "epoch": 5.7,
      "grad_norm": 1.7727277278900146,
      "learning_rate": 0.00013054545454545453,
      "loss": 0.2253,
      "step": 2850
    },
    {
      "epoch": 5.72,
      "grad_norm": 1.0975592136383057,
      "learning_rate": 0.00012993939393939394,
      "loss": 0.2599,
      "step": 2860
    },
    {
      "epoch": 5.74,
      "grad_norm": 2.1874449253082275,
      "learning_rate": 0.00012933333333333332,
      "loss": 0.2882,
      "step": 2870
    },
    {
      "epoch": 5.76,
      "grad_norm": 3.5751144886016846,
      "learning_rate": 0.0001287272727272727,
      "loss": 0.2384,
      "step": 2880
    },
    {
      "epoch": 5.78,
      "grad_norm": 1.1261624097824097,
      "learning_rate": 0.0001281212121212121,
      "loss": 0.2502,
      "step": 2890
    },
    {
      "epoch": 5.8,
      "grad_norm": 1.5940619707107544,
      "learning_rate": 0.0001275151515151515,
      "loss": 0.2323,
      "step": 2900
    },
    {
      "epoch": 5.8,
      "eval_loss": 1.1028683185577393,
      "eval_runtime": 8.3482,
      "eval_samples_per_second": 23.957,
      "eval_steps_per_second": 23.957,
      "step": 2900
    },
    {
      "epoch": 5.82,
      "grad_norm": 2.1706459522247314,
      "learning_rate": 0.0001269090909090909,
      "loss": 0.2364,
      "step": 2910
    },
    {
      "epoch": 5.84,
      "grad_norm": 2.269864559173584,
      "learning_rate": 0.0001263030303030303,
      "loss": 0.2898,
      "step": 2920
    },
    {
      "epoch": 5.86,
      "grad_norm": 1.05785071849823,
      "learning_rate": 0.00012569696969696968,
      "loss": 0.2638,
      "step": 2930
    },
    {
      "epoch": 5.88,
      "grad_norm": 2.2841217517852783,
      "learning_rate": 0.0001250909090909091,
      "loss": 0.279,
      "step": 2940
    },
    {
      "epoch": 5.9,
      "grad_norm": 1.5660936832427979,
      "learning_rate": 0.00012448484848484847,
      "loss": 0.249,
      "step": 2950
    },
    {
      "epoch": 5.92,
      "grad_norm": 2.6701557636260986,
      "learning_rate": 0.00012387878787878785,
      "loss": 0.2872,
      "step": 2960
    },
    {
      "epoch": 5.9399999999999995,
      "grad_norm": 2.1248202323913574,
      "learning_rate": 0.00012327272727272727,
      "loss": 0.2557,
      "step": 2970
    },
    {
      "epoch": 5.96,
      "grad_norm": 3.169881820678711,
      "learning_rate": 0.00012266666666666668,
      "loss": 0.2758,
      "step": 2980
    },
    {
      "epoch": 5.98,
      "grad_norm": 1.3323272466659546,
      "learning_rate": 0.00012206060606060606,
      "loss": 0.2508,
      "step": 2990
    },
    {
      "epoch": 6.0,
      "grad_norm": 1.0211684703826904,
      "learning_rate": 0.00012145454545454544,
      "loss": 0.2439,
      "step": 3000
    },
    {
      "epoch": 6.0,
      "eval_loss": 1.0639536380767822,
      "eval_runtime": 8.4006,
      "eval_samples_per_second": 23.808,
      "eval_steps_per_second": 23.808,
      "step": 3000
    },
    {
      "epoch": 6.02,
      "grad_norm": 1.3321963548660278,
      "learning_rate": 0.00012084848484848484,
      "loss": 0.1892,
      "step": 3010
    },
    {
      "epoch": 6.04,
      "grad_norm": 1.6954307556152344,
      "learning_rate": 0.00012024242424242424,
      "loss": 0.1839,
      "step": 3020
    },
    {
      "epoch": 6.06,
      "grad_norm": 1.821722388267517,
      "learning_rate": 0.00011963636363636363,
      "loss": 0.1781,
      "step": 3030
    },
    {
      "epoch": 6.08,
      "grad_norm": 2.1345443725585938,
      "learning_rate": 0.00011903030303030302,
      "loss": 0.2099,
      "step": 3040
    },
    {
      "epoch": 6.1,
      "grad_norm": 3.3175106048583984,
      "learning_rate": 0.00011842424242424241,
      "loss": 0.2164,
      "step": 3050
    },
    {
      "epoch": 6.12,
      "grad_norm": 1.710340976715088,
      "learning_rate": 0.0001178181818181818,
      "loss": 0.1855,
      "step": 3060
    },
    {
      "epoch": 6.14,
      "grad_norm": 2.0768706798553467,
      "learning_rate": 0.00011721212121212121,
      "loss": 0.2003,
      "step": 3070
    },
    {
      "epoch": 6.16,
      "grad_norm": 2.324995994567871,
      "learning_rate": 0.0001166060606060606,
      "loss": 0.1502,
      "step": 3080
    },
    {
      "epoch": 6.18,
      "grad_norm": 3.2927300930023193,
      "learning_rate": 0.00011599999999999999,
      "loss": 0.184,
      "step": 3090
    },
    {
      "epoch": 6.2,
      "grad_norm": 3.2333436012268066,
      "learning_rate": 0.00011539393939393938,
      "loss": 0.2127,
      "step": 3100
    },
    {
      "epoch": 6.2,
      "eval_loss": 1.1828060150146484,
      "eval_runtime": 8.3516,
      "eval_samples_per_second": 23.948,
      "eval_steps_per_second": 23.948,
      "step": 3100
    },
    {
      "epoch": 6.22,
      "grad_norm": 9.14782428741455,
      "learning_rate": 0.00011478787878787878,
      "loss": 0.1835,
      "step": 3110
    },
    {
      "epoch": 6.24,
      "grad_norm": 1.1954808235168457,
      "learning_rate": 0.00011418181818181818,
      "loss": 0.1871,
      "step": 3120
    },
    {
      "epoch": 6.26,
      "grad_norm": 3.560466766357422,
      "learning_rate": 0.00011357575757575756,
      "loss": 0.2208,
      "step": 3130
    },
    {
      "epoch": 6.28,
      "grad_norm": 1.8564929962158203,
      "learning_rate": 0.00011296969696969696,
      "loss": 0.2123,
      "step": 3140
    },
    {
      "epoch": 6.3,
      "grad_norm": 4.77338171005249,
      "learning_rate": 0.00011236363636363635,
      "loss": 0.194,
      "step": 3150
    },
    {
      "epoch": 6.32,
      "grad_norm": 1.1412395238876343,
      "learning_rate": 0.00011175757575757575,
      "loss": 0.1762,
      "step": 3160
    },
    {
      "epoch": 6.34,
      "grad_norm": 2.356454372406006,
      "learning_rate": 0.00011115151515151513,
      "loss": 0.1685,
      "step": 3170
    },
    {
      "epoch": 6.36,
      "grad_norm": 2.7073357105255127,
      "learning_rate": 0.00011054545454545453,
      "loss": 0.2311,
      "step": 3180
    },
    {
      "epoch": 6.38,
      "grad_norm": 3.3719279766082764,
      "learning_rate": 0.00010993939393939392,
      "loss": 0.2084,
      "step": 3190
    },
    {
      "epoch": 6.4,
      "grad_norm": 1.794634222984314,
      "learning_rate": 0.00010933333333333333,
      "loss": 0.2235,
      "step": 3200
    },
    {
      "epoch": 6.4,
      "eval_loss": 1.1284642219543457,
      "eval_runtime": 8.315,
      "eval_samples_per_second": 24.053,
      "eval_steps_per_second": 24.053,
      "step": 3200
    },
    {
      "epoch": 6.42,
      "grad_norm": 2.3983702659606934,
      "learning_rate": 0.00010872727272727272,
      "loss": 0.1918,
      "step": 3210
    },
    {
      "epoch": 6.44,
      "grad_norm": 2.636401891708374,
      "learning_rate": 0.0001081212121212121,
      "loss": 0.2181,
      "step": 3220
    },
    {
      "epoch": 6.46,
      "grad_norm": 3.1018600463867188,
      "learning_rate": 0.0001075151515151515,
      "loss": 0.2485,
      "step": 3230
    },
    {
      "epoch": 6.48,
      "grad_norm": 2.5504884719848633,
      "learning_rate": 0.0001069090909090909,
      "loss": 0.2704,
      "step": 3240
    },
    {
      "epoch": 6.5,
      "grad_norm": 6.9784159660339355,
      "learning_rate": 0.0001063030303030303,
      "loss": 0.2322,
      "step": 3250
    },
    {
      "epoch": 6.52,
      "grad_norm": 0.7671191096305847,
      "learning_rate": 0.00010569696969696968,
      "loss": 0.1753,
      "step": 3260
    },
    {
      "epoch": 6.54,
      "grad_norm": 2.858339786529541,
      "learning_rate": 0.00010509090909090908,
      "loss": 0.1892,
      "step": 3270
    },
    {
      "epoch": 6.5600000000000005,
      "grad_norm": 1.5073819160461426,
      "learning_rate": 0.00010448484848484849,
      "loss": 0.2057,
      "step": 3280
    },
    {
      "epoch": 6.58,
      "grad_norm": 1.9896219968795776,
      "learning_rate": 0.00010387878787878787,
      "loss": 0.2066,
      "step": 3290
    },
    {
      "epoch": 6.6,
      "grad_norm": 2.868398904800415,
      "learning_rate": 0.00010327272727272727,
      "loss": 0.2185,
      "step": 3300
    },
    {
      "epoch": 6.6,
      "eval_loss": 1.1652499437332153,
      "eval_runtime": 8.3805,
      "eval_samples_per_second": 23.865,
      "eval_steps_per_second": 23.865,
      "step": 3300
    },
    {
      "epoch": 6.62,
      "grad_norm": 2.935107707977295,
      "learning_rate": 0.00010266666666666665,
      "loss": 0.206,
      "step": 3310
    },
    {
      "epoch": 6.64,
      "grad_norm": 1.7722649574279785,
      "learning_rate": 0.00010206060606060606,
      "loss": 0.2013,
      "step": 3320
    },
    {
      "epoch": 6.66,
      "grad_norm": 1.7540534734725952,
      "learning_rate": 0.00010145454545454544,
      "loss": 0.2032,
      "step": 3330
    },
    {
      "epoch": 6.68,
      "grad_norm": 1.6265273094177246,
      "learning_rate": 0.00010084848484848484,
      "loss": 0.1987,
      "step": 3340
    },
    {
      "epoch": 6.7,
      "grad_norm": 0.9076045155525208,
      "learning_rate": 0.00010024242424242422,
      "loss": 0.2047,
      "step": 3350
    },
    {
      "epoch": 6.72,
      "grad_norm": 2.6245648860931396,
      "learning_rate": 9.963636363636362e-05,
      "loss": 0.1901,
      "step": 3360
    },
    {
      "epoch": 6.74,
      "grad_norm": 2.02642560005188,
      "learning_rate": 9.903030303030303e-05,
      "loss": 0.2083,
      "step": 3370
    },
    {
      "epoch": 6.76,
      "grad_norm": 2.6882495880126953,
      "learning_rate": 9.842424242424241e-05,
      "loss": 0.2484,
      "step": 3380
    },
    {
      "epoch": 6.78,
      "grad_norm": 1.6534615755081177,
      "learning_rate": 9.781818181818181e-05,
      "loss": 0.2164,
      "step": 3390
    },
    {
      "epoch": 6.8,
      "grad_norm": 2.744581460952759,
      "learning_rate": 9.72121212121212e-05,
      "loss": 0.2294,
      "step": 3400
    },
    {
      "epoch": 6.8,
      "eval_loss": 1.1486505270004272,
      "eval_runtime": 8.2743,
      "eval_samples_per_second": 24.171,
      "eval_steps_per_second": 24.171,
      "step": 3400
    },
    {
      "epoch": 6.82,
      "grad_norm": 3.4266088008880615,
      "learning_rate": 9.66060606060606e-05,
      "loss": 0.1968,
      "step": 3410
    },
    {
      "epoch": 6.84,
      "grad_norm": 3.124720811843872,
      "learning_rate": 9.599999999999999e-05,
      "loss": 0.2125,
      "step": 3420
    },
    {
      "epoch": 6.86,
      "grad_norm": 1.4206254482269287,
      "learning_rate": 9.539393939393939e-05,
      "loss": 0.2357,
      "step": 3430
    },
    {
      "epoch": 6.88,
      "grad_norm": 1.3186357021331787,
      "learning_rate": 9.478787878787877e-05,
      "loss": 0.1946,
      "step": 3440
    },
    {
      "epoch": 6.9,
      "grad_norm": 2.8148550987243652,
      "learning_rate": 9.418181818181818e-05,
      "loss": 0.2354,
      "step": 3450
    },
    {
      "epoch": 6.92,
      "grad_norm": 2.87355375289917,
      "learning_rate": 9.357575757575758e-05,
      "loss": 0.2119,
      "step": 3460
    },
    {
      "epoch": 6.9399999999999995,
      "grad_norm": 1.4761364459991455,
      "learning_rate": 9.296969696969696e-05,
      "loss": 0.211,
      "step": 3470
    },
    {
      "epoch": 6.96,
      "grad_norm": 1.5980535745620728,
      "learning_rate": 9.236363636363636e-05,
      "loss": 0.2004,
      "step": 3480
    },
    {
      "epoch": 6.98,
      "grad_norm": 4.51729679107666,
      "learning_rate": 9.175757575757575e-05,
      "loss": 0.219,
      "step": 3490
    },
    {
      "epoch": 7.0,
      "grad_norm": 1.1810970306396484,
      "learning_rate": 9.115151515151515e-05,
      "loss": 0.1841,
      "step": 3500
    },
    {
      "epoch": 7.0,
      "eval_loss": 1.1809214353561401,
      "eval_runtime": 8.3616,
      "eval_samples_per_second": 23.919,
      "eval_steps_per_second": 23.919,
      "step": 3500
    },
    {
      "epoch": 7.02,
      "grad_norm": 1.3160094022750854,
      "learning_rate": 9.054545454545453e-05,
      "loss": 0.1504,
      "step": 3510
    },
    {
      "epoch": 7.04,
      "grad_norm": 1.042719841003418,
      "learning_rate": 8.993939393939393e-05,
      "loss": 0.1407,
      "step": 3520
    },
    {
      "epoch": 7.06,
      "grad_norm": 1.028834581375122,
      "learning_rate": 8.933333333333331e-05,
      "loss": 0.1614,
      "step": 3530
    },
    {
      "epoch": 7.08,
      "grad_norm": 2.8503940105438232,
      "learning_rate": 8.872727272727272e-05,
      "loss": 0.1655,
      "step": 3540
    },
    {
      "epoch": 7.1,
      "grad_norm": 1.7404351234436035,
      "learning_rate": 8.812121212121212e-05,
      "loss": 0.1655,
      "step": 3550
    },
    {
      "epoch": 7.12,
      "grad_norm": 2.0087270736694336,
      "learning_rate": 8.75151515151515e-05,
      "loss": 0.1618,
      "step": 3560
    },
    {
      "epoch": 7.14,
      "grad_norm": 1.746517539024353,
      "learning_rate": 8.69090909090909e-05,
      "loss": 0.1654,
      "step": 3570
    },
    {
      "epoch": 7.16,
      "grad_norm": 2.23830509185791,
      "learning_rate": 8.63030303030303e-05,
      "loss": 0.1803,
      "step": 3580
    },
    {
      "epoch": 7.18,
      "grad_norm": 1.2267729043960571,
      "learning_rate": 8.56969696969697e-05,
      "loss": 0.1608,
      "step": 3590
    },
    {
      "epoch": 7.2,
      "grad_norm": 6.806366920471191,
      "learning_rate": 8.509090909090908e-05,
      "loss": 0.172,
      "step": 3600
    },
    {
      "epoch": 7.2,
      "eval_loss": 1.2341959476470947,
      "eval_runtime": 8.3374,
      "eval_samples_per_second": 23.988,
      "eval_steps_per_second": 23.988,
      "step": 3600
    },
    {
      "epoch": 7.22,
      "grad_norm": 1.0968772172927856,
      "learning_rate": 8.448484848484848e-05,
      "loss": 0.1964,
      "step": 3610
    },
    {
      "epoch": 7.24,
      "grad_norm": 0.9994886517524719,
      "learning_rate": 8.387878787878787e-05,
      "loss": 0.1681,
      "step": 3620
    },
    {
      "epoch": 7.26,
      "grad_norm": 2.043701648712158,
      "learning_rate": 8.327272727272727e-05,
      "loss": 0.1689,
      "step": 3630
    },
    {
      "epoch": 7.28,
      "grad_norm": 1.4198709726333618,
      "learning_rate": 8.266666666666665e-05,
      "loss": 0.1844,
      "step": 3640
    },
    {
      "epoch": 7.3,
      "grad_norm": 1.1212759017944336,
      "learning_rate": 8.206060606060605e-05,
      "loss": 0.1719,
      "step": 3650
    },
    {
      "epoch": 7.32,
      "grad_norm": 1.5103098154067993,
      "learning_rate": 8.145454545454546e-05,
      "loss": 0.1681,
      "step": 3660
    },
    {
      "epoch": 7.34,
      "grad_norm": 1.2925132513046265,
      "learning_rate": 8.084848484848484e-05,
      "loss": 0.1727,
      "step": 3670
    },
    {
      "epoch": 7.36,
      "grad_norm": 1.806132197380066,
      "learning_rate": 8.024242424242424e-05,
      "loss": 0.1767,
      "step": 3680
    },
    {
      "epoch": 7.38,
      "grad_norm": 3.4713752269744873,
      "learning_rate": 7.963636363636362e-05,
      "loss": 0.1592,
      "step": 3690
    },
    {
      "epoch": 7.4,
      "grad_norm": 1.2632886171340942,
      "learning_rate": 7.903030303030302e-05,
      "loss": 0.1502,
      "step": 3700
    },
    {
      "epoch": 7.4,
      "eval_loss": 1.2136404514312744,
      "eval_runtime": 8.3138,
      "eval_samples_per_second": 24.056,
      "eval_steps_per_second": 24.056,
      "step": 3700
    },
    {
      "epoch": 7.42,
      "grad_norm": 4.18938684463501,
      "learning_rate": 7.842424242424242e-05,
      "loss": 0.2057,
      "step": 3710
    },
    {
      "epoch": 7.44,
      "grad_norm": 1.369813084602356,
      "learning_rate": 7.781818181818181e-05,
      "loss": 0.1581,
      "step": 3720
    },
    {
      "epoch": 7.46,
      "grad_norm": 1.4910081624984741,
      "learning_rate": 7.72121212121212e-05,
      "loss": 0.1878,
      "step": 3730
    },
    {
      "epoch": 7.48,
      "grad_norm": 0.7919020056724548,
      "learning_rate": 7.66060606060606e-05,
      "loss": 0.1792,
      "step": 3740
    },
    {
      "epoch": 7.5,
      "grad_norm": 2.234137773513794,
      "learning_rate": 7.6e-05,
      "loss": 0.1924,
      "step": 3750
    },
    {
      "epoch": 7.52,
      "grad_norm": 5.491089820861816,
      "learning_rate": 7.539393939393939e-05,
      "loss": 0.1728,
      "step": 3760
    },
    {
      "epoch": 7.54,
      "grad_norm": 2.654283046722412,
      "learning_rate": 7.478787878787878e-05,
      "loss": 0.187,
      "step": 3770
    },
    {
      "epoch": 7.5600000000000005,
      "grad_norm": 2.5118234157562256,
      "learning_rate": 7.418181818181818e-05,
      "loss": 0.1704,
      "step": 3780
    },
    {
      "epoch": 7.58,
      "grad_norm": 1.586327314376831,
      "learning_rate": 7.357575757575756e-05,
      "loss": 0.1808,
      "step": 3790
    },
    {
      "epoch": 7.6,
      "grad_norm": 1.2131569385528564,
      "learning_rate": 7.296969696969696e-05,
      "loss": 0.1899,
      "step": 3800
    },
    {
      "epoch": 7.6,
      "eval_loss": 1.232593059539795,
      "eval_runtime": 8.3213,
      "eval_samples_per_second": 24.035,
      "eval_steps_per_second": 24.035,
      "step": 3800
    },
    {
      "epoch": 7.62,
      "grad_norm": 1.4199836254119873,
      "learning_rate": 7.236363636363636e-05,
      "loss": 0.1994,
      "step": 3810
    },
    {
      "epoch": 7.64,
      "grad_norm": 3.0432395935058594,
      "learning_rate": 7.175757575757576e-05,
      "loss": 0.1824,
      "step": 3820
    },
    {
      "epoch": 7.66,
      "grad_norm": 2.841797351837158,
      "learning_rate": 7.115151515151515e-05,
      "loss": 0.1973,
      "step": 3830
    },
    {
      "epoch": 7.68,
      "grad_norm": 2.3984010219573975,
      "learning_rate": 7.054545454545454e-05,
      "loss": 0.1829,
      "step": 3840
    },
    {
      "epoch": 7.7,
      "grad_norm": 2.3416969776153564,
      "learning_rate": 7e-05,
      "loss": 0.1856,
      "step": 3850
    },
    {
      "epoch": 7.72,
      "grad_norm": 1.5078753232955933,
      "learning_rate": 6.939393939393939e-05,
      "loss": 0.1817,
      "step": 3860
    },
    {
      "epoch": 7.74,
      "grad_norm": 1.2536609172821045,
      "learning_rate": 6.878787878787879e-05,
      "loss": 0.1758,
      "step": 3870
    },
    {
      "epoch": 7.76,
      "grad_norm": 1.22177255153656,
      "learning_rate": 6.818181818181817e-05,
      "loss": 0.1847,
      "step": 3880
    },
    {
      "epoch": 7.78,
      "grad_norm": 2.6992945671081543,
      "learning_rate": 6.757575757575757e-05,
      "loss": 0.1766,
      "step": 3890
    },
    {
      "epoch": 7.8,
      "grad_norm": 1.7207938432693481,
      "learning_rate": 6.696969696969696e-05,
      "loss": 0.1869,
      "step": 3900
    },
    {
      "epoch": 7.8,
      "eval_loss": 1.2058032751083374,
      "eval_runtime": 8.3297,
      "eval_samples_per_second": 24.01,
      "eval_steps_per_second": 24.01,
      "step": 3900
    },
    {
      "epoch": 7.82,
      "grad_norm": 1.7772279977798462,
      "learning_rate": 6.636363636363636e-05,
      "loss": 0.1795,
      "step": 3910
    },
    {
      "epoch": 7.84,
      "grad_norm": 1.2042524814605713,
      "learning_rate": 6.575757575757574e-05,
      "loss": 0.1904,
      "step": 3920
    },
    {
      "epoch": 7.86,
      "grad_norm": 1.9548753499984741,
      "learning_rate": 6.515151515151516e-05,
      "loss": 0.1605,
      "step": 3930
    },
    {
      "epoch": 7.88,
      "grad_norm": 1.414753794670105,
      "learning_rate": 6.454545454545454e-05,
      "loss": 0.1737,
      "step": 3940
    },
    {
      "epoch": 7.9,
      "grad_norm": 0.48476409912109375,
      "learning_rate": 6.393939393939394e-05,
      "loss": 0.1816,
      "step": 3950
    },
    {
      "epoch": 7.92,
      "grad_norm": 0.8082965612411499,
      "learning_rate": 6.333333333333333e-05,
      "loss": 0.1681,
      "step": 3960
    },
    {
      "epoch": 7.9399999999999995,
      "grad_norm": 2.4591124057769775,
      "learning_rate": 6.272727272727272e-05,
      "loss": 0.173,
      "step": 3970
    },
    {
      "epoch": 7.96,
      "grad_norm": 1.800615906715393,
      "learning_rate": 6.212121212121211e-05,
      "loss": 0.1906,
      "step": 3980
    },
    {
      "epoch": 7.98,
      "grad_norm": 1.4592552185058594,
      "learning_rate": 6.151515151515151e-05,
      "loss": 0.1749,
      "step": 3990
    },
    {
      "epoch": 8.0,
      "grad_norm": 2.0445303916931152,
      "learning_rate": 6.0909090909090906e-05,
      "loss": 0.2205,
      "step": 4000
    },
    {
      "epoch": 8.0,
      "eval_loss": 1.2063608169555664,
      "eval_runtime": 8.3126,
      "eval_samples_per_second": 24.06,
      "eval_steps_per_second": 24.06,
      "step": 4000
    },
    {
      "epoch": 8.02,
      "grad_norm": 1.809332013130188,
      "learning_rate": 6.0303030303030296e-05,
      "loss": 0.1352,
      "step": 4010
    },
    {
      "epoch": 8.04,
      "grad_norm": 1.2004488706588745,
      "learning_rate": 5.969696969696969e-05,
      "loss": 0.1527,
      "step": 4020
    },
    {
      "epoch": 8.06,
      "grad_norm": 0.922960638999939,
      "learning_rate": 5.909090909090908e-05,
      "loss": 0.1405,
      "step": 4030
    },
    {
      "epoch": 8.08,
      "grad_norm": 1.7665421962738037,
      "learning_rate": 5.848484848484848e-05,
      "loss": 0.1358,
      "step": 4040
    },
    {
      "epoch": 8.1,
      "grad_norm": 1.1814918518066406,
      "learning_rate": 5.787878787878787e-05,
      "loss": 0.1456,
      "step": 4050
    },
    {
      "epoch": 8.12,
      "grad_norm": 1.066715955734253,
      "learning_rate": 5.727272727272727e-05,
      "loss": 0.1387,
      "step": 4060
    },
    {
      "epoch": 8.14,
      "grad_norm": 3.676804542541504,
      "learning_rate": 5.666666666666666e-05,
      "loss": 0.1341,
      "step": 4070
    },
    {
      "epoch": 8.16,
      "grad_norm": 1.8904953002929688,
      "learning_rate": 5.606060606060606e-05,
      "loss": 0.1753,
      "step": 4080
    },
    {
      "epoch": 8.18,
      "grad_norm": 1.7768454551696777,
      "learning_rate": 5.545454545454545e-05,
      "loss": 0.1557,
      "step": 4090
    },
    {
      "epoch": 8.2,
      "grad_norm": 3.1011650562286377,
      "learning_rate": 5.484848484848485e-05,
      "loss": 0.142,
      "step": 4100
    },
    {
      "epoch": 8.2,
      "eval_loss": 1.3053367137908936,
      "eval_runtime": 8.3587,
      "eval_samples_per_second": 23.927,
      "eval_steps_per_second": 23.927,
      "step": 4100
    },
    {
      "epoch": 8.22,
      "grad_norm": 1.1146368980407715,
      "learning_rate": 5.424242424242424e-05,
      "loss": 0.1432,
      "step": 4110
    },
    {
      "epoch": 8.24,
      "grad_norm": 1.175757646560669,
      "learning_rate": 5.3636363636363635e-05,
      "loss": 0.1642,
      "step": 4120
    },
    {
      "epoch": 8.26,
      "grad_norm": 1.8681159019470215,
      "learning_rate": 5.3030303030303025e-05,
      "loss": 0.176,
      "step": 4130
    },
    {
      "epoch": 8.28,
      "grad_norm": 1.0817958116531372,
      "learning_rate": 5.2424242424242415e-05,
      "loss": 0.1821,
      "step": 4140
    },
    {
      "epoch": 8.3,
      "grad_norm": 1.744973063468933,
      "learning_rate": 5.181818181818181e-05,
      "loss": 0.1493,
      "step": 4150
    },
    {
      "epoch": 8.32,
      "grad_norm": 1.4422271251678467,
      "learning_rate": 5.12121212121212e-05,
      "loss": 0.1512,
      "step": 4160
    },
    {
      "epoch": 8.34,
      "grad_norm": 2.311823606491089,
      "learning_rate": 5.0606060606060606e-05,
      "loss": 0.1765,
      "step": 4170
    },
    {
      "epoch": 8.36,
      "grad_norm": 1.5028390884399414,
      "learning_rate": 4.9999999999999996e-05,
      "loss": 0.1612,
      "step": 4180
    },
    {
      "epoch": 8.38,
      "grad_norm": 2.199484348297119,
      "learning_rate": 4.939393939393939e-05,
      "loss": 0.1547,
      "step": 4190
    },
    {
      "epoch": 8.4,
      "grad_norm": 1.1300926208496094,
      "learning_rate": 4.878787878787878e-05,
      "loss": 0.1373,
      "step": 4200
    },
    {
      "epoch": 8.4,
      "eval_loss": 1.2864891290664673,
      "eval_runtime": 8.36,
      "eval_samples_per_second": 23.924,
      "eval_steps_per_second": 23.924,
      "step": 4200
    },
    {
      "epoch": 8.42,
      "grad_norm": 1.6043239831924438,
      "learning_rate": 4.818181818181818e-05,
      "loss": 0.1455,
      "step": 4210
    },
    {
      "epoch": 8.44,
      "grad_norm": 1.478893518447876,
      "learning_rate": 4.757575757575757e-05,
      "loss": 0.1765,
      "step": 4220
    },
    {
      "epoch": 8.46,
      "grad_norm": 1.374954104423523,
      "learning_rate": 4.6969696969696966e-05,
      "loss": 0.1508,
      "step": 4230
    },
    {
      "epoch": 8.48,
      "grad_norm": 1.8257219791412354,
      "learning_rate": 4.6363636363636356e-05,
      "loss": 0.1683,
      "step": 4240
    },
    {
      "epoch": 8.5,
      "grad_norm": 2.0973458290100098,
      "learning_rate": 4.575757575757576e-05,
      "loss": 0.1551,
      "step": 4250
    },
    {
      "epoch": 8.52,
      "grad_norm": 2.2255642414093018,
      "learning_rate": 4.515151515151515e-05,
      "loss": 0.145,
      "step": 4260
    },
    {
      "epoch": 8.54,
      "grad_norm": 1.6798644065856934,
      "learning_rate": 4.454545454545455e-05,
      "loss": 0.1465,
      "step": 4270
    },
    {
      "epoch": 8.56,
      "grad_norm": 1.377312421798706,
      "learning_rate": 4.393939393939394e-05,
      "loss": 0.1624,
      "step": 4280
    },
    {
      "epoch": 8.58,
      "grad_norm": 1.4797353744506836,
      "learning_rate": 4.333333333333333e-05,
      "loss": 0.166,
      "step": 4290
    },
    {
      "epoch": 8.6,
      "grad_norm": 1.0349071025848389,
      "learning_rate": 4.2727272727272724e-05,
      "loss": 0.1459,
      "step": 4300
    },
    {
      "epoch": 8.6,
      "eval_loss": 1.2854888439178467,
      "eval_runtime": 8.3981,
      "eval_samples_per_second": 23.815,
      "eval_steps_per_second": 23.815,
      "step": 4300
    },
    {
      "epoch": 8.62,
      "grad_norm": 0.9574476480484009,
      "learning_rate": 4.2121212121212114e-05,
      "loss": 0.1564,
      "step": 4310
    },
    {
      "epoch": 8.64,
      "grad_norm": 2.675785541534424,
      "learning_rate": 4.151515151515151e-05,
      "loss": 0.1881,
      "step": 4320
    },
    {
      "epoch": 8.66,
      "grad_norm": 2.646092176437378,
      "learning_rate": 4.09090909090909e-05,
      "loss": 0.1604,
      "step": 4330
    },
    {
      "epoch": 8.68,
      "grad_norm": 1.2109376192092896,
      "learning_rate": 4.03030303030303e-05,
      "loss": 0.1551,
      "step": 4340
    },
    {
      "epoch": 8.7,
      "grad_norm": 1.2296303510665894,
      "learning_rate": 3.969696969696969e-05,
      "loss": 0.1414,
      "step": 4350
    },
    {
      "epoch": 8.72,
      "grad_norm": 1.4793453216552734,
      "learning_rate": 3.909090909090909e-05,
      "loss": 0.1654,
      "step": 4360
    },
    {
      "epoch": 8.74,
      "grad_norm": 1.9558091163635254,
      "learning_rate": 3.848484848484848e-05,
      "loss": 0.1518,
      "step": 4370
    },
    {
      "epoch": 8.76,
      "grad_norm": 2.147312641143799,
      "learning_rate": 3.787878787878788e-05,
      "loss": 0.128,
      "step": 4380
    },
    {
      "epoch": 8.78,
      "grad_norm": 2.194577932357788,
      "learning_rate": 3.727272727272727e-05,
      "loss": 0.1844,
      "step": 4390
    },
    {
      "epoch": 8.8,
      "grad_norm": 1.227791666984558,
      "learning_rate": 3.666666666666666e-05,
      "loss": 0.1592,
      "step": 4400
    },
    {
      "epoch": 8.8,
      "eval_loss": 1.2778156995773315,
      "eval_runtime": 8.3745,
      "eval_samples_per_second": 23.882,
      "eval_steps_per_second": 23.882,
      "step": 4400
    },
    {
      "epoch": 8.82,
      "grad_norm": 3.0963783264160156,
      "learning_rate": 3.6060606060606056e-05,
      "loss": 0.1867,
      "step": 4410
    },
    {
      "epoch": 8.84,
      "grad_norm": 1.6047340631484985,
      "learning_rate": 3.545454545454545e-05,
      "loss": 0.1584,
      "step": 4420
    },
    {
      "epoch": 8.86,
      "grad_norm": 1.2368459701538086,
      "learning_rate": 3.484848484848484e-05,
      "loss": 0.1739,
      "step": 4430
    },
    {
      "epoch": 8.88,
      "grad_norm": 1.908576488494873,
      "learning_rate": 3.424242424242424e-05,
      "loss": 0.1626,
      "step": 4440
    },
    {
      "epoch": 8.9,
      "grad_norm": 3.1277496814727783,
      "learning_rate": 3.3636363636363636e-05,
      "loss": 0.1571,
      "step": 4450
    },
    {
      "epoch": 8.92,
      "grad_norm": 1.1109130382537842,
      "learning_rate": 3.3030303030303027e-05,
      "loss": 0.1526,
      "step": 4460
    },
    {
      "epoch": 8.94,
      "grad_norm": 1.2675780057907104,
      "learning_rate": 3.2424242424242423e-05,
      "loss": 0.1533,
      "step": 4470
    },
    {
      "epoch": 8.96,
      "grad_norm": 1.4172853231430054,
      "learning_rate": 3.1818181818181814e-05,
      "loss": 0.172,
      "step": 4480
    },
    {
      "epoch": 8.98,
      "grad_norm": 1.4570794105529785,
      "learning_rate": 3.121212121212121e-05,
      "loss": 0.1432,
      "step": 4490
    },
    {
      "epoch": 9.0,
      "grad_norm": 2.235438346862793,
      "learning_rate": 3.060606060606061e-05,
      "loss": 0.1603,
      "step": 4500
    },
    {
      "epoch": 9.0,
      "eval_loss": 1.2930233478546143,
      "eval_runtime": 8.385,
      "eval_samples_per_second": 23.852,
      "eval_steps_per_second": 23.852,
      "step": 4500
    }
  ],
  "logging_steps": 10,
  "max_steps": 5000,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 10,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 1.3472250200064e+16,
  "train_batch_size": 1,
  "trial_name": null,
  "trial_params": null
}

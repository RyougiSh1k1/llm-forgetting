{
  "best_global_step": null,
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 9.0,
  "eval_steps": 100,
  "global_step": 4500,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.02,
      "grad_norm": 2.663423776626587,
      "learning_rate": 4.2e-05,
      "loss": 2.6019,
      "step": 10
    },
    {
      "epoch": 0.04,
      "grad_norm": 5.119857311248779,
      "learning_rate": 0.000102,
      "loss": 2.3903,
      "step": 20
    },
    {
      "epoch": 0.06,
      "grad_norm": 3.3923046588897705,
      "learning_rate": 0.000162,
      "loss": 1.839,
      "step": 30
    },
    {
      "epoch": 0.08,
      "grad_norm": 3.882093906402588,
      "learning_rate": 0.00022199999999999998,
      "loss": 1.4508,
      "step": 40
    },
    {
      "epoch": 0.1,
      "grad_norm": 3.8828964233398438,
      "learning_rate": 0.00028199999999999997,
      "loss": 1.4192,
      "step": 50
    },
    {
      "epoch": 0.12,
      "grad_norm": 7.945639133453369,
      "learning_rate": 0.00029957575757575756,
      "loss": 1.2175,
      "step": 60
    },
    {
      "epoch": 0.14,
      "grad_norm": 3.5189383029937744,
      "learning_rate": 0.0002989696969696969,
      "loss": 1.2731,
      "step": 70
    },
    {
      "epoch": 0.16,
      "grad_norm": 10.169319152832031,
      "learning_rate": 0.0002983636363636363,
      "loss": 1.0513,
      "step": 80
    },
    {
      "epoch": 0.18,
      "grad_norm": 3.053553581237793,
      "learning_rate": 0.00029775757575757573,
      "loss": 1.1747,
      "step": 90
    },
    {
      "epoch": 0.2,
      "grad_norm": 3.9247488975524902,
      "learning_rate": 0.00029715151515151514,
      "loss": 1.2551,
      "step": 100
    },
    {
      "epoch": 0.2,
      "eval_loss": 1.131382703781128,
      "eval_runtime": 8.3633,
      "eval_samples_per_second": 23.914,
      "eval_steps_per_second": 23.914,
      "step": 100
    },
    {
      "epoch": 0.22,
      "grad_norm": 2.8847482204437256,
      "learning_rate": 0.00029654545454545455,
      "loss": 1.1186,
      "step": 110
    },
    {
      "epoch": 0.24,
      "grad_norm": 6.813830375671387,
      "learning_rate": 0.0002959393939393939,
      "loss": 0.9365,
      "step": 120
    },
    {
      "epoch": 0.26,
      "grad_norm": 3.3011841773986816,
      "learning_rate": 0.0002953333333333333,
      "loss": 1.3471,
      "step": 130
    },
    {
      "epoch": 0.28,
      "grad_norm": 2.9140470027923584,
      "learning_rate": 0.0002947272727272727,
      "loss": 1.2512,
      "step": 140
    },
    {
      "epoch": 0.3,
      "grad_norm": 2.382434368133545,
      "learning_rate": 0.0002941212121212121,
      "loss": 0.7509,
      "step": 150
    },
    {
      "epoch": 0.32,
      "grad_norm": 3.163572311401367,
      "learning_rate": 0.0002935151515151515,
      "loss": 0.8499,
      "step": 160
    },
    {
      "epoch": 0.34,
      "grad_norm": 7.132478713989258,
      "learning_rate": 0.00029290909090909085,
      "loss": 1.0945,
      "step": 170
    },
    {
      "epoch": 0.36,
      "grad_norm": 3.033984661102295,
      "learning_rate": 0.00029230303030303026,
      "loss": 1.2394,
      "step": 180
    },
    {
      "epoch": 0.38,
      "grad_norm": 4.063960075378418,
      "learning_rate": 0.0002916969696969697,
      "loss": 1.1062,
      "step": 190
    },
    {
      "epoch": 0.4,
      "grad_norm": 4.245260238647461,
      "learning_rate": 0.0002910909090909091,
      "loss": 0.8645,
      "step": 200
    },
    {
      "epoch": 0.4,
      "eval_loss": 0.901013970375061,
      "eval_runtime": 8.4028,
      "eval_samples_per_second": 23.802,
      "eval_steps_per_second": 23.802,
      "step": 200
    },
    {
      "epoch": 0.42,
      "grad_norm": 4.540550231933594,
      "learning_rate": 0.00029048484848484844,
      "loss": 0.7206,
      "step": 210
    },
    {
      "epoch": 0.44,
      "grad_norm": 3.0409278869628906,
      "learning_rate": 0.00028987878787878785,
      "loss": 0.9604,
      "step": 220
    },
    {
      "epoch": 0.46,
      "grad_norm": 4.831951141357422,
      "learning_rate": 0.00028927272727272726,
      "loss": 0.7863,
      "step": 230
    },
    {
      "epoch": 0.48,
      "grad_norm": 2.596836805343628,
      "learning_rate": 0.0002886666666666666,
      "loss": 0.7641,
      "step": 240
    },
    {
      "epoch": 0.5,
      "grad_norm": 3.8830459117889404,
      "learning_rate": 0.00028806060606060603,
      "loss": 0.9269,
      "step": 250
    },
    {
      "epoch": 0.52,
      "grad_norm": 4.644800662994385,
      "learning_rate": 0.00028745454545454544,
      "loss": 0.847,
      "step": 260
    },
    {
      "epoch": 0.54,
      "grad_norm": 5.099691867828369,
      "learning_rate": 0.00028684848484848485,
      "loss": 0.9862,
      "step": 270
    },
    {
      "epoch": 0.56,
      "grad_norm": 4.206416606903076,
      "learning_rate": 0.0002862424242424242,
      "loss": 1.0737,
      "step": 280
    },
    {
      "epoch": 0.58,
      "grad_norm": 5.388011932373047,
      "learning_rate": 0.0002856363636363636,
      "loss": 0.9313,
      "step": 290
    },
    {
      "epoch": 0.6,
      "grad_norm": 2.917682647705078,
      "learning_rate": 0.000285030303030303,
      "loss": 0.7635,
      "step": 300
    },
    {
      "epoch": 0.6,
      "eval_loss": 0.8859052062034607,
      "eval_runtime": 8.3565,
      "eval_samples_per_second": 23.933,
      "eval_steps_per_second": 23.933,
      "step": 300
    },
    {
      "epoch": 0.62,
      "grad_norm": 4.10420560836792,
      "learning_rate": 0.0002844242424242424,
      "loss": 1.0442,
      "step": 310
    },
    {
      "epoch": 0.64,
      "grad_norm": 8.48910903930664,
      "learning_rate": 0.0002838181818181818,
      "loss": 0.6386,
      "step": 320
    },
    {
      "epoch": 0.66,
      "grad_norm": 3.7237343788146973,
      "learning_rate": 0.0002832121212121212,
      "loss": 0.7157,
      "step": 330
    },
    {
      "epoch": 0.68,
      "grad_norm": 4.393184185028076,
      "learning_rate": 0.00028260606060606056,
      "loss": 1.0214,
      "step": 340
    },
    {
      "epoch": 0.7,
      "grad_norm": 1.7698115110397339,
      "learning_rate": 0.00028199999999999997,
      "loss": 0.8309,
      "step": 350
    },
    {
      "epoch": 0.72,
      "grad_norm": 4.713278293609619,
      "learning_rate": 0.0002813939393939394,
      "loss": 0.8393,
      "step": 360
    },
    {
      "epoch": 0.74,
      "grad_norm": 2.9664926528930664,
      "learning_rate": 0.0002807878787878788,
      "loss": 0.8267,
      "step": 370
    },
    {
      "epoch": 0.76,
      "grad_norm": 3.59342885017395,
      "learning_rate": 0.00028018181818181815,
      "loss": 0.8602,
      "step": 380
    },
    {
      "epoch": 0.78,
      "grad_norm": 2.7889068126678467,
      "learning_rate": 0.00027957575757575756,
      "loss": 0.6372,
      "step": 390
    },
    {
      "epoch": 0.8,
      "grad_norm": 9.05543327331543,
      "learning_rate": 0.00027896969696969697,
      "loss": 0.7746,
      "step": 400
    },
    {
      "epoch": 0.8,
      "eval_loss": 0.8812602162361145,
      "eval_runtime": 8.3682,
      "eval_samples_per_second": 23.9,
      "eval_steps_per_second": 23.9,
      "step": 400
    },
    {
      "epoch": 0.82,
      "grad_norm": 3.243727922439575,
      "learning_rate": 0.0002783636363636363,
      "loss": 1.1336,
      "step": 410
    },
    {
      "epoch": 0.84,
      "grad_norm": 6.154764652252197,
      "learning_rate": 0.00027775757575757573,
      "loss": 0.8345,
      "step": 420
    },
    {
      "epoch": 0.86,
      "grad_norm": 5.2939252853393555,
      "learning_rate": 0.0002771515151515151,
      "loss": 0.7109,
      "step": 430
    },
    {
      "epoch": 0.88,
      "grad_norm": 3.7077646255493164,
      "learning_rate": 0.00027654545454545456,
      "loss": 0.7087,
      "step": 440
    },
    {
      "epoch": 0.9,
      "grad_norm": 3.0022497177124023,
      "learning_rate": 0.0002759393939393939,
      "loss": 0.7219,
      "step": 450
    },
    {
      "epoch": 0.92,
      "grad_norm": 3.2323737144470215,
      "learning_rate": 0.0002753333333333333,
      "loss": 1.0143,
      "step": 460
    },
    {
      "epoch": 0.94,
      "grad_norm": 2.630401134490967,
      "learning_rate": 0.00027472727272727273,
      "loss": 0.7282,
      "step": 470
    },
    {
      "epoch": 0.96,
      "grad_norm": 1.9801772832870483,
      "learning_rate": 0.0002741212121212121,
      "loss": 0.9254,
      "step": 480
    },
    {
      "epoch": 0.98,
      "grad_norm": 1.5959144830703735,
      "learning_rate": 0.0002735151515151515,
      "loss": 0.9695,
      "step": 490
    },
    {
      "epoch": 1.0,
      "grad_norm": 7.5784687995910645,
      "learning_rate": 0.00027290909090909086,
      "loss": 0.8114,
      "step": 500
    },
    {
      "epoch": 1.0,
      "eval_loss": 0.8746289014816284,
      "eval_runtime": 8.8273,
      "eval_samples_per_second": 22.657,
      "eval_steps_per_second": 22.657,
      "step": 500
    },
    {
      "epoch": 1.02,
      "grad_norm": 3.969801425933838,
      "learning_rate": 0.00027236363636363634,
      "loss": 0.8152,
      "step": 510
    },
    {
      "epoch": 1.04,
      "grad_norm": 10.717437744140625,
      "learning_rate": 0.0002717575757575757,
      "loss": 0.7385,
      "step": 520
    },
    {
      "epoch": 1.06,
      "grad_norm": 1.784667730331421,
      "learning_rate": 0.00027115151515151516,
      "loss": 0.5718,
      "step": 530
    },
    {
      "epoch": 1.08,
      "grad_norm": 2.4492878913879395,
      "learning_rate": 0.0002705454545454545,
      "loss": 0.7323,
      "step": 540
    },
    {
      "epoch": 1.1,
      "grad_norm": 2.363171339035034,
      "learning_rate": 0.00026993939393939393,
      "loss": 0.606,
      "step": 550
    },
    {
      "epoch": 1.12,
      "grad_norm": 1.7890979051589966,
      "learning_rate": 0.00026933333333333334,
      "loss": 0.6887,
      "step": 560
    },
    {
      "epoch": 1.1400000000000001,
      "grad_norm": 3.24419903755188,
      "learning_rate": 0.0002687272727272727,
      "loss": 0.6049,
      "step": 570
    },
    {
      "epoch": 1.16,
      "grad_norm": 5.5412516593933105,
      "learning_rate": 0.0002681212121212121,
      "loss": 0.8873,
      "step": 580
    },
    {
      "epoch": 1.18,
      "grad_norm": 2.5828545093536377,
      "learning_rate": 0.00026751515151515146,
      "loss": 0.6399,
      "step": 590
    },
    {
      "epoch": 1.2,
      "grad_norm": 1.757550835609436,
      "learning_rate": 0.00026690909090909087,
      "loss": 0.5976,
      "step": 600
    },
    {
      "epoch": 1.2,
      "eval_loss": 0.8665665984153748,
      "eval_runtime": 8.5066,
      "eval_samples_per_second": 23.511,
      "eval_steps_per_second": 23.511,
      "step": 600
    },
    {
      "epoch": 1.22,
      "grad_norm": 3.948349952697754,
      "learning_rate": 0.0002663030303030303,
      "loss": 0.6758,
      "step": 610
    },
    {
      "epoch": 1.24,
      "grad_norm": 3.075629711151123,
      "learning_rate": 0.0002656969696969697,
      "loss": 0.7698,
      "step": 620
    },
    {
      "epoch": 1.26,
      "grad_norm": 3.2441484928131104,
      "learning_rate": 0.00026509090909090905,
      "loss": 0.7422,
      "step": 630
    },
    {
      "epoch": 1.28,
      "grad_norm": 2.543654680252075,
      "learning_rate": 0.00026448484848484846,
      "loss": 0.7165,
      "step": 640
    },
    {
      "epoch": 1.3,
      "grad_norm": 4.957982540130615,
      "learning_rate": 0.00026387878787878787,
      "loss": 0.7706,
      "step": 650
    },
    {
      "epoch": 1.32,
      "grad_norm": 2.535698175430298,
      "learning_rate": 0.0002632727272727272,
      "loss": 0.5657,
      "step": 660
    },
    {
      "epoch": 1.34,
      "grad_norm": 1.8545246124267578,
      "learning_rate": 0.00026266666666666664,
      "loss": 0.7642,
      "step": 670
    },
    {
      "epoch": 1.3599999999999999,
      "grad_norm": 2.8102850914001465,
      "learning_rate": 0.00026206060606060605,
      "loss": 0.8741,
      "step": 680
    },
    {
      "epoch": 1.38,
      "grad_norm": 3.0893611907958984,
      "learning_rate": 0.0002614545454545454,
      "loss": 0.5678,
      "step": 690
    },
    {
      "epoch": 1.4,
      "grad_norm": 3.7278430461883545,
      "learning_rate": 0.0002608484848484848,
      "loss": 0.6686,
      "step": 700
    },
    {
      "epoch": 1.4,
      "eval_loss": 0.8804444670677185,
      "eval_runtime": 8.4845,
      "eval_samples_per_second": 23.572,
      "eval_steps_per_second": 23.572,
      "step": 700
    },
    {
      "epoch": 1.42,
      "grad_norm": 2.2124807834625244,
      "learning_rate": 0.0002602424242424242,
      "loss": 0.73,
      "step": 710
    },
    {
      "epoch": 1.44,
      "grad_norm": 3.0058212280273438,
      "learning_rate": 0.00025963636363636363,
      "loss": 0.6434,
      "step": 720
    },
    {
      "epoch": 1.46,
      "grad_norm": 3.913599729537964,
      "learning_rate": 0.000259030303030303,
      "loss": 0.7765,
      "step": 730
    },
    {
      "epoch": 1.48,
      "grad_norm": 1.79198157787323,
      "learning_rate": 0.0002584242424242424,
      "loss": 0.6913,
      "step": 740
    },
    {
      "epoch": 1.5,
      "grad_norm": 5.218415260314941,
      "learning_rate": 0.0002578181818181818,
      "loss": 0.755,
      "step": 750
    },
    {
      "epoch": 1.52,
      "grad_norm": 3.168846368789673,
      "learning_rate": 0.00025721212121212117,
      "loss": 0.8149,
      "step": 760
    },
    {
      "epoch": 1.54,
      "grad_norm": 1.5356477499008179,
      "learning_rate": 0.0002566060606060606,
      "loss": 0.7409,
      "step": 770
    },
    {
      "epoch": 1.56,
      "grad_norm": 1.4163068532943726,
      "learning_rate": 0.000256,
      "loss": 0.5449,
      "step": 780
    },
    {
      "epoch": 1.58,
      "grad_norm": 4.657138347625732,
      "learning_rate": 0.0002553939393939394,
      "loss": 0.6438,
      "step": 790
    },
    {
      "epoch": 1.6,
      "grad_norm": 3.0618159770965576,
      "learning_rate": 0.00025478787878787876,
      "loss": 0.7869,
      "step": 800
    },
    {
      "epoch": 1.6,
      "eval_loss": 0.8615272641181946,
      "eval_runtime": 8.4606,
      "eval_samples_per_second": 23.639,
      "eval_steps_per_second": 23.639,
      "step": 800
    },
    {
      "epoch": 1.62,
      "grad_norm": 3.771108627319336,
      "learning_rate": 0.00025418181818181817,
      "loss": 0.6884,
      "step": 810
    },
    {
      "epoch": 1.6400000000000001,
      "grad_norm": 2.8647985458374023,
      "learning_rate": 0.0002535757575757576,
      "loss": 0.6052,
      "step": 820
    },
    {
      "epoch": 1.6600000000000001,
      "grad_norm": 3.9850223064422607,
      "learning_rate": 0.00025296969696969693,
      "loss": 0.7238,
      "step": 830
    },
    {
      "epoch": 1.6800000000000002,
      "grad_norm": 3.9547410011291504,
      "learning_rate": 0.00025236363636363634,
      "loss": 0.6619,
      "step": 840
    },
    {
      "epoch": 1.7,
      "grad_norm": 3.5978000164031982,
      "learning_rate": 0.0002517575757575757,
      "loss": 0.7476,
      "step": 850
    },
    {
      "epoch": 1.72,
      "grad_norm": 3.3630120754241943,
      "learning_rate": 0.0002511515151515151,
      "loss": 0.7102,
      "step": 860
    },
    {
      "epoch": 1.74,
      "grad_norm": 4.615638256072998,
      "learning_rate": 0.0002505454545454545,
      "loss": 0.6446,
      "step": 870
    },
    {
      "epoch": 1.76,
      "grad_norm": 4.842613220214844,
      "learning_rate": 0.00024993939393939393,
      "loss": 0.7608,
      "step": 880
    },
    {
      "epoch": 1.78,
      "grad_norm": 2.174208402633667,
      "learning_rate": 0.00024933333333333334,
      "loss": 0.5569,
      "step": 890
    },
    {
      "epoch": 1.8,
      "grad_norm": 3.911093235015869,
      "learning_rate": 0.0002487272727272727,
      "loss": 0.6621,
      "step": 900
    },
    {
      "epoch": 1.8,
      "eval_loss": 0.8462263345718384,
      "eval_runtime": 8.457,
      "eval_samples_per_second": 23.649,
      "eval_steps_per_second": 23.649,
      "step": 900
    },
    {
      "epoch": 1.8199999999999998,
      "grad_norm": 1.6013624668121338,
      "learning_rate": 0.0002481212121212121,
      "loss": 0.6447,
      "step": 910
    },
    {
      "epoch": 1.8399999999999999,
      "grad_norm": 4.008474826812744,
      "learning_rate": 0.00024751515151515146,
      "loss": 0.788,
      "step": 920
    },
    {
      "epoch": 1.8599999999999999,
      "grad_norm": 2.808678388595581,
      "learning_rate": 0.0002469090909090909,
      "loss": 0.7785,
      "step": 930
    },
    {
      "epoch": 1.88,
      "grad_norm": 3.5831551551818848,
      "learning_rate": 0.0002463030303030303,
      "loss": 0.6225,
      "step": 940
    },
    {
      "epoch": 1.9,
      "grad_norm": 4.738509178161621,
      "learning_rate": 0.00024569696969696964,
      "loss": 0.7628,
      "step": 950
    },
    {
      "epoch": 1.92,
      "grad_norm": 2.10768723487854,
      "learning_rate": 0.0002450909090909091,
      "loss": 0.6101,
      "step": 960
    },
    {
      "epoch": 1.94,
      "grad_norm": 3.989753484725952,
      "learning_rate": 0.00024448484848484846,
      "loss": 0.9466,
      "step": 970
    },
    {
      "epoch": 1.96,
      "grad_norm": 4.139882564544678,
      "learning_rate": 0.00024387878787878787,
      "loss": 0.7857,
      "step": 980
    },
    {
      "epoch": 1.98,
      "grad_norm": 3.5630459785461426,
      "learning_rate": 0.00024327272727272725,
      "loss": 0.5699,
      "step": 990
    },
    {
      "epoch": 2.0,
      "grad_norm": 2.9606096744537354,
      "learning_rate": 0.00024266666666666664,
      "loss": 0.8259,
      "step": 1000
    },
    {
      "epoch": 2.0,
      "eval_loss": 0.8520410656929016,
      "eval_runtime": 8.4068,
      "eval_samples_per_second": 23.79,
      "eval_steps_per_second": 23.79,
      "step": 1000
    },
    {
      "epoch": 2.02,
      "grad_norm": 4.771359443664551,
      "learning_rate": 0.00024206060606060602,
      "loss": 0.4313,
      "step": 1010
    },
    {
      "epoch": 2.04,
      "grad_norm": 2.8624446392059326,
      "learning_rate": 0.00024145454545454543,
      "loss": 0.4985,
      "step": 1020
    },
    {
      "epoch": 2.06,
      "grad_norm": 4.154097557067871,
      "learning_rate": 0.00024084848484848482,
      "loss": 0.6177,
      "step": 1030
    },
    {
      "epoch": 2.08,
      "grad_norm": 2.980839967727661,
      "learning_rate": 0.00024024242424242423,
      "loss": 0.4959,
      "step": 1040
    },
    {
      "epoch": 2.1,
      "grad_norm": 2.309659957885742,
      "learning_rate": 0.00023963636363636364,
      "loss": 0.4665,
      "step": 1050
    },
    {
      "epoch": 2.12,
      "grad_norm": 2.868190050125122,
      "learning_rate": 0.00023903030303030302,
      "loss": 0.5551,
      "step": 1060
    },
    {
      "epoch": 2.14,
      "grad_norm": 3.3385980129241943,
      "learning_rate": 0.0002384242424242424,
      "loss": 0.4493,
      "step": 1070
    },
    {
      "epoch": 2.16,
      "grad_norm": 4.993950366973877,
      "learning_rate": 0.00023781818181818179,
      "loss": 0.6393,
      "step": 1080
    },
    {
      "epoch": 2.18,
      "grad_norm": 2.241640567779541,
      "learning_rate": 0.0002372121212121212,
      "loss": 0.4596,
      "step": 1090
    },
    {
      "epoch": 2.2,
      "grad_norm": 1.2617287635803223,
      "learning_rate": 0.00023660606060606058,
      "loss": 0.3717,
      "step": 1100
    },
    {
      "epoch": 2.2,
      "eval_loss": 0.9382076859474182,
      "eval_runtime": 8.3899,
      "eval_samples_per_second": 23.838,
      "eval_steps_per_second": 23.838,
      "step": 1100
    },
    {
      "epoch": 2.22,
      "grad_norm": 4.962890148162842,
      "learning_rate": 0.00023599999999999996,
      "loss": 0.4394,
      "step": 1110
    },
    {
      "epoch": 2.24,
      "grad_norm": 2.373471260070801,
      "learning_rate": 0.00023539393939393935,
      "loss": 0.4998,
      "step": 1120
    },
    {
      "epoch": 2.26,
      "grad_norm": 1.988887906074524,
      "learning_rate": 0.00023478787878787878,
      "loss": 0.4721,
      "step": 1130
    },
    {
      "epoch": 2.2800000000000002,
      "grad_norm": 5.722217082977295,
      "learning_rate": 0.00023418181818181817,
      "loss": 0.5409,
      "step": 1140
    },
    {
      "epoch": 2.3,
      "grad_norm": 5.907480716705322,
      "learning_rate": 0.00023357575757575755,
      "loss": 0.4862,
      "step": 1150
    },
    {
      "epoch": 2.32,
      "grad_norm": 3.736476421356201,
      "learning_rate": 0.00023296969696969696,
      "loss": 0.4243,
      "step": 1160
    },
    {
      "epoch": 2.34,
      "grad_norm": 3.210723400115967,
      "learning_rate": 0.00023236363636363634,
      "loss": 0.4664,
      "step": 1170
    },
    {
      "epoch": 2.36,
      "grad_norm": 4.63379430770874,
      "learning_rate": 0.00023175757575757573,
      "loss": 0.4572,
      "step": 1180
    },
    {
      "epoch": 2.38,
      "grad_norm": 5.114528179168701,
      "learning_rate": 0.0002311515151515151,
      "loss": 0.4741,
      "step": 1190
    },
    {
      "epoch": 2.4,
      "grad_norm": 4.007542610168457,
      "learning_rate": 0.00023054545454545452,
      "loss": 0.4466,
      "step": 1200
    },
    {
      "epoch": 2.4,
      "eval_loss": 0.9100024700164795,
      "eval_runtime": 8.7744,
      "eval_samples_per_second": 22.794,
      "eval_steps_per_second": 22.794,
      "step": 1200
    },
    {
      "epoch": 2.42,
      "grad_norm": 2.9319376945495605,
      "learning_rate": 0.00022993939393939393,
      "loss": 0.3663,
      "step": 1210
    },
    {
      "epoch": 2.44,
      "grad_norm": 5.28032922744751,
      "learning_rate": 0.00022933333333333332,
      "loss": 0.6427,
      "step": 1220
    },
    {
      "epoch": 2.46,
      "grad_norm": 6.114151477813721,
      "learning_rate": 0.00022872727272727273,
      "loss": 0.4982,
      "step": 1230
    },
    {
      "epoch": 2.48,
      "grad_norm": 3.035724639892578,
      "learning_rate": 0.0002281212121212121,
      "loss": 0.5736,
      "step": 1240
    },
    {
      "epoch": 2.5,
      "grad_norm": 4.775924205780029,
      "learning_rate": 0.0002275151515151515,
      "loss": 0.5643,
      "step": 1250
    },
    {
      "epoch": 2.52,
      "grad_norm": 2.385502815246582,
      "learning_rate": 0.00022690909090909088,
      "loss": 0.6325,
      "step": 1260
    },
    {
      "epoch": 2.54,
      "grad_norm": 4.5041704177856445,
      "learning_rate": 0.00022630303030303029,
      "loss": 0.5777,
      "step": 1270
    },
    {
      "epoch": 2.56,
      "grad_norm": 1.4641817808151245,
      "learning_rate": 0.00022569696969696967,
      "loss": 0.4184,
      "step": 1280
    },
    {
      "epoch": 2.58,
      "grad_norm": 2.7838220596313477,
      "learning_rate": 0.00022509090909090905,
      "loss": 0.4241,
      "step": 1290
    },
    {
      "epoch": 2.6,
      "grad_norm": 3.529980421066284,
      "learning_rate": 0.0002244848484848485,
      "loss": 0.566,
      "step": 1300
    },
    {
      "epoch": 2.6,
      "eval_loss": 0.9129668474197388,
      "eval_runtime": 8.8027,
      "eval_samples_per_second": 22.72,
      "eval_steps_per_second": 22.72,
      "step": 1300
    },
    {
      "epoch": 2.62,
      "grad_norm": 2.4060018062591553,
      "learning_rate": 0.00022387878787878787,
      "loss": 0.5876,
      "step": 1310
    },
    {
      "epoch": 2.64,
      "grad_norm": 1.9259124994277954,
      "learning_rate": 0.00022327272727272726,
      "loss": 0.4491,
      "step": 1320
    },
    {
      "epoch": 2.66,
      "grad_norm": 4.503479480743408,
      "learning_rate": 0.00022266666666666664,
      "loss": 0.5914,
      "step": 1330
    },
    {
      "epoch": 2.68,
      "grad_norm": 1.8804450035095215,
      "learning_rate": 0.00022206060606060605,
      "loss": 0.4774,
      "step": 1340
    },
    {
      "epoch": 2.7,
      "grad_norm": 2.1319222450256348,
      "learning_rate": 0.00022145454545454543,
      "loss": 0.4803,
      "step": 1350
    },
    {
      "epoch": 2.7199999999999998,
      "grad_norm": 2.4922163486480713,
      "learning_rate": 0.00022084848484848482,
      "loss": 0.4636,
      "step": 1360
    },
    {
      "epoch": 2.74,
      "grad_norm": 2.8786773681640625,
      "learning_rate": 0.0002202424242424242,
      "loss": 0.459,
      "step": 1370
    },
    {
      "epoch": 2.76,
      "grad_norm": 4.161379337310791,
      "learning_rate": 0.00021963636363636364,
      "loss": 0.5726,
      "step": 1380
    },
    {
      "epoch": 2.7800000000000002,
      "grad_norm": 2.4137320518493652,
      "learning_rate": 0.00021903030303030302,
      "loss": 0.619,
      "step": 1390
    },
    {
      "epoch": 2.8,
      "grad_norm": 5.125668525695801,
      "learning_rate": 0.0002184242424242424,
      "loss": 0.5457,
      "step": 1400
    },
    {
      "epoch": 2.8,
      "eval_loss": 0.9027073383331299,
      "eval_runtime": 8.8365,
      "eval_samples_per_second": 22.633,
      "eval_steps_per_second": 22.633,
      "step": 1400
    },
    {
      "epoch": 2.82,
      "grad_norm": 2.3170504570007324,
      "learning_rate": 0.00021781818181818181,
      "loss": 0.3946,
      "step": 1410
    },
    {
      "epoch": 2.84,
      "grad_norm": 4.291963577270508,
      "learning_rate": 0.0002172121212121212,
      "loss": 0.416,
      "step": 1420
    },
    {
      "epoch": 2.86,
      "grad_norm": 2.882906198501587,
      "learning_rate": 0.00021660606060606058,
      "loss": 0.4675,
      "step": 1430
    },
    {
      "epoch": 2.88,
      "grad_norm": 3.765012264251709,
      "learning_rate": 0.00021599999999999996,
      "loss": 0.3766,
      "step": 1440
    },
    {
      "epoch": 2.9,
      "grad_norm": 2.496382713317871,
      "learning_rate": 0.00021539393939393938,
      "loss": 0.3673,
      "step": 1450
    },
    {
      "epoch": 2.92,
      "grad_norm": 1.7534525394439697,
      "learning_rate": 0.00021478787878787876,
      "loss": 0.611,
      "step": 1460
    },
    {
      "epoch": 2.94,
      "grad_norm": 1.7260512113571167,
      "learning_rate": 0.00021418181818181817,
      "loss": 0.4265,
      "step": 1470
    },
    {
      "epoch": 2.96,
      "grad_norm": 3.840850591659546,
      "learning_rate": 0.00021357575757575758,
      "loss": 0.4497,
      "step": 1480
    },
    {
      "epoch": 2.98,
      "grad_norm": 3.215914726257324,
      "learning_rate": 0.00021296969696969696,
      "loss": 0.5806,
      "step": 1490
    },
    {
      "epoch": 3.0,
      "grad_norm": 4.698976993560791,
      "learning_rate": 0.00021236363636363635,
      "loss": 0.6496,
      "step": 1500
    },
    {
      "epoch": 3.0,
      "eval_loss": 0.8813842535018921,
      "eval_runtime": 8.3759,
      "eval_samples_per_second": 23.878,
      "eval_steps_per_second": 23.878,
      "step": 1500
    },
    {
      "epoch": 3.02,
      "grad_norm": 2.459584951400757,
      "learning_rate": 0.00021175757575757573,
      "loss": 0.3726,
      "step": 1510
    },
    {
      "epoch": 3.04,
      "grad_norm": 2.562415361404419,
      "learning_rate": 0.00021115151515151514,
      "loss": 0.3162,
      "step": 1520
    },
    {
      "epoch": 3.06,
      "grad_norm": 2.9703619480133057,
      "learning_rate": 0.00021054545454545452,
      "loss": 0.3503,
      "step": 1530
    },
    {
      "epoch": 3.08,
      "grad_norm": 7.032725811004639,
      "learning_rate": 0.0002099393939393939,
      "loss": 0.3195,
      "step": 1540
    },
    {
      "epoch": 3.1,
      "grad_norm": 3.0160980224609375,
      "learning_rate": 0.00020933333333333334,
      "loss": 0.4739,
      "step": 1550
    },
    {
      "epoch": 3.12,
      "grad_norm": 3.6283388137817383,
      "learning_rate": 0.00020872727272727273,
      "loss": 0.3346,
      "step": 1560
    },
    {
      "epoch": 3.14,
      "grad_norm": 1.9052857160568237,
      "learning_rate": 0.0002081212121212121,
      "loss": 0.3976,
      "step": 1570
    },
    {
      "epoch": 3.16,
      "grad_norm": 1.6765180826187134,
      "learning_rate": 0.0002075151515151515,
      "loss": 0.2851,
      "step": 1580
    },
    {
      "epoch": 3.18,
      "grad_norm": 3.4253368377685547,
      "learning_rate": 0.0002069090909090909,
      "loss": 0.4054,
      "step": 1590
    },
    {
      "epoch": 3.2,
      "grad_norm": 3.3636484146118164,
      "learning_rate": 0.0002063030303030303,
      "loss": 0.4286,
      "step": 1600
    },
    {
      "epoch": 3.2,
      "eval_loss": 0.9705173969268799,
      "eval_runtime": 8.3919,
      "eval_samples_per_second": 23.833,
      "eval_steps_per_second": 23.833,
      "step": 1600
    },
    {
      "epoch": 3.22,
      "grad_norm": 1.7059118747711182,
      "learning_rate": 0.00020569696969696967,
      "loss": 0.3347,
      "step": 1610
    },
    {
      "epoch": 3.24,
      "grad_norm": 5.104366779327393,
      "learning_rate": 0.00020509090909090905,
      "loss": 0.2947,
      "step": 1620
    },
    {
      "epoch": 3.26,
      "grad_norm": 1.3287802934646606,
      "learning_rate": 0.00020448484848484846,
      "loss": 0.3188,
      "step": 1630
    },
    {
      "epoch": 3.2800000000000002,
      "grad_norm": 3.1412124633789062,
      "learning_rate": 0.00020387878787878788,
      "loss": 0.4813,
      "step": 1640
    },
    {
      "epoch": 3.3,
      "grad_norm": 3.272514581680298,
      "learning_rate": 0.00020327272727272726,
      "loss": 0.3834,
      "step": 1650
    },
    {
      "epoch": 3.32,
      "grad_norm": 1.7554854154586792,
      "learning_rate": 0.00020266666666666664,
      "loss": 0.3472,
      "step": 1660
    },
    {
      "epoch": 3.34,
      "grad_norm": 7.340727806091309,
      "learning_rate": 0.00020206060606060605,
      "loss": 0.2946,
      "step": 1670
    },
    {
      "epoch": 3.36,
      "grad_norm": 4.300562858581543,
      "learning_rate": 0.00020145454545454544,
      "loss": 0.3511,
      "step": 1680
    },
    {
      "epoch": 3.38,
      "grad_norm": 3.0721676349639893,
      "learning_rate": 0.00020084848484848482,
      "loss": 0.4248,
      "step": 1690
    },
    {
      "epoch": 3.4,
      "grad_norm": 3.620314121246338,
      "learning_rate": 0.0002002424242424242,
      "loss": 0.4093,
      "step": 1700
    },
    {
      "epoch": 3.4,
      "eval_loss": 0.9992559552192688,
      "eval_runtime": 8.8404,
      "eval_samples_per_second": 22.623,
      "eval_steps_per_second": 22.623,
      "step": 1700
    },
    {
      "epoch": 3.42,
      "grad_norm": 3.191690444946289,
      "learning_rate": 0.0001996363636363636,
      "loss": 0.3999,
      "step": 1710
    },
    {
      "epoch": 3.44,
      "grad_norm": 2.9383089542388916,
      "learning_rate": 0.00019903030303030302,
      "loss": 0.3166,
      "step": 1720
    },
    {
      "epoch": 3.46,
      "grad_norm": 1.9872989654541016,
      "learning_rate": 0.0001984242424242424,
      "loss": 0.4125,
      "step": 1730
    },
    {
      "epoch": 3.48,
      "grad_norm": 1.2365893125534058,
      "learning_rate": 0.00019781818181818182,
      "loss": 0.3662,
      "step": 1740
    },
    {
      "epoch": 3.5,
      "grad_norm": 2.2598869800567627,
      "learning_rate": 0.0001972121212121212,
      "loss": 0.405,
      "step": 1750
    },
    {
      "epoch": 3.52,
      "grad_norm": 3.3728671073913574,
      "learning_rate": 0.00019660606060606058,
      "loss": 0.3725,
      "step": 1760
    },
    {
      "epoch": 3.54,
      "grad_norm": 2.6517739295959473,
      "learning_rate": 0.00019599999999999997,
      "loss": 0.297,
      "step": 1770
    },
    {
      "epoch": 3.56,
      "grad_norm": 2.938714027404785,
      "learning_rate": 0.00019539393939393938,
      "loss": 0.365,
      "step": 1780
    },
    {
      "epoch": 3.58,
      "grad_norm": 1.5982403755187988,
      "learning_rate": 0.00019478787878787876,
      "loss": 0.2699,
      "step": 1790
    },
    {
      "epoch": 3.6,
      "grad_norm": 3.5013492107391357,
      "learning_rate": 0.00019418181818181814,
      "loss": 0.3766,
      "step": 1800
    },
    {
      "epoch": 3.6,
      "eval_loss": 0.992283046245575,
      "eval_runtime": 8.8805,
      "eval_samples_per_second": 22.521,
      "eval_steps_per_second": 22.521,
      "step": 1800
    },
    {
      "epoch": 3.62,
      "grad_norm": 3.995497465133667,
      "learning_rate": 0.00019357575757575758,
      "loss": 0.3974,
      "step": 1810
    },
    {
      "epoch": 3.64,
      "grad_norm": 2.927260637283325,
      "learning_rate": 0.00019296969696969696,
      "loss": 0.4134,
      "step": 1820
    },
    {
      "epoch": 3.66,
      "grad_norm": 2.9478225708007812,
      "learning_rate": 0.00019236363636363635,
      "loss": 0.3296,
      "step": 1830
    },
    {
      "epoch": 3.68,
      "grad_norm": 4.16333532333374,
      "learning_rate": 0.00019175757575757573,
      "loss": 0.3575,
      "step": 1840
    },
    {
      "epoch": 3.7,
      "grad_norm": 3.8403337001800537,
      "learning_rate": 0.00019115151515151514,
      "loss": 0.3456,
      "step": 1850
    },
    {
      "epoch": 3.7199999999999998,
      "grad_norm": 2.125169038772583,
      "learning_rate": 0.00019054545454545452,
      "loss": 0.3875,
      "step": 1860
    },
    {
      "epoch": 3.74,
      "grad_norm": 2.3224339485168457,
      "learning_rate": 0.0001899393939393939,
      "loss": 0.4435,
      "step": 1870
    },
    {
      "epoch": 3.76,
      "grad_norm": 2.3387675285339355,
      "learning_rate": 0.0001893333333333333,
      "loss": 0.3796,
      "step": 1880
    },
    {
      "epoch": 3.7800000000000002,
      "grad_norm": 3.3076562881469727,
      "learning_rate": 0.00018872727272727273,
      "loss": 0.3937,
      "step": 1890
    },
    {
      "epoch": 3.8,
      "grad_norm": 2.772808074951172,
      "learning_rate": 0.0001881212121212121,
      "loss": 0.3914,
      "step": 1900
    },
    {
      "epoch": 3.8,
      "eval_loss": 0.9917616844177246,
      "eval_runtime": 8.8531,
      "eval_samples_per_second": 22.591,
      "eval_steps_per_second": 22.591,
      "step": 1900
    },
    {
      "epoch": 3.82,
      "grad_norm": 4.807129383087158,
      "learning_rate": 0.0001875151515151515,
      "loss": 0.4436,
      "step": 1910
    },
    {
      "epoch": 3.84,
      "grad_norm": 2.7756435871124268,
      "learning_rate": 0.0001869090909090909,
      "loss": 0.3353,
      "step": 1920
    },
    {
      "epoch": 3.86,
      "grad_norm": 2.7770168781280518,
      "learning_rate": 0.0001863030303030303,
      "loss": 0.3798,
      "step": 1930
    },
    {
      "epoch": 3.88,
      "grad_norm": 2.8054542541503906,
      "learning_rate": 0.00018569696969696967,
      "loss": 0.3642,
      "step": 1940
    },
    {
      "epoch": 3.9,
      "grad_norm": 2.911552667617798,
      "learning_rate": 0.00018509090909090906,
      "loss": 0.3853,
      "step": 1950
    },
    {
      "epoch": 3.92,
      "grad_norm": 3.1882755756378174,
      "learning_rate": 0.00018448484848484847,
      "loss": 0.4268,
      "step": 1960
    },
    {
      "epoch": 3.94,
      "grad_norm": 3.171989679336548,
      "learning_rate": 0.00018387878787878785,
      "loss": 0.3598,
      "step": 1970
    },
    {
      "epoch": 3.96,
      "grad_norm": 1.311004877090454,
      "learning_rate": 0.00018327272727272726,
      "loss": 0.4039,
      "step": 1980
    },
    {
      "epoch": 3.98,
      "grad_norm": 2.0849697589874268,
      "learning_rate": 0.00018266666666666667,
      "loss": 0.3007,
      "step": 1990
    },
    {
      "epoch": 4.0,
      "grad_norm": 2.4317314624786377,
      "learning_rate": 0.00018206060606060605,
      "loss": 0.3759,
      "step": 2000
    },
    {
      "epoch": 4.0,
      "eval_loss": 0.9585912823677063,
      "eval_runtime": 8.3911,
      "eval_samples_per_second": 23.835,
      "eval_steps_per_second": 23.835,
      "step": 2000
    },
    {
      "epoch": 4.02,
      "grad_norm": 1.6869269609451294,
      "learning_rate": 0.00018145454545454544,
      "loss": 0.2436,
      "step": 2010
    },
    {
      "epoch": 4.04,
      "grad_norm": 3.762708902359009,
      "learning_rate": 0.00018084848484848482,
      "loss": 0.2783,
      "step": 2020
    },
    {
      "epoch": 4.06,
      "grad_norm": 1.289811372756958,
      "learning_rate": 0.00018024242424242423,
      "loss": 0.2666,
      "step": 2030
    },
    {
      "epoch": 4.08,
      "grad_norm": 3.1009843349456787,
      "learning_rate": 0.00017963636363636361,
      "loss": 0.2417,
      "step": 2040
    },
    {
      "epoch": 4.1,
      "grad_norm": 3.8780648708343506,
      "learning_rate": 0.000179030303030303,
      "loss": 0.3156,
      "step": 2050
    },
    {
      "epoch": 4.12,
      "grad_norm": 1.4488648176193237,
      "learning_rate": 0.00017842424242424244,
      "loss": 0.243,
      "step": 2060
    },
    {
      "epoch": 4.14,
      "grad_norm": 2.103776454925537,
      "learning_rate": 0.00017781818181818182,
      "loss": 0.3078,
      "step": 2070
    },
    {
      "epoch": 4.16,
      "grad_norm": 2.0107169151306152,
      "learning_rate": 0.0001772121212121212,
      "loss": 0.2413,
      "step": 2080
    },
    {
      "epoch": 4.18,
      "grad_norm": 2.9652907848358154,
      "learning_rate": 0.00017660606060606059,
      "loss": 0.2589,
      "step": 2090
    },
    {
      "epoch": 4.2,
      "grad_norm": 2.7192232608795166,
      "learning_rate": 0.000176,
      "loss": 0.3589,
      "step": 2100
    },
    {
      "epoch": 4.2,
      "eval_loss": 1.032345175743103,
      "eval_runtime": 8.3884,
      "eval_samples_per_second": 23.842,
      "eval_steps_per_second": 23.842,
      "step": 2100
    },
    {
      "epoch": 4.22,
      "grad_norm": 3.29054856300354,
      "learning_rate": 0.00017539393939393938,
      "loss": 0.3245,
      "step": 2110
    },
    {
      "epoch": 4.24,
      "grad_norm": 1.6548631191253662,
      "learning_rate": 0.00017478787878787876,
      "loss": 0.2668,
      "step": 2120
    },
    {
      "epoch": 4.26,
      "grad_norm": 1.9185985326766968,
      "learning_rate": 0.00017418181818181815,
      "loss": 0.3087,
      "step": 2130
    },
    {
      "epoch": 4.28,
      "grad_norm": 1.9193953275680542,
      "learning_rate": 0.00017357575757575756,
      "loss": 0.2752,
      "step": 2140
    },
    {
      "epoch": 4.3,
      "grad_norm": 1.6984565258026123,
      "learning_rate": 0.00017296969696969697,
      "loss": 0.2879,
      "step": 2150
    },
    {
      "epoch": 4.32,
      "grad_norm": 1.8534449338912964,
      "learning_rate": 0.00017236363636363635,
      "loss": 0.2888,
      "step": 2160
    },
    {
      "epoch": 4.34,
      "grad_norm": 2.079160690307617,
      "learning_rate": 0.00017175757575757576,
      "loss": 0.2989,
      "step": 2170
    },
    {
      "epoch": 4.36,
      "grad_norm": 3.3275721073150635,
      "learning_rate": 0.00017115151515151514,
      "loss": 0.3102,
      "step": 2180
    },
    {
      "epoch": 4.38,
      "grad_norm": 1.889898657798767,
      "learning_rate": 0.00017054545454545453,
      "loss": 0.3013,
      "step": 2190
    },
    {
      "epoch": 4.4,
      "grad_norm": 5.275403022766113,
      "learning_rate": 0.0001699393939393939,
      "loss": 0.3444,
      "step": 2200
    },
    {
      "epoch": 4.4,
      "eval_loss": 1.0278332233428955,
      "eval_runtime": 8.4451,
      "eval_samples_per_second": 23.682,
      "eval_steps_per_second": 23.682,
      "step": 2200
    },
    {
      "epoch": 4.42,
      "grad_norm": 2.955165147781372,
      "learning_rate": 0.00016933333333333332,
      "loss": 0.3112,
      "step": 2210
    },
    {
      "epoch": 4.44,
      "grad_norm": 2.882605791091919,
      "learning_rate": 0.0001687272727272727,
      "loss": 0.2753,
      "step": 2220
    },
    {
      "epoch": 4.46,
      "grad_norm": 2.8468756675720215,
      "learning_rate": 0.0001681212121212121,
      "loss": 0.2702,
      "step": 2230
    },
    {
      "epoch": 4.48,
      "grad_norm": 2.2024552822113037,
      "learning_rate": 0.00016751515151515152,
      "loss": 0.2761,
      "step": 2240
    },
    {
      "epoch": 4.5,
      "grad_norm": 3.1042609214782715,
      "learning_rate": 0.0001669090909090909,
      "loss": 0.2775,
      "step": 2250
    },
    {
      "epoch": 4.52,
      "grad_norm": 2.1357369422912598,
      "learning_rate": 0.0001663030303030303,
      "loss": 0.3263,
      "step": 2260
    },
    {
      "epoch": 4.54,
      "grad_norm": 2.2952072620391846,
      "learning_rate": 0.00016569696969696967,
      "loss": 0.291,
      "step": 2270
    },
    {
      "epoch": 4.5600000000000005,
      "grad_norm": 1.9778780937194824,
      "learning_rate": 0.00016509090909090908,
      "loss": 0.2682,
      "step": 2280
    },
    {
      "epoch": 4.58,
      "grad_norm": 2.7628045082092285,
      "learning_rate": 0.00016448484848484847,
      "loss": 0.3292,
      "step": 2290
    },
    {
      "epoch": 4.6,
      "grad_norm": 2.5718982219696045,
      "learning_rate": 0.00016387878787878785,
      "loss": 0.2981,
      "step": 2300
    },
    {
      "epoch": 4.6,
      "eval_loss": 1.0162469148635864,
      "eval_runtime": 8.5672,
      "eval_samples_per_second": 23.345,
      "eval_steps_per_second": 23.345,
      "step": 2300
    },
    {
      "epoch": 4.62,
      "grad_norm": 3.585395574569702,
      "learning_rate": 0.00016327272727272723,
      "loss": 0.3122,
      "step": 2310
    },
    {
      "epoch": 4.64,
      "grad_norm": 2.7576828002929688,
      "learning_rate": 0.00016266666666666667,
      "loss": 0.2935,
      "step": 2320
    },
    {
      "epoch": 4.66,
      "grad_norm": 2.77673602104187,
      "learning_rate": 0.00016206060606060606,
      "loss": 0.2879,
      "step": 2330
    },
    {
      "epoch": 4.68,
      "grad_norm": 4.0228705406188965,
      "learning_rate": 0.00016145454545454544,
      "loss": 0.3439,
      "step": 2340
    },
    {
      "epoch": 4.7,
      "grad_norm": 2.0685269832611084,
      "learning_rate": 0.00016084848484848485,
      "loss": 0.2541,
      "step": 2350
    },
    {
      "epoch": 4.72,
      "grad_norm": 2.536288022994995,
      "learning_rate": 0.00016024242424242423,
      "loss": 0.3072,
      "step": 2360
    },
    {
      "epoch": 4.74,
      "grad_norm": 1.9716789722442627,
      "learning_rate": 0.00015963636363636362,
      "loss": 0.3907,
      "step": 2370
    },
    {
      "epoch": 4.76,
      "grad_norm": 3.3841664791107178,
      "learning_rate": 0.000159030303030303,
      "loss": 0.302,
      "step": 2380
    },
    {
      "epoch": 4.78,
      "grad_norm": 3.0305614471435547,
      "learning_rate": 0.0001584242424242424,
      "loss": 0.2996,
      "step": 2390
    },
    {
      "epoch": 4.8,
      "grad_norm": 0.8058642148971558,
      "learning_rate": 0.0001578181818181818,
      "loss": 0.218,
      "step": 2400
    },
    {
      "epoch": 4.8,
      "eval_loss": 1.0304914712905884,
      "eval_runtime": 8.5771,
      "eval_samples_per_second": 23.318,
      "eval_steps_per_second": 23.318,
      "step": 2400
    },
    {
      "epoch": 4.82,
      "grad_norm": 2.442681074142456,
      "learning_rate": 0.0001572121212121212,
      "loss": 0.3296,
      "step": 2410
    },
    {
      "epoch": 4.84,
      "grad_norm": 3.2102911472320557,
      "learning_rate": 0.00015660606060606061,
      "loss": 0.2882,
      "step": 2420
    },
    {
      "epoch": 4.86,
      "grad_norm": 8.351142883300781,
      "learning_rate": 0.000156,
      "loss": 0.3273,
      "step": 2430
    },
    {
      "epoch": 4.88,
      "grad_norm": 1.4157330989837646,
      "learning_rate": 0.00015539393939393938,
      "loss": 0.2718,
      "step": 2440
    },
    {
      "epoch": 4.9,
      "grad_norm": 2.079132318496704,
      "learning_rate": 0.00015478787878787876,
      "loss": 0.3269,
      "step": 2450
    },
    {
      "epoch": 4.92,
      "grad_norm": 2.8269107341766357,
      "learning_rate": 0.00015418181818181817,
      "loss": 0.2609,
      "step": 2460
    },
    {
      "epoch": 4.9399999999999995,
      "grad_norm": 2.129020929336548,
      "learning_rate": 0.00015357575757575756,
      "loss": 0.3245,
      "step": 2470
    },
    {
      "epoch": 4.96,
      "grad_norm": 1.2657661437988281,
      "learning_rate": 0.00015296969696969694,
      "loss": 0.3101,
      "step": 2480
    },
    {
      "epoch": 4.98,
      "grad_norm": 1.0149896144866943,
      "learning_rate": 0.00015236363636363638,
      "loss": 0.304,
      "step": 2490
    },
    {
      "epoch": 5.0,
      "grad_norm": 1.98909592628479,
      "learning_rate": 0.00015175757575757576,
      "loss": 0.2728,
      "step": 2500
    },
    {
      "epoch": 5.0,
      "eval_loss": 1.0342656373977661,
      "eval_runtime": 8.422,
      "eval_samples_per_second": 23.747,
      "eval_steps_per_second": 23.747,
      "step": 2500
    },
    {
      "epoch": 5.02,
      "grad_norm": 1.9250702857971191,
      "learning_rate": 0.00015115151515151515,
      "loss": 0.2567,
      "step": 2510
    },
    {
      "epoch": 5.04,
      "grad_norm": 1.452207326889038,
      "learning_rate": 0.00015054545454545453,
      "loss": 0.2015,
      "step": 2520
    },
    {
      "epoch": 5.06,
      "grad_norm": 3.625490665435791,
      "learning_rate": 0.00014993939393939394,
      "loss": 0.1912,
      "step": 2530
    },
    {
      "epoch": 5.08,
      "grad_norm": 0.9554265141487122,
      "learning_rate": 0.00014933333333333332,
      "loss": 0.2339,
      "step": 2540
    },
    {
      "epoch": 5.1,
      "grad_norm": 1.6037580966949463,
      "learning_rate": 0.0001487272727272727,
      "loss": 0.1855,
      "step": 2550
    },
    {
      "epoch": 5.12,
      "grad_norm": 2.786381721496582,
      "learning_rate": 0.00014812121212121212,
      "loss": 0.2473,
      "step": 2560
    },
    {
      "epoch": 5.14,
      "grad_norm": 2.2637462615966797,
      "learning_rate": 0.0001475151515151515,
      "loss": 0.2283,
      "step": 2570
    },
    {
      "epoch": 5.16,
      "grad_norm": 2.7499172687530518,
      "learning_rate": 0.00014690909090909088,
      "loss": 0.2057,
      "step": 2580
    },
    {
      "epoch": 5.18,
      "grad_norm": 3.5208332538604736,
      "learning_rate": 0.0001463030303030303,
      "loss": 0.2463,
      "step": 2590
    },
    {
      "epoch": 5.2,
      "grad_norm": 1.1341990232467651,
      "learning_rate": 0.0001456969696969697,
      "loss": 0.2567,
      "step": 2600
    },
    {
      "epoch": 5.2,
      "eval_loss": 1.1186503171920776,
      "eval_runtime": 8.5565,
      "eval_samples_per_second": 23.374,
      "eval_steps_per_second": 23.374,
      "step": 2600
    },
    {
      "epoch": 5.22,
      "grad_norm": 2.5383853912353516,
      "learning_rate": 0.0001450909090909091,
      "loss": 0.2334,
      "step": 2610
    },
    {
      "epoch": 5.24,
      "grad_norm": 5.8245134353637695,
      "learning_rate": 0.00014448484848484847,
      "loss": 0.2896,
      "step": 2620
    },
    {
      "epoch": 5.26,
      "grad_norm": 1.657612919807434,
      "learning_rate": 0.00014387878787878785,
      "loss": 0.2221,
      "step": 2630
    },
    {
      "epoch": 5.28,
      "grad_norm": 2.551978588104248,
      "learning_rate": 0.00014327272727272726,
      "loss": 0.2345,
      "step": 2640
    },
    {
      "epoch": 5.3,
      "grad_norm": 2.565352201461792,
      "learning_rate": 0.00014266666666666665,
      "loss": 0.2787,
      "step": 2650
    },
    {
      "epoch": 5.32,
      "grad_norm": 1.9325149059295654,
      "learning_rate": 0.00014206060606060606,
      "loss": 0.2353,
      "step": 2660
    },
    {
      "epoch": 5.34,
      "grad_norm": 2.948582887649536,
      "learning_rate": 0.00014145454545454544,
      "loss": 0.2195,
      "step": 2670
    },
    {
      "epoch": 5.36,
      "grad_norm": 0.7336887121200562,
      "learning_rate": 0.00014084848484848485,
      "loss": 0.2129,
      "step": 2680
    },
    {
      "epoch": 5.38,
      "grad_norm": 7.3581132888793945,
      "learning_rate": 0.00014024242424242423,
      "loss": 0.2512,
      "step": 2690
    },
    {
      "epoch": 5.4,
      "grad_norm": 0.9122839570045471,
      "learning_rate": 0.00013963636363636362,
      "loss": 0.2399,
      "step": 2700
    },
    {
      "epoch": 5.4,
      "eval_loss": 1.1138495206832886,
      "eval_runtime": 8.5288,
      "eval_samples_per_second": 23.45,
      "eval_steps_per_second": 23.45,
      "step": 2700
    },
    {
      "epoch": 5.42,
      "grad_norm": 1.7986980676651,
      "learning_rate": 0.000139030303030303,
      "loss": 0.238,
      "step": 2710
    },
    {
      "epoch": 5.44,
      "grad_norm": 1.5805927515029907,
      "learning_rate": 0.0001384242424242424,
      "loss": 0.2848,
      "step": 2720
    },
    {
      "epoch": 5.46,
      "grad_norm": 2.6316466331481934,
      "learning_rate": 0.00013781818181818182,
      "loss": 0.208,
      "step": 2730
    },
    {
      "epoch": 5.48,
      "grad_norm": 1.6805516481399536,
      "learning_rate": 0.0001372121212121212,
      "loss": 0.2277,
      "step": 2740
    },
    {
      "epoch": 5.5,
      "grad_norm": 2.1519322395324707,
      "learning_rate": 0.0001366060606060606,
      "loss": 0.2114,
      "step": 2750
    },
    {
      "epoch": 5.52,
      "grad_norm": 1.126383900642395,
      "learning_rate": 0.00013599999999999997,
      "loss": 0.2206,
      "step": 2760
    },
    {
      "epoch": 5.54,
      "grad_norm": 3.3353168964385986,
      "learning_rate": 0.00013539393939393938,
      "loss": 0.2428,
      "step": 2770
    },
    {
      "epoch": 5.5600000000000005,
      "grad_norm": 2.6078970432281494,
      "learning_rate": 0.00013478787878787877,
      "loss": 0.2113,
      "step": 2780
    },
    {
      "epoch": 5.58,
      "grad_norm": 2.6800496578216553,
      "learning_rate": 0.00013418181818181818,
      "loss": 0.2902,
      "step": 2790
    },
    {
      "epoch": 5.6,
      "grad_norm": 1.0300275087356567,
      "learning_rate": 0.00013357575757575756,
      "loss": 0.2286,
      "step": 2800
    },
    {
      "epoch": 5.6,
      "eval_loss": 1.062872290611267,
      "eval_runtime": 8.3983,
      "eval_samples_per_second": 23.814,
      "eval_steps_per_second": 23.814,
      "step": 2800
    },
    {
      "epoch": 5.62,
      "grad_norm": 1.7620793581008911,
      "learning_rate": 0.00013296969696969697,
      "loss": 0.241,
      "step": 2810
    },
    {
      "epoch": 5.64,
      "grad_norm": 2.799813985824585,
      "learning_rate": 0.00013236363636363635,
      "loss": 0.2441,
      "step": 2820
    },
    {
      "epoch": 5.66,
      "grad_norm": 2.0335206985473633,
      "learning_rate": 0.00013175757575757574,
      "loss": 0.2337,
      "step": 2830
    },
    {
      "epoch": 5.68,
      "grad_norm": 2.6851747035980225,
      "learning_rate": 0.00013115151515151515,
      "loss": 0.241,
      "step": 2840
    },
    {
      "epoch": 5.7,
      "grad_norm": 1.4150876998901367,
      "learning_rate": 0.00013054545454545453,
      "loss": 0.2212,
      "step": 2850
    },
    {
      "epoch": 5.72,
      "grad_norm": 1.2365128993988037,
      "learning_rate": 0.00012993939393939394,
      "loss": 0.2553,
      "step": 2860
    },
    {
      "epoch": 5.74,
      "grad_norm": 1.965718388557434,
      "learning_rate": 0.00012933333333333332,
      "loss": 0.2871,
      "step": 2870
    },
    {
      "epoch": 5.76,
      "grad_norm": 3.2932772636413574,
      "learning_rate": 0.0001287272727272727,
      "loss": 0.2408,
      "step": 2880
    },
    {
      "epoch": 5.78,
      "grad_norm": 1.3751908540725708,
      "learning_rate": 0.0001281212121212121,
      "loss": 0.2387,
      "step": 2890
    },
    {
      "epoch": 5.8,
      "grad_norm": 1.9348808526992798,
      "learning_rate": 0.0001275151515151515,
      "loss": 0.2415,
      "step": 2900
    },
    {
      "epoch": 5.8,
      "eval_loss": 1.1068693399429321,
      "eval_runtime": 8.8843,
      "eval_samples_per_second": 22.512,
      "eval_steps_per_second": 22.512,
      "step": 2900
    },
    {
      "epoch": 5.82,
      "grad_norm": 1.3045334815979004,
      "learning_rate": 0.0001269090909090909,
      "loss": 0.2386,
      "step": 2910
    },
    {
      "epoch": 5.84,
      "grad_norm": 2.4444775581359863,
      "learning_rate": 0.0001263030303030303,
      "loss": 0.2955,
      "step": 2920
    },
    {
      "epoch": 5.86,
      "grad_norm": 2.3696370124816895,
      "learning_rate": 0.00012569696969696968,
      "loss": 0.2851,
      "step": 2930
    },
    {
      "epoch": 5.88,
      "grad_norm": 5.334808349609375,
      "learning_rate": 0.0001250909090909091,
      "loss": 0.2459,
      "step": 2940
    },
    {
      "epoch": 5.9,
      "grad_norm": 1.5700310468673706,
      "learning_rate": 0.00012448484848484847,
      "loss": 0.2508,
      "step": 2950
    },
    {
      "epoch": 5.92,
      "grad_norm": 2.3417248725891113,
      "learning_rate": 0.00012387878787878785,
      "loss": 0.2812,
      "step": 2960
    },
    {
      "epoch": 5.9399999999999995,
      "grad_norm": 2.1412038803100586,
      "learning_rate": 0.00012327272727272727,
      "loss": 0.2622,
      "step": 2970
    },
    {
      "epoch": 5.96,
      "grad_norm": 5.333791255950928,
      "learning_rate": 0.00012266666666666668,
      "loss": 0.2735,
      "step": 2980
    },
    {
      "epoch": 5.98,
      "grad_norm": 2.420886516571045,
      "learning_rate": 0.00012206060606060606,
      "loss": 0.2415,
      "step": 2990
    },
    {
      "epoch": 6.0,
      "grad_norm": 0.9824159145355225,
      "learning_rate": 0.00012145454545454544,
      "loss": 0.2594,
      "step": 3000
    },
    {
      "epoch": 6.0,
      "eval_loss": 1.1205227375030518,
      "eval_runtime": 8.493,
      "eval_samples_per_second": 23.549,
      "eval_steps_per_second": 23.549,
      "step": 3000
    },
    {
      "epoch": 6.02,
      "grad_norm": 1.2057956457138062,
      "learning_rate": 0.00012084848484848484,
      "loss": 0.1894,
      "step": 3010
    },
    {
      "epoch": 6.04,
      "grad_norm": 1.870360255241394,
      "learning_rate": 0.00012024242424242424,
      "loss": 0.1959,
      "step": 3020
    },
    {
      "epoch": 6.06,
      "grad_norm": 1.9344934225082397,
      "learning_rate": 0.00011963636363636363,
      "loss": 0.1701,
      "step": 3030
    },
    {
      "epoch": 6.08,
      "grad_norm": 2.055373191833496,
      "learning_rate": 0.00011903030303030302,
      "loss": 0.2123,
      "step": 3040
    },
    {
      "epoch": 6.1,
      "grad_norm": 2.084559440612793,
      "learning_rate": 0.00011842424242424241,
      "loss": 0.2068,
      "step": 3050
    },
    {
      "epoch": 6.12,
      "grad_norm": 1.7566386461257935,
      "learning_rate": 0.0001178181818181818,
      "loss": 0.1893,
      "step": 3060
    },
    {
      "epoch": 6.14,
      "grad_norm": 2.0619282722473145,
      "learning_rate": 0.00011721212121212121,
      "loss": 0.209,
      "step": 3070
    },
    {
      "epoch": 6.16,
      "grad_norm": 1.401980996131897,
      "learning_rate": 0.0001166060606060606,
      "loss": 0.147,
      "step": 3080
    },
    {
      "epoch": 6.18,
      "grad_norm": 3.080033302307129,
      "learning_rate": 0.00011599999999999999,
      "loss": 0.2036,
      "step": 3090
    },
    {
      "epoch": 6.2,
      "grad_norm": 2.276749610900879,
      "learning_rate": 0.00011539393939393938,
      "loss": 0.212,
      "step": 3100
    },
    {
      "epoch": 6.2,
      "eval_loss": 1.1610766649246216,
      "eval_runtime": 8.8413,
      "eval_samples_per_second": 22.621,
      "eval_steps_per_second": 22.621,
      "step": 3100
    },
    {
      "epoch": 6.22,
      "grad_norm": 1.6918041706085205,
      "learning_rate": 0.00011478787878787878,
      "loss": 0.172,
      "step": 3110
    },
    {
      "epoch": 6.24,
      "grad_norm": 0.9076359868049622,
      "learning_rate": 0.00011418181818181818,
      "loss": 0.1856,
      "step": 3120
    },
    {
      "epoch": 6.26,
      "grad_norm": 3.5203850269317627,
      "learning_rate": 0.00011357575757575756,
      "loss": 0.2175,
      "step": 3130
    },
    {
      "epoch": 6.28,
      "grad_norm": 1.8144491910934448,
      "learning_rate": 0.00011296969696969696,
      "loss": 0.209,
      "step": 3140
    },
    {
      "epoch": 6.3,
      "grad_norm": 2.1194159984588623,
      "learning_rate": 0.00011236363636363635,
      "loss": 0.2068,
      "step": 3150
    },
    {
      "epoch": 6.32,
      "grad_norm": 1.233843207359314,
      "learning_rate": 0.00011175757575757575,
      "loss": 0.1766,
      "step": 3160
    },
    {
      "epoch": 6.34,
      "grad_norm": 10.80879020690918,
      "learning_rate": 0.00011115151515151513,
      "loss": 0.1915,
      "step": 3170
    },
    {
      "epoch": 6.36,
      "grad_norm": 3.1764628887176514,
      "learning_rate": 0.00011054545454545453,
      "loss": 0.2344,
      "step": 3180
    },
    {
      "epoch": 6.38,
      "grad_norm": 2.882840871810913,
      "learning_rate": 0.00010993939393939392,
      "loss": 0.2113,
      "step": 3190
    },
    {
      "epoch": 6.4,
      "grad_norm": 1.7748372554779053,
      "learning_rate": 0.00010939393939393939,
      "loss": 0.2265,
      "step": 3200
    },
    {
      "epoch": 6.4,
      "eval_loss": 1.1569156646728516,
      "eval_runtime": 8.8353,
      "eval_samples_per_second": 22.636,
      "eval_steps_per_second": 22.636,
      "step": 3200
    },
    {
      "epoch": 6.42,
      "grad_norm": 2.335589647293091,
      "learning_rate": 0.00010878787878787878,
      "loss": 0.1975,
      "step": 3210
    },
    {
      "epoch": 6.44,
      "grad_norm": 3.377354383468628,
      "learning_rate": 0.00010818181818181817,
      "loss": 0.2082,
      "step": 3220
    },
    {
      "epoch": 6.46,
      "grad_norm": 3.0406501293182373,
      "learning_rate": 0.00010757575757575756,
      "loss": 0.2101,
      "step": 3230
    },
    {
      "epoch": 6.48,
      "grad_norm": 2.565119504928589,
      "learning_rate": 0.00010696969696969696,
      "loss": 0.2826,
      "step": 3240
    },
    {
      "epoch": 6.5,
      "grad_norm": 5.536566257476807,
      "learning_rate": 0.00010636363636363636,
      "loss": 0.2158,
      "step": 3250
    },
    {
      "epoch": 6.52,
      "grad_norm": 0.7918152213096619,
      "learning_rate": 0.00010575757575757574,
      "loss": 0.1765,
      "step": 3260
    },
    {
      "epoch": 6.54,
      "grad_norm": 2.208676338195801,
      "learning_rate": 0.00010515151515151514,
      "loss": 0.1904,
      "step": 3270
    },
    {
      "epoch": 6.5600000000000005,
      "grad_norm": 1.774970531463623,
      "learning_rate": 0.00010454545454545455,
      "loss": 0.2016,
      "step": 3280
    },
    {
      "epoch": 6.58,
      "grad_norm": 2.4181129932403564,
      "learning_rate": 0.00010393939393939393,
      "loss": 0.2188,
      "step": 3290
    },
    {
      "epoch": 6.6,
      "grad_norm": 2.2090516090393066,
      "learning_rate": 0.00010333333333333333,
      "loss": 0.2213,
      "step": 3300
    },
    {
      "epoch": 6.6,
      "eval_loss": 1.175437569618225,
      "eval_runtime": 8.4696,
      "eval_samples_per_second": 23.614,
      "eval_steps_per_second": 23.614,
      "step": 3300
    },
    {
      "epoch": 6.62,
      "grad_norm": 2.651553153991699,
      "learning_rate": 0.00010272727272727271,
      "loss": 0.2165,
      "step": 3310
    },
    {
      "epoch": 6.64,
      "grad_norm": 1.7709981203079224,
      "learning_rate": 0.00010212121212121212,
      "loss": 0.1906,
      "step": 3320
    },
    {
      "epoch": 6.66,
      "grad_norm": 1.8576714992523193,
      "learning_rate": 0.0001015151515151515,
      "loss": 0.1977,
      "step": 3330
    },
    {
      "epoch": 6.68,
      "grad_norm": 3.2550065517425537,
      "learning_rate": 0.0001009090909090909,
      "loss": 0.2034,
      "step": 3340
    },
    {
      "epoch": 6.7,
      "grad_norm": 1.0070483684539795,
      "learning_rate": 0.00010030303030303029,
      "loss": 0.2029,
      "step": 3350
    },
    {
      "epoch": 6.72,
      "grad_norm": 2.166268825531006,
      "learning_rate": 9.969696969696968e-05,
      "loss": 0.1944,
      "step": 3360
    },
    {
      "epoch": 6.74,
      "grad_norm": 1.890401005744934,
      "learning_rate": 9.90909090909091e-05,
      "loss": 0.2056,
      "step": 3370
    },
    {
      "epoch": 6.76,
      "grad_norm": 2.3905346393585205,
      "learning_rate": 9.848484848484848e-05,
      "loss": 0.2535,
      "step": 3380
    },
    {
      "epoch": 6.78,
      "grad_norm": 1.7490921020507812,
      "learning_rate": 9.787878787878787e-05,
      "loss": 0.2131,
      "step": 3390
    },
    {
      "epoch": 6.8,
      "grad_norm": 2.4201149940490723,
      "learning_rate": 9.727272727272726e-05,
      "loss": 0.2241,
      "step": 3400
    },
    {
      "epoch": 6.8,
      "eval_loss": 1.1883279085159302,
      "eval_runtime": 8.342,
      "eval_samples_per_second": 23.975,
      "eval_steps_per_second": 23.975,
      "step": 3400
    },
    {
      "epoch": 6.82,
      "grad_norm": 1.657393455505371,
      "learning_rate": 9.666666666666667e-05,
      "loss": 0.1778,
      "step": 3410
    },
    {
      "epoch": 6.84,
      "grad_norm": 2.385497570037842,
      "learning_rate": 9.606060606060605e-05,
      "loss": 0.1972,
      "step": 3420
    },
    {
      "epoch": 6.86,
      "grad_norm": 1.6717805862426758,
      "learning_rate": 9.545454545454545e-05,
      "loss": 0.249,
      "step": 3430
    },
    {
      "epoch": 6.88,
      "grad_norm": 1.1117117404937744,
      "learning_rate": 9.484848484848483e-05,
      "loss": 0.2029,
      "step": 3440
    },
    {
      "epoch": 6.9,
      "grad_norm": 4.6819844245910645,
      "learning_rate": 9.424242424242424e-05,
      "loss": 0.2471,
      "step": 3450
    },
    {
      "epoch": 6.92,
      "grad_norm": 4.140103816986084,
      "learning_rate": 9.363636363636364e-05,
      "loss": 0.2016,
      "step": 3460
    },
    {
      "epoch": 6.9399999999999995,
      "grad_norm": 1.698867678642273,
      "learning_rate": 9.303030303030302e-05,
      "loss": 0.2074,
      "step": 3470
    },
    {
      "epoch": 6.96,
      "grad_norm": 2.119135856628418,
      "learning_rate": 9.242424242424242e-05,
      "loss": 0.2199,
      "step": 3480
    },
    {
      "epoch": 6.98,
      "grad_norm": 2.775576591491699,
      "learning_rate": 9.18181818181818e-05,
      "loss": 0.2081,
      "step": 3490
    },
    {
      "epoch": 7.0,
      "grad_norm": 1.328877329826355,
      "learning_rate": 9.121212121212121e-05,
      "loss": 0.1799,
      "step": 3500
    },
    {
      "epoch": 7.0,
      "eval_loss": 1.1640647649765015,
      "eval_runtime": 8.4784,
      "eval_samples_per_second": 23.589,
      "eval_steps_per_second": 23.589,
      "step": 3500
    },
    {
      "epoch": 7.02,
      "grad_norm": 1.2281116247177124,
      "learning_rate": 9.06060606060606e-05,
      "loss": 0.1476,
      "step": 3510
    },
    {
      "epoch": 7.04,
      "grad_norm": 1.600813388824463,
      "learning_rate": 8.999999999999999e-05,
      "loss": 0.1507,
      "step": 3520
    },
    {
      "epoch": 7.06,
      "grad_norm": 1.0818063020706177,
      "learning_rate": 8.939393939393938e-05,
      "loss": 0.1571,
      "step": 3530
    },
    {
      "epoch": 7.08,
      "grad_norm": 3.8260533809661865,
      "learning_rate": 8.878787878787879e-05,
      "loss": 0.1603,
      "step": 3540
    },
    {
      "epoch": 7.1,
      "grad_norm": 1.570345401763916,
      "learning_rate": 8.818181818181817e-05,
      "loss": 0.1645,
      "step": 3550
    },
    {
      "epoch": 7.12,
      "grad_norm": 3.581082820892334,
      "learning_rate": 8.757575757575757e-05,
      "loss": 0.1695,
      "step": 3560
    },
    {
      "epoch": 7.14,
      "grad_norm": 3.4377384185791016,
      "learning_rate": 8.696969696969695e-05,
      "loss": 0.1745,
      "step": 3570
    },
    {
      "epoch": 7.16,
      "grad_norm": 2.1579980850219727,
      "learning_rate": 8.636363636363636e-05,
      "loss": 0.173,
      "step": 3580
    },
    {
      "epoch": 7.18,
      "grad_norm": 1.0927469730377197,
      "learning_rate": 8.575757575757576e-05,
      "loss": 0.162,
      "step": 3590
    },
    {
      "epoch": 7.2,
      "grad_norm": 5.074203968048096,
      "learning_rate": 8.515151515151514e-05,
      "loss": 0.1617,
      "step": 3600
    },
    {
      "epoch": 7.2,
      "eval_loss": 1.2052019834518433,
      "eval_runtime": 8.4665,
      "eval_samples_per_second": 23.622,
      "eval_steps_per_second": 23.622,
      "step": 3600
    },
    {
      "epoch": 7.22,
      "grad_norm": 1.0743718147277832,
      "learning_rate": 8.454545454545454e-05,
      "loss": 0.189,
      "step": 3610
    },
    {
      "epoch": 7.24,
      "grad_norm": 2.033320903778076,
      "learning_rate": 8.393939393939393e-05,
      "loss": 0.1752,
      "step": 3620
    },
    {
      "epoch": 7.26,
      "grad_norm": 1.6800377368927002,
      "learning_rate": 8.333333333333333e-05,
      "loss": 0.1728,
      "step": 3630
    },
    {
      "epoch": 7.28,
      "grad_norm": 1.1165223121643066,
      "learning_rate": 8.272727272727271e-05,
      "loss": 0.188,
      "step": 3640
    },
    {
      "epoch": 7.3,
      "grad_norm": 1.145973563194275,
      "learning_rate": 8.212121212121211e-05,
      "loss": 0.1701,
      "step": 3650
    },
    {
      "epoch": 7.32,
      "grad_norm": 1.5192112922668457,
      "learning_rate": 8.15151515151515e-05,
      "loss": 0.171,
      "step": 3660
    },
    {
      "epoch": 7.34,
      "grad_norm": 1.2939101457595825,
      "learning_rate": 8.09090909090909e-05,
      "loss": 0.1792,
      "step": 3670
    },
    {
      "epoch": 7.36,
      "grad_norm": 1.6355373859405518,
      "learning_rate": 8.03030303030303e-05,
      "loss": 0.1809,
      "step": 3680
    },
    {
      "epoch": 7.38,
      "grad_norm": 2.338700532913208,
      "learning_rate": 7.969696969696968e-05,
      "loss": 0.1506,
      "step": 3690
    },
    {
      "epoch": 7.4,
      "grad_norm": 1.3055757284164429,
      "learning_rate": 7.909090909090908e-05,
      "loss": 0.1494,
      "step": 3700
    },
    {
      "epoch": 7.4,
      "eval_loss": 1.2462599277496338,
      "eval_runtime": 8.4863,
      "eval_samples_per_second": 23.567,
      "eval_steps_per_second": 23.567,
      "step": 3700
    },
    {
      "epoch": 7.42,
      "grad_norm": 3.428755044937134,
      "learning_rate": 7.848484848484848e-05,
      "loss": 0.2091,
      "step": 3710
    },
    {
      "epoch": 7.44,
      "grad_norm": 2.335456609725952,
      "learning_rate": 7.787878787878788e-05,
      "loss": 0.1558,
      "step": 3720
    },
    {
      "epoch": 7.46,
      "grad_norm": 1.5178943872451782,
      "learning_rate": 7.727272727272726e-05,
      "loss": 0.1899,
      "step": 3730
    },
    {
      "epoch": 7.48,
      "grad_norm": 0.8991772532463074,
      "learning_rate": 7.666666666666666e-05,
      "loss": 0.1753,
      "step": 3740
    },
    {
      "epoch": 7.5,
      "grad_norm": 1.2214264869689941,
      "learning_rate": 7.606060606060607e-05,
      "loss": 0.2099,
      "step": 3750
    },
    {
      "epoch": 7.52,
      "grad_norm": 2.6801655292510986,
      "learning_rate": 7.545454545454545e-05,
      "loss": 0.1725,
      "step": 3760
    },
    {
      "epoch": 7.54,
      "grad_norm": 3.278235912322998,
      "learning_rate": 7.484848484848485e-05,
      "loss": 0.2078,
      "step": 3770
    },
    {
      "epoch": 7.5600000000000005,
      "grad_norm": 10.079875946044922,
      "learning_rate": 7.424242424242424e-05,
      "loss": 0.1733,
      "step": 3780
    },
    {
      "epoch": 7.58,
      "grad_norm": 1.5926605463027954,
      "learning_rate": 7.363636363636363e-05,
      "loss": 0.1789,
      "step": 3790
    },
    {
      "epoch": 7.6,
      "grad_norm": 1.1858526468276978,
      "learning_rate": 7.303030303030302e-05,
      "loss": 0.1918,
      "step": 3800
    },
    {
      "epoch": 7.6,
      "eval_loss": 1.2150970697402954,
      "eval_runtime": 8.4732,
      "eval_samples_per_second": 23.604,
      "eval_steps_per_second": 23.604,
      "step": 3800
    },
    {
      "epoch": 7.62,
      "grad_norm": 2.5453906059265137,
      "learning_rate": 7.242424242424242e-05,
      "loss": 0.2102,
      "step": 3810
    },
    {
      "epoch": 7.64,
      "grad_norm": 3.0739705562591553,
      "learning_rate": 7.18181818181818e-05,
      "loss": 0.192,
      "step": 3820
    },
    {
      "epoch": 7.66,
      "grad_norm": 2.333636522293091,
      "learning_rate": 7.12121212121212e-05,
      "loss": 0.1918,
      "step": 3830
    },
    {
      "epoch": 7.68,
      "grad_norm": 2.1958343982696533,
      "learning_rate": 7.06060606060606e-05,
      "loss": 0.1865,
      "step": 3840
    },
    {
      "epoch": 7.7,
      "grad_norm": 3.4089527130126953,
      "learning_rate": 7e-05,
      "loss": 0.1804,
      "step": 3850
    },
    {
      "epoch": 7.72,
      "grad_norm": 1.3761928081512451,
      "learning_rate": 6.939393939393939e-05,
      "loss": 0.1864,
      "step": 3860
    },
    {
      "epoch": 7.74,
      "grad_norm": 4.746391296386719,
      "learning_rate": 6.878787878787879e-05,
      "loss": 0.1851,
      "step": 3870
    },
    {
      "epoch": 7.76,
      "grad_norm": 1.1826521158218384,
      "learning_rate": 6.818181818181817e-05,
      "loss": 0.1951,
      "step": 3880
    },
    {
      "epoch": 7.78,
      "grad_norm": 2.5578582286834717,
      "learning_rate": 6.757575757575757e-05,
      "loss": 0.1805,
      "step": 3890
    },
    {
      "epoch": 7.8,
      "grad_norm": 3.4000561237335205,
      "learning_rate": 6.696969696969696e-05,
      "loss": 0.1894,
      "step": 3900
    },
    {
      "epoch": 7.8,
      "eval_loss": 1.2307909727096558,
      "eval_runtime": 8.8916,
      "eval_samples_per_second": 22.493,
      "eval_steps_per_second": 22.493,
      "step": 3900
    },
    {
      "epoch": 7.82,
      "grad_norm": 2.0296053886413574,
      "learning_rate": 6.636363636363636e-05,
      "loss": 0.1993,
      "step": 3910
    },
    {
      "epoch": 7.84,
      "grad_norm": 1.5826976299285889,
      "learning_rate": 6.58181818181818e-05,
      "loss": 0.2081,
      "step": 3920
    },
    {
      "epoch": 7.86,
      "grad_norm": 1.2012542486190796,
      "learning_rate": 6.52121212121212e-05,
      "loss": 0.1555,
      "step": 3930
    },
    {
      "epoch": 7.88,
      "grad_norm": 1.4262821674346924,
      "learning_rate": 6.46060606060606e-05,
      "loss": 0.1791,
      "step": 3940
    },
    {
      "epoch": 7.9,
      "grad_norm": 0.5615153312683105,
      "learning_rate": 6.4e-05,
      "loss": 0.1685,
      "step": 3950
    },
    {
      "epoch": 7.92,
      "grad_norm": 1.2483879327774048,
      "learning_rate": 6.33939393939394e-05,
      "loss": 0.1744,
      "step": 3960
    },
    {
      "epoch": 7.9399999999999995,
      "grad_norm": 2.252588987350464,
      "learning_rate": 6.278787878787878e-05,
      "loss": 0.182,
      "step": 3970
    },
    {
      "epoch": 7.96,
      "grad_norm": 1.7889437675476074,
      "learning_rate": 6.218181818181817e-05,
      "loss": 0.1879,
      "step": 3980
    },
    {
      "epoch": 7.98,
      "grad_norm": 1.5042556524276733,
      "learning_rate": 6.157575757575757e-05,
      "loss": 0.1753,
      "step": 3990
    },
    {
      "epoch": 8.0,
      "grad_norm": 2.032034158706665,
      "learning_rate": 6.096969696969697e-05,
      "loss": 0.2123,
      "step": 4000
    },
    {
      "epoch": 8.0,
      "eval_loss": 1.2219202518463135,
      "eval_runtime": 8.475,
      "eval_samples_per_second": 23.599,
      "eval_steps_per_second": 23.599,
      "step": 4000
    },
    {
      "epoch": 8.02,
      "grad_norm": 1.4952328205108643,
      "learning_rate": 6.036363636363636e-05,
      "loss": 0.148,
      "step": 4010
    },
    {
      "epoch": 8.04,
      "grad_norm": 1.9032059907913208,
      "learning_rate": 5.9757575757575755e-05,
      "loss": 0.1534,
      "step": 4020
    },
    {
      "epoch": 8.06,
      "grad_norm": 0.9519612193107605,
      "learning_rate": 5.9151515151515145e-05,
      "loss": 0.1546,
      "step": 4030
    },
    {
      "epoch": 8.08,
      "grad_norm": 1.7156673669815063,
      "learning_rate": 5.854545454545454e-05,
      "loss": 0.1466,
      "step": 4040
    },
    {
      "epoch": 8.1,
      "grad_norm": 1.0796303749084473,
      "learning_rate": 5.793939393939393e-05,
      "loss": 0.153,
      "step": 4050
    },
    {
      "epoch": 8.12,
      "grad_norm": 1.183915138244629,
      "learning_rate": 5.733333333333333e-05,
      "loss": 0.1463,
      "step": 4060
    },
    {
      "epoch": 8.14,
      "grad_norm": 3.554619312286377,
      "learning_rate": 5.672727272727272e-05,
      "loss": 0.1396,
      "step": 4070
    },
    {
      "epoch": 8.16,
      "grad_norm": 1.7663795948028564,
      "learning_rate": 5.612121212121212e-05,
      "loss": 0.1763,
      "step": 4080
    },
    {
      "epoch": 8.18,
      "grad_norm": 1.8454192876815796,
      "learning_rate": 5.551515151515151e-05,
      "loss": 0.1542,
      "step": 4090
    },
    {
      "epoch": 8.2,
      "grad_norm": 2.3644511699676514,
      "learning_rate": 5.490909090909091e-05,
      "loss": 0.1416,
      "step": 4100
    },
    {
      "epoch": 8.2,
      "eval_loss": 1.2863404750823975,
      "eval_runtime": 8.6609,
      "eval_samples_per_second": 23.092,
      "eval_steps_per_second": 23.092,
      "step": 4100
    },
    {
      "epoch": 8.22,
      "grad_norm": 0.9969800710678101,
      "learning_rate": 5.43030303030303e-05,
      "loss": 0.1481,
      "step": 4110
    },
    {
      "epoch": 8.24,
      "grad_norm": 1.5539854764938354,
      "learning_rate": 5.369696969696969e-05,
      "loss": 0.1626,
      "step": 4120
    },
    {
      "epoch": 8.26,
      "grad_norm": 1.9980498552322388,
      "learning_rate": 5.3090909090909087e-05,
      "loss": 0.1802,
      "step": 4130
    },
    {
      "epoch": 8.28,
      "grad_norm": 1.6476459503173828,
      "learning_rate": 5.2484848484848477e-05,
      "loss": 0.1734,
      "step": 4140
    },
    {
      "epoch": 8.3,
      "grad_norm": 1.3446438312530518,
      "learning_rate": 5.1878787878787873e-05,
      "loss": 0.1403,
      "step": 4150
    },
    {
      "epoch": 8.32,
      "grad_norm": 1.520301342010498,
      "learning_rate": 5.1272727272727264e-05,
      "loss": 0.1596,
      "step": 4160
    },
    {
      "epoch": 8.34,
      "grad_norm": 2.5190236568450928,
      "learning_rate": 5.066666666666666e-05,
      "loss": 0.1789,
      "step": 4170
    },
    {
      "epoch": 8.36,
      "grad_norm": 1.6627439260482788,
      "learning_rate": 5.006060606060605e-05,
      "loss": 0.1568,
      "step": 4180
    },
    {
      "epoch": 8.38,
      "grad_norm": 1.4797570705413818,
      "learning_rate": 4.9454545454545454e-05,
      "loss": 0.1511,
      "step": 4190
    },
    {
      "epoch": 8.4,
      "grad_norm": 2.6609554290771484,
      "learning_rate": 4.8848484848484844e-05,
      "loss": 0.152,
      "step": 4200
    },
    {
      "epoch": 8.4,
      "eval_loss": 1.2918435335159302,
      "eval_runtime": 8.4749,
      "eval_samples_per_second": 23.599,
      "eval_steps_per_second": 23.599,
      "step": 4200
    },
    {
      "epoch": 8.42,
      "grad_norm": 1.9424837827682495,
      "learning_rate": 4.824242424242424e-05,
      "loss": 0.1455,
      "step": 4210
    },
    {
      "epoch": 8.44,
      "grad_norm": 1.434245228767395,
      "learning_rate": 4.763636363636363e-05,
      "loss": 0.1777,
      "step": 4220
    },
    {
      "epoch": 8.46,
      "grad_norm": 1.2910383939743042,
      "learning_rate": 4.703030303030303e-05,
      "loss": 0.1614,
      "step": 4230
    },
    {
      "epoch": 8.48,
      "grad_norm": 2.3600575923919678,
      "learning_rate": 4.642424242424242e-05,
      "loss": 0.1658,
      "step": 4240
    },
    {
      "epoch": 8.5,
      "grad_norm": 1.7288119792938232,
      "learning_rate": 4.5818181818181815e-05,
      "loss": 0.1555,
      "step": 4250
    },
    {
      "epoch": 8.52,
      "grad_norm": 2.2565035820007324,
      "learning_rate": 4.5212121212121205e-05,
      "loss": 0.1463,
      "step": 4260
    },
    {
      "epoch": 8.54,
      "grad_norm": 1.9069008827209473,
      "learning_rate": 4.460606060606061e-05,
      "loss": 0.1411,
      "step": 4270
    },
    {
      "epoch": 8.56,
      "grad_norm": 1.3876729011535645,
      "learning_rate": 4.4e-05,
      "loss": 0.1631,
      "step": 4280
    },
    {
      "epoch": 8.58,
      "grad_norm": 1.0676311254501343,
      "learning_rate": 4.339393939393939e-05,
      "loss": 0.168,
      "step": 4290
    },
    {
      "epoch": 8.6,
      "grad_norm": 1.1220301389694214,
      "learning_rate": 4.2787878787878786e-05,
      "loss": 0.147,
      "step": 4300
    },
    {
      "epoch": 8.6,
      "eval_loss": 1.2887011766433716,
      "eval_runtime": 8.3945,
      "eval_samples_per_second": 23.825,
      "eval_steps_per_second": 23.825,
      "step": 4300
    },
    {
      "epoch": 8.62,
      "grad_norm": 1.0779435634613037,
      "learning_rate": 4.2181818181818176e-05,
      "loss": 0.1554,
      "step": 4310
    },
    {
      "epoch": 8.64,
      "grad_norm": 2.480586290359497,
      "learning_rate": 4.157575757575757e-05,
      "loss": 0.1904,
      "step": 4320
    },
    {
      "epoch": 8.66,
      "grad_norm": 3.1319165229797363,
      "learning_rate": 4.096969696969696e-05,
      "loss": 0.1641,
      "step": 4330
    },
    {
      "epoch": 8.68,
      "grad_norm": 1.2270005941390991,
      "learning_rate": 4.036363636363636e-05,
      "loss": 0.1378,
      "step": 4340
    },
    {
      "epoch": 8.7,
      "grad_norm": 1.1545840501785278,
      "learning_rate": 3.975757575757575e-05,
      "loss": 0.1436,
      "step": 4350
    },
    {
      "epoch": 8.72,
      "grad_norm": 1.6032670736312866,
      "learning_rate": 3.9151515151515153e-05,
      "loss": 0.1744,
      "step": 4360
    },
    {
      "epoch": 8.74,
      "grad_norm": 1.179451823234558,
      "learning_rate": 3.8545454545454544e-05,
      "loss": 0.1468,
      "step": 4370
    },
    {
      "epoch": 8.76,
      "grad_norm": 1.7824985980987549,
      "learning_rate": 3.793939393939394e-05,
      "loss": 0.1327,
      "step": 4380
    },
    {
      "epoch": 8.78,
      "grad_norm": 2.0770161151885986,
      "learning_rate": 3.733333333333333e-05,
      "loss": 0.1806,
      "step": 4390
    },
    {
      "epoch": 8.8,
      "grad_norm": 1.288549542427063,
      "learning_rate": 3.672727272727272e-05,
      "loss": 0.1556,
      "step": 4400
    },
    {
      "epoch": 8.8,
      "eval_loss": 1.2769864797592163,
      "eval_runtime": 8.4594,
      "eval_samples_per_second": 23.642,
      "eval_steps_per_second": 23.642,
      "step": 4400
    },
    {
      "epoch": 8.82,
      "grad_norm": 2.9568073749542236,
      "learning_rate": 3.612121212121212e-05,
      "loss": 0.1735,
      "step": 4410
    },
    {
      "epoch": 8.84,
      "grad_norm": 1.5031545162200928,
      "learning_rate": 3.5515151515151514e-05,
      "loss": 0.1869,
      "step": 4420
    },
    {
      "epoch": 8.86,
      "grad_norm": 3.0219051837921143,
      "learning_rate": 3.4909090909090904e-05,
      "loss": 0.1809,
      "step": 4430
    },
    {
      "epoch": 8.88,
      "grad_norm": 2.432485580444336,
      "learning_rate": 3.43030303030303e-05,
      "loss": 0.1588,
      "step": 4440
    },
    {
      "epoch": 8.9,
      "grad_norm": 3.5772509574890137,
      "learning_rate": 3.369696969696969e-05,
      "loss": 0.1604,
      "step": 4450
    },
    {
      "epoch": 8.92,
      "grad_norm": 1.100866675376892,
      "learning_rate": 3.309090909090909e-05,
      "loss": 0.1515,
      "step": 4460
    },
    {
      "epoch": 8.94,
      "grad_norm": 4.727199077606201,
      "learning_rate": 3.2484848484848485e-05,
      "loss": 0.1652,
      "step": 4470
    },
    {
      "epoch": 8.96,
      "grad_norm": 1.4664185047149658,
      "learning_rate": 3.1878787878787875e-05,
      "loss": 0.1702,
      "step": 4480
    },
    {
      "epoch": 8.98,
      "grad_norm": 1.4963936805725098,
      "learning_rate": 3.127272727272727e-05,
      "loss": 0.1424,
      "step": 4490
    },
    {
      "epoch": 9.0,
      "grad_norm": 2.577475070953369,
      "learning_rate": 3.066666666666667e-05,
      "loss": 0.1566,
      "step": 4500
    },
    {
      "epoch": 9.0,
      "eval_loss": 1.2752618789672852,
      "eval_runtime": 8.8537,
      "eval_samples_per_second": 22.589,
      "eval_steps_per_second": 22.589,
      "step": 4500
    }
  ],
  "logging_steps": 10,
  "max_steps": 5000,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 10,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 1.3472250200064e+16,
  "train_batch_size": 1,
  "trial_name": null,
  "trial_params": null
}

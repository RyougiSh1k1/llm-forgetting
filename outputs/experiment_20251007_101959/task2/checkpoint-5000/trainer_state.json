{
  "best_global_step": null,
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 10.0,
  "eval_steps": 100,
  "global_step": 5000,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.02,
      "grad_norm": 20.788599014282227,
      "learning_rate": 3.5999999999999994e-05,
      "loss": 4.8846,
      "step": 10
    },
    {
      "epoch": 0.04,
      "grad_norm": 7.722951412200928,
      "learning_rate": 9.599999999999999e-05,
      "loss": 3.6474,
      "step": 20
    },
    {
      "epoch": 0.06,
      "grad_norm": 6.048445701599121,
      "learning_rate": 0.000156,
      "loss": 2.3636,
      "step": 30
    },
    {
      "epoch": 0.08,
      "grad_norm": 4.085275173187256,
      "learning_rate": 0.00021599999999999996,
      "loss": 1.6064,
      "step": 40
    },
    {
      "epoch": 0.1,
      "grad_norm": 2.537984848022461,
      "learning_rate": 0.000276,
      "loss": 1.4412,
      "step": 50
    },
    {
      "epoch": 0.12,
      "grad_norm": 2.563957929611206,
      "learning_rate": 0.00029963636363636363,
      "loss": 1.4902,
      "step": 60
    },
    {
      "epoch": 0.14,
      "grad_norm": 2.1937201023101807,
      "learning_rate": 0.000299030303030303,
      "loss": 1.3998,
      "step": 70
    },
    {
      "epoch": 0.16,
      "grad_norm": 2.4062862396240234,
      "learning_rate": 0.0002984242424242424,
      "loss": 1.3081,
      "step": 80
    },
    {
      "epoch": 0.18,
      "grad_norm": 2.0826544761657715,
      "learning_rate": 0.00029781818181818175,
      "loss": 1.2589,
      "step": 90
    },
    {
      "epoch": 0.2,
      "grad_norm": 2.43731689453125,
      "learning_rate": 0.0002972121212121212,
      "loss": 1.0661,
      "step": 100
    },
    {
      "epoch": 0.2,
      "eval_loss": 1.3491220474243164,
      "eval_runtime": 8.3052,
      "eval_samples_per_second": 24.081,
      "eval_steps_per_second": 24.081,
      "step": 100
    },
    {
      "epoch": 0.22,
      "grad_norm": 2.723761796951294,
      "learning_rate": 0.0002966060606060606,
      "loss": 1.0929,
      "step": 110
    },
    {
      "epoch": 0.24,
      "grad_norm": 2.55906343460083,
      "learning_rate": 0.000296,
      "loss": 1.3819,
      "step": 120
    },
    {
      "epoch": 0.26,
      "grad_norm": 2.5648112297058105,
      "learning_rate": 0.0002953939393939394,
      "loss": 1.1184,
      "step": 130
    },
    {
      "epoch": 0.28,
      "grad_norm": 1.8137750625610352,
      "learning_rate": 0.00029478787878787875,
      "loss": 1.065,
      "step": 140
    },
    {
      "epoch": 0.3,
      "grad_norm": 3.1553263664245605,
      "learning_rate": 0.00029418181818181816,
      "loss": 1.4307,
      "step": 150
    },
    {
      "epoch": 0.32,
      "grad_norm": 2.5592854022979736,
      "learning_rate": 0.0002935757575757575,
      "loss": 1.4506,
      "step": 160
    },
    {
      "epoch": 0.34,
      "grad_norm": 2.032785177230835,
      "learning_rate": 0.00029296969696969693,
      "loss": 1.3856,
      "step": 170
    },
    {
      "epoch": 0.36,
      "grad_norm": 2.5884337425231934,
      "learning_rate": 0.00029236363636363634,
      "loss": 1.1487,
      "step": 180
    },
    {
      "epoch": 0.38,
      "grad_norm": 2.513716220855713,
      "learning_rate": 0.00029175757575757575,
      "loss": 1.3546,
      "step": 190
    },
    {
      "epoch": 0.4,
      "grad_norm": 2.785922050476074,
      "learning_rate": 0.00029115151515151516,
      "loss": 1.121,
      "step": 200
    },
    {
      "epoch": 0.4,
      "eval_loss": 1.293134331703186,
      "eval_runtime": 8.3463,
      "eval_samples_per_second": 23.963,
      "eval_steps_per_second": 23.963,
      "step": 200
    },
    {
      "epoch": 0.42,
      "grad_norm": 1.889014720916748,
      "learning_rate": 0.0002905454545454545,
      "loss": 1.3803,
      "step": 210
    },
    {
      "epoch": 0.44,
      "grad_norm": 1.6480484008789062,
      "learning_rate": 0.0002899393939393939,
      "loss": 1.2116,
      "step": 220
    },
    {
      "epoch": 0.46,
      "grad_norm": 2.8069589138031006,
      "learning_rate": 0.0002893333333333333,
      "loss": 1.2939,
      "step": 230
    },
    {
      "epoch": 0.48,
      "grad_norm": 1.8041050434112549,
      "learning_rate": 0.0002887272727272727,
      "loss": 1.2756,
      "step": 240
    },
    {
      "epoch": 0.5,
      "grad_norm": 2.498398780822754,
      "learning_rate": 0.0002881212121212121,
      "loss": 1.2471,
      "step": 250
    },
    {
      "epoch": 0.52,
      "grad_norm": 2.7260053157806396,
      "learning_rate": 0.00028751515151515146,
      "loss": 1.1025,
      "step": 260
    },
    {
      "epoch": 0.54,
      "grad_norm": 2.19099497795105,
      "learning_rate": 0.0002869090909090909,
      "loss": 1.3941,
      "step": 270
    },
    {
      "epoch": 0.56,
      "grad_norm": 2.599045753479004,
      "learning_rate": 0.0002863030303030303,
      "loss": 1.2085,
      "step": 280
    },
    {
      "epoch": 0.58,
      "grad_norm": 1.8689368963241577,
      "learning_rate": 0.0002856969696969697,
      "loss": 1.2266,
      "step": 290
    },
    {
      "epoch": 0.6,
      "grad_norm": 1.5851857662200928,
      "learning_rate": 0.00028509090909090905,
      "loss": 1.3812,
      "step": 300
    },
    {
      "epoch": 0.6,
      "eval_loss": 1.2801038026809692,
      "eval_runtime": 8.3212,
      "eval_samples_per_second": 24.035,
      "eval_steps_per_second": 24.035,
      "step": 300
    },
    {
      "epoch": 0.62,
      "grad_norm": 2.360945701599121,
      "learning_rate": 0.00028448484848484846,
      "loss": 1.2103,
      "step": 310
    },
    {
      "epoch": 0.64,
      "grad_norm": 2.33096981048584,
      "learning_rate": 0.00028387878787878787,
      "loss": 1.0801,
      "step": 320
    },
    {
      "epoch": 0.66,
      "grad_norm": 1.8178552389144897,
      "learning_rate": 0.0002832727272727272,
      "loss": 1.2496,
      "step": 330
    },
    {
      "epoch": 0.68,
      "grad_norm": 2.492278575897217,
      "learning_rate": 0.00028266666666666663,
      "loss": 1.2957,
      "step": 340
    },
    {
      "epoch": 0.7,
      "grad_norm": 1.53425133228302,
      "learning_rate": 0.00028206060606060605,
      "loss": 1.1335,
      "step": 350
    },
    {
      "epoch": 0.72,
      "grad_norm": 2.4668631553649902,
      "learning_rate": 0.00028145454545454546,
      "loss": 1.1173,
      "step": 360
    },
    {
      "epoch": 0.74,
      "grad_norm": 3.4307262897491455,
      "learning_rate": 0.0002808484848484848,
      "loss": 1.3755,
      "step": 370
    },
    {
      "epoch": 0.76,
      "grad_norm": 2.6253228187561035,
      "learning_rate": 0.0002802424242424242,
      "loss": 1.3563,
      "step": 380
    },
    {
      "epoch": 0.78,
      "grad_norm": 2.1975629329681396,
      "learning_rate": 0.00027963636363636363,
      "loss": 1.4193,
      "step": 390
    },
    {
      "epoch": 0.8,
      "grad_norm": 1.9004210233688354,
      "learning_rate": 0.000279030303030303,
      "loss": 1.196,
      "step": 400
    },
    {
      "epoch": 0.8,
      "eval_loss": 1.2683244943618774,
      "eval_runtime": 8.3805,
      "eval_samples_per_second": 23.865,
      "eval_steps_per_second": 23.865,
      "step": 400
    },
    {
      "epoch": 0.82,
      "grad_norm": 1.8287540674209595,
      "learning_rate": 0.0002784242424242424,
      "loss": 1.1156,
      "step": 410
    },
    {
      "epoch": 0.84,
      "grad_norm": 1.9484572410583496,
      "learning_rate": 0.0002778181818181818,
      "loss": 0.9865,
      "step": 420
    },
    {
      "epoch": 0.86,
      "grad_norm": 2.4064226150512695,
      "learning_rate": 0.00027721212121212117,
      "loss": 1.4356,
      "step": 430
    },
    {
      "epoch": 0.88,
      "grad_norm": 2.1319684982299805,
      "learning_rate": 0.0002766060606060606,
      "loss": 1.2215,
      "step": 440
    },
    {
      "epoch": 0.9,
      "grad_norm": 2.0601611137390137,
      "learning_rate": 0.000276,
      "loss": 1.2925,
      "step": 450
    },
    {
      "epoch": 0.92,
      "grad_norm": 3.394808530807495,
      "learning_rate": 0.0002753939393939394,
      "loss": 1.163,
      "step": 460
    },
    {
      "epoch": 0.94,
      "grad_norm": 2.319035530090332,
      "learning_rate": 0.00027478787878787875,
      "loss": 1.2526,
      "step": 470
    },
    {
      "epoch": 0.96,
      "grad_norm": 1.9323824644088745,
      "learning_rate": 0.00027418181818181816,
      "loss": 1.3272,
      "step": 480
    },
    {
      "epoch": 0.98,
      "grad_norm": 1.7164441347122192,
      "learning_rate": 0.0002735757575757576,
      "loss": 1.2374,
      "step": 490
    },
    {
      "epoch": 1.0,
      "grad_norm": 2.735447883605957,
      "learning_rate": 0.00027296969696969693,
      "loss": 1.4333,
      "step": 500
    },
    {
      "epoch": 1.0,
      "eval_loss": 1.2584270238876343,
      "eval_runtime": 8.4967,
      "eval_samples_per_second": 23.538,
      "eval_steps_per_second": 23.538,
      "step": 500
    },
    {
      "epoch": 1.02,
      "grad_norm": 1.778694748878479,
      "learning_rate": 0.00027236363636363634,
      "loss": 1.2132,
      "step": 510
    },
    {
      "epoch": 1.04,
      "grad_norm": 1.000161051750183,
      "learning_rate": 0.0002717575757575757,
      "loss": 1.0924,
      "step": 520
    },
    {
      "epoch": 1.06,
      "grad_norm": 2.2482810020446777,
      "learning_rate": 0.00027115151515151516,
      "loss": 0.8986,
      "step": 530
    },
    {
      "epoch": 1.08,
      "grad_norm": 4.429777145385742,
      "learning_rate": 0.0002705454545454545,
      "loss": 0.952,
      "step": 540
    },
    {
      "epoch": 1.1,
      "grad_norm": 2.2755260467529297,
      "learning_rate": 0.00026993939393939393,
      "loss": 0.9053,
      "step": 550
    },
    {
      "epoch": 1.12,
      "grad_norm": 1.883063554763794,
      "learning_rate": 0.00026933333333333334,
      "loss": 1.0349,
      "step": 560
    },
    {
      "epoch": 1.1400000000000001,
      "grad_norm": 2.8001255989074707,
      "learning_rate": 0.0002687272727272727,
      "loss": 0.967,
      "step": 570
    },
    {
      "epoch": 1.16,
      "grad_norm": 2.204253673553467,
      "learning_rate": 0.0002681212121212121,
      "loss": 0.9635,
      "step": 580
    },
    {
      "epoch": 1.18,
      "grad_norm": 3.2555766105651855,
      "learning_rate": 0.00026751515151515146,
      "loss": 1.1258,
      "step": 590
    },
    {
      "epoch": 1.2,
      "grad_norm": 2.456810235977173,
      "learning_rate": 0.00026690909090909087,
      "loss": 1.016,
      "step": 600
    },
    {
      "epoch": 1.2,
      "eval_loss": 1.290378212928772,
      "eval_runtime": 8.3613,
      "eval_samples_per_second": 23.92,
      "eval_steps_per_second": 23.92,
      "step": 600
    },
    {
      "epoch": 1.22,
      "grad_norm": 2.252378225326538,
      "learning_rate": 0.0002663030303030303,
      "loss": 1.1855,
      "step": 610
    },
    {
      "epoch": 1.24,
      "grad_norm": 2.4354281425476074,
      "learning_rate": 0.0002656969696969697,
      "loss": 0.8938,
      "step": 620
    },
    {
      "epoch": 1.26,
      "grad_norm": 3.1943459510803223,
      "learning_rate": 0.00026509090909090905,
      "loss": 1.1817,
      "step": 630
    },
    {
      "epoch": 1.28,
      "grad_norm": 2.8549671173095703,
      "learning_rate": 0.00026448484848484846,
      "loss": 0.9607,
      "step": 640
    },
    {
      "epoch": 1.3,
      "grad_norm": 2.2902188301086426,
      "learning_rate": 0.00026387878787878787,
      "loss": 0.8993,
      "step": 650
    },
    {
      "epoch": 1.32,
      "grad_norm": 3.022796392440796,
      "learning_rate": 0.0002632727272727272,
      "loss": 1.0051,
      "step": 660
    },
    {
      "epoch": 1.34,
      "grad_norm": 2.5475966930389404,
      "learning_rate": 0.00026266666666666664,
      "loss": 0.9972,
      "step": 670
    },
    {
      "epoch": 1.3599999999999999,
      "grad_norm": 2.1734490394592285,
      "learning_rate": 0.00026206060606060605,
      "loss": 1.118,
      "step": 680
    },
    {
      "epoch": 1.38,
      "grad_norm": 2.5244526863098145,
      "learning_rate": 0.0002614545454545454,
      "loss": 1.029,
      "step": 690
    },
    {
      "epoch": 1.4,
      "grad_norm": 2.996542453765869,
      "learning_rate": 0.0002608484848484848,
      "loss": 1.2022,
      "step": 700
    },
    {
      "epoch": 1.4,
      "eval_loss": 1.2921720743179321,
      "eval_runtime": 8.4882,
      "eval_samples_per_second": 23.562,
      "eval_steps_per_second": 23.562,
      "step": 700
    },
    {
      "epoch": 1.42,
      "grad_norm": 2.335610866546631,
      "learning_rate": 0.0002602424242424242,
      "loss": 1.0858,
      "step": 710
    },
    {
      "epoch": 1.44,
      "grad_norm": 2.925466537475586,
      "learning_rate": 0.00025963636363636363,
      "loss": 1.0406,
      "step": 720
    },
    {
      "epoch": 1.46,
      "grad_norm": 2.3421432971954346,
      "learning_rate": 0.000259030303030303,
      "loss": 1.1128,
      "step": 730
    },
    {
      "epoch": 1.48,
      "grad_norm": 1.4417846202850342,
      "learning_rate": 0.0002584242424242424,
      "loss": 0.904,
      "step": 740
    },
    {
      "epoch": 1.5,
      "grad_norm": 2.2203903198242188,
      "learning_rate": 0.0002578181818181818,
      "loss": 0.991,
      "step": 750
    },
    {
      "epoch": 1.52,
      "grad_norm": 2.4011406898498535,
      "learning_rate": 0.00025721212121212117,
      "loss": 0.9428,
      "step": 760
    },
    {
      "epoch": 1.54,
      "grad_norm": 2.1964526176452637,
      "learning_rate": 0.0002566060606060606,
      "loss": 1.0608,
      "step": 770
    },
    {
      "epoch": 1.56,
      "grad_norm": 2.0247013568878174,
      "learning_rate": 0.000256,
      "loss": 0.8906,
      "step": 780
    },
    {
      "epoch": 1.58,
      "grad_norm": 2.658097982406616,
      "learning_rate": 0.0002553939393939394,
      "loss": 1.0587,
      "step": 790
    },
    {
      "epoch": 1.6,
      "grad_norm": 2.7588682174682617,
      "learning_rate": 0.00025478787878787876,
      "loss": 1.08,
      "step": 800
    },
    {
      "epoch": 1.6,
      "eval_loss": 1.2858223915100098,
      "eval_runtime": 8.3616,
      "eval_samples_per_second": 23.919,
      "eval_steps_per_second": 23.919,
      "step": 800
    },
    {
      "epoch": 1.62,
      "grad_norm": 2.0871782302856445,
      "learning_rate": 0.00025418181818181817,
      "loss": 1.0517,
      "step": 810
    },
    {
      "epoch": 1.6400000000000001,
      "grad_norm": 3.0088186264038086,
      "learning_rate": 0.0002535757575757576,
      "loss": 1.0805,
      "step": 820
    },
    {
      "epoch": 1.6600000000000001,
      "grad_norm": 3.1908979415893555,
      "learning_rate": 0.00025296969696969693,
      "loss": 1.1871,
      "step": 830
    },
    {
      "epoch": 1.6800000000000002,
      "grad_norm": 3.4513745307922363,
      "learning_rate": 0.00025236363636363634,
      "loss": 1.2432,
      "step": 840
    },
    {
      "epoch": 1.7,
      "grad_norm": 2.5660269260406494,
      "learning_rate": 0.0002517575757575757,
      "loss": 0.9157,
      "step": 850
    },
    {
      "epoch": 1.72,
      "grad_norm": 2.4701383113861084,
      "learning_rate": 0.0002511515151515151,
      "loss": 1.0721,
      "step": 860
    },
    {
      "epoch": 1.74,
      "grad_norm": 2.3640685081481934,
      "learning_rate": 0.0002505454545454545,
      "loss": 0.9423,
      "step": 870
    },
    {
      "epoch": 1.76,
      "grad_norm": 3.3965628147125244,
      "learning_rate": 0.00024993939393939393,
      "loss": 1.146,
      "step": 880
    },
    {
      "epoch": 1.78,
      "grad_norm": 2.6655542850494385,
      "learning_rate": 0.00024933333333333334,
      "loss": 1.0132,
      "step": 890
    },
    {
      "epoch": 1.8,
      "grad_norm": 2.6536929607391357,
      "learning_rate": 0.0002487272727272727,
      "loss": 0.9781,
      "step": 900
    },
    {
      "epoch": 1.8,
      "eval_loss": 1.2855547666549683,
      "eval_runtime": 8.3845,
      "eval_samples_per_second": 23.854,
      "eval_steps_per_second": 23.854,
      "step": 900
    },
    {
      "epoch": 1.8199999999999998,
      "grad_norm": 3.17092227935791,
      "learning_rate": 0.0002481212121212121,
      "loss": 0.9894,
      "step": 910
    },
    {
      "epoch": 1.8399999999999999,
      "grad_norm": 4.556439399719238,
      "learning_rate": 0.00024751515151515146,
      "loss": 1.1892,
      "step": 920
    },
    {
      "epoch": 1.8599999999999999,
      "grad_norm": 2.300058603286743,
      "learning_rate": 0.0002469090909090909,
      "loss": 0.9219,
      "step": 930
    },
    {
      "epoch": 1.88,
      "grad_norm": 2.364719867706299,
      "learning_rate": 0.0002463030303030303,
      "loss": 1.0508,
      "step": 940
    },
    {
      "epoch": 1.9,
      "grad_norm": 3.4463791847229004,
      "learning_rate": 0.00024569696969696964,
      "loss": 0.9441,
      "step": 950
    },
    {
      "epoch": 1.92,
      "grad_norm": 2.9589130878448486,
      "learning_rate": 0.0002450909090909091,
      "loss": 0.9397,
      "step": 960
    },
    {
      "epoch": 1.94,
      "grad_norm": 3.8540539741516113,
      "learning_rate": 0.00024448484848484846,
      "loss": 0.8976,
      "step": 970
    },
    {
      "epoch": 1.96,
      "grad_norm": 2.9543685913085938,
      "learning_rate": 0.00024387878787878787,
      "loss": 1.2179,
      "step": 980
    },
    {
      "epoch": 1.98,
      "grad_norm": 3.055506706237793,
      "learning_rate": 0.00024327272727272725,
      "loss": 1.192,
      "step": 990
    },
    {
      "epoch": 2.0,
      "grad_norm": 2.294754981994629,
      "learning_rate": 0.00024266666666666664,
      "loss": 0.7925,
      "step": 1000
    },
    {
      "epoch": 2.0,
      "eval_loss": 1.2810418605804443,
      "eval_runtime": 8.4672,
      "eval_samples_per_second": 23.621,
      "eval_steps_per_second": 23.621,
      "step": 1000
    },
    {
      "epoch": 2.02,
      "grad_norm": 2.738079309463501,
      "learning_rate": 0.00024206060606060602,
      "loss": 0.6046,
      "step": 1010
    },
    {
      "epoch": 2.04,
      "grad_norm": 7.531743049621582,
      "learning_rate": 0.00024145454545454543,
      "loss": 0.6627,
      "step": 1020
    },
    {
      "epoch": 2.06,
      "grad_norm": 3.147780656814575,
      "learning_rate": 0.00024084848484848482,
      "loss": 0.8891,
      "step": 1030
    },
    {
      "epoch": 2.08,
      "grad_norm": 3.340425729751587,
      "learning_rate": 0.00024024242424242423,
      "loss": 0.721,
      "step": 1040
    },
    {
      "epoch": 2.1,
      "grad_norm": 3.086094856262207,
      "learning_rate": 0.00023963636363636364,
      "loss": 0.6133,
      "step": 1050
    },
    {
      "epoch": 2.12,
      "grad_norm": 0.43009838461875916,
      "learning_rate": 0.00023903030303030302,
      "loss": 0.9337,
      "step": 1060
    },
    {
      "epoch": 2.14,
      "grad_norm": 3.0574965476989746,
      "learning_rate": 0.0002384242424242424,
      "loss": 0.7944,
      "step": 1070
    },
    {
      "epoch": 2.16,
      "grad_norm": 2.924511432647705,
      "learning_rate": 0.00023781818181818179,
      "loss": 0.8383,
      "step": 1080
    },
    {
      "epoch": 2.18,
      "grad_norm": 3.0546715259552,
      "learning_rate": 0.0002372121212121212,
      "loss": 0.7315,
      "step": 1090
    },
    {
      "epoch": 2.2,
      "grad_norm": 4.14332389831543,
      "learning_rate": 0.00023660606060606058,
      "loss": 0.6542,
      "step": 1100
    },
    {
      "epoch": 2.2,
      "eval_loss": 1.3846532106399536,
      "eval_runtime": 8.5147,
      "eval_samples_per_second": 23.489,
      "eval_steps_per_second": 23.489,
      "step": 1100
    },
    {
      "epoch": 2.22,
      "grad_norm": 3.279345750808716,
      "learning_rate": 0.00023599999999999996,
      "loss": 0.7676,
      "step": 1110
    },
    {
      "epoch": 2.24,
      "grad_norm": 6.377760887145996,
      "learning_rate": 0.00023539393939393935,
      "loss": 0.7844,
      "step": 1120
    },
    {
      "epoch": 2.26,
      "grad_norm": 2.223440647125244,
      "learning_rate": 0.00023478787878787878,
      "loss": 0.6387,
      "step": 1130
    },
    {
      "epoch": 2.2800000000000002,
      "grad_norm": 2.969494104385376,
      "learning_rate": 0.00023418181818181817,
      "loss": 0.8471,
      "step": 1140
    },
    {
      "epoch": 2.3,
      "grad_norm": 4.717640399932861,
      "learning_rate": 0.00023357575757575755,
      "loss": 0.6737,
      "step": 1150
    },
    {
      "epoch": 2.32,
      "grad_norm": 2.61985445022583,
      "learning_rate": 0.00023296969696969696,
      "loss": 0.6828,
      "step": 1160
    },
    {
      "epoch": 2.34,
      "grad_norm": 2.1649060249328613,
      "learning_rate": 0.00023236363636363634,
      "loss": 0.6972,
      "step": 1170
    },
    {
      "epoch": 2.36,
      "grad_norm": 3.39762806892395,
      "learning_rate": 0.00023175757575757573,
      "loss": 0.7988,
      "step": 1180
    },
    {
      "epoch": 2.38,
      "grad_norm": 3.342259645462036,
      "learning_rate": 0.0002311515151515151,
      "loss": 0.8501,
      "step": 1190
    },
    {
      "epoch": 2.4,
      "grad_norm": 2.482815742492676,
      "learning_rate": 0.00023054545454545452,
      "loss": 0.7282,
      "step": 1200
    },
    {
      "epoch": 2.4,
      "eval_loss": 1.3874964714050293,
      "eval_runtime": 8.3778,
      "eval_samples_per_second": 23.873,
      "eval_steps_per_second": 23.873,
      "step": 1200
    },
    {
      "epoch": 2.42,
      "grad_norm": 3.7695000171661377,
      "learning_rate": 0.00022993939393939393,
      "loss": 0.7555,
      "step": 1210
    },
    {
      "epoch": 2.44,
      "grad_norm": 3.0421488285064697,
      "learning_rate": 0.00022933333333333332,
      "loss": 0.8245,
      "step": 1220
    },
    {
      "epoch": 2.46,
      "grad_norm": 2.9065022468566895,
      "learning_rate": 0.00022872727272727273,
      "loss": 0.6871,
      "step": 1230
    },
    {
      "epoch": 2.48,
      "grad_norm": 1.9024003744125366,
      "learning_rate": 0.0002281212121212121,
      "loss": 0.7726,
      "step": 1240
    },
    {
      "epoch": 2.5,
      "grad_norm": 3.7290198802948,
      "learning_rate": 0.0002275151515151515,
      "loss": 0.7354,
      "step": 1250
    },
    {
      "epoch": 2.52,
      "grad_norm": 3.14257550239563,
      "learning_rate": 0.00022690909090909088,
      "loss": 0.7412,
      "step": 1260
    },
    {
      "epoch": 2.54,
      "grad_norm": 2.5741615295410156,
      "learning_rate": 0.00022630303030303029,
      "loss": 0.8746,
      "step": 1270
    },
    {
      "epoch": 2.56,
      "grad_norm": 2.3829026222229004,
      "learning_rate": 0.00022569696969696967,
      "loss": 0.7551,
      "step": 1280
    },
    {
      "epoch": 2.58,
      "grad_norm": 5.103395938873291,
      "learning_rate": 0.00022509090909090905,
      "loss": 0.8945,
      "step": 1290
    },
    {
      "epoch": 2.6,
      "grad_norm": 4.174041748046875,
      "learning_rate": 0.0002244848484848485,
      "loss": 0.8501,
      "step": 1300
    },
    {
      "epoch": 2.6,
      "eval_loss": 1.3958346843719482,
      "eval_runtime": 8.3765,
      "eval_samples_per_second": 23.876,
      "eval_steps_per_second": 23.876,
      "step": 1300
    },
    {
      "epoch": 2.62,
      "grad_norm": 4.623409271240234,
      "learning_rate": 0.00022387878787878787,
      "loss": 0.7564,
      "step": 1310
    },
    {
      "epoch": 2.64,
      "grad_norm": 3.1204638481140137,
      "learning_rate": 0.00022327272727272726,
      "loss": 0.8474,
      "step": 1320
    },
    {
      "epoch": 2.66,
      "grad_norm": 2.4491233825683594,
      "learning_rate": 0.00022266666666666664,
      "loss": 0.8567,
      "step": 1330
    },
    {
      "epoch": 2.68,
      "grad_norm": 2.83192777633667,
      "learning_rate": 0.00022206060606060605,
      "loss": 0.7826,
      "step": 1340
    },
    {
      "epoch": 2.7,
      "grad_norm": 3.010483503341675,
      "learning_rate": 0.00022145454545454543,
      "loss": 0.6509,
      "step": 1350
    },
    {
      "epoch": 2.7199999999999998,
      "grad_norm": 2.679687261581421,
      "learning_rate": 0.00022084848484848482,
      "loss": 0.7483,
      "step": 1360
    },
    {
      "epoch": 2.74,
      "grad_norm": 3.4579062461853027,
      "learning_rate": 0.0002202424242424242,
      "loss": 0.7421,
      "step": 1370
    },
    {
      "epoch": 2.76,
      "grad_norm": 4.059321880340576,
      "learning_rate": 0.00021963636363636364,
      "loss": 0.7298,
      "step": 1380
    },
    {
      "epoch": 2.7800000000000002,
      "grad_norm": 4.328625679016113,
      "learning_rate": 0.00021903030303030302,
      "loss": 0.7259,
      "step": 1390
    },
    {
      "epoch": 2.8,
      "grad_norm": 3.6137123107910156,
      "learning_rate": 0.0002184242424242424,
      "loss": 0.7273,
      "step": 1400
    },
    {
      "epoch": 2.8,
      "eval_loss": 1.388364553451538,
      "eval_runtime": 8.4475,
      "eval_samples_per_second": 23.676,
      "eval_steps_per_second": 23.676,
      "step": 1400
    },
    {
      "epoch": 2.82,
      "grad_norm": 3.5004005432128906,
      "learning_rate": 0.00021781818181818181,
      "loss": 0.8047,
      "step": 1410
    },
    {
      "epoch": 2.84,
      "grad_norm": 2.0052716732025146,
      "learning_rate": 0.0002172121212121212,
      "loss": 0.7972,
      "step": 1420
    },
    {
      "epoch": 2.86,
      "grad_norm": 3.3754262924194336,
      "learning_rate": 0.00021660606060606058,
      "loss": 0.7397,
      "step": 1430
    },
    {
      "epoch": 2.88,
      "grad_norm": 3.3942182064056396,
      "learning_rate": 0.00021599999999999996,
      "loss": 0.6636,
      "step": 1440
    },
    {
      "epoch": 2.9,
      "grad_norm": 2.7944421768188477,
      "learning_rate": 0.00021539393939393938,
      "loss": 0.7786,
      "step": 1450
    },
    {
      "epoch": 2.92,
      "grad_norm": 2.5153634548187256,
      "learning_rate": 0.00021478787878787876,
      "loss": 0.7181,
      "step": 1460
    },
    {
      "epoch": 2.94,
      "grad_norm": 2.5370936393737793,
      "learning_rate": 0.00021418181818181817,
      "loss": 0.7698,
      "step": 1470
    },
    {
      "epoch": 2.96,
      "grad_norm": 3.2410216331481934,
      "learning_rate": 0.00021357575757575758,
      "loss": 0.7695,
      "step": 1480
    },
    {
      "epoch": 2.98,
      "grad_norm": 4.173376560211182,
      "learning_rate": 0.00021296969696969696,
      "loss": 0.8672,
      "step": 1490
    },
    {
      "epoch": 3.0,
      "grad_norm": 2.1326889991760254,
      "learning_rate": 0.00021236363636363635,
      "loss": 0.7381,
      "step": 1500
    },
    {
      "epoch": 3.0,
      "eval_loss": 1.3524489402770996,
      "eval_runtime": 8.3996,
      "eval_samples_per_second": 23.811,
      "eval_steps_per_second": 23.811,
      "step": 1500
    },
    {
      "epoch": 3.02,
      "grad_norm": 3.3256287574768066,
      "learning_rate": 0.00021175757575757573,
      "loss": 0.6173,
      "step": 1510
    },
    {
      "epoch": 3.04,
      "grad_norm": 4.4024977684021,
      "learning_rate": 0.00021115151515151514,
      "loss": 0.5758,
      "step": 1520
    },
    {
      "epoch": 3.06,
      "grad_norm": 0.7748313546180725,
      "learning_rate": 0.00021054545454545452,
      "loss": 0.4278,
      "step": 1530
    },
    {
      "epoch": 3.08,
      "grad_norm": 3.0260865688323975,
      "learning_rate": 0.0002099393939393939,
      "loss": 0.5852,
      "step": 1540
    },
    {
      "epoch": 3.1,
      "grad_norm": 3.7506461143493652,
      "learning_rate": 0.00020933333333333334,
      "loss": 0.4304,
      "step": 1550
    },
    {
      "epoch": 3.12,
      "grad_norm": 0.9196578860282898,
      "learning_rate": 0.00020872727272727273,
      "loss": 0.414,
      "step": 1560
    },
    {
      "epoch": 3.14,
      "grad_norm": 6.895211219787598,
      "learning_rate": 0.0002081212121212121,
      "loss": 0.3947,
      "step": 1570
    },
    {
      "epoch": 3.16,
      "grad_norm": 3.730776786804199,
      "learning_rate": 0.0002075151515151515,
      "loss": 0.5319,
      "step": 1580
    },
    {
      "epoch": 3.18,
      "grad_norm": 3.1734352111816406,
      "learning_rate": 0.0002069090909090909,
      "loss": 0.5488,
      "step": 1590
    },
    {
      "epoch": 3.2,
      "grad_norm": 2.480898857116699,
      "learning_rate": 0.0002063030303030303,
      "loss": 0.6504,
      "step": 1600
    },
    {
      "epoch": 3.2,
      "eval_loss": 1.528218388557434,
      "eval_runtime": 8.3573,
      "eval_samples_per_second": 23.931,
      "eval_steps_per_second": 23.931,
      "step": 1600
    },
    {
      "epoch": 3.22,
      "grad_norm": 5.095895290374756,
      "learning_rate": 0.00020569696969696967,
      "loss": 0.4225,
      "step": 1610
    },
    {
      "epoch": 3.24,
      "grad_norm": 2.807425022125244,
      "learning_rate": 0.00020509090909090905,
      "loss": 0.5406,
      "step": 1620
    },
    {
      "epoch": 3.26,
      "grad_norm": 3.944387912750244,
      "learning_rate": 0.00020448484848484846,
      "loss": 0.5043,
      "step": 1630
    },
    {
      "epoch": 3.2800000000000002,
      "grad_norm": 3.030510663986206,
      "learning_rate": 0.00020387878787878788,
      "loss": 0.588,
      "step": 1640
    },
    {
      "epoch": 3.3,
      "grad_norm": 5.094097137451172,
      "learning_rate": 0.00020327272727272726,
      "loss": 0.6708,
      "step": 1650
    },
    {
      "epoch": 3.32,
      "grad_norm": 6.799983024597168,
      "learning_rate": 0.00020266666666666664,
      "loss": 0.5678,
      "step": 1660
    },
    {
      "epoch": 3.34,
      "grad_norm": 4.100103855133057,
      "learning_rate": 0.00020206060606060605,
      "loss": 0.4905,
      "step": 1670
    },
    {
      "epoch": 3.36,
      "grad_norm": 5.611510276794434,
      "learning_rate": 0.00020145454545454544,
      "loss": 0.5429,
      "step": 1680
    },
    {
      "epoch": 3.38,
      "grad_norm": 4.842541694641113,
      "learning_rate": 0.00020084848484848482,
      "loss": 0.5549,
      "step": 1690
    },
    {
      "epoch": 3.4,
      "grad_norm": 1.845619559288025,
      "learning_rate": 0.0002002424242424242,
      "loss": 0.4838,
      "step": 1700
    },
    {
      "epoch": 3.4,
      "eval_loss": 1.5311455726623535,
      "eval_runtime": 8.4093,
      "eval_samples_per_second": 23.783,
      "eval_steps_per_second": 23.783,
      "step": 1700
    },
    {
      "epoch": 3.42,
      "grad_norm": 0.5232613682746887,
      "learning_rate": 0.0001996363636363636,
      "loss": 0.4691,
      "step": 1710
    },
    {
      "epoch": 3.44,
      "grad_norm": 4.10788631439209,
      "learning_rate": 0.00019903030303030302,
      "loss": 0.6268,
      "step": 1720
    },
    {
      "epoch": 3.46,
      "grad_norm": 1.9578052759170532,
      "learning_rate": 0.0001984242424242424,
      "loss": 0.4408,
      "step": 1730
    },
    {
      "epoch": 3.48,
      "grad_norm": 4.691435813903809,
      "learning_rate": 0.00019781818181818182,
      "loss": 0.5134,
      "step": 1740
    },
    {
      "epoch": 3.5,
      "grad_norm": 5.095338344573975,
      "learning_rate": 0.0001972121212121212,
      "loss": 0.5365,
      "step": 1750
    },
    {
      "epoch": 3.52,
      "grad_norm": 3.2053253650665283,
      "learning_rate": 0.00019660606060606058,
      "loss": 0.5925,
      "step": 1760
    },
    {
      "epoch": 3.54,
      "grad_norm": 3.5959088802337646,
      "learning_rate": 0.00019599999999999997,
      "loss": 0.4769,
      "step": 1770
    },
    {
      "epoch": 3.56,
      "grad_norm": 4.2717485427856445,
      "learning_rate": 0.00019545454545454543,
      "loss": 0.4899,
      "step": 1780
    },
    {
      "epoch": 3.58,
      "grad_norm": 5.744688987731934,
      "learning_rate": 0.0001948484848484848,
      "loss": 0.5343,
      "step": 1790
    },
    {
      "epoch": 3.6,
      "grad_norm": 4.743598937988281,
      "learning_rate": 0.00019424242424242422,
      "loss": 0.3997,
      "step": 1800
    },
    {
      "epoch": 3.6,
      "eval_loss": 1.536286473274231,
      "eval_runtime": 8.3612,
      "eval_samples_per_second": 23.92,
      "eval_steps_per_second": 23.92,
      "step": 1800
    },
    {
      "epoch": 3.62,
      "grad_norm": 5.748965740203857,
      "learning_rate": 0.00019363636363636363,
      "loss": 0.5341,
      "step": 1810
    },
    {
      "epoch": 3.64,
      "grad_norm": 5.613407135009766,
      "learning_rate": 0.000193030303030303,
      "loss": 0.4868,
      "step": 1820
    },
    {
      "epoch": 3.66,
      "grad_norm": 2.5155222415924072,
      "learning_rate": 0.00019242424242424242,
      "loss": 0.3894,
      "step": 1830
    },
    {
      "epoch": 3.68,
      "grad_norm": 0.7147247791290283,
      "learning_rate": 0.0001918181818181818,
      "loss": 0.5245,
      "step": 1840
    },
    {
      "epoch": 3.7,
      "grad_norm": 2.678208351135254,
      "learning_rate": 0.0001912121212121212,
      "loss": 0.4919,
      "step": 1850
    },
    {
      "epoch": 3.7199999999999998,
      "grad_norm": 4.321725845336914,
      "learning_rate": 0.00019060606060606057,
      "loss": 0.6569,
      "step": 1860
    },
    {
      "epoch": 3.74,
      "grad_norm": 4.7923264503479,
      "learning_rate": 0.00018999999999999998,
      "loss": 0.6529,
      "step": 1870
    },
    {
      "epoch": 3.76,
      "grad_norm": 4.538217067718506,
      "learning_rate": 0.00018939393939393937,
      "loss": 0.4946,
      "step": 1880
    },
    {
      "epoch": 3.7800000000000002,
      "grad_norm": 2.380460023880005,
      "learning_rate": 0.00018878787878787878,
      "loss": 0.633,
      "step": 1890
    },
    {
      "epoch": 3.8,
      "grad_norm": 4.832754135131836,
      "learning_rate": 0.0001881818181818182,
      "loss": 0.5508,
      "step": 1900
    },
    {
      "epoch": 3.8,
      "eval_loss": 1.474726915359497,
      "eval_runtime": 8.429,
      "eval_samples_per_second": 23.728,
      "eval_steps_per_second": 23.728,
      "step": 1900
    },
    {
      "epoch": 3.82,
      "grad_norm": 3.0722529888153076,
      "learning_rate": 0.00018757575757575757,
      "loss": 0.3807,
      "step": 1910
    },
    {
      "epoch": 3.84,
      "grad_norm": 4.6024699211120605,
      "learning_rate": 0.00018696969696969695,
      "loss": 0.5498,
      "step": 1920
    },
    {
      "epoch": 3.86,
      "grad_norm": 4.427898406982422,
      "learning_rate": 0.00018636363636363634,
      "loss": 0.5613,
      "step": 1930
    },
    {
      "epoch": 3.88,
      "grad_norm": 4.234375,
      "learning_rate": 0.00018575757575757575,
      "loss": 0.4677,
      "step": 1940
    },
    {
      "epoch": 3.9,
      "grad_norm": 3.3363728523254395,
      "learning_rate": 0.00018515151515151513,
      "loss": 0.6605,
      "step": 1950
    },
    {
      "epoch": 3.92,
      "grad_norm": 5.152710437774658,
      "learning_rate": 0.00018454545454545451,
      "loss": 0.606,
      "step": 1960
    },
    {
      "epoch": 3.94,
      "grad_norm": 3.799739122390747,
      "learning_rate": 0.0001839393939393939,
      "loss": 0.5029,
      "step": 1970
    },
    {
      "epoch": 3.96,
      "grad_norm": 4.040075778961182,
      "learning_rate": 0.00018333333333333334,
      "loss": 0.6761,
      "step": 1980
    },
    {
      "epoch": 3.98,
      "grad_norm": 3.6610758304595947,
      "learning_rate": 0.00018272727272727272,
      "loss": 0.4174,
      "step": 1990
    },
    {
      "epoch": 4.0,
      "grad_norm": 3.621148109436035,
      "learning_rate": 0.0001821212121212121,
      "loss": 0.5084,
      "step": 2000
    },
    {
      "epoch": 4.0,
      "eval_loss": 1.5548052787780762,
      "eval_runtime": 8.3945,
      "eval_samples_per_second": 23.825,
      "eval_steps_per_second": 23.825,
      "step": 2000
    },
    {
      "epoch": 4.02,
      "grad_norm": 4.417520999908447,
      "learning_rate": 0.0001815151515151515,
      "loss": 0.3894,
      "step": 2010
    },
    {
      "epoch": 4.04,
      "grad_norm": 3.980726480484009,
      "learning_rate": 0.0001809090909090909,
      "loss": 0.2936,
      "step": 2020
    },
    {
      "epoch": 4.06,
      "grad_norm": 3.6982192993164062,
      "learning_rate": 0.00018030303030303028,
      "loss": 0.3375,
      "step": 2030
    },
    {
      "epoch": 4.08,
      "grad_norm": 4.709786891937256,
      "learning_rate": 0.00017969696969696966,
      "loss": 0.4196,
      "step": 2040
    },
    {
      "epoch": 4.1,
      "grad_norm": 4.230037212371826,
      "learning_rate": 0.00017909090909090907,
      "loss": 0.2817,
      "step": 2050
    },
    {
      "epoch": 4.12,
      "grad_norm": 1.652517557144165,
      "learning_rate": 0.00017848484848484846,
      "loss": 0.2868,
      "step": 2060
    },
    {
      "epoch": 4.14,
      "grad_norm": 4.328096389770508,
      "learning_rate": 0.00017787878787878787,
      "loss": 0.2376,
      "step": 2070
    },
    {
      "epoch": 4.16,
      "grad_norm": 4.009884834289551,
      "learning_rate": 0.00017727272727272728,
      "loss": 0.2415,
      "step": 2080
    },
    {
      "epoch": 4.18,
      "grad_norm": 10.300779342651367,
      "learning_rate": 0.00017666666666666666,
      "loss": 0.3979,
      "step": 2090
    },
    {
      "epoch": 4.2,
      "grad_norm": 1.7030768394470215,
      "learning_rate": 0.00017606060606060604,
      "loss": 0.2806,
      "step": 2100
    },
    {
      "epoch": 4.2,
      "eval_loss": 1.645825982093811,
      "eval_runtime": 8.3911,
      "eval_samples_per_second": 23.835,
      "eval_steps_per_second": 23.835,
      "step": 2100
    },
    {
      "epoch": 4.22,
      "grad_norm": 8.307416915893555,
      "learning_rate": 0.00017545454545454543,
      "loss": 0.2515,
      "step": 2110
    },
    {
      "epoch": 4.24,
      "grad_norm": 1.7903196811676025,
      "learning_rate": 0.00017484848484848484,
      "loss": 0.2541,
      "step": 2120
    },
    {
      "epoch": 4.26,
      "grad_norm": 5.522449970245361,
      "learning_rate": 0.00017424242424242422,
      "loss": 0.2468,
      "step": 2130
    },
    {
      "epoch": 4.28,
      "grad_norm": 4.366516590118408,
      "learning_rate": 0.0001736363636363636,
      "loss": 0.3989,
      "step": 2140
    },
    {
      "epoch": 4.3,
      "grad_norm": 4.989831924438477,
      "learning_rate": 0.00017303030303030304,
      "loss": 0.39,
      "step": 2150
    },
    {
      "epoch": 4.32,
      "grad_norm": 1.0321954488754272,
      "learning_rate": 0.00017242424242424242,
      "loss": 0.4411,
      "step": 2160
    },
    {
      "epoch": 4.34,
      "grad_norm": 4.574234485626221,
      "learning_rate": 0.0001718181818181818,
      "loss": 0.3044,
      "step": 2170
    },
    {
      "epoch": 4.36,
      "grad_norm": 1.6043474674224854,
      "learning_rate": 0.0001712121212121212,
      "loss": 0.3933,
      "step": 2180
    },
    {
      "epoch": 4.38,
      "grad_norm": 1.7562596797943115,
      "learning_rate": 0.0001706060606060606,
      "loss": 0.3135,
      "step": 2190
    },
    {
      "epoch": 4.4,
      "grad_norm": 2.869459390640259,
      "learning_rate": 0.00016999999999999999,
      "loss": 0.3395,
      "step": 2200
    },
    {
      "epoch": 4.4,
      "eval_loss": 1.7374001741409302,
      "eval_runtime": 8.3775,
      "eval_samples_per_second": 23.874,
      "eval_steps_per_second": 23.874,
      "step": 2200
    },
    {
      "epoch": 4.42,
      "grad_norm": 2.5751736164093018,
      "learning_rate": 0.00016939393939393937,
      "loss": 0.3872,
      "step": 2210
    },
    {
      "epoch": 4.44,
      "grad_norm": 4.29768180847168,
      "learning_rate": 0.00016878787878787875,
      "loss": 0.4268,
      "step": 2220
    },
    {
      "epoch": 4.46,
      "grad_norm": 6.611233711242676,
      "learning_rate": 0.00016818181818181816,
      "loss": 0.2735,
      "step": 2230
    },
    {
      "epoch": 4.48,
      "grad_norm": 3.3042407035827637,
      "learning_rate": 0.00016757575757575757,
      "loss": 0.367,
      "step": 2240
    },
    {
      "epoch": 4.5,
      "grad_norm": 8.007160186767578,
      "learning_rate": 0.00016696969696969696,
      "loss": 0.3566,
      "step": 2250
    },
    {
      "epoch": 4.52,
      "grad_norm": 4.689454555511475,
      "learning_rate": 0.00016636363636363637,
      "loss": 0.2925,
      "step": 2260
    },
    {
      "epoch": 4.54,
      "grad_norm": 2.6550471782684326,
      "learning_rate": 0.00016575757575757575,
      "loss": 0.3654,
      "step": 2270
    },
    {
      "epoch": 4.5600000000000005,
      "grad_norm": 6.152278900146484,
      "learning_rate": 0.00016515151515151513,
      "loss": 0.5983,
      "step": 2280
    },
    {
      "epoch": 4.58,
      "grad_norm": 2.605675220489502,
      "learning_rate": 0.00016454545454545452,
      "loss": 0.3951,
      "step": 2290
    },
    {
      "epoch": 4.6,
      "grad_norm": 5.491109371185303,
      "learning_rate": 0.00016393939393939393,
      "loss": 0.3336,
      "step": 2300
    },
    {
      "epoch": 4.6,
      "eval_loss": 1.6781822443008423,
      "eval_runtime": 8.3948,
      "eval_samples_per_second": 23.824,
      "eval_steps_per_second": 23.824,
      "step": 2300
    },
    {
      "epoch": 4.62,
      "grad_norm": 6.1975812911987305,
      "learning_rate": 0.0001633333333333333,
      "loss": 0.2984,
      "step": 2310
    },
    {
      "epoch": 4.64,
      "grad_norm": 3.3720922470092773,
      "learning_rate": 0.00016272727272727272,
      "loss": 0.5194,
      "step": 2320
    },
    {
      "epoch": 4.66,
      "grad_norm": 1.3036510944366455,
      "learning_rate": 0.00016212121212121213,
      "loss": 0.3676,
      "step": 2330
    },
    {
      "epoch": 4.68,
      "grad_norm": 4.759589195251465,
      "learning_rate": 0.00016151515151515151,
      "loss": 0.3189,
      "step": 2340
    },
    {
      "epoch": 4.7,
      "grad_norm": 3.570564031600952,
      "learning_rate": 0.0001609090909090909,
      "loss": 0.414,
      "step": 2350
    },
    {
      "epoch": 4.72,
      "grad_norm": 3.9903922080993652,
      "learning_rate": 0.00016030303030303028,
      "loss": 0.3658,
      "step": 2360
    },
    {
      "epoch": 4.74,
      "grad_norm": 2.959141254425049,
      "learning_rate": 0.0001596969696969697,
      "loss": 0.5785,
      "step": 2370
    },
    {
      "epoch": 4.76,
      "grad_norm": 2.394806146621704,
      "learning_rate": 0.00015909090909090907,
      "loss": 0.3725,
      "step": 2380
    },
    {
      "epoch": 4.78,
      "grad_norm": 3.9375112056732178,
      "learning_rate": 0.00015848484848484846,
      "loss": 0.3543,
      "step": 2390
    },
    {
      "epoch": 4.8,
      "grad_norm": 4.756628513336182,
      "learning_rate": 0.00015787878787878784,
      "loss": 0.4654,
      "step": 2400
    },
    {
      "epoch": 4.8,
      "eval_loss": 1.663790225982666,
      "eval_runtime": 8.4645,
      "eval_samples_per_second": 23.628,
      "eval_steps_per_second": 23.628,
      "step": 2400
    },
    {
      "epoch": 4.82,
      "grad_norm": 3.731551170349121,
      "learning_rate": 0.00015727272727272728,
      "loss": 0.3713,
      "step": 2410
    },
    {
      "epoch": 4.84,
      "grad_norm": 4.754940986633301,
      "learning_rate": 0.00015666666666666666,
      "loss": 0.4477,
      "step": 2420
    },
    {
      "epoch": 4.86,
      "grad_norm": 5.044239044189453,
      "learning_rate": 0.00015606060606060605,
      "loss": 0.4075,
      "step": 2430
    },
    {
      "epoch": 4.88,
      "grad_norm": 6.078528881072998,
      "learning_rate": 0.00015545454545454546,
      "loss": 0.3514,
      "step": 2440
    },
    {
      "epoch": 4.9,
      "grad_norm": 5.349736213684082,
      "learning_rate": 0.00015484848484848484,
      "loss": 0.3091,
      "step": 2450
    },
    {
      "epoch": 4.92,
      "grad_norm": 4.2755327224731445,
      "learning_rate": 0.00015424242424242422,
      "loss": 0.4,
      "step": 2460
    },
    {
      "epoch": 4.9399999999999995,
      "grad_norm": 2.165381908416748,
      "learning_rate": 0.0001536363636363636,
      "loss": 0.3766,
      "step": 2470
    },
    {
      "epoch": 4.96,
      "grad_norm": 2.2234139442443848,
      "learning_rate": 0.00015303030303030302,
      "loss": 0.3622,
      "step": 2480
    },
    {
      "epoch": 4.98,
      "grad_norm": 2.6140387058258057,
      "learning_rate": 0.00015242424242424243,
      "loss": 0.3345,
      "step": 2490
    },
    {
      "epoch": 5.0,
      "grad_norm": 5.603015899658203,
      "learning_rate": 0.0001518181818181818,
      "loss": 0.3502,
      "step": 2500
    },
    {
      "epoch": 5.0,
      "eval_loss": 1.6835763454437256,
      "eval_runtime": 8.5399,
      "eval_samples_per_second": 23.419,
      "eval_steps_per_second": 23.419,
      "step": 2500
    },
    {
      "epoch": 5.02,
      "grad_norm": 4.597621917724609,
      "learning_rate": 0.00015121212121212122,
      "loss": 0.2722,
      "step": 2510
    },
    {
      "epoch": 5.04,
      "grad_norm": 1.907793641090393,
      "learning_rate": 0.0001506060606060606,
      "loss": 0.1933,
      "step": 2520
    },
    {
      "epoch": 5.06,
      "grad_norm": 1.3942646980285645,
      "learning_rate": 0.00015,
      "loss": 0.2316,
      "step": 2530
    },
    {
      "epoch": 5.08,
      "grad_norm": 1.3928101062774658,
      "learning_rate": 0.00014939393939393937,
      "loss": 0.2262,
      "step": 2540
    },
    {
      "epoch": 5.1,
      "grad_norm": 7.329982280731201,
      "learning_rate": 0.00014878787878787875,
      "loss": 0.2795,
      "step": 2550
    },
    {
      "epoch": 5.12,
      "grad_norm": 0.963598906993866,
      "learning_rate": 0.00014818181818181816,
      "loss": 0.2494,
      "step": 2560
    },
    {
      "epoch": 5.14,
      "grad_norm": 1.3055821657180786,
      "learning_rate": 0.00014757575757575757,
      "loss": 0.2562,
      "step": 2570
    },
    {
      "epoch": 5.16,
      "grad_norm": 13.356985092163086,
      "learning_rate": 0.00014696969696969696,
      "loss": 0.3592,
      "step": 2580
    },
    {
      "epoch": 5.18,
      "grad_norm": 2.595771551132202,
      "learning_rate": 0.00014636363636363634,
      "loss": 0.3392,
      "step": 2590
    },
    {
      "epoch": 5.2,
      "grad_norm": 3.1290745735168457,
      "learning_rate": 0.00014575757575757575,
      "loss": 0.2214,
      "step": 2600
    },
    {
      "epoch": 5.2,
      "eval_loss": 1.8362817764282227,
      "eval_runtime": 8.5007,
      "eval_samples_per_second": 23.527,
      "eval_steps_per_second": 23.527,
      "step": 2600
    },
    {
      "epoch": 5.22,
      "grad_norm": 4.17289400100708,
      "learning_rate": 0.00014515151515151513,
      "loss": 0.2205,
      "step": 2610
    },
    {
      "epoch": 5.24,
      "grad_norm": 0.6712756752967834,
      "learning_rate": 0.00014454545454545452,
      "loss": 0.2287,
      "step": 2620
    },
    {
      "epoch": 5.26,
      "grad_norm": 2.303347110748291,
      "learning_rate": 0.00014393939393939393,
      "loss": 0.2636,
      "step": 2630
    },
    {
      "epoch": 5.28,
      "grad_norm": 2.2398581504821777,
      "learning_rate": 0.00014333333333333334,
      "loss": 0.1918,
      "step": 2640
    },
    {
      "epoch": 5.3,
      "grad_norm": 2.522350549697876,
      "learning_rate": 0.00014272727272727272,
      "loss": 0.261,
      "step": 2650
    },
    {
      "epoch": 5.32,
      "grad_norm": 3.2845451831817627,
      "learning_rate": 0.0001421212121212121,
      "loss": 0.2272,
      "step": 2660
    },
    {
      "epoch": 5.34,
      "grad_norm": 2.94088077545166,
      "learning_rate": 0.0001415151515151515,
      "loss": 0.2599,
      "step": 2670
    },
    {
      "epoch": 5.36,
      "grad_norm": 7.271677017211914,
      "learning_rate": 0.0001409090909090909,
      "loss": 0.244,
      "step": 2680
    },
    {
      "epoch": 5.38,
      "grad_norm": 3.047004222869873,
      "learning_rate": 0.00014030303030303028,
      "loss": 0.2756,
      "step": 2690
    },
    {
      "epoch": 5.4,
      "grad_norm": 2.022937536239624,
      "learning_rate": 0.0001396969696969697,
      "loss": 0.1761,
      "step": 2700
    },
    {
      "epoch": 5.4,
      "eval_loss": 1.8199938535690308,
      "eval_runtime": 8.4024,
      "eval_samples_per_second": 23.803,
      "eval_steps_per_second": 23.803,
      "step": 2700
    },
    {
      "epoch": 5.42,
      "grad_norm": 2.248382568359375,
      "learning_rate": 0.00013909090909090908,
      "loss": 0.2215,
      "step": 2710
    },
    {
      "epoch": 5.44,
      "grad_norm": 4.171881198883057,
      "learning_rate": 0.00013848484848484846,
      "loss": 0.2262,
      "step": 2720
    },
    {
      "epoch": 5.46,
      "grad_norm": 1.7769140005111694,
      "learning_rate": 0.00013787878787878787,
      "loss": 0.2769,
      "step": 2730
    },
    {
      "epoch": 5.48,
      "grad_norm": 3.5807430744171143,
      "learning_rate": 0.00013727272727272725,
      "loss": 0.2156,
      "step": 2740
    },
    {
      "epoch": 5.5,
      "grad_norm": 3.622218370437622,
      "learning_rate": 0.00013666666666666666,
      "loss": 0.2602,
      "step": 2750
    },
    {
      "epoch": 5.52,
      "grad_norm": 6.061017036437988,
      "learning_rate": 0.00013606060606060605,
      "loss": 0.2327,
      "step": 2760
    },
    {
      "epoch": 5.54,
      "grad_norm": 4.845405101776123,
      "learning_rate": 0.00013545454545454546,
      "loss": 0.2328,
      "step": 2770
    },
    {
      "epoch": 5.5600000000000005,
      "grad_norm": 3.7230947017669678,
      "learning_rate": 0.00013484848484848484,
      "loss": 0.2148,
      "step": 2780
    },
    {
      "epoch": 5.58,
      "grad_norm": 3.150223731994629,
      "learning_rate": 0.00013424242424242422,
      "loss": 0.2565,
      "step": 2790
    },
    {
      "epoch": 5.6,
      "grad_norm": 6.300233840942383,
      "learning_rate": 0.0001336363636363636,
      "loss": 0.3743,
      "step": 2800
    },
    {
      "epoch": 5.6,
      "eval_loss": 1.8015038967132568,
      "eval_runtime": 8.3859,
      "eval_samples_per_second": 23.85,
      "eval_steps_per_second": 23.85,
      "step": 2800
    },
    {
      "epoch": 5.62,
      "grad_norm": 2.5285820960998535,
      "learning_rate": 0.00013303030303030302,
      "loss": 0.2423,
      "step": 2810
    },
    {
      "epoch": 5.64,
      "grad_norm": 5.046591758728027,
      "learning_rate": 0.00013242424242424243,
      "loss": 0.2432,
      "step": 2820
    },
    {
      "epoch": 5.66,
      "grad_norm": 4.959532260894775,
      "learning_rate": 0.0001318181818181818,
      "loss": 0.2867,
      "step": 2830
    },
    {
      "epoch": 5.68,
      "grad_norm": 7.614986896514893,
      "learning_rate": 0.0001312121212121212,
      "loss": 0.2286,
      "step": 2840
    },
    {
      "epoch": 5.7,
      "grad_norm": 2.757978677749634,
      "learning_rate": 0.00013060606060606058,
      "loss": 0.2872,
      "step": 2850
    },
    {
      "epoch": 5.72,
      "grad_norm": 2.56771183013916,
      "learning_rate": 0.00013,
      "loss": 0.2377,
      "step": 2860
    },
    {
      "epoch": 5.74,
      "grad_norm": 4.4333109855651855,
      "learning_rate": 0.00012939393939393937,
      "loss": 0.2094,
      "step": 2870
    },
    {
      "epoch": 5.76,
      "grad_norm": 2.010286569595337,
      "learning_rate": 0.00012878787878787878,
      "loss": 0.278,
      "step": 2880
    },
    {
      "epoch": 5.78,
      "grad_norm": 3.697336196899414,
      "learning_rate": 0.00012818181818181817,
      "loss": 0.194,
      "step": 2890
    },
    {
      "epoch": 5.8,
      "grad_norm": 0.8093091249465942,
      "learning_rate": 0.00012757575757575758,
      "loss": 0.191,
      "step": 2900
    },
    {
      "epoch": 5.8,
      "eval_loss": 1.831576943397522,
      "eval_runtime": 8.4088,
      "eval_samples_per_second": 23.785,
      "eval_steps_per_second": 23.785,
      "step": 2900
    },
    {
      "epoch": 5.82,
      "grad_norm": 4.4792914390563965,
      "learning_rate": 0.00012696969696969696,
      "loss": 0.2595,
      "step": 2910
    },
    {
      "epoch": 5.84,
      "grad_norm": 1.4140303134918213,
      "learning_rate": 0.00012636363636363634,
      "loss": 0.2928,
      "step": 2920
    },
    {
      "epoch": 5.86,
      "grad_norm": 2.283290386199951,
      "learning_rate": 0.00012575757575757575,
      "loss": 0.279,
      "step": 2930
    },
    {
      "epoch": 5.88,
      "grad_norm": 6.381338119506836,
      "learning_rate": 0.00012515151515151514,
      "loss": 0.2041,
      "step": 2940
    },
    {
      "epoch": 5.9,
      "grad_norm": 3.7459027767181396,
      "learning_rate": 0.00012454545454545455,
      "loss": 0.2888,
      "step": 2950
    },
    {
      "epoch": 5.92,
      "grad_norm": 5.154891490936279,
      "learning_rate": 0.00012393939393939393,
      "loss": 0.4293,
      "step": 2960
    },
    {
      "epoch": 5.9399999999999995,
      "grad_norm": 1.7921620607376099,
      "learning_rate": 0.0001233333333333333,
      "loss": 0.2411,
      "step": 2970
    },
    {
      "epoch": 5.96,
      "grad_norm": 3.681396722793579,
      "learning_rate": 0.00012272727272727272,
      "loss": 0.257,
      "step": 2980
    },
    {
      "epoch": 5.98,
      "grad_norm": 5.866201877593994,
      "learning_rate": 0.0001221212121212121,
      "loss": 0.3162,
      "step": 2990
    },
    {
      "epoch": 6.0,
      "grad_norm": 4.652614116668701,
      "learning_rate": 0.0001215151515151515,
      "loss": 0.2534,
      "step": 3000
    },
    {
      "epoch": 6.0,
      "eval_loss": 1.8159443140029907,
      "eval_runtime": 8.4418,
      "eval_samples_per_second": 23.692,
      "eval_steps_per_second": 23.692,
      "step": 3000
    },
    {
      "epoch": 6.02,
      "grad_norm": 0.7343081831932068,
      "learning_rate": 0.0001209090909090909,
      "loss": 0.1545,
      "step": 3010
    },
    {
      "epoch": 6.04,
      "grad_norm": 3.451598644256592,
      "learning_rate": 0.00012030303030303028,
      "loss": 0.1604,
      "step": 3020
    },
    {
      "epoch": 6.06,
      "grad_norm": 2.900007486343384,
      "learning_rate": 0.0001196969696969697,
      "loss": 0.1869,
      "step": 3030
    },
    {
      "epoch": 6.08,
      "grad_norm": 6.919779300689697,
      "learning_rate": 0.00011909090909090908,
      "loss": 0.2094,
      "step": 3040
    },
    {
      "epoch": 6.1,
      "grad_norm": 4.272679805755615,
      "learning_rate": 0.00011848484848484847,
      "loss": 0.1584,
      "step": 3050
    },
    {
      "epoch": 6.12,
      "grad_norm": 5.039063930511475,
      "learning_rate": 0.00011787878787878786,
      "loss": 0.1826,
      "step": 3060
    },
    {
      "epoch": 6.14,
      "grad_norm": 2.2787137031555176,
      "learning_rate": 0.00011727272727272727,
      "loss": 0.2024,
      "step": 3070
    },
    {
      "epoch": 6.16,
      "grad_norm": 2.3873517513275146,
      "learning_rate": 0.00011666666666666665,
      "loss": 0.2025,
      "step": 3080
    },
    {
      "epoch": 6.18,
      "grad_norm": 4.652674198150635,
      "learning_rate": 0.00011606060606060605,
      "loss": 0.1907,
      "step": 3090
    },
    {
      "epoch": 6.2,
      "grad_norm": 1.434949517250061,
      "learning_rate": 0.00011545454545454543,
      "loss": 0.169,
      "step": 3100
    },
    {
      "epoch": 6.2,
      "eval_loss": 1.9925085306167603,
      "eval_runtime": 8.5028,
      "eval_samples_per_second": 23.522,
      "eval_steps_per_second": 23.522,
      "step": 3100
    },
    {
      "epoch": 6.22,
      "grad_norm": 2.914409637451172,
      "learning_rate": 0.00011484848484848484,
      "loss": 0.1719,
      "step": 3110
    },
    {
      "epoch": 6.24,
      "grad_norm": 1.7230920791625977,
      "learning_rate": 0.00011424242424242424,
      "loss": 0.1944,
      "step": 3120
    },
    {
      "epoch": 6.26,
      "grad_norm": 1.8485569953918457,
      "learning_rate": 0.00011363636363636362,
      "loss": 0.193,
      "step": 3130
    },
    {
      "epoch": 6.28,
      "grad_norm": 2.2687840461730957,
      "learning_rate": 0.00011303030303030302,
      "loss": 0.1751,
      "step": 3140
    },
    {
      "epoch": 6.3,
      "grad_norm": 2.7156174182891846,
      "learning_rate": 0.00011242424242424242,
      "loss": 0.159,
      "step": 3150
    },
    {
      "epoch": 6.32,
      "grad_norm": 1.2257026433944702,
      "learning_rate": 0.00011181818181818181,
      "loss": 0.2526,
      "step": 3160
    },
    {
      "epoch": 6.34,
      "grad_norm": 2.204145669937134,
      "learning_rate": 0.0001112121212121212,
      "loss": 0.2186,
      "step": 3170
    },
    {
      "epoch": 6.36,
      "grad_norm": 5.84227180480957,
      "learning_rate": 0.0001106060606060606,
      "loss": 0.1922,
      "step": 3180
    },
    {
      "epoch": 6.38,
      "grad_norm": 1.0778437852859497,
      "learning_rate": 0.00010999999999999998,
      "loss": 0.1794,
      "step": 3190
    },
    {
      "epoch": 6.4,
      "grad_norm": 0.922448992729187,
      "learning_rate": 0.00010939393939393939,
      "loss": 0.1842,
      "step": 3200
    },
    {
      "epoch": 6.4,
      "eval_loss": 2.0106770992279053,
      "eval_runtime": 8.5183,
      "eval_samples_per_second": 23.479,
      "eval_steps_per_second": 23.479,
      "step": 3200
    },
    {
      "epoch": 6.42,
      "grad_norm": 2.685436487197876,
      "learning_rate": 0.00010878787878787878,
      "loss": 0.1528,
      "step": 3210
    },
    {
      "epoch": 6.44,
      "grad_norm": 3.92879056930542,
      "learning_rate": 0.00010818181818181817,
      "loss": 0.2376,
      "step": 3220
    },
    {
      "epoch": 6.46,
      "grad_norm": 6.347426891326904,
      "learning_rate": 0.00010757575757575756,
      "loss": 0.2035,
      "step": 3230
    },
    {
      "epoch": 6.48,
      "grad_norm": 1.7179937362670898,
      "learning_rate": 0.00010696969696969696,
      "loss": 0.1742,
      "step": 3240
    },
    {
      "epoch": 6.5,
      "grad_norm": 2.042635917663574,
      "learning_rate": 0.00010636363636363636,
      "loss": 0.2118,
      "step": 3250
    },
    {
      "epoch": 6.52,
      "grad_norm": 3.003598213195801,
      "learning_rate": 0.00010575757575757574,
      "loss": 0.1978,
      "step": 3260
    },
    {
      "epoch": 6.54,
      "grad_norm": 3.716623544692993,
      "learning_rate": 0.00010515151515151514,
      "loss": 0.164,
      "step": 3270
    },
    {
      "epoch": 6.5600000000000005,
      "grad_norm": 2.2349839210510254,
      "learning_rate": 0.00010454545454545455,
      "loss": 0.1571,
      "step": 3280
    },
    {
      "epoch": 6.58,
      "grad_norm": 1.4195232391357422,
      "learning_rate": 0.00010393939393939393,
      "loss": 0.2373,
      "step": 3290
    },
    {
      "epoch": 6.6,
      "grad_norm": 3.4256632328033447,
      "learning_rate": 0.00010333333333333333,
      "loss": 0.1485,
      "step": 3300
    },
    {
      "epoch": 6.6,
      "eval_loss": 2.015472650527954,
      "eval_runtime": 8.3849,
      "eval_samples_per_second": 23.853,
      "eval_steps_per_second": 23.853,
      "step": 3300
    },
    {
      "epoch": 6.62,
      "grad_norm": 8.69211196899414,
      "learning_rate": 0.00010272727272727271,
      "loss": 0.2602,
      "step": 3310
    },
    {
      "epoch": 6.64,
      "grad_norm": 2.5927252769470215,
      "learning_rate": 0.00010212121212121212,
      "loss": 0.1357,
      "step": 3320
    },
    {
      "epoch": 6.66,
      "grad_norm": 3.3947436809539795,
      "learning_rate": 0.0001015151515151515,
      "loss": 0.171,
      "step": 3330
    },
    {
      "epoch": 6.68,
      "grad_norm": 2.223693609237671,
      "learning_rate": 0.0001009090909090909,
      "loss": 0.2087,
      "step": 3340
    },
    {
      "epoch": 6.7,
      "grad_norm": 1.4521223306655884,
      "learning_rate": 0.00010030303030303029,
      "loss": 0.1377,
      "step": 3350
    },
    {
      "epoch": 6.72,
      "grad_norm": 1.6644014120101929,
      "learning_rate": 9.969696969696968e-05,
      "loss": 0.1839,
      "step": 3360
    },
    {
      "epoch": 6.74,
      "grad_norm": 0.8893623352050781,
      "learning_rate": 9.90909090909091e-05,
      "loss": 0.2092,
      "step": 3370
    },
    {
      "epoch": 6.76,
      "grad_norm": 3.8338470458984375,
      "learning_rate": 9.848484848484848e-05,
      "loss": 0.2037,
      "step": 3380
    },
    {
      "epoch": 6.78,
      "grad_norm": 0.942733108997345,
      "learning_rate": 9.787878787878787e-05,
      "loss": 0.1855,
      "step": 3390
    },
    {
      "epoch": 6.8,
      "grad_norm": 1.188066005706787,
      "learning_rate": 9.727272727272726e-05,
      "loss": 0.1759,
      "step": 3400
    },
    {
      "epoch": 6.8,
      "eval_loss": 1.9841748476028442,
      "eval_runtime": 8.4125,
      "eval_samples_per_second": 23.774,
      "eval_steps_per_second": 23.774,
      "step": 3400
    },
    {
      "epoch": 6.82,
      "grad_norm": 3.9348843097686768,
      "learning_rate": 9.666666666666667e-05,
      "loss": 0.3478,
      "step": 3410
    },
    {
      "epoch": 6.84,
      "grad_norm": 4.592368125915527,
      "learning_rate": 9.606060606060605e-05,
      "loss": 0.2564,
      "step": 3420
    },
    {
      "epoch": 6.86,
      "grad_norm": 2.0102555751800537,
      "learning_rate": 9.545454545454545e-05,
      "loss": 0.1593,
      "step": 3430
    },
    {
      "epoch": 6.88,
      "grad_norm": 2.582216739654541,
      "learning_rate": 9.484848484848483e-05,
      "loss": 0.1795,
      "step": 3440
    },
    {
      "epoch": 6.9,
      "grad_norm": 2.917409896850586,
      "learning_rate": 9.424242424242424e-05,
      "loss": 0.2006,
      "step": 3450
    },
    {
      "epoch": 6.92,
      "grad_norm": 3.5045993328094482,
      "learning_rate": 9.363636363636364e-05,
      "loss": 0.1981,
      "step": 3460
    },
    {
      "epoch": 6.9399999999999995,
      "grad_norm": 1.1907132863998413,
      "learning_rate": 9.303030303030302e-05,
      "loss": 0.2178,
      "step": 3470
    },
    {
      "epoch": 6.96,
      "grad_norm": 3.43795108795166,
      "learning_rate": 9.242424242424242e-05,
      "loss": 0.2043,
      "step": 3480
    },
    {
      "epoch": 6.98,
      "grad_norm": 1.7062387466430664,
      "learning_rate": 9.18181818181818e-05,
      "loss": 0.1812,
      "step": 3490
    },
    {
      "epoch": 7.0,
      "grad_norm": 2.1834487915039062,
      "learning_rate": 9.121212121212121e-05,
      "loss": 0.1657,
      "step": 3500
    },
    {
      "epoch": 7.0,
      "eval_loss": 1.9849255084991455,
      "eval_runtime": 8.4166,
      "eval_samples_per_second": 23.763,
      "eval_steps_per_second": 23.763,
      "step": 3500
    },
    {
      "epoch": 7.02,
      "grad_norm": 1.2032026052474976,
      "learning_rate": 9.06060606060606e-05,
      "loss": 0.1515,
      "step": 3510
    },
    {
      "epoch": 7.04,
      "grad_norm": 3.036860704421997,
      "learning_rate": 8.999999999999999e-05,
      "loss": 0.1318,
      "step": 3520
    },
    {
      "epoch": 7.06,
      "grad_norm": 1.6734226942062378,
      "learning_rate": 8.939393939393938e-05,
      "loss": 0.2006,
      "step": 3530
    },
    {
      "epoch": 7.08,
      "grad_norm": 1.6023790836334229,
      "learning_rate": 8.878787878787879e-05,
      "loss": 0.1529,
      "step": 3540
    },
    {
      "epoch": 7.1,
      "grad_norm": 3.289828062057495,
      "learning_rate": 8.818181818181817e-05,
      "loss": 0.168,
      "step": 3550
    },
    {
      "epoch": 7.12,
      "grad_norm": 1.930580496788025,
      "learning_rate": 8.757575757575757e-05,
      "loss": 0.1375,
      "step": 3560
    },
    {
      "epoch": 7.14,
      "grad_norm": 1.8161451816558838,
      "learning_rate": 8.696969696969695e-05,
      "loss": 0.1369,
      "step": 3570
    },
    {
      "epoch": 7.16,
      "grad_norm": 2.272611379623413,
      "learning_rate": 8.636363636363636e-05,
      "loss": 0.1228,
      "step": 3580
    },
    {
      "epoch": 7.18,
      "grad_norm": 4.883435249328613,
      "learning_rate": 8.575757575757576e-05,
      "loss": 0.157,
      "step": 3590
    },
    {
      "epoch": 7.2,
      "grad_norm": 1.7961535453796387,
      "learning_rate": 8.515151515151514e-05,
      "loss": 0.1507,
      "step": 3600
    },
    {
      "epoch": 7.2,
      "eval_loss": 2.0906763076782227,
      "eval_runtime": 8.4367,
      "eval_samples_per_second": 23.706,
      "eval_steps_per_second": 23.706,
      "step": 3600
    },
    {
      "epoch": 7.22,
      "grad_norm": 0.7605738639831543,
      "learning_rate": 8.454545454545454e-05,
      "loss": 0.1637,
      "step": 3610
    },
    {
      "epoch": 7.24,
      "grad_norm": 1.0116724967956543,
      "learning_rate": 8.393939393939393e-05,
      "loss": 0.1633,
      "step": 3620
    },
    {
      "epoch": 7.26,
      "grad_norm": 2.411223888397217,
      "learning_rate": 8.333333333333333e-05,
      "loss": 0.1291,
      "step": 3630
    },
    {
      "epoch": 7.28,
      "grad_norm": 0.8190164566040039,
      "learning_rate": 8.272727272727271e-05,
      "loss": 0.1334,
      "step": 3640
    },
    {
      "epoch": 7.3,
      "grad_norm": 3.8376359939575195,
      "learning_rate": 8.212121212121211e-05,
      "loss": 0.1621,
      "step": 3650
    },
    {
      "epoch": 7.32,
      "grad_norm": 1.4983271360397339,
      "learning_rate": 8.15151515151515e-05,
      "loss": 0.1822,
      "step": 3660
    },
    {
      "epoch": 7.34,
      "grad_norm": 2.8816733360290527,
      "learning_rate": 8.09090909090909e-05,
      "loss": 0.1528,
      "step": 3670
    },
    {
      "epoch": 7.36,
      "grad_norm": 1.851561427116394,
      "learning_rate": 8.03030303030303e-05,
      "loss": 0.1419,
      "step": 3680
    },
    {
      "epoch": 7.38,
      "grad_norm": 3.7736752033233643,
      "learning_rate": 7.969696969696968e-05,
      "loss": 0.1543,
      "step": 3690
    },
    {
      "epoch": 7.4,
      "grad_norm": 4.541472434997559,
      "learning_rate": 7.909090909090908e-05,
      "loss": 0.1457,
      "step": 3700
    },
    {
      "epoch": 7.4,
      "eval_loss": 2.0856168270111084,
      "eval_runtime": 8.4607,
      "eval_samples_per_second": 23.639,
      "eval_steps_per_second": 23.639,
      "step": 3700
    },
    {
      "epoch": 7.42,
      "grad_norm": 0.6397626996040344,
      "learning_rate": 7.848484848484848e-05,
      "loss": 0.1787,
      "step": 3710
    },
    {
      "epoch": 7.44,
      "grad_norm": 4.616375923156738,
      "learning_rate": 7.787878787878788e-05,
      "loss": 0.1744,
      "step": 3720
    },
    {
      "epoch": 7.46,
      "grad_norm": 2.6636078357696533,
      "learning_rate": 7.727272727272726e-05,
      "loss": 0.1301,
      "step": 3730
    },
    {
      "epoch": 7.48,
      "grad_norm": 2.9502556324005127,
      "learning_rate": 7.666666666666666e-05,
      "loss": 0.1459,
      "step": 3740
    },
    {
      "epoch": 7.5,
      "grad_norm": 0.620749294757843,
      "learning_rate": 7.606060606060607e-05,
      "loss": 0.166,
      "step": 3750
    },
    {
      "epoch": 7.52,
      "grad_norm": 6.352558612823486,
      "learning_rate": 7.545454545454545e-05,
      "loss": 0.1552,
      "step": 3760
    },
    {
      "epoch": 7.54,
      "grad_norm": 3.766414165496826,
      "learning_rate": 7.484848484848485e-05,
      "loss": 0.16,
      "step": 3770
    },
    {
      "epoch": 7.5600000000000005,
      "grad_norm": 0.7104647159576416,
      "learning_rate": 7.424242424242424e-05,
      "loss": 0.1361,
      "step": 3780
    },
    {
      "epoch": 7.58,
      "grad_norm": 2.3523855209350586,
      "learning_rate": 7.363636363636363e-05,
      "loss": 0.1964,
      "step": 3790
    },
    {
      "epoch": 7.6,
      "grad_norm": 2.193485736846924,
      "learning_rate": 7.303030303030302e-05,
      "loss": 0.1398,
      "step": 3800
    },
    {
      "epoch": 7.6,
      "eval_loss": 2.0890185832977295,
      "eval_runtime": 8.3855,
      "eval_samples_per_second": 23.851,
      "eval_steps_per_second": 23.851,
      "step": 3800
    },
    {
      "epoch": 7.62,
      "grad_norm": 0.973861038684845,
      "learning_rate": 7.242424242424242e-05,
      "loss": 0.1365,
      "step": 3810
    },
    {
      "epoch": 7.64,
      "grad_norm": 1.110742449760437,
      "learning_rate": 7.18181818181818e-05,
      "loss": 0.1489,
      "step": 3820
    },
    {
      "epoch": 7.66,
      "grad_norm": 0.5645270347595215,
      "learning_rate": 7.12121212121212e-05,
      "loss": 0.1329,
      "step": 3830
    },
    {
      "epoch": 7.68,
      "grad_norm": 3.172577381134033,
      "learning_rate": 7.06060606060606e-05,
      "loss": 0.1599,
      "step": 3840
    },
    {
      "epoch": 7.7,
      "grad_norm": 2.9107472896575928,
      "learning_rate": 7e-05,
      "loss": 0.145,
      "step": 3850
    },
    {
      "epoch": 7.72,
      "grad_norm": 3.175618886947632,
      "learning_rate": 6.939393939393939e-05,
      "loss": 0.1625,
      "step": 3860
    },
    {
      "epoch": 7.74,
      "grad_norm": 1.1631107330322266,
      "learning_rate": 6.878787878787879e-05,
      "loss": 0.1428,
      "step": 3870
    },
    {
      "epoch": 7.76,
      "grad_norm": 1.189072847366333,
      "learning_rate": 6.818181818181817e-05,
      "loss": 0.1362,
      "step": 3880
    },
    {
      "epoch": 7.78,
      "grad_norm": 4.91981840133667,
      "learning_rate": 6.757575757575757e-05,
      "loss": 0.1469,
      "step": 3890
    },
    {
      "epoch": 7.8,
      "grad_norm": 1.823357105255127,
      "learning_rate": 6.696969696969696e-05,
      "loss": 0.1485,
      "step": 3900
    },
    {
      "epoch": 7.8,
      "eval_loss": 2.0603842735290527,
      "eval_runtime": 8.4569,
      "eval_samples_per_second": 23.649,
      "eval_steps_per_second": 23.649,
      "step": 3900
    },
    {
      "epoch": 7.82,
      "grad_norm": 0.8242409229278564,
      "learning_rate": 6.636363636363636e-05,
      "loss": 0.1482,
      "step": 3910
    },
    {
      "epoch": 7.84,
      "grad_norm": 1.1787264347076416,
      "learning_rate": 6.575757575757574e-05,
      "loss": 0.1877,
      "step": 3920
    },
    {
      "epoch": 7.86,
      "grad_norm": 3.147735357284546,
      "learning_rate": 6.515151515151516e-05,
      "loss": 0.1668,
      "step": 3930
    },
    {
      "epoch": 7.88,
      "grad_norm": 1.9438353776931763,
      "learning_rate": 6.454545454545454e-05,
      "loss": 0.1503,
      "step": 3940
    },
    {
      "epoch": 7.9,
      "grad_norm": 1.0258417129516602,
      "learning_rate": 6.393939393939394e-05,
      "loss": 0.1376,
      "step": 3950
    },
    {
      "epoch": 7.92,
      "grad_norm": 3.8894824981689453,
      "learning_rate": 6.333333333333333e-05,
      "loss": 0.1823,
      "step": 3960
    },
    {
      "epoch": 7.9399999999999995,
      "grad_norm": 1.5054059028625488,
      "learning_rate": 6.272727272727272e-05,
      "loss": 0.1702,
      "step": 3970
    },
    {
      "epoch": 7.96,
      "grad_norm": 1.7209314107894897,
      "learning_rate": 6.212121212121211e-05,
      "loss": 0.1372,
      "step": 3980
    },
    {
      "epoch": 7.98,
      "grad_norm": 1.4456238746643066,
      "learning_rate": 6.151515151515151e-05,
      "loss": 0.1428,
      "step": 3990
    },
    {
      "epoch": 8.0,
      "grad_norm": 9.318727493286133,
      "learning_rate": 6.0909090909090906e-05,
      "loss": 0.1793,
      "step": 4000
    },
    {
      "epoch": 8.0,
      "eval_loss": 2.0909481048583984,
      "eval_runtime": 8.5021,
      "eval_samples_per_second": 23.524,
      "eval_steps_per_second": 23.524,
      "step": 4000
    },
    {
      "epoch": 8.02,
      "grad_norm": 0.8660368919372559,
      "learning_rate": 6.0303030303030296e-05,
      "loss": 0.1287,
      "step": 4010
    },
    {
      "epoch": 8.04,
      "grad_norm": 2.169588804244995,
      "learning_rate": 5.969696969696969e-05,
      "loss": 0.1188,
      "step": 4020
    },
    {
      "epoch": 8.06,
      "grad_norm": 2.2188568115234375,
      "learning_rate": 5.909090909090908e-05,
      "loss": 0.1103,
      "step": 4030
    },
    {
      "epoch": 8.08,
      "grad_norm": 0.8762121796607971,
      "learning_rate": 5.848484848484848e-05,
      "loss": 0.1256,
      "step": 4040
    },
    {
      "epoch": 8.1,
      "grad_norm": 0.6896849274635315,
      "learning_rate": 5.787878787878787e-05,
      "loss": 0.1445,
      "step": 4050
    },
    {
      "epoch": 8.12,
      "grad_norm": 1.2406445741653442,
      "learning_rate": 5.727272727272727e-05,
      "loss": 0.1048,
      "step": 4060
    },
    {
      "epoch": 8.14,
      "grad_norm": 3.6911518573760986,
      "learning_rate": 5.666666666666666e-05,
      "loss": 0.2017,
      "step": 4070
    },
    {
      "epoch": 8.16,
      "grad_norm": 1.1818548440933228,
      "learning_rate": 5.606060606060606e-05,
      "loss": 0.1159,
      "step": 4080
    },
    {
      "epoch": 8.18,
      "grad_norm": 1.6047563552856445,
      "learning_rate": 5.545454545454545e-05,
      "loss": 0.1109,
      "step": 4090
    },
    {
      "epoch": 8.2,
      "grad_norm": 0.8403178453445435,
      "learning_rate": 5.484848484848485e-05,
      "loss": 0.1187,
      "step": 4100
    },
    {
      "epoch": 8.2,
      "eval_loss": 2.1847057342529297,
      "eval_runtime": 8.3882,
      "eval_samples_per_second": 23.843,
      "eval_steps_per_second": 23.843,
      "step": 4100
    },
    {
      "epoch": 8.22,
      "grad_norm": 1.9071213006973267,
      "learning_rate": 5.424242424242424e-05,
      "loss": 0.1247,
      "step": 4110
    },
    {
      "epoch": 8.24,
      "grad_norm": 1.6950480937957764,
      "learning_rate": 5.3636363636363635e-05,
      "loss": 0.1342,
      "step": 4120
    },
    {
      "epoch": 8.26,
      "grad_norm": 0.9684578776359558,
      "learning_rate": 5.3030303030303025e-05,
      "loss": 0.1204,
      "step": 4130
    },
    {
      "epoch": 8.28,
      "grad_norm": 3.247499942779541,
      "learning_rate": 5.2424242424242415e-05,
      "loss": 0.1292,
      "step": 4140
    },
    {
      "epoch": 8.3,
      "grad_norm": 1.0721166133880615,
      "learning_rate": 5.181818181818181e-05,
      "loss": 0.1484,
      "step": 4150
    },
    {
      "epoch": 8.32,
      "grad_norm": 0.999123215675354,
      "learning_rate": 5.12121212121212e-05,
      "loss": 0.1132,
      "step": 4160
    },
    {
      "epoch": 8.34,
      "grad_norm": 3.0196545124053955,
      "learning_rate": 5.0606060606060606e-05,
      "loss": 0.1542,
      "step": 4170
    },
    {
      "epoch": 8.36,
      "grad_norm": 0.5755018591880798,
      "learning_rate": 4.9999999999999996e-05,
      "loss": 0.1301,
      "step": 4180
    },
    {
      "epoch": 8.38,
      "grad_norm": 3.740105390548706,
      "learning_rate": 4.939393939393939e-05,
      "loss": 0.1375,
      "step": 4190
    },
    {
      "epoch": 8.4,
      "grad_norm": 1.2050858736038208,
      "learning_rate": 4.878787878787878e-05,
      "loss": 0.1288,
      "step": 4200
    },
    {
      "epoch": 8.4,
      "eval_loss": 2.2153589725494385,
      "eval_runtime": 8.3859,
      "eval_samples_per_second": 23.85,
      "eval_steps_per_second": 23.85,
      "step": 4200
    },
    {
      "epoch": 8.42,
      "grad_norm": 0.6663340330123901,
      "learning_rate": 4.818181818181818e-05,
      "loss": 0.1411,
      "step": 4210
    },
    {
      "epoch": 8.44,
      "grad_norm": 0.9369032382965088,
      "learning_rate": 4.757575757575757e-05,
      "loss": 0.1429,
      "step": 4220
    },
    {
      "epoch": 8.46,
      "grad_norm": 1.040677785873413,
      "learning_rate": 4.6969696969696966e-05,
      "loss": 0.1298,
      "step": 4230
    },
    {
      "epoch": 8.48,
      "grad_norm": 1.119921088218689,
      "learning_rate": 4.6363636363636356e-05,
      "loss": 0.1153,
      "step": 4240
    },
    {
      "epoch": 8.5,
      "grad_norm": 4.236505031585693,
      "learning_rate": 4.575757575757576e-05,
      "loss": 0.1566,
      "step": 4250
    },
    {
      "epoch": 8.52,
      "grad_norm": 0.784904420375824,
      "learning_rate": 4.515151515151515e-05,
      "loss": 0.1241,
      "step": 4260
    },
    {
      "epoch": 8.54,
      "grad_norm": 2.0232553482055664,
      "learning_rate": 4.454545454545455e-05,
      "loss": 0.1492,
      "step": 4270
    },
    {
      "epoch": 8.56,
      "grad_norm": 1.4348808526992798,
      "learning_rate": 4.393939393939394e-05,
      "loss": 0.1223,
      "step": 4280
    },
    {
      "epoch": 8.58,
      "grad_norm": 0.7826250791549683,
      "learning_rate": 4.333333333333333e-05,
      "loss": 0.122,
      "step": 4290
    },
    {
      "epoch": 8.6,
      "grad_norm": 0.6884377598762512,
      "learning_rate": 4.2727272727272724e-05,
      "loss": 0.1164,
      "step": 4300
    },
    {
      "epoch": 8.6,
      "eval_loss": 2.1791305541992188,
      "eval_runtime": 8.3601,
      "eval_samples_per_second": 23.923,
      "eval_steps_per_second": 23.923,
      "step": 4300
    },
    {
      "epoch": 8.62,
      "grad_norm": 1.3716461658477783,
      "learning_rate": 4.2121212121212114e-05,
      "loss": 0.1411,
      "step": 4310
    },
    {
      "epoch": 8.64,
      "grad_norm": 1.0119304656982422,
      "learning_rate": 4.151515151515151e-05,
      "loss": 0.1193,
      "step": 4320
    },
    {
      "epoch": 8.66,
      "grad_norm": 0.986996054649353,
      "learning_rate": 4.09090909090909e-05,
      "loss": 0.1226,
      "step": 4330
    },
    {
      "epoch": 8.68,
      "grad_norm": 1.3537095785140991,
      "learning_rate": 4.03030303030303e-05,
      "loss": 0.1204,
      "step": 4340
    },
    {
      "epoch": 8.7,
      "grad_norm": 1.5337998867034912,
      "learning_rate": 3.969696969696969e-05,
      "loss": 0.1364,
      "step": 4350
    },
    {
      "epoch": 8.72,
      "grad_norm": 6.457711219787598,
      "learning_rate": 3.909090909090909e-05,
      "loss": 0.1317,
      "step": 4360
    },
    {
      "epoch": 8.74,
      "grad_norm": 1.7828396558761597,
      "learning_rate": 3.848484848484848e-05,
      "loss": 0.126,
      "step": 4370
    },
    {
      "epoch": 8.76,
      "grad_norm": 1.0051409006118774,
      "learning_rate": 3.787878787878788e-05,
      "loss": 0.1171,
      "step": 4380
    },
    {
      "epoch": 8.78,
      "grad_norm": 0.7143088579177856,
      "learning_rate": 3.727272727272727e-05,
      "loss": 0.1435,
      "step": 4390
    },
    {
      "epoch": 8.8,
      "grad_norm": 1.1842228174209595,
      "learning_rate": 3.666666666666666e-05,
      "loss": 0.1184,
      "step": 4400
    },
    {
      "epoch": 8.8,
      "eval_loss": 2.2130801677703857,
      "eval_runtime": 8.3566,
      "eval_samples_per_second": 23.933,
      "eval_steps_per_second": 23.933,
      "step": 4400
    },
    {
      "epoch": 8.82,
      "grad_norm": 0.5640490055084229,
      "learning_rate": 3.6060606060606056e-05,
      "loss": 0.1306,
      "step": 4410
    },
    {
      "epoch": 8.84,
      "grad_norm": 1.6032389402389526,
      "learning_rate": 3.545454545454545e-05,
      "loss": 0.1638,
      "step": 4420
    },
    {
      "epoch": 8.86,
      "grad_norm": 4.232578277587891,
      "learning_rate": 3.484848484848484e-05,
      "loss": 0.1275,
      "step": 4430
    },
    {
      "epoch": 8.88,
      "grad_norm": 0.6435989737510681,
      "learning_rate": 3.424242424242424e-05,
      "loss": 0.122,
      "step": 4440
    },
    {
      "epoch": 8.9,
      "grad_norm": 1.3208644390106201,
      "learning_rate": 3.3636363636363636e-05,
      "loss": 0.1234,
      "step": 4450
    },
    {
      "epoch": 8.92,
      "grad_norm": 1.338857650756836,
      "learning_rate": 3.3030303030303027e-05,
      "loss": 0.126,
      "step": 4460
    },
    {
      "epoch": 8.94,
      "grad_norm": 1.6411387920379639,
      "learning_rate": 3.2424242424242423e-05,
      "loss": 0.1204,
      "step": 4470
    },
    {
      "epoch": 8.96,
      "grad_norm": 0.7634267807006836,
      "learning_rate": 3.1818181818181814e-05,
      "loss": 0.1241,
      "step": 4480
    },
    {
      "epoch": 8.98,
      "grad_norm": 3.12062406539917,
      "learning_rate": 3.121212121212121e-05,
      "loss": 0.1405,
      "step": 4490
    },
    {
      "epoch": 9.0,
      "grad_norm": 1.2577518224716187,
      "learning_rate": 3.060606060606061e-05,
      "loss": 0.1205,
      "step": 4500
    },
    {
      "epoch": 9.0,
      "eval_loss": 2.2314727306365967,
      "eval_runtime": 8.3559,
      "eval_samples_per_second": 23.935,
      "eval_steps_per_second": 23.935,
      "step": 4500
    },
    {
      "epoch": 9.02,
      "grad_norm": 0.64055997133255,
      "learning_rate": 2.9999999999999997e-05,
      "loss": 0.1183,
      "step": 4510
    },
    {
      "epoch": 9.04,
      "grad_norm": 0.9756233096122742,
      "learning_rate": 2.9393939393939394e-05,
      "loss": 0.1096,
      "step": 4520
    },
    {
      "epoch": 9.06,
      "grad_norm": 1.5994327068328857,
      "learning_rate": 2.8787878787878784e-05,
      "loss": 0.1161,
      "step": 4530
    },
    {
      "epoch": 9.08,
      "grad_norm": 0.7194117903709412,
      "learning_rate": 2.8181818181818178e-05,
      "loss": 0.1113,
      "step": 4540
    },
    {
      "epoch": 9.1,
      "grad_norm": 1.1376416683197021,
      "learning_rate": 2.757575757575757e-05,
      "loss": 0.1128,
      "step": 4550
    },
    {
      "epoch": 9.12,
      "grad_norm": 2.506934881210327,
      "learning_rate": 2.6969696969696965e-05,
      "loss": 0.1231,
      "step": 4560
    },
    {
      "epoch": 9.14,
      "grad_norm": 1.2483185529708862,
      "learning_rate": 2.636363636363636e-05,
      "loss": 0.1241,
      "step": 4570
    },
    {
      "epoch": 9.16,
      "grad_norm": 0.92396080493927,
      "learning_rate": 2.5757575757575755e-05,
      "loss": 0.1154,
      "step": 4580
    },
    {
      "epoch": 9.18,
      "grad_norm": 1.5380198955535889,
      "learning_rate": 2.515151515151515e-05,
      "loss": 0.1153,
      "step": 4590
    },
    {
      "epoch": 9.2,
      "grad_norm": 0.6279959678649902,
      "learning_rate": 2.4545454545454542e-05,
      "loss": 0.1141,
      "step": 4600
    },
    {
      "epoch": 9.2,
      "eval_loss": 2.2954599857330322,
      "eval_runtime": 8.3275,
      "eval_samples_per_second": 24.017,
      "eval_steps_per_second": 24.017,
      "step": 4600
    },
    {
      "epoch": 9.22,
      "grad_norm": 2.558497190475464,
      "learning_rate": 2.393939393939394e-05,
      "loss": 0.1162,
      "step": 4610
    },
    {
      "epoch": 9.24,
      "grad_norm": 1.2189940214157104,
      "learning_rate": 2.3333333333333332e-05,
      "loss": 0.1374,
      "step": 4620
    },
    {
      "epoch": 9.26,
      "grad_norm": 1.4204562902450562,
      "learning_rate": 2.2727272727272726e-05,
      "loss": 0.1648,
      "step": 4630
    },
    {
      "epoch": 9.28,
      "grad_norm": 1.3359180688858032,
      "learning_rate": 2.212121212121212e-05,
      "loss": 0.1117,
      "step": 4640
    },
    {
      "epoch": 9.3,
      "grad_norm": 1.005122184753418,
      "learning_rate": 2.1515151515151513e-05,
      "loss": 0.1187,
      "step": 4650
    },
    {
      "epoch": 9.32,
      "grad_norm": 1.3852779865264893,
      "learning_rate": 2.090909090909091e-05,
      "loss": 0.1082,
      "step": 4660
    },
    {
      "epoch": 9.34,
      "grad_norm": 2.823486804962158,
      "learning_rate": 2.0303030303030303e-05,
      "loss": 0.1161,
      "step": 4670
    },
    {
      "epoch": 9.36,
      "grad_norm": 0.7457917332649231,
      "learning_rate": 1.9696969696969697e-05,
      "loss": 0.1017,
      "step": 4680
    },
    {
      "epoch": 9.38,
      "grad_norm": 1.040602684020996,
      "learning_rate": 1.9090909090909087e-05,
      "loss": 0.1029,
      "step": 4690
    },
    {
      "epoch": 9.4,
      "grad_norm": 0.9867235422134399,
      "learning_rate": 1.8484848484848484e-05,
      "loss": 0.1198,
      "step": 4700
    },
    {
      "epoch": 9.4,
      "eval_loss": 2.317831516265869,
      "eval_runtime": 8.3866,
      "eval_samples_per_second": 23.848,
      "eval_steps_per_second": 23.848,
      "step": 4700
    },
    {
      "epoch": 9.42,
      "grad_norm": 1.2817401885986328,
      "learning_rate": 1.7878787878787877e-05,
      "loss": 0.1014,
      "step": 4710
    },
    {
      "epoch": 9.44,
      "grad_norm": 0.9136762619018555,
      "learning_rate": 1.727272727272727e-05,
      "loss": 0.113,
      "step": 4720
    },
    {
      "epoch": 9.46,
      "grad_norm": 1.6341896057128906,
      "learning_rate": 1.6666666666666664e-05,
      "loss": 0.1119,
      "step": 4730
    },
    {
      "epoch": 9.48,
      "grad_norm": 1.0317376852035522,
      "learning_rate": 1.6060606060606058e-05,
      "loss": 0.1065,
      "step": 4740
    },
    {
      "epoch": 9.5,
      "grad_norm": 1.0753642320632935,
      "learning_rate": 1.5454545454545454e-05,
      "loss": 0.1199,
      "step": 4750
    },
    {
      "epoch": 9.52,
      "grad_norm": 0.9733407497406006,
      "learning_rate": 1.4848484848484846e-05,
      "loss": 0.1052,
      "step": 4760
    },
    {
      "epoch": 9.54,
      "grad_norm": 0.8870410323143005,
      "learning_rate": 1.4242424242424241e-05,
      "loss": 0.1103,
      "step": 4770
    },
    {
      "epoch": 9.56,
      "grad_norm": 1.568019986152649,
      "learning_rate": 1.3636363636363635e-05,
      "loss": 0.1226,
      "step": 4780
    },
    {
      "epoch": 9.58,
      "grad_norm": 2.3412725925445557,
      "learning_rate": 1.303030303030303e-05,
      "loss": 0.1095,
      "step": 4790
    },
    {
      "epoch": 9.6,
      "grad_norm": 1.4559204578399658,
      "learning_rate": 1.2424242424242424e-05,
      "loss": 0.1122,
      "step": 4800
    },
    {
      "epoch": 9.6,
      "eval_loss": 2.3164873123168945,
      "eval_runtime": 8.4604,
      "eval_samples_per_second": 23.64,
      "eval_steps_per_second": 23.64,
      "step": 4800
    },
    {
      "epoch": 9.62,
      "grad_norm": 2.166132688522339,
      "learning_rate": 1.1818181818181817e-05,
      "loss": 0.1188,
      "step": 4810
    },
    {
      "epoch": 9.64,
      "grad_norm": 1.047545075416565,
      "learning_rate": 1.121212121212121e-05,
      "loss": 0.1082,
      "step": 4820
    },
    {
      "epoch": 9.66,
      "grad_norm": 0.7955185770988464,
      "learning_rate": 1.0606060606060604e-05,
      "loss": 0.1187,
      "step": 4830
    },
    {
      "epoch": 9.68,
      "grad_norm": 1.7626951932907104,
      "learning_rate": 9.999999999999999e-06,
      "loss": 0.1137,
      "step": 4840
    },
    {
      "epoch": 9.7,
      "grad_norm": 0.6281421184539795,
      "learning_rate": 9.393939393939393e-06,
      "loss": 0.1237,
      "step": 4850
    },
    {
      "epoch": 9.72,
      "grad_norm": 1.8935436010360718,
      "learning_rate": 8.787878787878788e-06,
      "loss": 0.1169,
      "step": 4860
    },
    {
      "epoch": 9.74,
      "grad_norm": 0.9029380679130554,
      "learning_rate": 8.181818181818181e-06,
      "loss": 0.1178,
      "step": 4870
    },
    {
      "epoch": 9.76,
      "grad_norm": 1.3793866634368896,
      "learning_rate": 7.575757575757575e-06,
      "loss": 0.1052,
      "step": 4880
    },
    {
      "epoch": 9.78,
      "grad_norm": 0.9379765391349792,
      "learning_rate": 6.969696969696969e-06,
      "loss": 0.1102,
      "step": 4890
    },
    {
      "epoch": 9.8,
      "grad_norm": 2.791062593460083,
      "learning_rate": 6.363636363636363e-06,
      "loss": 0.1142,
      "step": 4900
    },
    {
      "epoch": 9.8,
      "eval_loss": 2.298302173614502,
      "eval_runtime": 8.3938,
      "eval_samples_per_second": 23.827,
      "eval_steps_per_second": 23.827,
      "step": 4900
    },
    {
      "epoch": 9.82,
      "grad_norm": 0.9432592988014221,
      "learning_rate": 5.757575757575757e-06,
      "loss": 0.1089,
      "step": 4910
    },
    {
      "epoch": 9.84,
      "grad_norm": 0.9680823683738708,
      "learning_rate": 5.151515151515151e-06,
      "loss": 0.1067,
      "step": 4920
    },
    {
      "epoch": 9.86,
      "grad_norm": 0.40712907910346985,
      "learning_rate": 4.5454545454545455e-06,
      "loss": 0.1059,
      "step": 4930
    },
    {
      "epoch": 9.88,
      "grad_norm": 0.7771145701408386,
      "learning_rate": 3.939393939393939e-06,
      "loss": 0.1082,
      "step": 4940
    },
    {
      "epoch": 9.9,
      "grad_norm": 1.1651066541671753,
      "learning_rate": 3.3333333333333333e-06,
      "loss": 0.1148,
      "step": 4950
    },
    {
      "epoch": 9.92,
      "grad_norm": 0.6666712164878845,
      "learning_rate": 2.727272727272727e-06,
      "loss": 0.1138,
      "step": 4960
    },
    {
      "epoch": 9.94,
      "grad_norm": 1.7042471170425415,
      "learning_rate": 2.121212121212121e-06,
      "loss": 0.1103,
      "step": 4970
    },
    {
      "epoch": 9.96,
      "grad_norm": 1.1324974298477173,
      "learning_rate": 1.5151515151515152e-06,
      "loss": 0.1004,
      "step": 4980
    },
    {
      "epoch": 9.98,
      "grad_norm": 1.483344554901123,
      "learning_rate": 9.09090909090909e-07,
      "loss": 0.1078,
      "step": 4990
    },
    {
      "epoch": 10.0,
      "grad_norm": 1.2142244577407837,
      "learning_rate": 3.03030303030303e-07,
      "loss": 0.107,
      "step": 5000
    },
    {
      "epoch": 10.0,
      "eval_loss": 2.290351629257202,
      "eval_runtime": 8.5304,
      "eval_samples_per_second": 23.446,
      "eval_steps_per_second": 23.446,
      "step": 5000
    }
  ],
  "logging_steps": 10,
  "max_steps": 5000,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 10,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 1.496916688896e+16,
  "train_batch_size": 1,
  "trial_name": null,
  "trial_params": null
}
